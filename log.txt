<<<<<<< HEAD
<<<<<<< HEAD
=======
INFO: Number of parameters: 177348
INFO: QNetwork(
  (conv_feature): Sequential(
    (0): Conv2d(1, 64, kernel_size=(3, 3), stride=(1, 1))
    (1): ReLU()
    (2): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (3): Conv2d(64, 32, kernel_size=(3, 3), stride=(1, 1))
    (4): ReLU()
    (5): BatchNorm2d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
  )
  (fc_feature): Sequential(
    (0): Linear(in_features=1152, out_features=128, bias=True)
    (1): ReLU()
    (2): Linear(in_features=128, out_features=64, bias=True)
    (3): ReLU()
    (4): Linear(in_features=64, out_features=32, bias=True)
    (5): ReLU()
    (6): Linear(in_features=32, out_features=4, bias=True)
  )
)
INFO: Learning...
ERROR: can only concatenate tuple (not "float") to tuple
INFO: Number of parameters: 177348
INFO: QNetwork(
  (conv_feature): Sequential(
    (0): Conv2d(1, 64, kernel_size=(3, 3), stride=(1, 1))
    (1): ReLU()
    (2): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (3): Conv2d(64, 32, kernel_size=(3, 3), stride=(1, 1))
    (4): ReLU()
    (5): BatchNorm2d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
  )
  (fc_feature): Sequential(
    (0): Linear(in_features=1152, out_features=128, bias=True)
    (1): ReLU()
    (2): Linear(in_features=128, out_features=64, bias=True)
    (3): ReLU()
    (4): Linear(in_features=64, out_features=32, bias=True)
    (5): ReLU()
    (6): Linear(in_features=32, out_features=4, bias=True)
  )
)
INFO: Learning...
INFO: Number of parameters: 177348
INFO: QNetwork(
  (conv_feature): Sequential(
    (0): Conv2d(1, 64, kernel_size=(3, 3), stride=(1, 1))
    (1): ReLU()
    (2): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (3): Conv2d(64, 32, kernel_size=(3, 3), stride=(1, 1))
    (4): ReLU()
    (5): BatchNorm2d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
  )
  (fc_feature): Sequential(
    (0): Linear(in_features=1152, out_features=128, bias=True)
    (1): ReLU()
    (2): Linear(in_features=128, out_features=64, bias=True)
    (3): ReLU()
    (4): Linear(in_features=64, out_features=32, bias=True)
    (5): ReLU()
    (6): Linear(in_features=32, out_features=4, bias=True)
  )
)
INFO: Learning...
INFO: Number of parameters: 177348
INFO: QNetwork(
  (conv_feature): Sequential(
    (0): Conv2d(1, 64, kernel_size=(3, 3), stride=(1, 1))
    (1): ReLU()
    (2): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (3): Conv2d(64, 32, kernel_size=(3, 3), stride=(1, 1))
    (4): ReLU()
    (5): BatchNorm2d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
  )
  (fc_feature): Sequential(
    (0): Linear(in_features=1152, out_features=128, bias=True)
    (1): ReLU()
    (2): Linear(in_features=128, out_features=64, bias=True)
    (3): ReLU()
    (4): Linear(in_features=64, out_features=32, bias=True)
    (5): ReLU()
    (6): Linear(in_features=32, out_features=4, bias=True)
  )
)
INFO: Learning...
INFO: Number of parameters: 177348
INFO: QNetwork(
  (conv_feature): Sequential(
    (0): Conv2d(1, 64, kernel_size=(3, 3), stride=(1, 1))
    (1): ReLU()
    (2): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (3): Conv2d(64, 32, kernel_size=(3, 3), stride=(1, 1))
    (4): ReLU()
    (5): BatchNorm2d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
  )
  (fc_feature): Sequential(
    (0): Linear(in_features=1152, out_features=128, bias=True)
    (1): ReLU()
    (2): Linear(in_features=128, out_features=64, bias=True)
    (3): ReLU()
    (4): Linear(in_features=64, out_features=32, bias=True)
    (5): ReLU()
    (6): Linear(in_features=32, out_features=4, bias=True)
  )
)
INFO: Learning...
INFO: Number of parameters: 177348
INFO: QNetwork(
  (conv_feature): Sequential(
    (0): Conv2d(1, 64, kernel_size=(3, 3), stride=(1, 1))
    (1): ReLU()
    (2): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (3): Conv2d(64, 32, kernel_size=(3, 3), stride=(1, 1))
    (4): ReLU()
    (5): BatchNorm2d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
  )
  (fc_feature): Sequential(
    (0): Linear(in_features=1152, out_features=128, bias=True)
    (1): ReLU()
    (2): Linear(in_features=128, out_features=64, bias=True)
    (3): ReLU()
    (4): Linear(in_features=64, out_features=32, bias=True)
    (5): ReLU()
    (6): Linear(in_features=32, out_features=4, bias=True)
  )
)
INFO: Learning...
INFO: Number of parameters: 177348
INFO: QNetwork(
  (conv_feature): Sequential(
    (0): Conv2d(1, 64, kernel_size=(3, 3), stride=(1, 1))
    (1): ReLU()
    (2): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (3): Conv2d(64, 32, kernel_size=(3, 3), stride=(1, 1))
    (4): ReLU()
    (5): BatchNorm2d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
  )
  (fc_feature): Sequential(
    (0): Linear(in_features=1152, out_features=128, bias=True)
    (1): ReLU()
    (2): Linear(in_features=128, out_features=64, bias=True)
    (3): ReLU()
    (4): Linear(in_features=64, out_features=32, bias=True)
    (5): ReLU()
    (6): Linear(in_features=32, out_features=4, bias=True)
  )
)
INFO: Learning...
INFO: Number of parameters: 177348
INFO: QNetwork(
  (conv_feature): Sequential(
    (0): Conv2d(1, 64, kernel_size=(3, 3), stride=(1, 1))
    (1): ReLU()
    (2): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (3): Conv2d(64, 32, kernel_size=(3, 3), stride=(1, 1))
    (4): ReLU()
    (5): BatchNorm2d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
  )
  (fc_feature): Sequential(
    (0): Linear(in_features=1152, out_features=128, bias=True)
    (1): ReLU()
    (2): Linear(in_features=128, out_features=64, bias=True)
    (3): ReLU()
    (4): Linear(in_features=64, out_features=32, bias=True)
    (5): ReLU()
    (6): Linear(in_features=32, out_features=4, bias=True)
  )
)
INFO: Learning...
INFO: Number of parameters: 177348
INFO: QNetwork(
  (conv_feature): Sequential(
    (0): Conv2d(1, 64, kernel_size=(3, 3), stride=(1, 1))
    (1): ReLU()
    (2): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (3): Conv2d(64, 32, kernel_size=(3, 3), stride=(1, 1))
    (4): ReLU()
    (5): BatchNorm2d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
  )
  (fc_feature): Sequential(
    (0): Linear(in_features=1152, out_features=128, bias=True)
    (1): ReLU()
    (2): Linear(in_features=128, out_features=64, bias=True)
    (3): ReLU()
    (4): Linear(in_features=64, out_features=32, bias=True)
    (5): ReLU()
    (6): Linear(in_features=32, out_features=4, bias=True)
  )
)
INFO: Learning...
INFO: Number of parameters: 177348
INFO: QNetwork(
  (conv_feature): Sequential(
    (0): Conv2d(1, 64, kernel_size=(3, 3), stride=(1, 1))
    (1): ReLU()
    (2): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (3): Conv2d(64, 32, kernel_size=(3, 3), stride=(1, 1))
    (4): ReLU()
    (5): BatchNorm2d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
  )
  (fc_feature): Sequential(
    (0): Linear(in_features=1152, out_features=128, bias=True)
    (1): ReLU()
    (2): Linear(in_features=128, out_features=64, bias=True)
    (3): ReLU()
    (4): Linear(in_features=64, out_features=32, bias=True)
    (5): ReLU()
    (6): Linear(in_features=32, out_features=4, bias=True)
  )
)
INFO: Learning...
INFO: Number of parameters: 177348
INFO: QNetwork(
  (conv_feature): Sequential(
    (0): Conv2d(1, 64, kernel_size=(3, 3), stride=(1, 1))
    (1): ReLU()
    (2): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (3): Conv2d(64, 32, kernel_size=(3, 3), stride=(1, 1))
    (4): ReLU()
    (5): BatchNorm2d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
  )
  (fc_feature): Sequential(
    (0): Linear(in_features=1152, out_features=128, bias=True)
    (1): ReLU()
    (2): Linear(in_features=128, out_features=64, bias=True)
    (3): ReLU()
    (4): Linear(in_features=64, out_features=32, bias=True)
    (5): ReLU()
    (6): Linear(in_features=32, out_features=4, bias=True)
  )
)
INFO: Learning...
INFO: Number of parameters: 177348
INFO: QNetwork(
  (conv_feature): Sequential(
    (0): Conv2d(1, 64, kernel_size=(3, 3), stride=(1, 1))
    (1): ReLU()
    (2): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (3): Conv2d(64, 32, kernel_size=(3, 3), stride=(1, 1))
    (4): ReLU()
    (5): BatchNorm2d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
  )
  (fc_feature): Sequential(
    (0): Linear(in_features=1152, out_features=128, bias=True)
    (1): ReLU()
    (2): Linear(in_features=128, out_features=64, bias=True)
    (3): ReLU()
    (4): Linear(in_features=64, out_features=32, bias=True)
    (5): ReLU()
    (6): Linear(in_features=32, out_features=4, bias=True)
  )
)
INFO: Learning...
INFO: Number of parameters: 177348
INFO: QNetwork(
  (conv_feature): Sequential(
    (0): Conv2d(1, 64, kernel_size=(3, 3), stride=(1, 1))
    (1): ReLU()
    (2): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (3): Conv2d(64, 32, kernel_size=(3, 3), stride=(1, 1))
    (4): ReLU()
    (5): BatchNorm2d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
  )
  (fc_feature): Sequential(
    (0): Linear(in_features=1152, out_features=128, bias=True)
    (1): ReLU()
    (2): Linear(in_features=128, out_features=64, bias=True)
    (3): ReLU()
    (4): Linear(in_features=64, out_features=32, bias=True)
    (5): ReLU()
    (6): Linear(in_features=32, out_features=4, bias=True)
  )
)
INFO: Learning...
INFO: Number of parameters: 177348
INFO: QNetwork(
  (conv_feature): Sequential(
    (0): Conv2d(1, 64, kernel_size=(3, 3), stride=(1, 1))
    (1): ReLU()
    (2): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (3): Conv2d(64, 32, kernel_size=(3, 3), stride=(1, 1))
    (4): ReLU()
    (5): BatchNorm2d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
  )
  (fc_feature): Sequential(
    (0): Linear(in_features=1152, out_features=128, bias=True)
    (1): ReLU()
    (2): Linear(in_features=128, out_features=64, bias=True)
    (3): ReLU()
    (4): Linear(in_features=64, out_features=32, bias=True)
    (5): ReLU()
    (6): Linear(in_features=32, out_features=4, bias=True)
  )
)
INFO: Learning...
INFO: Number of parameters: 177348
INFO: QNetwork(
  (conv_feature): Sequential(
    (0): Conv2d(1, 64, kernel_size=(3, 3), stride=(1, 1))
    (1): ReLU()
    (2): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (3): Conv2d(64, 32, kernel_size=(3, 3), stride=(1, 1))
    (4): ReLU()
    (5): BatchNorm2d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
  )
  (fc_feature): Sequential(
    (0): Linear(in_features=1152, out_features=128, bias=True)
    (1): ReLU()
    (2): Linear(in_features=128, out_features=64, bias=True)
    (3): ReLU()
    (4): Linear(in_features=64, out_features=32, bias=True)
    (5): ReLU()
    (6): Linear(in_features=32, out_features=4, bias=True)
  )
)
INFO: Learning...
INFO: Number of parameters: 66756
INFO: QNetwork(
  (conv_feature): Sequential(
    (0): Conv2d(1, 64, kernel_size=(3, 3), stride=(1, 1))
    (1): ReLU()
    (2): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (3): Conv2d(64, 32, kernel_size=(3, 3), stride=(1, 1))
    (4): ReLU()
    (5): BatchNorm2d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
  )
  (fc_feature): Sequential(
    (0): Linear(in_features=288, out_features=128, bias=True)
    (1): ReLU()
    (2): Linear(in_features=128, out_features=64, bias=True)
    (3): ReLU()
    (4): Linear(in_features=64, out_features=32, bias=True)
    (5): ReLU()
    (6): Linear(in_features=32, out_features=4, bias=True)
  )
)
WARNING: GIF is enabled but the environment does not support RGB array rendering.
INFO: Learning...
INFO: BootcampName.HIDER bootcamp completed, starting BootcampName.SEEKER bootcamp
ERROR: boolean index did not match indexed array along dimension 0; dimension is 10 but corresponding boolean dimension is 7
WARNING: Error: Could not find wandb directory: ./wandb
INFO: Number of parameters: 66756
INFO: QNetwork(
  (conv_feature): Sequential(
    (0): Conv2d(1, 64, kernel_size=(3, 3), stride=(1, 1))
    (1): ReLU()
    (2): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (3): Conv2d(64, 32, kernel_size=(3, 3), stride=(1, 1))
    (4): ReLU()
    (5): BatchNorm2d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
  )
  (fc_feature): Sequential(
    (0): Linear(in_features=288, out_features=128, bias=True)
    (1): ReLU()
    (2): Linear(in_features=128, out_features=64, bias=True)
    (3): ReLU()
    (4): Linear(in_features=64, out_features=32, bias=True)
    (5): ReLU()
    (6): Linear(in_features=32, out_features=4, bias=True)
  )
)
WARNING: GIF is enabled but the environment does not support RGB array rendering.
INFO: Learning...
INFO: BootcampName.HIDER bootcamp completed, starting BootcampName.SEEKER bootcamp
ERROR: boolean index did not match indexed array along dimension 0; dimension is 10 but corresponding boolean dimension is 7
WARNING: Error: Could not find wandb directory: ./wandb
INFO: Number of parameters: 66756
INFO: QNetwork(
  (conv_feature): Sequential(
    (0): Conv2d(1, 64, kernel_size=(3, 3), stride=(1, 1))
    (1): ReLU()
    (2): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (3): Conv2d(64, 32, kernel_size=(3, 3), stride=(1, 1))
    (4): ReLU()
    (5): BatchNorm2d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
  )
  (fc_feature): Sequential(
    (0): Linear(in_features=288, out_features=128, bias=True)
    (1): ReLU()
    (2): Linear(in_features=128, out_features=64, bias=True)
    (3): ReLU()
    (4): Linear(in_features=64, out_features=32, bias=True)
    (5): ReLU()
    (6): Linear(in_features=32, out_features=4, bias=True)
  )
)
WARNING: GIF is enabled but the environment does not support RGB array rendering.
INFO: Learning...
INFO: BootcampName.HIDER bootcamp completed, starting BootcampName.SEEKER bootcamp
ERROR: boolean index did not match indexed array along dimension 0; dimension is 10 but corresponding boolean dimension is 7
ERROR: Traceback (most recent call last):
  File "/home/eirik/Projects/XAI/rl/src/dqn/wrapper/multi_agent_dqn.py", line 74, in learn
    self._collect_rollouts()
  File "/home/eirik/Projects/XAI/rl/src/dqn/wrapper/multi_agent_dqn.py", line 135, in _collect_rollouts
    ) = self.env.get_wrapper_attr("step_multiple")(actions)
        ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/eirik/Projects/XAI/environments/gymnasium/wrappers/multi_agent_env.py", line 37, in step_multiple
    self.get_wrapper_attr("concatenate_states")(full_states)
  File "/home/eirik/Projects/XAI/environments/gymnasium/envs/tag/tag.py", line 240, in concatenate_states
    self.render(self.render_mode)
  File "/home/eirik/Projects/XAI/environments/gymnasium/envs/tag/tag.py", line 218, in render
    return self.tag_renderer.render(self.state.full, render_mode)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/eirik/Projects/XAI/environments/gymnasium/envs/tag/tag_renderer.py", line 64, in render
    self.apply_color_masks(color_matrix, state)
  File "/home/eirik/Projects/XAI/environments/gymnasium/envs/tag/tag_renderer.py", line 94, in apply_color_masks
    color_matrix[full_state == TileType.OBSTACLE.value] = Color.BLACK.value
    ~~~~~~~~~~~~^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
IndexError: boolean index did not match indexed array along dimension 0; dimension is 10 but corresponding boolean dimension is 7

WARNING: Error: Could not find wandb directory: ./wandb
INFO: Number of parameters: 177348
INFO: QNetwork(
  (conv_feature): Sequential(
    (0): Conv2d(1, 64, kernel_size=(3, 3), stride=(1, 1))
    (1): ReLU()
    (2): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (3): Conv2d(64, 32, kernel_size=(3, 3), stride=(1, 1))
    (4): ReLU()
    (5): BatchNorm2d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
  )
  (fc_feature): Sequential(
    (0): Linear(in_features=1152, out_features=128, bias=True)
    (1): ReLU()
    (2): Linear(in_features=128, out_features=64, bias=True)
    (3): ReLU()
    (4): Linear(in_features=64, out_features=32, bias=True)
    (5): ReLU()
    (6): Linear(in_features=32, out_features=4, bias=True)
  )
)
WARNING: GIF is enabled but the environment does not support RGB array rendering.
INFO: Learning...
INFO: BootcampName.HIDER bootcamp completed, starting BootcampName.SEEKER bootcamp
WARNING: No frames in gif to save.
WARNING: No frames in gif to save.
WARNING: No frames in gif to save.
WARNING: No frames in gif to save.
WARNING: No frames in gif to save.
WARNING: No frames in gif to save.
WARNING: No frames in gif to save.
WARNING: No frames in gif to save.
WARNING: No frames in gif to save.
WARNING: No frames in gif to save.
WARNING: No frames in gif to save.
WARNING: No frames in gif to save.
WARNING: No frames in gif to save.
WARNING: No frames in gif to save.
WARNING: No frames in gif to save.
WARNING: No frames in gif to save.
WARNING: No frames in gif to save.
WARNING: No frames in gif to save.
WARNING: No frames in gif to save.
WARNING: No frames in gif to save.
INFO: BootcampName.SEEKER bootcamp completed, starting BootcampName.SLOW_HIDER bootcamp
WARNING: No frames in gif to save.
WARNING: No frames in gif to save.
INFO: Cleaning cache: /home/eirik/.cache/wandb/artifacts/obj 0.00390625 MB
INFO: cleaning local: /home/eirik/.local/share/wandb/artifacts/staging 0.00390625 MB
INFO: Number of parameters: 177348
INFO: QNetwork(
  (conv_feature): Sequential(
    (0): Conv2d(1, 64, kernel_size=(3, 3), stride=(1, 1))
    (1): ReLU()
    (2): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (3): Conv2d(64, 32, kernel_size=(3, 3), stride=(1, 1))
    (4): ReLU()
    (5): BatchNorm2d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
  )
  (fc_feature): Sequential(
    (0): Linear(in_features=1152, out_features=128, bias=True)
    (1): ReLU()
    (2): Linear(in_features=128, out_features=64, bias=True)
    (3): ReLU()
    (4): Linear(in_features=64, out_features=32, bias=True)
    (5): ReLU()
    (6): Linear(in_features=32, out_features=4, bias=True)
  )
)
WARNING: GIF is enabled but the environment does not support RGB array rendering.
INFO: Learning...
INFO: BootcampName.HIDER bootcamp completed, starting BootcampName.SEEKER bootcamp
INFO: Number of parameters: 177348
INFO: QNetwork(
  (conv_feature): Sequential(
    (0): Conv2d(1, 64, kernel_size=(3, 3), stride=(1, 1))
    (1): ReLU()
    (2): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (3): Conv2d(64, 32, kernel_size=(3, 3), stride=(1, 1))
    (4): ReLU()
    (5): BatchNorm2d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
  )
  (fc_feature): Sequential(
    (0): Linear(in_features=1152, out_features=128, bias=True)
    (1): ReLU()
    (2): Linear(in_features=128, out_features=64, bias=True)
    (3): ReLU()
    (4): Linear(in_features=64, out_features=32, bias=True)
    (5): ReLU()
    (6): Linear(in_features=32, out_features=4, bias=True)
  )
)
WARNING: GIF is enabled but the environment does not support RGB array rendering.
INFO: Learning...
INFO: BootcampName.HIDER bootcamp completed, starting BootcampName.SEEKER bootcamp
INFO: Number of parameters: 177348
INFO: QNetwork(
  (conv_feature): Sequential(
    (0): Conv2d(1, 64, kernel_size=(3, 3), stride=(1, 1))
    (1): ReLU()
    (2): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (3): Conv2d(64, 32, kernel_size=(3, 3), stride=(1, 1))
    (4): ReLU()
    (5): BatchNorm2d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
  )
  (fc_feature): Sequential(
    (0): Linear(in_features=1152, out_features=128, bias=True)
    (1): ReLU()
    (2): Linear(in_features=128, out_features=64, bias=True)
    (3): ReLU()
    (4): Linear(in_features=64, out_features=32, bias=True)
    (5): ReLU()
    (6): Linear(in_features=32, out_features=4, bias=True)
  )
)
WARNING: GIF is enabled but the environment does not support RGB array rendering.
INFO: Learning...
INFO: BootcampName.HIDER bootcamp completed, starting BootcampName.SEEKER bootcamp
INFO: Number of parameters: 177348
INFO: QNetwork(
  (conv_feature): Sequential(
    (0): Conv2d(1, 64, kernel_size=(3, 3), stride=(1, 1))
    (1): ReLU()
    (2): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (3): Conv2d(64, 32, kernel_size=(3, 3), stride=(1, 1))
    (4): ReLU()
    (5): BatchNorm2d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
  )
  (fc_feature): Sequential(
    (0): Linear(in_features=1152, out_features=128, bias=True)
    (1): ReLU()
    (2): Linear(in_features=128, out_features=64, bias=True)
    (3): ReLU()
    (4): Linear(in_features=64, out_features=32, bias=True)
    (5): ReLU()
    (6): Linear(in_features=32, out_features=4, bias=True)
  )
)
WARNING: GIF is enabled but the environment does not support RGB array rendering.
INFO: Learning...
INFO: BootcampName.HIDER bootcamp completed, starting BootcampName.SEEKER bootcamp
INFO: Number of parameters: 177348
INFO: QNetwork(
  (conv_feature): Sequential(
    (0): Conv2d(1, 64, kernel_size=(3, 3), stride=(1, 1))
    (1): ReLU()
    (2): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (3): Conv2d(64, 32, kernel_size=(3, 3), stride=(1, 1))
    (4): ReLU()
    (5): BatchNorm2d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
  )
  (fc_feature): Sequential(
    (0): Linear(in_features=1152, out_features=128, bias=True)
    (1): ReLU()
    (2): Linear(in_features=128, out_features=64, bias=True)
    (3): ReLU()
    (4): Linear(in_features=64, out_features=32, bias=True)
    (5): ReLU()
    (6): Linear(in_features=32, out_features=4, bias=True)
  )
)
WARNING: GIF is enabled but the environment does not support RGB array rendering.
INFO: Learning...
INFO: BootcampName.HIDER bootcamp completed, starting BootcampName.SEEKER bootcamp
INFO: Number of parameters: 177348
INFO: QNetwork(
  (conv_feature): Sequential(
    (0): Conv2d(1, 64, kernel_size=(3, 3), stride=(1, 1))
    (1): ReLU()
    (2): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (3): Conv2d(64, 32, kernel_size=(3, 3), stride=(1, 1))
    (4): ReLU()
    (5): BatchNorm2d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
  )
  (fc_feature): Sequential(
    (0): Linear(in_features=1152, out_features=128, bias=True)
    (1): ReLU()
    (2): Linear(in_features=128, out_features=64, bias=True)
    (3): ReLU()
    (4): Linear(in_features=64, out_features=32, bias=True)
    (5): ReLU()
    (6): Linear(in_features=32, out_features=4, bias=True)
  )
)
WARNING: GIF is enabled but the environment does not support RGB array rendering.
INFO: Learning...
INFO: BootcampName.HIDER bootcamp completed, starting BootcampName.SEEKER bootcamp
INFO: Number of parameters: 177348
INFO: QNetwork(
  (conv_feature): Sequential(
    (0): Conv2d(1, 64, kernel_size=(3, 3), stride=(1, 1))
    (1): ReLU()
    (2): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (3): Conv2d(64, 32, kernel_size=(3, 3), stride=(1, 1))
    (4): ReLU()
    (5): BatchNorm2d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
  )
  (fc_feature): Sequential(
    (0): Linear(in_features=1152, out_features=128, bias=True)
    (1): ReLU()
    (2): Linear(in_features=128, out_features=64, bias=True)
    (3): ReLU()
    (4): Linear(in_features=64, out_features=32, bias=True)
    (5): ReLU()
    (6): Linear(in_features=32, out_features=4, bias=True)
  )
)
WARNING: GIF is enabled but the environment does not support RGB array rendering.
INFO: Learning...
INFO: BootcampName.HIDER bootcamp completed, starting BootcampName.SEEKER bootcamp
INFO: Number of parameters: 177348
INFO: QNetwork(
  (conv_feature): Sequential(
    (0): Conv2d(1, 64, kernel_size=(3, 3), stride=(1, 1))
    (1): ReLU()
    (2): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (3): Conv2d(64, 32, kernel_size=(3, 3), stride=(1, 1))
    (4): ReLU()
    (5): BatchNorm2d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
  )
  (fc_feature): Sequential(
    (0): Linear(in_features=1152, out_features=128, bias=True)
    (1): ReLU()
    (2): Linear(in_features=128, out_features=64, bias=True)
    (3): ReLU()
    (4): Linear(in_features=64, out_features=32, bias=True)
    (5): ReLU()
    (6): Linear(in_features=32, out_features=4, bias=True)
  )
)
WARNING: GIF is enabled but the environment does not support RGB array rendering.
INFO: Learning...
INFO: BootcampName.HIDER bootcamp completed, starting BootcampName.SEEKER bootcamp
INFO: Number of parameters: 177348
INFO: QNetwork(
  (conv_feature): Sequential(
    (0): Conv2d(1, 64, kernel_size=(3, 3), stride=(1, 1))
    (1): ReLU()
    (2): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (3): Conv2d(64, 32, kernel_size=(3, 3), stride=(1, 1))
    (4): ReLU()
    (5): BatchNorm2d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
  )
  (fc_feature): Sequential(
    (0): Linear(in_features=1152, out_features=128, bias=True)
    (1): ReLU()
    (2): Linear(in_features=128, out_features=64, bias=True)
    (3): ReLU()
    (4): Linear(in_features=64, out_features=32, bias=True)
    (5): ReLU()
    (6): Linear(in_features=32, out_features=4, bias=True)
  )
)
WARNING: GIF is enabled but the environment does not support RGB array rendering.
INFO: Learning...
INFO: BootcampName.HIDER bootcamp completed, starting BootcampName.SEEKER bootcamp
ERROR: can only concatenate tuple (not "float") to tuple
ERROR: Traceback (most recent call last):
  File "/home/eirik/Projects/XAI/rl/src/dqn/wrapper/multi_agent_dqn.py", line 74, in learn
    self._collect_rollouts()
  File "/home/eirik/Projects/XAI/rl/src/dqn/wrapper/multi_agent_dqn.py", line 135, in _collect_rollouts
    ) = self.env.get_wrapper_attr("step_multiple")(actions)
        ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/eirik/Projects/XAI/environments/gymnasium/wrappers/multi_agent_env.py", line 37, in step_multiple
    self.get_wrapper_attr("concatenate_states")(full_states)
  File "/home/eirik/Projects/XAI/environments/gymnasium/envs/tag/tag.py", line 230, in concatenate_states
    rewards, tag_terminated = self.tag_rewards.get_tag_reward(
                              ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/eirik/Projects/XAI/environments/gymnasium/envs/tag/tag_rewards.py", line 37, in get_tag_reward
    self.not_tagged_reward + exp_distance,
    ~~~~~~~~~~~~~~~~~~~~~~~^~~~~~~~~~~~~~
TypeError: can only concatenate tuple (not "float") to tuple

WARNING: Error: Could not find wandb directory: ./wandb
INFO: Number of parameters: 177348
INFO: QNetwork(
  (conv_feature): Sequential(
    (0): Conv2d(1, 64, kernel_size=(3, 3), stride=(1, 1))
    (1): ReLU()
    (2): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (3): Conv2d(64, 32, kernel_size=(3, 3), stride=(1, 1))
    (4): ReLU()
    (5): BatchNorm2d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
  )
  (fc_feature): Sequential(
    (0): Linear(in_features=1152, out_features=128, bias=True)
    (1): ReLU()
    (2): Linear(in_features=128, out_features=64, bias=True)
    (3): ReLU()
    (4): Linear(in_features=64, out_features=32, bias=True)
    (5): ReLU()
    (6): Linear(in_features=32, out_features=4, bias=True)
  )
)
WARNING: GIF is enabled but the environment does not support RGB array rendering.
INFO: Learning...
INFO: BootcampName.HIDER bootcamp completed, starting BootcampName.SEEKER bootcamp
ERROR: can only concatenate tuple (not "float") to tuple
ERROR: Traceback (most recent call last):
  File "/home/eirik/Projects/XAI/rl/src/dqn/wrapper/multi_agent_dqn.py", line 74, in learn
    self._collect_rollouts()
  File "/home/eirik/Projects/XAI/rl/src/dqn/wrapper/multi_agent_dqn.py", line 135, in _collect_rollouts
    ) = self.env.get_wrapper_attr("step_multiple")(actions)
        ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/eirik/Projects/XAI/environments/gymnasium/wrappers/multi_agent_env.py", line 37, in step_multiple
    self.get_wrapper_attr("concatenate_states")(full_states)
  File "/home/eirik/Projects/XAI/environments/gymnasium/envs/tag/tag.py", line 230, in concatenate_states
    rewards, tag_terminated = self.tag_rewards.get_tag_reward(
                              ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/eirik/Projects/XAI/environments/gymnasium/envs/tag/tag_rewards.py", line 37, in get_tag_reward
    self.not_tagged_reward + exp_distance,
    ~~~~~~~~~~~~~~~~~~~~~~~^~~~~~~~~~~~~~
TypeError: can only concatenate tuple (not "float") to tuple

WARNING: Error: Could not find wandb directory: ./wandb
INFO: Number of parameters: 177348
INFO: QNetwork(
  (conv_feature): Sequential(
    (0): Conv2d(1, 64, kernel_size=(3, 3), stride=(1, 1))
    (1): ReLU()
    (2): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (3): Conv2d(64, 32, kernel_size=(3, 3), stride=(1, 1))
    (4): ReLU()
    (5): BatchNorm2d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
  )
  (fc_feature): Sequential(
    (0): Linear(in_features=1152, out_features=128, bias=True)
    (1): ReLU()
    (2): Linear(in_features=128, out_features=64, bias=True)
    (3): ReLU()
    (4): Linear(in_features=64, out_features=32, bias=True)
    (5): ReLU()
    (6): Linear(in_features=32, out_features=4, bias=True)
  )
)
WARNING: GIF is enabled but the environment does not support RGB array rendering.
INFO: Learning...
INFO: BootcampName.HIDER bootcamp completed, starting BootcampName.SEEKER bootcamp
WARNING: No frames in gif to save.
WARNING: No frames in gif to save.
WARNING: No frames in gif to save.
WARNING: No frames in gif to save.
WARNING: No frames in gif to save.
WARNING: No frames in gif to save.
INFO: Number of parameters: 177348
INFO: QNetwork(
  (conv_feature): Sequential(
    (0): Conv2d(1, 64, kernel_size=(3, 3), stride=(1, 1))
    (1): ReLU()
    (2): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (3): Conv2d(64, 32, kernel_size=(3, 3), stride=(1, 1))
    (4): ReLU()
    (5): BatchNorm2d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
  )
  (fc_feature): Sequential(
    (0): Linear(in_features=1152, out_features=128, bias=True)
    (1): ReLU()
    (2): Linear(in_features=128, out_features=64, bias=True)
    (3): ReLU()
    (4): Linear(in_features=64, out_features=32, bias=True)
    (5): ReLU()
    (6): Linear(in_features=32, out_features=4, bias=True)
  )
)
WARNING: GIF is enabled but the environment does not support RGB array rendering.
INFO: Learning...
INFO: BootcampName.HIDER bootcamp completed, starting BootcampName.SEEKER bootcamp
ERROR: not enough values to unpack (expected 6, got 4)
ERROR: Traceback (most recent call last):
  File "/home/eirik/Projects/XAI/rl/src/dqn/wrapper/multi_agent_dqn.py", line 75, in learn
    self._collect_rollouts()
  File "/home/eirik/Projects/XAI/rl/src/dqn/wrapper/multi_agent_dqn.py", line 139, in _collect_rollouts
    ) = self.env.get_wrapper_attr("step_multiple")(actions)
        ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/eirik/Projects/XAI/environments/gymnasium/wrappers/multi_agent_env.py", line 37, in step_multiple
    (
ValueError: not enough values to unpack (expected 6, got 4)

WARNING: Error: Could not find wandb directory: ./wandb
INFO: Number of parameters: 177348
INFO: QNetwork(
  (conv_feature): Sequential(
    (0): Conv2d(1, 64, kernel_size=(3, 3), stride=(1, 1))
    (1): ReLU()
    (2): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (3): Conv2d(64, 32, kernel_size=(3, 3), stride=(1, 1))
    (4): ReLU()
    (5): BatchNorm2d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
  )
  (fc_feature): Sequential(
    (0): Linear(in_features=1152, out_features=128, bias=True)
    (1): ReLU()
    (2): Linear(in_features=128, out_features=64, bias=True)
    (3): ReLU()
    (4): Linear(in_features=64, out_features=32, bias=True)
    (5): ReLU()
    (6): Linear(in_features=32, out_features=4, bias=True)
  )
)
WARNING: GIF is enabled but the environment does not support RGB array rendering.
INFO: Learning...
INFO: BootcampName.HIDER bootcamp completed, starting BootcampName.SEEKER bootcamp
WARNING: No frames in gif to save.
WARNING: No frames in gif to save.
WARNING: No frames in gif to save.
WARNING: No frames in gif to save.
WARNING: No frames in gif to save.
WARNING: No frames in gif to save.
INFO: Number of parameters: 177348
INFO: QNetwork(
  (conv_feature): Sequential(
    (0): Conv2d(1, 64, kernel_size=(3, 3), stride=(1, 1))
    (1): ReLU()
    (2): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (3): Conv2d(64, 32, kernel_size=(3, 3), stride=(1, 1))
    (4): ReLU()
    (5): BatchNorm2d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
  )
  (fc_feature): Sequential(
    (0): Linear(in_features=1152, out_features=128, bias=True)
    (1): ReLU()
    (2): Linear(in_features=128, out_features=64, bias=True)
    (3): ReLU()
    (4): Linear(in_features=64, out_features=32, bias=True)
    (5): ReLU()
    (6): Linear(in_features=32, out_features=4, bias=True)
  )
)
WARNING: GIF is enabled but the environment does not support RGB array rendering.
INFO: Learning...
INFO: BootcampName.HIDER bootcamp completed, starting BootcampName.SEEKER bootcamp
WARNING: No frames in gif to save.
WARNING: No frames in gif to save.
WARNING: No frames in gif to save.
WARNING: No frames in gif to save.
WARNING: No frames in gif to save.
WARNING: No frames in gif to save.
WARNING: No frames in gif to save.
WARNING: No frames in gif to save.
INFO: Number of parameters: 177348
INFO: QNetwork(
  (conv_feature): Sequential(
    (0): Conv2d(1, 64, kernel_size=(3, 3), stride=(1, 1))
    (1): ReLU()
    (2): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (3): Conv2d(64, 32, kernel_size=(3, 3), stride=(1, 1))
    (4): ReLU()
    (5): BatchNorm2d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
  )
  (fc_feature): Sequential(
    (0): Linear(in_features=1152, out_features=128, bias=True)
    (1): ReLU()
    (2): Linear(in_features=128, out_features=64, bias=True)
    (3): ReLU()
    (4): Linear(in_features=64, out_features=32, bias=True)
    (5): ReLU()
    (6): Linear(in_features=32, out_features=4, bias=True)
  )
)
WARNING: GIF is enabled but the environment does not support RGB array rendering.
INFO: Learning...
INFO: BootcampName.HIDER bootcamp completed, starting BootcampName.SEEKER bootcamp
INFO: Number of parameters: 177348
INFO: QNetwork(
  (conv_feature): Sequential(
    (0): Conv2d(1, 64, kernel_size=(3, 3), stride=(1, 1))
    (1): ReLU()
    (2): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (3): Conv2d(64, 32, kernel_size=(3, 3), stride=(1, 1))
    (4): ReLU()
    (5): BatchNorm2d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
  )
  (fc_feature): Sequential(
    (0): Linear(in_features=1152, out_features=128, bias=True)
    (1): ReLU()
    (2): Linear(in_features=128, out_features=64, bias=True)
    (3): ReLU()
    (4): Linear(in_features=64, out_features=32, bias=True)
    (5): ReLU()
    (6): Linear(in_features=32, out_features=4, bias=True)
  )
)
WARNING: GIF is enabled but the environment does not support RGB array rendering.
INFO: Learning...
INFO: BootcampName.HIDER bootcamp completed, starting BootcampName.SEEKER bootcamp
WARNING: No frames in gif to save.
WARNING: No frames in gif to save.
WARNING: No frames in gif to save.
WARNING: No frames in gif to save.
WARNING: No frames in gif to save.
WARNING: No frames in gif to save.
WARNING: No frames in gif to save.
WARNING: No frames in gif to save.
WARNING: No frames in gif to save.
WARNING: No frames in gif to save.
INFO: Number of parameters: 177348
INFO: QNetwork(
  (conv_feature): Sequential(
    (0): Conv2d(1, 64, kernel_size=(3, 3), stride=(1, 1))
    (1): ReLU()
    (2): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (3): Conv2d(64, 32, kernel_size=(3, 3), stride=(1, 1))
    (4): ReLU()
    (5): BatchNorm2d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
  )
  (fc_feature): Sequential(
    (0): Linear(in_features=1152, out_features=128, bias=True)
    (1): ReLU()
    (2): Linear(in_features=128, out_features=64, bias=True)
    (3): ReLU()
    (4): Linear(in_features=64, out_features=32, bias=True)
    (5): ReLU()
    (6): Linear(in_features=32, out_features=4, bias=True)
  )
)
WARNING: GIF is enabled but the environment does not support RGB array rendering.
INFO: Learning...
INFO: BootcampName.HIDER bootcamp completed, starting BootcampName.SEEKER bootcamp
WARNING: No frames in gif to save.
WARNING: No frames in gif to save.
WARNING: No frames in gif to save.
WARNING: No frames in gif to save.
WARNING: No frames in gif to save.
WARNING: No frames in gif to save.
WARNING: No frames in gif to save.
WARNING: No frames in gif to save.
WARNING: No frames in gif to save.
WARNING: No frames in gif to save.
WARNING: No frames in gif to save.
WARNING: No frames in gif to save.
WARNING: No frames in gif to save.
WARNING: No frames in gif to save.
WARNING: No frames in gif to save.
WARNING: No frames in gif to save.
WARNING: No frames in gif to save.
WARNING: No frames in gif to save.
INFO: Number of parameters: 177348
INFO: QNetwork(
  (conv_feature): Sequential(
    (0): Conv2d(1, 64, kernel_size=(3, 3), stride=(1, 1))
    (1): ReLU()
    (2): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (3): Conv2d(64, 32, kernel_size=(3, 3), stride=(1, 1))
    (4): ReLU()
    (5): BatchNorm2d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
  )
  (fc_feature): Sequential(
    (0): Linear(in_features=1152, out_features=128, bias=True)
    (1): ReLU()
    (2): Linear(in_features=128, out_features=64, bias=True)
    (3): ReLU()
    (4): Linear(in_features=64, out_features=32, bias=True)
    (5): ReLU()
    (6): Linear(in_features=32, out_features=4, bias=True)
  )
)
WARNING: GIF is enabled but the environment does not support RGB array rendering.
INFO: Learning...
INFO: BootcampName.HIDER bootcamp completed, starting BootcampName.SEEKER bootcamp
WARNING: No frames in gif to save.
WARNING: No frames in gif to save.
WARNING: No frames in gif to save.
WARNING: No frames in gif to save.
WARNING: No frames in gif to save.
WARNING: No frames in gif to save.
WARNING: No frames in gif to save.
WARNING: No frames in gif to save.
WARNING: No frames in gif to save.
WARNING: No frames in gif to save.
WARNING: No frames in gif to save.
WARNING: No frames in gif to save.
INFO: Number of parameters: 29956
INFO: QNetwork(
  (conv_feature): Sequential()
  (fc_feature): Sequential(
    (0): Linear(in_features=100, out_features=128, bias=True)
    (1): ReLU()
    (2): Linear(in_features=128, out_features=128, bias=True)
    (3): ReLU()
    (4): Linear(in_features=128, out_features=4, bias=True)
  )
)
WARNING: GIF is enabled but the environment does not support RGB array rendering.
INFO: Learning...
INFO: BootcampName.HIDER bootcamp completed, starting BootcampName.SEEKER bootcamp
WARNING: No frames in gif to save.
WARNING: No frames in gif to save.
WARNING: No frames in gif to save.
WARNING: No frames in gif to save.
WARNING: No frames in gif to save.
WARNING: No frames in gif to save.
WARNING: No frames in gif to save.
WARNING: No frames in gif to save.
WARNING: No frames in gif to save.
WARNING: No frames in gif to save.
INFO: Number of parameters: 29956
INFO: QNetwork(
  (conv_feature): Sequential()
  (fc_feature): Sequential(
    (0): Linear(in_features=100, out_features=128, bias=True)
    (1): ReLU()
    (2): Linear(in_features=128, out_features=128, bias=True)
    (3): ReLU()
    (4): Linear(in_features=128, out_features=4, bias=True)
  )
)
WARNING: GIF is enabled but the environment does not support RGB array rendering.
INFO: Learning...
INFO: BootcampName.HIDER bootcamp completed, starting BootcampName.SEEKER bootcamp
WARNING: No frames in gif to save.
WARNING: No frames in gif to save.
WARNING: No frames in gif to save.
WARNING: No frames in gif to save.
WARNING: No frames in gif to save.
WARNING: No frames in gif to save.
WARNING: No frames in gif to save.
WARNING: No frames in gif to save.
WARNING: No frames in gif to save.
WARNING: No frames in gif to save.
WARNING: No frames in gif to save.
WARNING: No frames in gif to save.
WARNING: No frames in gif to save.
WARNING: No frames in gif to save.
WARNING: No frames in gif to save.
WARNING: No frames in gif to save.
WARNING: No frames in gif to save.
WARNING: No frames in gif to save.
WARNING: No frames in gif to save.
WARNING: No frames in gif to save.
INFO: BootcampName.SEEKER bootcamp completed, starting BootcampName.SLOW_HIDER bootcamp
WARNING: No frames in gif to save.
WARNING: No frames in gif to save.
INFO: Cleaning cache: /home/eirik/.cache/wandb/artifacts/obj 0.00390625 MB
INFO: cleaning local: /home/eirik/.local/share/wandb/artifacts/staging 0.00390625 MB
WARNING: No frames in gif to save.
WARNING: No frames in gif to save.
WARNING: No frames in gif to save.
WARNING: No frames in gif to save.
WARNING: No frames in gif to save.
WARNING: No frames in gif to save.
WARNING: No frames in gif to save.
WARNING: No frames in gif to save.
INFO: Number of parameters: 29956
INFO: QNetwork(
  (conv_feature): Sequential()
  (fc_feature): Sequential(
    (0): Linear(in_features=100, out_features=128, bias=True)
    (1): ReLU()
    (2): Linear(in_features=128, out_features=128, bias=True)
    (3): ReLU()
    (4): Linear(in_features=128, out_features=4, bias=True)
  )
)
WARNING: GIF is enabled but the environment does not support RGB array rendering.
INFO: Learning...
INFO: BootcampName.HIDER bootcamp completed, starting BootcampName.SEEKER bootcamp
WARNING: No frames in gif to save.
WARNING: No frames in gif to save.
INFO: Number of parameters: 29956
INFO: QNetwork(
  (conv_feature): Sequential()
  (fc_feature): Sequential(
    (0): Linear(in_features=100, out_features=128, bias=True)
    (1): ReLU()
    (2): Linear(in_features=128, out_features=128, bias=True)
    (3): ReLU()
    (4): Linear(in_features=128, out_features=4, bias=True)
  )
)
WARNING: GIF is enabled but the environment does not support RGB array rendering.
INFO: Learning...
INFO: BootcampName.HIDER bootcamp completed, starting BootcampName.SEEKER bootcamp
WARNING: No frames in gif to save.
WARNING: No frames in gif to save.
WARNING: No frames in gif to save.
WARNING: No frames in gif to save.
INFO: Number of parameters: 29956
INFO: QNetwork(
  (conv_feature): Sequential()
  (fc_feature): Sequential(
    (0): Linear(in_features=100, out_features=128, bias=True)
    (1): ReLU()
    (2): Linear(in_features=128, out_features=128, bias=True)
    (3): ReLU()
    (4): Linear(in_features=128, out_features=4, bias=True)
  )
)
WARNING: GIF is enabled but the environment does not support RGB array rendering.
INFO: Learning...
INFO: BootcampName.HIDER bootcamp completed, starting BootcampName.SEEKER bootcamp
WARNING: No frames in gif to save.
WARNING: No frames in gif to save.
INFO: Number of parameters: 29956
INFO: QNetwork(
  (conv_feature): Sequential()
  (fc_feature): Sequential(
    (0): Linear(in_features=100, out_features=128, bias=True)
    (1): ReLU()
    (2): Linear(in_features=128, out_features=128, bias=True)
    (3): ReLU()
    (4): Linear(in_features=128, out_features=4, bias=True)
  )
)
WARNING: GIF is enabled but the environment does not support RGB array rendering.
INFO: Learning...
INFO: BootcampName.HIDER bootcamp completed, starting BootcampName.SEEKER bootcamp
WARNING: No frames in gif to save.
WARNING: No frames in gif to save.
WARNING: No frames in gif to save.
WARNING: No frames in gif to save.
INFO: Number of parameters: 29956
INFO: QNetwork(
  (conv_feature): Sequential()
  (fc_feature): Sequential(
    (0): Linear(in_features=100, out_features=128, bias=True)
    (1): ReLU()
    (2): Linear(in_features=128, out_features=128, bias=True)
    (3): ReLU()
    (4): Linear(in_features=128, out_features=4, bias=True)
  )
)
WARNING: GIF is enabled but the environment does not support RGB array rendering.
INFO: Learning...
INFO: BootcampName.HIDER bootcamp completed, starting BootcampName.SEEKER bootcamp
WARNING: No frames in gif to save.
WARNING: No frames in gif to save.
WARNING: No frames in gif to save.
WARNING: No frames in gif to save.
INFO: Number of parameters: 29956
INFO: QNetwork(
  (conv_feature): Sequential()
  (fc_feature): Sequential(
    (0): Linear(in_features=100, out_features=128, bias=True)
    (1): ReLU()
    (2): Linear(in_features=128, out_features=128, bias=True)
    (3): ReLU()
    (4): Linear(in_features=128, out_features=4, bias=True)
  )
)
WARNING: GIF is enabled but the environment does not support RGB array rendering.
INFO: Learning...
INFO: BootcampName.HIDER bootcamp completed, starting BootcampName.SEEKER bootcamp
INFO: Number of parameters: 29956
INFO: QNetwork(
  (conv_feature): Sequential()
  (fc_feature): Sequential(
    (0): Linear(in_features=100, out_features=128, bias=True)
    (1): ReLU()
    (2): Linear(in_features=128, out_features=128, bias=True)
    (3): ReLU()
    (4): Linear(in_features=128, out_features=4, bias=True)
  )
)
WARNING: GIF is enabled but the environment does not support RGB array rendering.
INFO: Learning...
INFO: BootcampName.HIDER bootcamp completed, starting BootcampName.SEEKER bootcamp
WARNING: No frames in gif to save.
WARNING: No frames in gif to save.
INFO: Number of parameters: 29956
INFO: QNetwork(
  (conv_feature): Sequential()
  (fc_feature): Sequential(
    (0): Linear(in_features=100, out_features=128, bias=True)
    (1): ReLU()
    (2): Linear(in_features=128, out_features=128, bias=True)
    (3): ReLU()
    (4): Linear(in_features=128, out_features=4, bias=True)
  )
)
WARNING: GIF is enabled but the environment does not support RGB array rendering.
INFO: Learning...
INFO: BootcampName.HIDER bootcamp completed, starting BootcampName.SEEKER bootcamp
WARNING: No frames in gif to save.
WARNING: No frames in gif to save.
WARNING: No frames in gif to save.
WARNING: No frames in gif to save.
INFO: Number of parameters: 29956
INFO: QNetwork(
  (conv_feature): Sequential()
  (fc_feature): Sequential(
    (0): Linear(in_features=100, out_features=128, bias=True)
    (1): ReLU()
    (2): Linear(in_features=128, out_features=128, bias=True)
    (3): ReLU()
    (4): Linear(in_features=128, out_features=4, bias=True)
  )
)
WARNING: GIF is enabled but the environment does not support RGB array rendering.
INFO: Learning...
INFO: BootcampName.HIDER bootcamp completed, starting BootcampName.SEEKER bootcamp
INFO: Number of parameters: 29956
INFO: QNetwork(
  (conv_feature): Sequential()
  (fc_feature): Sequential(
    (0): Linear(in_features=100, out_features=128, bias=True)
    (1): ReLU()
    (2): Linear(in_features=128, out_features=128, bias=True)
    (3): ReLU()
    (4): Linear(in_features=128, out_features=4, bias=True)
  )
)
WARNING: GIF is enabled but the environment does not support RGB array rendering.
INFO: Learning...
INFO: BootcampName.HIDER bootcamp completed, starting BootcampName.SEEKER bootcamp
INFO: Number of parameters: 29956
INFO: QNetwork(
  (conv_feature): Sequential()
  (fc_feature): Sequential(
    (0): Linear(in_features=100, out_features=128, bias=True)
    (1): ReLU()
    (2): Linear(in_features=128, out_features=128, bias=True)
    (3): ReLU()
    (4): Linear(in_features=128, out_features=4, bias=True)
  )
)
WARNING: GIF is enabled but the environment does not support RGB array rendering.
INFO: Learning...
INFO: BootcampName.HIDER bootcamp completed, starting BootcampName.SEEKER bootcamp
WARNING: No frames in gif to save.
WARNING: No frames in gif to save.
WARNING: No frames in gif to save.
WARNING: No frames in gif to save.
WARNING: No frames in gif to save.
WARNING: No frames in gif to save.
WARNING: No frames in gif to save.
WARNING: No frames in gif to save.
WARNING: No frames in gif to save.
WARNING: No frames in gif to save.
WARNING: No frames in gif to save.
WARNING: No frames in gif to save.
INFO: Number of parameters: 29956
INFO: QNetwork(
  (conv_feature): Sequential()
  (fc_feature): Sequential(
    (0): Linear(in_features=100, out_features=128, bias=True)
    (1): ReLU()
    (2): Linear(in_features=128, out_features=128, bias=True)
    (3): ReLU()
    (4): Linear(in_features=128, out_features=4, bias=True)
  )
)
WARNING: GIF is enabled but the environment does not support RGB array rendering.
INFO: Learning...
INFO: BootcampName.HIDER bootcamp completed, starting BootcampName.SEEKER bootcamp
WARNING: No frames in gif to save.
WARNING: No frames in gif to save.
WARNING: No frames in gif to save.
WARNING: No frames in gif to save.
WARNING: No frames in gif to save.
WARNING: No frames in gif to save.
WARNING: No frames in gif to save.
WARNING: No frames in gif to save.
WARNING: No frames in gif to save.
WARNING: No frames in gif to save.
WARNING: No frames in gif to save.
WARNING: No frames in gif to save.
WARNING: No frames in gif to save.
WARNING: No frames in gif to save.
WARNING: No frames in gif to save.
WARNING: No frames in gif to save.
WARNING: No frames in gif to save.
WARNING: No frames in gif to save.
WARNING: No frames in gif to save.
WARNING: No frames in gif to save.
WARNING: No frames in gif to save.
WARNING: No frames in gif to save.
INFO: Cleaning cache: /home/eirik/.cache/wandb/artifacts/obj 0.00390625 MB
INFO: cleaning local: /home/eirik/.local/share/wandb/artifacts/staging 0.00390625 MB
WARNING: No frames in gif to save.
WARNING: No frames in gif to save.
WARNING: No frames in gif to save.
WARNING: No frames in gif to save.
INFO: Number of parameters: 29956
INFO: QNetwork(
  (conv_feature): Sequential()
  (fc_feature): Sequential(
    (0): Linear(in_features=100, out_features=128, bias=True)
    (1): ReLU()
    (2): Linear(in_features=128, out_features=128, bias=True)
    (3): ReLU()
    (4): Linear(in_features=128, out_features=4, bias=True)
  )
)
WARNING: GIF is enabled but the environment does not support RGB array rendering.
INFO: Learning...
INFO: BootcampName.HIDER bootcamp completed, starting BootcampName.SEEKER bootcamp
WARNING: No frames in gif to save.
WARNING: No frames in gif to save.
INFO: Number of parameters: 29956
INFO: QNetwork(
  (conv_feature): Sequential()
  (fc_feature): Sequential(
    (0): Linear(in_features=100, out_features=128, bias=True)
    (1): ReLU()
    (2): Linear(in_features=128, out_features=128, bias=True)
    (3): ReLU()
    (4): Linear(in_features=128, out_features=4, bias=True)
  )
)
WARNING: GIF is enabled but the environment does not support RGB array rendering.
INFO: Learning...
INFO: BootcampName.HIDER bootcamp completed, starting BootcampName.SEEKER bootcamp
WARNING: No frames in gif to save.
WARNING: No frames in gif to save.
WARNING: No frames in gif to save.
WARNING: No frames in gif to save.
WARNING: No frames in gif to save.
WARNING: No frames in gif to save.
WARNING: No frames in gif to save.
WARNING: No frames in gif to save.
INFO: Number of parameters: 29956
INFO: QNetwork(
  (conv_feature): Sequential()
  (fc_feature): Sequential(
    (0): Linear(in_features=100, out_features=128, bias=True)
    (1): ReLU()
    (2): Linear(in_features=128, out_features=128, bias=True)
    (3): ReLU()
    (4): Linear(in_features=128, out_features=4, bias=True)
  )
)
WARNING: GIF is enabled but the environment does not support RGB array rendering.
INFO: Learning...
INFO: BootcampName.HIDER bootcamp completed, starting BootcampName.SEEKER bootcamp
WARNING: No frames in gif to save.
WARNING: No frames in gif to save.
WARNING: No frames in gif to save.
WARNING: No frames in gif to save.
WARNING: No frames in gif to save.
WARNING: No frames in gif to save.
WARNING: No frames in gif to save.
WARNING: No frames in gif to save.
WARNING: No frames in gif to save.
WARNING: No frames in gif to save.
WARNING: No frames in gif to save.
WARNING: No frames in gif to save.
WARNING: No frames in gif to save.
WARNING: No frames in gif to save.
WARNING: No frames in gif to save.
WARNING: No frames in gif to save.
INFO: BootcampName.SEEKER bootcamp completed, starting BootcampName.SLOW_HIDER bootcamp
WARNING: No frames in gif to save.
WARNING: No frames in gif to save.
WARNING: No frames in gif to save.
WARNING: No frames in gif to save.
WARNING: No frames in gif to save.
WARNING: No frames in gif to save.
INFO: Cleaning cache: /home/eirik/.cache/wandb/artifacts/obj 0.00390625 MB
INFO: cleaning local: /home/eirik/.local/share/wandb/artifacts/staging 0.00390625 MB
WARNING: No frames in gif to save.
WARNING: No frames in gif to save.
WARNING: No frames in gif to save.
WARNING: No frames in gif to save.
WARNING: No frames in gif to save.
WARNING: No frames in gif to save.
WARNING: No frames in gif to save.
WARNING: No frames in gif to save.
WARNING: No frames in gif to save.
WARNING: No frames in gif to save.
WARNING: No frames in gif to save.
WARNING: No frames in gif to save.
WARNING: No frames in gif to save.
WARNING: No frames in gif to save.
WARNING: No frames in gif to save.
WARNING: No frames in gif to save.
WARNING: No frames in gif to save.
WARNING: No frames in gif to save.
WARNING: No frames in gif to save.
WARNING: No frames in gif to save.
INFO: Cleaning cache: /home/eirik/.cache/wandb/artifacts/obj 0.00390625 MB
INFO: cleaning local: /home/eirik/.local/share/wandb/artifacts/staging 0.00390625 MB
WARNING: No frames in gif to save.
WARNING: No frames in gif to save.
WARNING: No frames in gif to save.
WARNING: No frames in gif to save.
WARNING: No frames in gif to save.
WARNING: No frames in gif to save.
WARNING: No frames in gif to save.
WARNING: No frames in gif to save.
WARNING: No frames in gif to save.
WARNING: No frames in gif to save.
WARNING: No frames in gif to save.
WARNING: No frames in gif to save.
WARNING: No frames in gif to save.
WARNING: No frames in gif to save.
WARNING: No frames in gif to save.
WARNING: No frames in gif to save.
WARNING: No frames in gif to save.
WARNING: No frames in gif to save.
WARNING: No frames in gif to save.
WARNING: No frames in gif to save.
WARNING: No frames in gif to save.
WARNING: No frames in gif to save.
INFO: Cleaning cache: /home/eirik/.cache/wandb/artifacts/obj 0.00390625 MB
INFO: cleaning local: /home/eirik/.local/share/wandb/artifacts/staging 0.00390625 MB
WARNING: No frames in gif to save.
WARNING: No frames in gif to save.
WARNING: No frames in gif to save.
WARNING: No frames in gif to save.
WARNING: No frames in gif to save.
WARNING: No frames in gif to save.
WARNING: No frames in gif to save.
WARNING: No frames in gif to save.
WARNING: No frames in gif to save.
WARNING: No frames in gif to save.
WARNING: No frames in gif to save.
WARNING: No frames in gif to save.
WARNING: No frames in gif to save.
WARNING: No frames in gif to save.
WARNING: No frames in gif to save.
WARNING: No frames in gif to save.
WARNING: No frames in gif to save.
WARNING: No frames in gif to save.
WARNING: No frames in gif to save.
WARNING: No frames in gif to save.
INFO: Cleaning cache: /home/eirik/.cache/wandb/artifacts/obj 0.00390625 MB
INFO: cleaning local: /home/eirik/.local/share/wandb/artifacts/staging 0.00390625 MB
WARNING: No frames in gif to save.
WARNING: No frames in gif to save.
WARNING: No frames in gif to save.
WARNING: No frames in gif to save.
WARNING: No frames in gif to save.
WARNING: No frames in gif to save.
WARNING: No frames in gif to save.
WARNING: No frames in gif to save.
WARNING: No frames in gif to save.
WARNING: No frames in gif to save.
WARNING: No frames in gif to save.
WARNING: No frames in gif to save.
WARNING: No frames in gif to save.
WARNING: No frames in gif to save.
INFO: Continuing with bootcamp BootcampName.SLOW_HIDER with slow hider factor: 19
WARNING: No frames in gif to save.
WARNING: No frames in gif to save.
WARNING: No frames in gif to save.
WARNING: No frames in gif to save.
WARNING: No frames in gif to save.
WARNING: No frames in gif to save.
WARNING: No frames in gif to save.
WARNING: No frames in gif to save.
INFO: Cleaning cache: /home/eirik/.cache/wandb/artifacts/obj 0.00390625 MB
INFO: cleaning local: /home/eirik/.local/share/wandb/artifacts/staging 0.00390625 MB
WARNING: No frames in gif to save.
WARNING: No frames in gif to save.
WARNING: No frames in gif to save.
WARNING: No frames in gif to save.
WARNING: No frames in gif to save.
WARNING: No frames in gif to save.
WARNING: No frames in gif to save.
WARNING: No frames in gif to save.
WARNING: No frames in gif to save.
WARNING: No frames in gif to save.
WARNING: No frames in gif to save.
WARNING: No frames in gif to save.
WARNING: No frames in gif to save.
WARNING: No frames in gif to save.
WARNING: No frames in gif to save.
WARNING: No frames in gif to save.
WARNING: No frames in gif to save.
WARNING: No frames in gif to save.
WARNING: No frames in gif to save.
WARNING: No frames in gif to save.
INFO: Cleaning cache: /home/eirik/.cache/wandb/artifacts/obj 0.00390625 MB
INFO: cleaning local: /home/eirik/.local/share/wandb/artifacts/staging 0.00390625 MB
WARNING: No frames in gif to save.
WARNING: No frames in gif to save.
WARNING: No frames in gif to save.
WARNING: No frames in gif to save.
INFO: Number of parameters: 29956
INFO: QNetwork(
  (conv_feature): Sequential()
  (fc_feature): Sequential(
    (0): Linear(in_features=100, out_features=128, bias=True)
    (1): ReLU()
    (2): Linear(in_features=128, out_features=128, bias=True)
    (3): ReLU()
    (4): Linear(in_features=128, out_features=4, bias=True)
  )
)
WARNING: GIF is enabled but the environment does not support RGB array rendering.
INFO: Learning...
INFO: BootcampName.HIDER bootcamp completed, starting BootcampName.SEEKER bootcamp
INFO: Number of parameters: 29956
INFO: QNetwork(
  (conv_feature): Sequential()
  (fc_feature): Sequential(
    (0): Linear(in_features=100, out_features=128, bias=True)
    (1): ReLU()
    (2): Linear(in_features=128, out_features=128, bias=True)
    (3): ReLU()
    (4): Linear(in_features=128, out_features=4, bias=True)
  )
)
WARNING: GIF is enabled but the environment does not support RGB array rendering.
INFO: Learning...
INFO: BootcampName.HIDER bootcamp completed, starting BootcampName.SEEKER bootcamp
WARNING: No frames in gif to save.
WARNING: No frames in gif to save.
WARNING: No frames in gif to save.
WARNING: No frames in gif to save.
WARNING: No frames in gif to save.
WARNING: No frames in gif to save.
INFO: BootcampName.SEEKER bootcamp completed, starting BootcampName.SLOW_HIDER bootcamp
WARNING: No frames in gif to save.
WARNING: No frames in gif to save.
WARNING: No frames in gif to save.
WARNING: No frames in gif to save.
WARNING: No frames in gif to save.
WARNING: No frames in gif to save.
WARNING: No frames in gif to save.
WARNING: No frames in gif to save.
WARNING: No frames in gif to save.
WARNING: No frames in gif to save.
WARNING: No frames in gif to save.
WARNING: No frames in gif to save.
WARNING: No frames in gif to save.
WARNING: No frames in gif to save.
WARNING: No frames in gif to save.
WARNING: No frames in gif to save.
INFO: Cleaning cache: /home/eirik/.cache/wandb/artifacts/obj 0.00390625 MB
INFO: cleaning local: /home/eirik/.local/share/wandb/artifacts/staging 0.00390625 MB
INFO: Continuing with bootcamp BootcampName.SLOW_HIDER with slow hider factor: 19
WARNING: No frames in gif to save.
WARNING: No frames in gif to save.
WARNING: No frames in gif to save.
WARNING: No frames in gif to save.
WARNING: No frames in gif to save.
WARNING: No frames in gif to save.
WARNING: No frames in gif to save.
WARNING: No frames in gif to save.
WARNING: No frames in gif to save.
WARNING: No frames in gif to save.
WARNING: No frames in gif to save.
WARNING: No frames in gif to save.
WARNING: No frames in gif to save.
WARNING: No frames in gif to save.
WARNING: No frames in gif to save.
WARNING: No frames in gif to save.
WARNING: No frames in gif to save.
WARNING: No frames in gif to save.
INFO: Number of parameters: 29956
INFO: QNetwork(
  (conv_feature): Sequential()
  (fc_feature): Sequential(
    (0): Linear(in_features=100, out_features=128, bias=True)
    (1): ReLU()
    (2): Linear(in_features=128, out_features=128, bias=True)
    (3): ReLU()
    (4): Linear(in_features=128, out_features=4, bias=True)
  )
)
WARNING: GIF is enabled but the environment does not support RGB array rendering.
INFO: Learning...
INFO: BootcampName.HIDER bootcamp completed, starting BootcampName.SEEKER bootcamp
INFO: Number of parameters: 29956
INFO: QNetwork(
  (conv_feature): Sequential()
  (fc_feature): Sequential(
    (0): Linear(in_features=100, out_features=128, bias=True)
    (1): ReLU()
    (2): Linear(in_features=128, out_features=128, bias=True)
    (3): ReLU()
    (4): Linear(in_features=128, out_features=4, bias=True)
  )
)
WARNING: GIF is enabled but the environment does not support RGB array rendering.
INFO: Learning...
INFO: BootcampName.HIDER bootcamp completed, starting BootcampName.SEEKER bootcamp
INFO: BootcampName.SEEKER bootcamp completed, starting BootcampName.SLOW_HIDER bootcamp
INFO: Continuing with bootcamp BootcampName.SLOW_HIDER with slow hider factor: 19
INFO: Continuing with bootcamp BootcampName.SLOW_HIDER with slow hider factor: 18
INFO: Continuing with bootcamp BootcampName.SLOW_HIDER with slow hider factor: 17
INFO: Continuing with bootcamp BootcampName.SLOW_HIDER with slow hider factor: 16
WARNING: No frames in gif to save.
WARNING: No frames in gif to save.
INFO: Continuing with bootcamp BootcampName.SLOW_HIDER with slow hider factor: 15
INFO: Continuing with bootcamp BootcampName.SLOW_HIDER with slow hider factor: 14
INFO: Continuing with bootcamp BootcampName.SLOW_HIDER with slow hider factor: 13
INFO: Continuing with bootcamp BootcampName.SLOW_HIDER with slow hider factor: 12
WARNING: No frames in gif to save.
WARNING: No frames in gif to save.
INFO: Continuing with bootcamp BootcampName.SLOW_HIDER with slow hider factor: 11
INFO: Continuing with bootcamp BootcampName.SLOW_HIDER with slow hider factor: 10
INFO: Continuing with bootcamp BootcampName.SLOW_HIDER with slow hider factor: 9
WARNING: No frames in gif to save.
WARNING: No frames in gif to save.
INFO: Continuing with bootcamp BootcampName.SLOW_HIDER with slow hider factor: 8
INFO: Continuing with bootcamp BootcampName.SLOW_HIDER with slow hider factor: 7
WARNING: No frames in gif to save.
WARNING: No frames in gif to save.
INFO: Continuing with bootcamp BootcampName.SLOW_HIDER with slow hider factor: 6
INFO: Continuing with bootcamp BootcampName.SLOW_HIDER with slow hider factor: 5
INFO: Continuing with bootcamp BootcampName.SLOW_HIDER with slow hider factor: 4
INFO: Continuing with bootcamp BootcampName.SLOW_HIDER with slow hider factor: 3
INFO: Continuing with bootcamp BootcampName.SLOW_HIDER with slow hider factor: 2
INFO: BootcampName.SLOW_HIDER bootcamp completed, starting BootcampName.COMBINED bootcamp
WARNING: No frames in gif to save.
WARNING: No frames in gif to save.
WARNING: No frames in gif to save.
WARNING: No frames in gif to save.
WARNING: No frames in gif to save.
WARNING: No frames in gif to save.
WARNING: No frames in gif to save.
WARNING: No frames in gif to save.
WARNING: No frames in gif to save.
WARNING: No frames in gif to save.
WARNING: No frames in gif to save.
WARNING: No frames in gif to save.
WARNING: No frames in gif to save.
WARNING: No frames in gif to save.
INFO: Cleaning cache: /home/eirik/.cache/wandb/artifacts/obj 0.00390625 MB
INFO: cleaning local: /home/eirik/.local/share/wandb/artifacts/staging 0.00390625 MB
WARNING: No frames in gif to save.
WARNING: No frames in gif to save.
WARNING: No frames in gif to save.
WARNING: No frames in gif to save.
WARNING: No frames in gif to save.
WARNING: No frames in gif to save.
WARNING: No frames in gif to save.
WARNING: No frames in gif to save.
WARNING: No frames in gif to save.
WARNING: No frames in gif to save.
WARNING: No frames in gif to save.
WARNING: No frames in gif to save.
WARNING: No frames in gif to save.
WARNING: No frames in gif to save.
WARNING: No frames in gif to save.
WARNING: No frames in gif to save.
WARNING: No frames in gif to save.
WARNING: No frames in gif to save.
WARNING: No frames in gif to save.
WARNING: No frames in gif to save.
INFO: Cleaning cache: /home/eirik/.cache/wandb/artifacts/obj 0.00390625 MB
INFO: cleaning local: /home/eirik/.local/share/wandb/artifacts/staging 0.00390625 MB
WARNING: No frames in gif to save.
WARNING: No frames in gif to save.
WARNING: No frames in gif to save.
WARNING: No frames in gif to save.
WARNING: No frames in gif to save.
WARNING: No frames in gif to save.
WARNING: No frames in gif to save.
WARNING: No frames in gif to save.
WARNING: No frames in gif to save.
WARNING: No frames in gif to save.
WARNING: No frames in gif to save.
WARNING: No frames in gif to save.
WARNING: No frames in gif to save.
WARNING: No frames in gif to save.
WARNING: No frames in gif to save.
WARNING: No frames in gif to save.
WARNING: No frames in gif to save.
WARNING: No frames in gif to save.
WARNING: No frames in gif to save.
WARNING: No frames in gif to save.
WARNING: No frames in gif to save.
WARNING: No frames in gif to save.
INFO: Cleaning cache: /home/eirik/.cache/wandb/artifacts/obj 0.00390625 MB
INFO: cleaning local: /home/eirik/.local/share/wandb/artifacts/staging 0.00390625 MB
INFO: Number of parameters: 29956
INFO: QNetwork(
  (conv_feature): Sequential()
  (fc_feature): Sequential(
    (0): Linear(in_features=100, out_features=128, bias=True)
    (1): ReLU()
    (2): Linear(in_features=128, out_features=128, bias=True)
    (3): ReLU()
    (4): Linear(in_features=128, out_features=4, bias=True)
  )
)
WARNING: GIF is enabled but the environment does not support RGB array rendering.
INFO: Learning...
INFO: BootcampName.HIDER bootcamp completed, starting BootcampName.SEEKER bootcamp
INFO: BootcampName.SEEKER bootcamp completed, starting BootcampName.SLOW_HIDER bootcamp
INFO: Continuing with bootcamp BootcampName.SLOW_HIDER with slow hider factor: 19
INFO: Continuing with bootcamp BootcampName.SLOW_HIDER with slow hider factor: 18
INFO: Continuing with bootcamp BootcampName.SLOW_HIDER with slow hider factor: 17
INFO: Continuing with bootcamp BootcampName.SLOW_HIDER with slow hider factor: 16
INFO: Continuing with bootcamp BootcampName.SLOW_HIDER with slow hider factor: 15
WARNING: No frames in gif to save.
WARNING: No frames in gif to save.
INFO: Continuing with bootcamp BootcampName.SLOW_HIDER with slow hider factor: 14
INFO: Continuing with bootcamp BootcampName.SLOW_HIDER with slow hider factor: 13
INFO: Continuing with bootcamp BootcampName.SLOW_HIDER with slow hider factor: 12
WARNING: No frames in gif to save.
WARNING: No frames in gif to save.
INFO: Continuing with bootcamp BootcampName.SLOW_HIDER with slow hider factor: 11
INFO: Continuing with bootcamp BootcampName.SLOW_HIDER with slow hider factor: 10
INFO: Continuing with bootcamp BootcampName.SLOW_HIDER with slow hider factor: 9
WARNING: No frames in gif to save.
WARNING: No frames in gif to save.
INFO: Continuing with bootcamp BootcampName.SLOW_HIDER with slow hider factor: 8
INFO: Continuing with bootcamp BootcampName.SLOW_HIDER with slow hider factor: 7
INFO: Continuing with bootcamp BootcampName.SLOW_HIDER with slow hider factor: 6
INFO: Continuing with bootcamp BootcampName.SLOW_HIDER with slow hider factor: 5
WARNING: No frames in gif to save.
WARNING: No frames in gif to save.
INFO: Continuing with bootcamp BootcampName.SLOW_HIDER with slow hider factor: 4
INFO: Continuing with bootcamp BootcampName.SLOW_HIDER with slow hider factor: 3
INFO: Continuing with bootcamp BootcampName.SLOW_HIDER with slow hider factor: 2
INFO: BootcampName.SLOW_HIDER bootcamp completed, starting BootcampName.COMBINED bootcamp
WARNING: No frames in gif to save.
WARNING: No frames in gif to save.
WARNING: No frames in gif to save.
WARNING: No frames in gif to save.
WARNING: No frames in gif to save.
WARNING: No frames in gif to save.
WARNING: No frames in gif to save.
WARNING: No frames in gif to save.
WARNING: No frames in gif to save.
WARNING: No frames in gif to save.
WARNING: No frames in gif to save.
WARNING: No frames in gif to save.
WARNING: No frames in gif to save.
WARNING: No frames in gif to save.
INFO: Cleaning cache: /home/eirik/.cache/wandb/artifacts/obj 0.00390625 MB
INFO: cleaning local: /home/eirik/.local/share/wandb/artifacts/staging 0.00390625 MB
WARNING: No frames in gif to save.
WARNING: No frames in gif to save.
WARNING: No frames in gif to save.
WARNING: No frames in gif to save.
WARNING: No frames in gif to save.
WARNING: No frames in gif to save.
WARNING: No frames in gif to save.
WARNING: No frames in gif to save.
WARNING: No frames in gif to save.
WARNING: No frames in gif to save.
WARNING: No frames in gif to save.
WARNING: No frames in gif to save.
WARNING: No frames in gif to save.
WARNING: No frames in gif to save.
WARNING: No frames in gif to save.
WARNING: No frames in gif to save.
WARNING: No frames in gif to save.
WARNING: No frames in gif to save.
WARNING: No frames in gif to save.
WARNING: No frames in gif to save.
INFO: Cleaning cache: /home/eirik/.cache/wandb/artifacts/obj 0.00390625 MB
INFO: cleaning local: /home/eirik/.local/share/wandb/artifacts/staging 0.00390625 MB
WARNING: No frames in gif to save.
WARNING: No frames in gif to save.
WARNING: No frames in gif to save.
WARNING: No frames in gif to save.
WARNING: No frames in gif to save.
WARNING: No frames in gif to save.
WARNING: No frames in gif to save.
WARNING: No frames in gif to save.
WARNING: No frames in gif to save.
WARNING: No frames in gif to save.
WARNING: No frames in gif to save.
WARNING: No frames in gif to save.
WARNING: No frames in gif to save.
WARNING: No frames in gif to save.
WARNING: No frames in gif to save.
WARNING: No frames in gif to save.
WARNING: No frames in gif to save.
WARNING: No frames in gif to save.
WARNING: No frames in gif to save.
WARNING: No frames in gif to save.
INFO: Number of parameters: 30085
INFO: QNetwork(
  (conv_feature): Sequential()
  (fc_feature): Sequential(
    (0): Linear(in_features=100, out_features=128, bias=True)
    (1): ReLU()
    (2): Linear(in_features=128, out_features=128, bias=True)
    (3): ReLU()
    (4): Linear(in_features=128, out_features=5, bias=True)
  )
)
WARNING: GIF is enabled but the environment does not support RGB array rendering.
INFO: Learning...
INFO: BootcampName.HIDER bootcamp completed, starting BootcampName.SEEKER bootcamp
INFO: BootcampName.SEEKER bootcamp completed, starting BootcampName.SLOW_HIDER bootcamp
INFO: Continuing with bootcamp BootcampName.SLOW_HIDER with slow hider factor: 19
INFO: Continuing with bootcamp BootcampName.SLOW_HIDER with slow hider factor: 18
INFO: Continuing with bootcamp BootcampName.SLOW_HIDER with slow hider factor: 17
WARNING: No frames in gif to save.
WARNING: No frames in gif to save.
INFO: Continuing with bootcamp BootcampName.SLOW_HIDER with slow hider factor: 16
INFO: Continuing with bootcamp BootcampName.SLOW_HIDER with slow hider factor: 15
INFO: Continuing with bootcamp BootcampName.SLOW_HIDER with slow hider factor: 14
INFO: Continuing with bootcamp BootcampName.SLOW_HIDER with slow hider factor: 13
WARNING: No frames in gif to save.
WARNING: No frames in gif to save.
INFO: Continuing with bootcamp BootcampName.SLOW_HIDER with slow hider factor: 12
INFO: Continuing with bootcamp BootcampName.SLOW_HIDER with slow hider factor: 11
INFO: Continuing with bootcamp BootcampName.SLOW_HIDER with slow hider factor: 10
WARNING: No frames in gif to save.
WARNING: No frames in gif to save.
INFO: Continuing with bootcamp BootcampName.SLOW_HIDER with slow hider factor: 9
INFO: Continuing with bootcamp BootcampName.SLOW_HIDER with slow hider factor: 8
INFO: Continuing with bootcamp BootcampName.SLOW_HIDER with slow hider factor: 7
WARNING: No frames in gif to save.
WARNING: No frames in gif to save.
INFO: Continuing with bootcamp BootcampName.SLOW_HIDER with slow hider factor: 6
INFO: Continuing with bootcamp BootcampName.SLOW_HIDER with slow hider factor: 5
INFO: Continuing with bootcamp BootcampName.SLOW_HIDER with slow hider factor: 4
INFO: Continuing with bootcamp BootcampName.SLOW_HIDER with slow hider factor: 3
WARNING: No frames in gif to save.
WARNING: No frames in gif to save.
INFO: Continuing with bootcamp BootcampName.SLOW_HIDER with slow hider factor: 2
INFO: BootcampName.SLOW_HIDER bootcamp completed, starting BootcampName.COMBINED bootcamp
WARNING: No frames in gif to save.
WARNING: No frames in gif to save.
WARNING: No frames in gif to save.
WARNING: No frames in gif to save.
WARNING: No frames in gif to save.
WARNING: No frames in gif to save.
WARNING: No frames in gif to save.
WARNING: No frames in gif to save.
WARNING: No frames in gif to save.
WARNING: No frames in gif to save.
WARNING: No frames in gif to save.
WARNING: No frames in gif to save.
INFO: Cleaning cache: /home/eirik/.cache/wandb/artifacts/obj 0.00390625 MB
INFO: cleaning local: /home/eirik/.local/share/wandb/artifacts/staging 0.00390625 MB
INFO: Number of parameters: 30085
INFO: QNetwork(
  (conv_feature): Sequential()
  (fc_feature): Sequential(
    (0): Linear(in_features=100, out_features=128, bias=True)
    (1): ReLU()
    (2): Linear(in_features=128, out_features=128, bias=True)
    (3): ReLU()
    (4): Linear(in_features=128, out_features=5, bias=True)
  )
)
WARNING: GIF is enabled but the environment does not support RGB array rendering.
INFO: Learning...
INFO: BootcampName.HIDER bootcamp completed, starting BootcampName.SEEKER bootcamp
INFO: BootcampName.SEEKER bootcamp completed, starting BootcampName.SLOW_HIDER bootcamp
INFO: Number of parameters: 30085
INFO: QNetwork(
  (conv_feature): Sequential()
  (fc_feature): Sequential(
    (0): Linear(in_features=100, out_features=128, bias=True)
    (1): ReLU()
    (2): Linear(in_features=128, out_features=128, bias=True)
    (3): ReLU()
    (4): Linear(in_features=128, out_features=5, bias=True)
  )
)
WARNING: GIF is enabled but the environment does not support RGB array rendering.
INFO: Learning...
INFO: BootcampName.HIDER bootcamp completed, starting BootcampName.SEEKER bootcamp
INFO: BootcampName.SEEKER bootcamp completed, starting BootcampName.SLOW_HIDER bootcamp
INFO: Continuing with bootcamp BootcampName.SLOW_HIDER with slow hider factor: 19
INFO: Continuing with bootcamp BootcampName.SLOW_HIDER with slow hider factor: 18
INFO: Continuing with bootcamp BootcampName.SLOW_HIDER with slow hider factor: 17
INFO: Continuing with bootcamp BootcampName.SLOW_HIDER with slow hider factor: 16
INFO: Continuing with bootcamp BootcampName.SLOW_HIDER with slow hider factor: 15
WARNING: No frames in gif to save.
WARNING: No frames in gif to save.
INFO: Continuing with bootcamp BootcampName.SLOW_HIDER with slow hider factor: 14
INFO: Continuing with bootcamp BootcampName.SLOW_HIDER with slow hider factor: 13
INFO: Continuing with bootcamp BootcampName.SLOW_HIDER with slow hider factor: 12
WARNING: No frames in gif to save.
WARNING: No frames in gif to save.
INFO: Continuing with bootcamp BootcampName.SLOW_HIDER with slow hider factor: 11
INFO: Continuing with bootcamp BootcampName.SLOW_HIDER with slow hider factor: 10
INFO: Continuing with bootcamp BootcampName.SLOW_HIDER with slow hider factor: 9
INFO: Continuing with bootcamp BootcampName.SLOW_HIDER with slow hider factor: 8
INFO: Continuing with bootcamp BootcampName.SLOW_HIDER with slow hider factor: 7
INFO: Continuing with bootcamp BootcampName.SLOW_HIDER with slow hider factor: 6
WARNING: No frames in gif to save.
WARNING: No frames in gif to save.
INFO: Continuing with bootcamp BootcampName.SLOW_HIDER with slow hider factor: 5
INFO: Continuing with bootcamp BootcampName.SLOW_HIDER with slow hider factor: 4
INFO: Continuing with bootcamp BootcampName.SLOW_HIDER with slow hider factor: 3
INFO: Continuing with bootcamp BootcampName.SLOW_HIDER with slow hider factor: 2
INFO: BootcampName.SLOW_HIDER bootcamp completed, starting BootcampName.COMBINED bootcamp
WARNING: No frames in gif to save.
WARNING: No frames in gif to save.
WARNING: No frames in gif to save.
WARNING: No frames in gif to save.
INFO: Number of parameters: 30085
INFO: QNetwork(
  (conv_feature): Sequential()
  (fc_feature): Sequential(
    (0): Linear(in_features=100, out_features=128, bias=True)
    (1): ReLU()
    (2): Linear(in_features=128, out_features=128, bias=True)
    (3): ReLU()
    (4): Linear(in_features=128, out_features=5, bias=True)
  )
)
WARNING: GIF is enabled but the environment does not support RGB array rendering.
INFO: Learning...
INFO: BootcampName.HIDER bootcamp completed, starting BootcampName.SEEKER bootcamp
INFO: BootcampName.SEEKER bootcamp completed, starting BootcampName.SLOW_HIDER bootcamp
INFO: Continuing with bootcamp BootcampName.SLOW_HIDER with slow hider factor: 19
INFO: Continuing with bootcamp BootcampName.SLOW_HIDER with slow hider factor: 18
INFO: Continuing with bootcamp BootcampName.SLOW_HIDER with slow hider factor: 17
INFO: Continuing with bootcamp BootcampName.SLOW_HIDER with slow hider factor: 16
INFO: Continuing with bootcamp BootcampName.SLOW_HIDER with slow hider factor: 15
INFO: Continuing with bootcamp BootcampName.SLOW_HIDER with slow hider factor: 14
INFO: Continuing with bootcamp BootcampName.SLOW_HIDER with slow hider factor: 13
INFO: Continuing with bootcamp BootcampName.SLOW_HIDER with slow hider factor: 12
INFO: Continuing with bootcamp BootcampName.SLOW_HIDER with slow hider factor: 11
WARNING: No frames in gif to save.
WARNING: No frames in gif to save.
INFO: Number of parameters: 30085
INFO: QNetwork(
  (conv_feature): Sequential()
  (fc_feature): Sequential(
    (0): Linear(in_features=100, out_features=128, bias=True)
    (1): ReLU()
    (2): Linear(in_features=128, out_features=128, bias=True)
    (3): ReLU()
    (4): Linear(in_features=128, out_features=5, bias=True)
  )
)
WARNING: GIF is enabled but the environment does not support RGB array rendering.
INFO: Learning...
INFO: BootcampName.HIDER bootcamp completed, starting BootcampName.SEEKER bootcamp
INFO: BootcampName.SEEKER bootcamp completed, starting BootcampName.SLOW_HIDER bootcamp
INFO: Continuing with bootcamp BootcampName.SLOW_HIDER with slow hider factor: 19
INFO: Continuing with bootcamp BootcampName.SLOW_HIDER with slow hider factor: 18
INFO: Continuing with bootcamp BootcampName.SLOW_HIDER with slow hider factor: 17
INFO: Continuing with bootcamp BootcampName.SLOW_HIDER with slow hider factor: 16
WARNING: No frames in gif to save.
WARNING: No frames in gif to save.
INFO: Continuing with bootcamp BootcampName.SLOW_HIDER with slow hider factor: 15
INFO: Continuing with bootcamp BootcampName.SLOW_HIDER with slow hider factor: 14
INFO: Continuing with bootcamp BootcampName.SLOW_HIDER with slow hider factor: 13
WARNING: No frames in gif to save.
WARNING: No frames in gif to save.
INFO: Continuing with bootcamp BootcampName.SLOW_HIDER with slow hider factor: 12
INFO: Continuing with bootcamp BootcampName.SLOW_HIDER with slow hider factor: 11
INFO: Continuing with bootcamp BootcampName.SLOW_HIDER with slow hider factor: 10
INFO: Continuing with bootcamp BootcampName.SLOW_HIDER with slow hider factor: 9
WARNING: No frames in gif to save.
WARNING: No frames in gif to save.
INFO: Continuing with bootcamp BootcampName.SLOW_HIDER with slow hider factor: 8
INFO: Continuing with bootcamp BootcampName.SLOW_HIDER with slow hider factor: 7
INFO: Continuing with bootcamp BootcampName.SLOW_HIDER with slow hider factor: 6
INFO: Continuing with bootcamp BootcampName.SLOW_HIDER with slow hider factor: 5
WARNING: No frames in gif to save.
WARNING: No frames in gif to save.
INFO: Continuing with bootcamp BootcampName.SLOW_HIDER with slow hider factor: 4
INFO: Continuing with bootcamp BootcampName.SLOW_HIDER with slow hider factor: 3
INFO: Continuing with bootcamp BootcampName.SLOW_HIDER with slow hider factor: 2
INFO: BootcampName.SLOW_HIDER bootcamp completed, starting BootcampName.COMBINED bootcamp
WARNING: No frames in gif to save.
WARNING: No frames in gif to save.
WARNING: No frames in gif to save.
WARNING: No frames in gif to save.
INFO: Number of parameters: 30085
INFO: QNetwork(
  (conv_feature): Sequential()
  (fc_feature): Sequential(
    (0): Linear(in_features=100, out_features=128, bias=True)
    (1): ReLU()
    (2): Linear(in_features=128, out_features=128, bias=True)
    (3): ReLU()
    (4): Linear(in_features=128, out_features=5, bias=True)
  )
)
WARNING: GIF is enabled but the environment does not support RGB array rendering.
INFO: Learning...
INFO: BootcampName.HIDER bootcamp completed, starting BootcampName.SEEKER bootcamp
INFO: Number of parameters: 30085
INFO: QNetwork(
  (conv_feature): Sequential()
  (fc_feature): Sequential(
    (0): Linear(in_features=100, out_features=128, bias=True)
    (1): ReLU()
    (2): Linear(in_features=128, out_features=128, bias=True)
    (3): ReLU()
    (4): Linear(in_features=128, out_features=5, bias=True)
  )
)
WARNING: GIF is enabled but the environment does not support RGB array rendering.
INFO: Learning...
INFO: BootcampName.HIDER bootcamp completed, starting BootcampName.SEEKER bootcamp
INFO: BootcampName.SEEKER bootcamp completed, starting BootcampName.SLOW_HIDER bootcamp
INFO: Continuing with bootcamp BootcampName.SLOW_HIDER with slow hider factor: 19
INFO: Continuing with bootcamp BootcampName.SLOW_HIDER with slow hider factor: 18
INFO: Continuing with bootcamp BootcampName.SLOW_HIDER with slow hider factor: 17
INFO: Continuing with bootcamp BootcampName.SLOW_HIDER with slow hider factor: 16
INFO: Continuing with bootcamp BootcampName.SLOW_HIDER with slow hider factor: 15
INFO: Continuing with bootcamp BootcampName.SLOW_HIDER with slow hider factor: 14
INFO: Continuing with bootcamp BootcampName.SLOW_HIDER with slow hider factor: 13
INFO: Continuing with bootcamp BootcampName.SLOW_HIDER with slow hider factor: 12
WARNING: No frames in gif to save.
WARNING: No frames in gif to save.
INFO: Continuing with bootcamp BootcampName.SLOW_HIDER with slow hider factor: 11
INFO: Continuing with bootcamp BootcampName.SLOW_HIDER with slow hider factor: 10
INFO: Continuing with bootcamp BootcampName.SLOW_HIDER with slow hider factor: 9
INFO: Continuing with bootcamp BootcampName.SLOW_HIDER with slow hider factor: 8
INFO: Continuing with bootcamp BootcampName.SLOW_HIDER with slow hider factor: 7
INFO: Continuing with bootcamp BootcampName.SLOW_HIDER with slow hider factor: 6
INFO: Continuing with bootcamp BootcampName.SLOW_HIDER with slow hider factor: 5
INFO: Continuing with bootcamp BootcampName.SLOW_HIDER with slow hider factor: 4
INFO: Continuing with bootcamp BootcampName.SLOW_HIDER with slow hider factor: 3
WARNING: No frames in gif to save.
WARNING: No frames in gif to save.
INFO: Continuing with bootcamp BootcampName.SLOW_HIDER with slow hider factor: 2
INFO: BootcampName.SLOW_HIDER bootcamp completed, starting BootcampName.COMBINED bootcamp
WARNING: No frames in gif to save.
WARNING: No frames in gif to save.
WARNING: No frames in gif to save.
WARNING: No frames in gif to save.
INFO: Number of parameters: 30085
INFO: QNetwork(
  (conv_feature): Sequential()
  (fc_feature): Sequential(
    (0): Linear(in_features=100, out_features=128, bias=True)
    (1): ReLU()
    (2): Linear(in_features=128, out_features=128, bias=True)
    (3): ReLU()
    (4): Linear(in_features=128, out_features=5, bias=True)
  )
)
WARNING: GIF is enabled but the environment does not support RGB array rendering.
INFO: Learning...
INFO: BootcampName.HIDER bootcamp completed, starting BootcampName.SEEKER bootcamp
INFO: Number of parameters: 30085
INFO: QNetwork(
  (conv_feature): Sequential()
  (fc_feature): Sequential(
    (0): Linear(in_features=100, out_features=128, bias=True)
    (1): ReLU()
    (2): Linear(in_features=128, out_features=128, bias=True)
    (3): ReLU()
    (4): Linear(in_features=128, out_features=5, bias=True)
  )
)
WARNING: GIF is enabled but the environment does not support RGB array rendering.
INFO: Learning...
INFO: BootcampName.HIDER bootcamp completed, starting BootcampName.SEEKER bootcamp
INFO: Number of parameters: 30085
INFO: QNetwork(
  (conv_feature): Sequential()
  (fc_feature): Sequential(
    (0): Linear(in_features=100, out_features=128, bias=True)
    (1): ReLU()
    (2): Linear(in_features=128, out_features=128, bias=True)
    (3): ReLU()
    (4): Linear(in_features=128, out_features=5, bias=True)
  )
)
WARNING: GIF is enabled but the environment does not support RGB array rendering.
INFO: Learning...
INFO: BootcampName.HIDER bootcamp completed, starting BootcampName.SEEKER bootcamp
ERROR: You must call wandb.init() before wandb.log()
ERROR: Traceback (most recent call last):
  File "/home/eirik/Projects/XAI/rl/src/dqn/wrapper/multi_agent_dqn.py", line 106, in learn
    self.wandb_manager.log(log)
  File "/home/eirik/Projects/XAI/rl/src/managers/wandb_manager.py", line 59, in log
    wandb.log(data)
  File "/home/eirik/.cache/pypoetry/virtualenvs/xai-is73Zs3s-py3.11/lib/python3.11/site-packages/wandb/sdk/lib/preinit.py", line 36, in preinit_wrapper
    raise wandb.Error(f"You must call wandb.init() before {name}()")
wandb.errors.errors.Error: You must call wandb.init() before wandb.log()

WARNING: Error: Could not find wandb directory: ./wandb
WARNING: Error: Could not find wandb directory: ./wandb
ERROR: You must call wandb.init() before wandb.log()
ERROR: Traceback (most recent call last):
  File "/home/eirik/Projects/XAI/rl/src/dqn/wrapper/multi_agent_dqn.py", line 106, in learn
    self.wandb_manager.log(log)
  File "/home/eirik/Projects/XAI/rl/src/managers/wandb_manager.py", line 59, in log
    wandb.log(data)
  File "/home/eirik/.cache/pypoetry/virtualenvs/xai-is73Zs3s-py3.11/lib/python3.11/site-packages/wandb/sdk/lib/preinit.py", line 36, in preinit_wrapper
    raise wandb.Error(f"You must call wandb.init() before {name}()")
wandb.errors.errors.Error: You must call wandb.init() before wandb.log()

WARNING: Error: Could not find wandb directory: ./wandb
WARNING: Error: Could not find wandb directory: ./wandb
INFO: Number of parameters: 30085
INFO: QNetwork(
  (conv_feature): Sequential()
  (fc_feature): Sequential(
    (0): Linear(in_features=100, out_features=128, bias=True)
    (1): ReLU()
    (2): Linear(in_features=128, out_features=128, bias=True)
    (3): ReLU()
    (4): Linear(in_features=128, out_features=5, bias=True)
  )
)
WARNING: GIF is enabled but the environment does not support RGB array rendering.
INFO: Learning...
INFO: BootcampName.HIDER bootcamp completed, starting BootcampName.SEEKER bootcamp
ERROR: You must call wandb.init() before wandb.log()
ERROR: Traceback (most recent call last):
  File "/home/eirik/Projects/XAI/rl/src/dqn/wrapper/multi_agent_dqn.py", line 106, in learn
    self.wandb_manager.log(log)
  File "/home/eirik/Projects/XAI/rl/src/managers/wandb_manager.py", line 59, in log
    wandb.log(data)
  File "/home/eirik/.cache/pypoetry/virtualenvs/xai-is73Zs3s-py3.11/lib/python3.11/site-packages/wandb/sdk/lib/preinit.py", line 36, in preinit_wrapper
    raise wandb.Error(f"You must call wandb.init() before {name}()")
wandb.errors.errors.Error: You must call wandb.init() before wandb.log()

WARNING: Error: Could not find wandb directory: ./wandb
WARNING: Error: Could not find wandb directory: ./wandb
ERROR: You must call wandb.init() before wandb.log()
ERROR: Traceback (most recent call last):
  File "/home/eirik/Projects/XAI/rl/src/dqn/wrapper/multi_agent_dqn.py", line 106, in learn
    self.wandb_manager.log(log)
  File "/home/eirik/Projects/XAI/rl/src/managers/wandb_manager.py", line 59, in log
    wandb.log(data)
  File "/home/eirik/.cache/pypoetry/virtualenvs/xai-is73Zs3s-py3.11/lib/python3.11/site-packages/wandb/sdk/lib/preinit.py", line 36, in preinit_wrapper
    raise wandb.Error(f"You must call wandb.init() before {name}()")
wandb.errors.errors.Error: You must call wandb.init() before wandb.log()

WARNING: Error: Could not find wandb directory: ./wandb
WARNING: Error: Could not find wandb directory: ./wandb
ERROR: You must call wandb.init() before wandb.log()
ERROR: Traceback (most recent call last):
  File "/home/eirik/Projects/XAI/rl/src/dqn/wrapper/multi_agent_dqn.py", line 106, in learn
    self.wandb_manager.log(log)
  File "/home/eirik/Projects/XAI/rl/src/managers/wandb_manager.py", line 59, in log
    wandb.log(data)
  File "/home/eirik/.cache/pypoetry/virtualenvs/xai-is73Zs3s-py3.11/lib/python3.11/site-packages/wandb/sdk/lib/preinit.py", line 36, in preinit_wrapper
    raise wandb.Error(f"You must call wandb.init() before {name}()")
wandb.errors.errors.Error: You must call wandb.init() before wandb.log()

WARNING: Error: Could not find wandb directory: ./wandb
WARNING: Error: Could not find wandb directory: ./wandb
ERROR: You must call wandb.init() before wandb.log()
ERROR: Traceback (most recent call last):
  File "/home/eirik/Projects/XAI/rl/src/dqn/wrapper/multi_agent_dqn.py", line 106, in learn
    self.wandb_manager.log(log)
  File "/home/eirik/Projects/XAI/rl/src/managers/wandb_manager.py", line 59, in log
    wandb.log(data)
  File "/home/eirik/.cache/pypoetry/virtualenvs/xai-is73Zs3s-py3.11/lib/python3.11/site-packages/wandb/sdk/lib/preinit.py", line 36, in preinit_wrapper
    raise wandb.Error(f"You must call wandb.init() before {name}()")
wandb.errors.errors.Error: You must call wandb.init() before wandb.log()

WARNING: Error: Could not find wandb directory: ./wandb
WARNING: Error: Could not find wandb directory: ./wandb
ERROR: You must call wandb.init() before wandb.log()
ERROR: Traceback (most recent call last):
  File "/home/eirik/Projects/XAI/rl/src/dqn/wrapper/multi_agent_dqn.py", line 106, in learn
    self.wandb_manager.log(log)
  File "/home/eirik/Projects/XAI/rl/src/managers/wandb_manager.py", line 59, in log
    wandb.log(data)
  File "/home/eirik/.cache/pypoetry/virtualenvs/xai-is73Zs3s-py3.11/lib/python3.11/site-packages/wandb/sdk/lib/preinit.py", line 36, in preinit_wrapper
    raise wandb.Error(f"You must call wandb.init() before {name}()")
wandb.errors.errors.Error: You must call wandb.init() before wandb.log()

WARNING: Error: Could not find wandb directory: ./wandb
WARNING: Error: Could not find wandb directory: ./wandb
INFO: BootcampName.SEEKER bootcamp completed, starting BootcampName.SLOW_HIDER bootcamp
ERROR: You must call wandb.init() before wandb.log()
ERROR: Traceback (most recent call last):
  File "/home/eirik/Projects/XAI/rl/src/dqn/wrapper/multi_agent_dqn.py", line 106, in learn
    self.wandb_manager.log(log)
  File "/home/eirik/Projects/XAI/rl/src/managers/wandb_manager.py", line 59, in log
    wandb.log(data)
  File "/home/eirik/.cache/pypoetry/virtualenvs/xai-is73Zs3s-py3.11/lib/python3.11/site-packages/wandb/sdk/lib/preinit.py", line 36, in preinit_wrapper
    raise wandb.Error(f"You must call wandb.init() before {name}()")
wandb.errors.errors.Error: You must call wandb.init() before wandb.log()

WARNING: Error: Could not find wandb directory: ./wandb
WARNING: Error: Could not find wandb directory: ./wandb
ERROR: You must call wandb.init() before wandb.log()
ERROR: Traceback (most recent call last):
  File "/home/eirik/Projects/XAI/rl/src/dqn/wrapper/multi_agent_dqn.py", line 106, in learn
    self.wandb_manager.log(log)
  File "/home/eirik/Projects/XAI/rl/src/managers/wandb_manager.py", line 59, in log
    wandb.log(data)
  File "/home/eirik/.cache/pypoetry/virtualenvs/xai-is73Zs3s-py3.11/lib/python3.11/site-packages/wandb/sdk/lib/preinit.py", line 36, in preinit_wrapper
    raise wandb.Error(f"You must call wandb.init() before {name}()")
wandb.errors.errors.Error: You must call wandb.init() before wandb.log()

WARNING: Error: Could not find wandb directory: ./wandb
WARNING: Error: Could not find wandb directory: ./wandb
ERROR: You must call wandb.init() before wandb.log()
ERROR: Traceback (most recent call last):
  File "/home/eirik/Projects/XAI/rl/src/dqn/wrapper/multi_agent_dqn.py", line 106, in learn
    self.wandb_manager.log(log)
  File "/home/eirik/Projects/XAI/rl/src/managers/wandb_manager.py", line 59, in log
    wandb.log(data)
  File "/home/eirik/.cache/pypoetry/virtualenvs/xai-is73Zs3s-py3.11/lib/python3.11/site-packages/wandb/sdk/lib/preinit.py", line 36, in preinit_wrapper
    raise wandb.Error(f"You must call wandb.init() before {name}()")
wandb.errors.errors.Error: You must call wandb.init() before wandb.log()

WARNING: Error: Could not find wandb directory: ./wandb
WARNING: Error: Could not find wandb directory: ./wandb
ERROR: You must call wandb.init() before wandb.log()
ERROR: Traceback (most recent call last):
  File "/home/eirik/Projects/XAI/rl/src/dqn/wrapper/multi_agent_dqn.py", line 106, in learn
    self.wandb_manager.log(log)
  File "/home/eirik/Projects/XAI/rl/src/managers/wandb_manager.py", line 59, in log
    wandb.log(data)
  File "/home/eirik/.cache/pypoetry/virtualenvs/xai-is73Zs3s-py3.11/lib/python3.11/site-packages/wandb/sdk/lib/preinit.py", line 36, in preinit_wrapper
    raise wandb.Error(f"You must call wandb.init() before {name}()")
wandb.errors.errors.Error: You must call wandb.init() before wandb.log()

WARNING: Error: Could not find wandb directory: ./wandb
WARNING: Error: Could not find wandb directory: ./wandb
ERROR: You must call wandb.init() before wandb.log()
ERROR: Traceback (most recent call last):
  File "/home/eirik/Projects/XAI/rl/src/dqn/wrapper/multi_agent_dqn.py", line 106, in learn
    self.wandb_manager.log(log)
  File "/home/eirik/Projects/XAI/rl/src/managers/wandb_manager.py", line 59, in log
    wandb.log(data)
  File "/home/eirik/.cache/pypoetry/virtualenvs/xai-is73Zs3s-py3.11/lib/python3.11/site-packages/wandb/sdk/lib/preinit.py", line 36, in preinit_wrapper
    raise wandb.Error(f"You must call wandb.init() before {name}()")
wandb.errors.errors.Error: You must call wandb.init() before wandb.log()

WARNING: Error: Could not find wandb directory: ./wandb
WARNING: Error: Could not find wandb directory: ./wandb
INFO: Continuing with bootcamp BootcampName.SLOW_HIDER with slow factor: 20
ERROR: You must call wandb.init() before wandb.log()
ERROR: Traceback (most recent call last):
  File "/home/eirik/Projects/XAI/rl/src/dqn/wrapper/multi_agent_dqn.py", line 106, in learn
    self.wandb_manager.log(log)
  File "/home/eirik/Projects/XAI/rl/src/managers/wandb_manager.py", line 59, in log
    wandb.log(data)
  File "/home/eirik/.cache/pypoetry/virtualenvs/xai-is73Zs3s-py3.11/lib/python3.11/site-packages/wandb/sdk/lib/preinit.py", line 36, in preinit_wrapper
    raise wandb.Error(f"You must call wandb.init() before {name}()")
wandb.errors.errors.Error: You must call wandb.init() before wandb.log()

WARNING: Error: Could not find wandb directory: ./wandb
WARNING: Error: Could not find wandb directory: ./wandb
ERROR: You must call wandb.init() before wandb.log()
ERROR: Traceback (most recent call last):
  File "/home/eirik/Projects/XAI/rl/src/dqn/wrapper/multi_agent_dqn.py", line 106, in learn
    self.wandb_manager.log(log)
  File "/home/eirik/Projects/XAI/rl/src/managers/wandb_manager.py", line 59, in log
    wandb.log(data)
  File "/home/eirik/.cache/pypoetry/virtualenvs/xai-is73Zs3s-py3.11/lib/python3.11/site-packages/wandb/sdk/lib/preinit.py", line 36, in preinit_wrapper
    raise wandb.Error(f"You must call wandb.init() before {name}()")
wandb.errors.errors.Error: You must call wandb.init() before wandb.log()

WARNING: Error: Could not find wandb directory: ./wandb
WARNING: Error: Could not find wandb directory: ./wandb
ERROR: You must call wandb.init() before wandb.log()
ERROR: Traceback (most recent call last):
  File "/home/eirik/Projects/XAI/rl/src/dqn/wrapper/multi_agent_dqn.py", line 106, in learn
    self.wandb_manager.log(log)
  File "/home/eirik/Projects/XAI/rl/src/managers/wandb_manager.py", line 59, in log
    wandb.log(data)
  File "/home/eirik/.cache/pypoetry/virtualenvs/xai-is73Zs3s-py3.11/lib/python3.11/site-packages/wandb/sdk/lib/preinit.py", line 36, in preinit_wrapper
    raise wandb.Error(f"You must call wandb.init() before {name}()")
wandb.errors.errors.Error: You must call wandb.init() before wandb.log()

WARNING: Error: Could not find wandb directory: ./wandb
WARNING: Error: Could not find wandb directory: ./wandb
ERROR: You must call wandb.init() before wandb.log()
ERROR: Traceback (most recent call last):
  File "/home/eirik/Projects/XAI/rl/src/dqn/wrapper/multi_agent_dqn.py", line 106, in learn
    self.wandb_manager.log(log)
  File "/home/eirik/Projects/XAI/rl/src/managers/wandb_manager.py", line 59, in log
    wandb.log(data)
  File "/home/eirik/.cache/pypoetry/virtualenvs/xai-is73Zs3s-py3.11/lib/python3.11/site-packages/wandb/sdk/lib/preinit.py", line 36, in preinit_wrapper
    raise wandb.Error(f"You must call wandb.init() before {name}()")
wandb.errors.errors.Error: You must call wandb.init() before wandb.log()

WARNING: Error: Could not find wandb directory: ./wandb
WARNING: Error: Could not find wandb directory: ./wandb
ERROR: You must call wandb.init() before wandb.log()
ERROR: Traceback (most recent call last):
  File "/home/eirik/Projects/XAI/rl/src/dqn/wrapper/multi_agent_dqn.py", line 106, in learn
    self.wandb_manager.log(log)
  File "/home/eirik/Projects/XAI/rl/src/managers/wandb_manager.py", line 59, in log
    wandb.log(data)
  File "/home/eirik/.cache/pypoetry/virtualenvs/xai-is73Zs3s-py3.11/lib/python3.11/site-packages/wandb/sdk/lib/preinit.py", line 36, in preinit_wrapper
    raise wandb.Error(f"You must call wandb.init() before {name}()")
wandb.errors.errors.Error: You must call wandb.init() before wandb.log()

WARNING: Error: Could not find wandb directory: ./wandb
WARNING: Error: Could not find wandb directory: ./wandb
ERROR: You must call wandb.init() before wandb.log()
ERROR: Traceback (most recent call last):
  File "/home/eirik/Projects/XAI/rl/src/dqn/wrapper/multi_agent_dqn.py", line 106, in learn
    self.wandb_manager.log(log)
  File "/home/eirik/Projects/XAI/rl/src/managers/wandb_manager.py", line 59, in log
    wandb.log(data)
  File "/home/eirik/.cache/pypoetry/virtualenvs/xai-is73Zs3s-py3.11/lib/python3.11/site-packages/wandb/sdk/lib/preinit.py", line 36, in preinit_wrapper
    raise wandb.Error(f"You must call wandb.init() before {name}()")
wandb.errors.errors.Error: You must call wandb.init() before wandb.log()

WARNING: Error: Could not find wandb directory: ./wandb
WARNING: Error: Could not find wandb directory: ./wandb
ERROR: You must call wandb.init() before wandb.log()
ERROR: Traceback (most recent call last):
  File "/home/eirik/Projects/XAI/rl/src/dqn/wrapper/multi_agent_dqn.py", line 106, in learn
    self.wandb_manager.log(log)
  File "/home/eirik/Projects/XAI/rl/src/managers/wandb_manager.py", line 59, in log
    wandb.log(data)
  File "/home/eirik/.cache/pypoetry/virtualenvs/xai-is73Zs3s-py3.11/lib/python3.11/site-packages/wandb/sdk/lib/preinit.py", line 36, in preinit_wrapper
    raise wandb.Error(f"You must call wandb.init() before {name}()")
wandb.errors.errors.Error: You must call wandb.init() before wandb.log()

WARNING: Error: Could not find wandb directory: ./wandb
WARNING: Error: Could not find wandb directory: ./wandb
INFO: Continuing with bootcamp BootcampName.SLOW_HIDER with slow factor: 20
ERROR: You must call wandb.init() before wandb.log()
ERROR: Traceback (most recent call last):
  File "/home/eirik/Projects/XAI/rl/src/dqn/wrapper/multi_agent_dqn.py", line 106, in learn
    self.wandb_manager.log(log)
  File "/home/eirik/Projects/XAI/rl/src/managers/wandb_manager.py", line 59, in log
    wandb.log(data)
  File "/home/eirik/.cache/pypoetry/virtualenvs/xai-is73Zs3s-py3.11/lib/python3.11/site-packages/wandb/sdk/lib/preinit.py", line 36, in preinit_wrapper
    raise wandb.Error(f"You must call wandb.init() before {name}()")
wandb.errors.errors.Error: You must call wandb.init() before wandb.log()

WARNING: Error: Could not find wandb directory: ./wandb
WARNING: Error: Could not find wandb directory: ./wandb
ERROR: You must call wandb.init() before wandb.log()
ERROR: Traceback (most recent call last):
  File "/home/eirik/Projects/XAI/rl/src/dqn/wrapper/multi_agent_dqn.py", line 106, in learn
    self.wandb_manager.log(log)
  File "/home/eirik/Projects/XAI/rl/src/managers/wandb_manager.py", line 59, in log
    wandb.log(data)
  File "/home/eirik/.cache/pypoetry/virtualenvs/xai-is73Zs3s-py3.11/lib/python3.11/site-packages/wandb/sdk/lib/preinit.py", line 36, in preinit_wrapper
    raise wandb.Error(f"You must call wandb.init() before {name}()")
wandb.errors.errors.Error: You must call wandb.init() before wandb.log()

WARNING: Error: Could not find wandb directory: ./wandb
WARNING: Error: Could not find wandb directory: ./wandb
ERROR: You must call wandb.init() before wandb.log()
ERROR: Traceback (most recent call last):
  File "/home/eirik/Projects/XAI/rl/src/dqn/wrapper/multi_agent_dqn.py", line 106, in learn
    self.wandb_manager.log(log)
  File "/home/eirik/Projects/XAI/rl/src/managers/wandb_manager.py", line 59, in log
    wandb.log(data)
  File "/home/eirik/.cache/pypoetry/virtualenvs/xai-is73Zs3s-py3.11/lib/python3.11/site-packages/wandb/sdk/lib/preinit.py", line 36, in preinit_wrapper
    raise wandb.Error(f"You must call wandb.init() before {name}()")
wandb.errors.errors.Error: You must call wandb.init() before wandb.log()

WARNING: Error: Could not find wandb directory: ./wandb
WARNING: Error: Could not find wandb directory: ./wandb
ERROR: You must call wandb.init() before wandb.log()
ERROR: Traceback (most recent call last):
  File "/home/eirik/Projects/XAI/rl/src/dqn/wrapper/multi_agent_dqn.py", line 106, in learn
    self.wandb_manager.log(log)
  File "/home/eirik/Projects/XAI/rl/src/managers/wandb_manager.py", line 59, in log
    wandb.log(data)
  File "/home/eirik/.cache/pypoetry/virtualenvs/xai-is73Zs3s-py3.11/lib/python3.11/site-packages/wandb/sdk/lib/preinit.py", line 36, in preinit_wrapper
    raise wandb.Error(f"You must call wandb.init() before {name}()")
wandb.errors.errors.Error: You must call wandb.init() before wandb.log()

WARNING: Error: Could not find wandb directory: ./wandb
WARNING: Error: Could not find wandb directory: ./wandb
ERROR: You must call wandb.init() before wandb.log()
ERROR: Traceback (most recent call last):
  File "/home/eirik/Projects/XAI/rl/src/dqn/wrapper/multi_agent_dqn.py", line 106, in learn
    self.wandb_manager.log(log)
  File "/home/eirik/Projects/XAI/rl/src/managers/wandb_manager.py", line 59, in log
    wandb.log(data)
  File "/home/eirik/.cache/pypoetry/virtualenvs/xai-is73Zs3s-py3.11/lib/python3.11/site-packages/wandb/sdk/lib/preinit.py", line 36, in preinit_wrapper
    raise wandb.Error(f"You must call wandb.init() before {name}()")
wandb.errors.errors.Error: You must call wandb.init() before wandb.log()

WARNING: Error: Could not find wandb directory: ./wandb
WARNING: Error: Could not find wandb directory: ./wandb
ERROR: You must call wandb.init() before wandb.log()
ERROR: Traceback (most recent call last):
  File "/home/eirik/Projects/XAI/rl/src/dqn/wrapper/multi_agent_dqn.py", line 106, in learn
    self.wandb_manager.log(log)
  File "/home/eirik/Projects/XAI/rl/src/managers/wandb_manager.py", line 59, in log
    wandb.log(data)
  File "/home/eirik/.cache/pypoetry/virtualenvs/xai-is73Zs3s-py3.11/lib/python3.11/site-packages/wandb/sdk/lib/preinit.py", line 36, in preinit_wrapper
    raise wandb.Error(f"You must call wandb.init() before {name}()")
wandb.errors.errors.Error: You must call wandb.init() before wandb.log()

WARNING: Error: Could not find wandb directory: ./wandb
WARNING: Error: Could not find wandb directory: ./wandb
ERROR: You must call wandb.init() before wandb.log()
ERROR: Traceback (most recent call last):
  File "/home/eirik/Projects/XAI/rl/src/dqn/wrapper/multi_agent_dqn.py", line 106, in learn
    self.wandb_manager.log(log)
  File "/home/eirik/Projects/XAI/rl/src/managers/wandb_manager.py", line 59, in log
    wandb.log(data)
  File "/home/eirik/.cache/pypoetry/virtualenvs/xai-is73Zs3s-py3.11/lib/python3.11/site-packages/wandb/sdk/lib/preinit.py", line 36, in preinit_wrapper
    raise wandb.Error(f"You must call wandb.init() before {name}()")
wandb.errors.errors.Error: You must call wandb.init() before wandb.log()

WARNING: Error: Could not find wandb directory: ./wandb
WARNING: Error: Could not find wandb directory: ./wandb
ERROR: You must call wandb.init() before wandb.log()
ERROR: Traceback (most recent call last):
  File "/home/eirik/Projects/XAI/rl/src/dqn/wrapper/multi_agent_dqn.py", line 106, in learn
    self.wandb_manager.log(log)
  File "/home/eirik/Projects/XAI/rl/src/managers/wandb_manager.py", line 59, in log
    wandb.log(data)
  File "/home/eirik/.cache/pypoetry/virtualenvs/xai-is73Zs3s-py3.11/lib/python3.11/site-packages/wandb/sdk/lib/preinit.py", line 36, in preinit_wrapper
    raise wandb.Error(f"You must call wandb.init() before {name}()")
wandb.errors.errors.Error: You must call wandb.init() before wandb.log()

WARNING: Error: Could not find wandb directory: ./wandb
WARNING: Error: Could not find wandb directory: ./wandb
ERROR: You must call wandb.init() before wandb.log()
ERROR: Traceback (most recent call last):
  File "/home/eirik/Projects/XAI/rl/src/dqn/wrapper/multi_agent_dqn.py", line 106, in learn
    self.wandb_manager.log(log)
  File "/home/eirik/Projects/XAI/rl/src/managers/wandb_manager.py", line 59, in log
    wandb.log(data)
  File "/home/eirik/.cache/pypoetry/virtualenvs/xai-is73Zs3s-py3.11/lib/python3.11/site-packages/wandb/sdk/lib/preinit.py", line 36, in preinit_wrapper
    raise wandb.Error(f"You must call wandb.init() before {name}()")
wandb.errors.errors.Error: You must call wandb.init() before wandb.log()

WARNING: Error: Could not find wandb directory: ./wandb
WARNING: Error: Could not find wandb directory: ./wandb
INFO: Continuing with bootcamp BootcampName.SLOW_HIDER with slow factor: 20
ERROR: You must call wandb.init() before wandb.log()
ERROR: Traceback (most recent call last):
  File "/home/eirik/Projects/XAI/rl/src/dqn/wrapper/multi_agent_dqn.py", line 106, in learn
    self.wandb_manager.log(log)
  File "/home/eirik/Projects/XAI/rl/src/managers/wandb_manager.py", line 59, in log
    wandb.log(data)
  File "/home/eirik/.cache/pypoetry/virtualenvs/xai-is73Zs3s-py3.11/lib/python3.11/site-packages/wandb/sdk/lib/preinit.py", line 36, in preinit_wrapper
    raise wandb.Error(f"You must call wandb.init() before {name}()")
wandb.errors.errors.Error: You must call wandb.init() before wandb.log()

WARNING: Error: Could not find wandb directory: ./wandb
WARNING: Error: Could not find wandb directory: ./wandb
ERROR: You must call wandb.init() before wandb.log()
ERROR: Traceback (most recent call last):
  File "/home/eirik/Projects/XAI/rl/src/dqn/wrapper/multi_agent_dqn.py", line 106, in learn
    self.wandb_manager.log(log)
  File "/home/eirik/Projects/XAI/rl/src/managers/wandb_manager.py", line 59, in log
    wandb.log(data)
  File "/home/eirik/.cache/pypoetry/virtualenvs/xai-is73Zs3s-py3.11/lib/python3.11/site-packages/wandb/sdk/lib/preinit.py", line 36, in preinit_wrapper
    raise wandb.Error(f"You must call wandb.init() before {name}()")
wandb.errors.errors.Error: You must call wandb.init() before wandb.log()

WARNING: Error: Could not find wandb directory: ./wandb
WARNING: Error: Could not find wandb directory: ./wandb
ERROR: You must call wandb.init() before wandb.log()
ERROR: Traceback (most recent call last):
  File "/home/eirik/Projects/XAI/rl/src/dqn/wrapper/multi_agent_dqn.py", line 106, in learn
    self.wandb_manager.log(log)
  File "/home/eirik/Projects/XAI/rl/src/managers/wandb_manager.py", line 59, in log
    wandb.log(data)
  File "/home/eirik/.cache/pypoetry/virtualenvs/xai-is73Zs3s-py3.11/lib/python3.11/site-packages/wandb/sdk/lib/preinit.py", line 36, in preinit_wrapper
    raise wandb.Error(f"You must call wandb.init() before {name}()")
wandb.errors.errors.Error: You must call wandb.init() before wandb.log()

WARNING: Error: Could not find wandb directory: ./wandb
WARNING: Error: Could not find wandb directory: ./wandb
ERROR: You must call wandb.init() before wandb.log()
ERROR: Traceback (most recent call last):
  File "/home/eirik/Projects/XAI/rl/src/dqn/wrapper/multi_agent_dqn.py", line 106, in learn
    self.wandb_manager.log(log)
  File "/home/eirik/Projects/XAI/rl/src/managers/wandb_manager.py", line 59, in log
    wandb.log(data)
  File "/home/eirik/.cache/pypoetry/virtualenvs/xai-is73Zs3s-py3.11/lib/python3.11/site-packages/wandb/sdk/lib/preinit.py", line 36, in preinit_wrapper
    raise wandb.Error(f"You must call wandb.init() before {name}()")
wandb.errors.errors.Error: You must call wandb.init() before wandb.log()

WARNING: Error: Could not find wandb directory: ./wandb
WARNING: Error: Could not find wandb directory: ./wandb
ERROR: You must call wandb.init() before wandb.log()
ERROR: Traceback (most recent call last):
  File "/home/eirik/Projects/XAI/rl/src/dqn/wrapper/multi_agent_dqn.py", line 106, in learn
    self.wandb_manager.log(log)
  File "/home/eirik/Projects/XAI/rl/src/managers/wandb_manager.py", line 59, in log
    wandb.log(data)
  File "/home/eirik/.cache/pypoetry/virtualenvs/xai-is73Zs3s-py3.11/lib/python3.11/site-packages/wandb/sdk/lib/preinit.py", line 36, in preinit_wrapper
    raise wandb.Error(f"You must call wandb.init() before {name}()")
wandb.errors.errors.Error: You must call wandb.init() before wandb.log()

WARNING: Error: Could not find wandb directory: ./wandb
WARNING: Error: Could not find wandb directory: ./wandb
INFO: Continuing with bootcamp BootcampName.SLOW_HIDER with slow factor: 20
ERROR: You must call wandb.init() before wandb.log()
ERROR: Traceback (most recent call last):
  File "/home/eirik/Projects/XAI/rl/src/dqn/wrapper/multi_agent_dqn.py", line 106, in learn
    self.wandb_manager.log(log)
  File "/home/eirik/Projects/XAI/rl/src/managers/wandb_manager.py", line 59, in log
    wandb.log(data)
  File "/home/eirik/.cache/pypoetry/virtualenvs/xai-is73Zs3s-py3.11/lib/python3.11/site-packages/wandb/sdk/lib/preinit.py", line 36, in preinit_wrapper
    raise wandb.Error(f"You must call wandb.init() before {name}()")
wandb.errors.errors.Error: You must call wandb.init() before wandb.log()

WARNING: Error: Could not find wandb directory: ./wandb
WARNING: Error: Could not find wandb directory: ./wandb
ERROR: You must call wandb.init() before wandb.log()
ERROR: Traceback (most recent call last):
  File "/home/eirik/Projects/XAI/rl/src/dqn/wrapper/multi_agent_dqn.py", line 106, in learn
    self.wandb_manager.log(log)
  File "/home/eirik/Projects/XAI/rl/src/managers/wandb_manager.py", line 59, in log
    wandb.log(data)
  File "/home/eirik/.cache/pypoetry/virtualenvs/xai-is73Zs3s-py3.11/lib/python3.11/site-packages/wandb/sdk/lib/preinit.py", line 36, in preinit_wrapper
    raise wandb.Error(f"You must call wandb.init() before {name}()")
wandb.errors.errors.Error: You must call wandb.init() before wandb.log()

WARNING: Error: Could not find wandb directory: ./wandb
WARNING: Error: Could not find wandb directory: ./wandb
ERROR: You must call wandb.init() before wandb.log()
ERROR: Traceback (most recent call last):
  File "/home/eirik/Projects/XAI/rl/src/dqn/wrapper/multi_agent_dqn.py", line 106, in learn
    self.wandb_manager.log(log)
  File "/home/eirik/Projects/XAI/rl/src/managers/wandb_manager.py", line 59, in log
    wandb.log(data)
  File "/home/eirik/.cache/pypoetry/virtualenvs/xai-is73Zs3s-py3.11/lib/python3.11/site-packages/wandb/sdk/lib/preinit.py", line 36, in preinit_wrapper
    raise wandb.Error(f"You must call wandb.init() before {name}()")
wandb.errors.errors.Error: You must call wandb.init() before wandb.log()

WARNING: Error: Could not find wandb directory: ./wandb
WARNING: Error: Could not find wandb directory: ./wandb
ERROR: You must call wandb.init() before wandb.log()
ERROR: Traceback (most recent call last):
  File "/home/eirik/Projects/XAI/rl/src/dqn/wrapper/multi_agent_dqn.py", line 106, in learn
    self.wandb_manager.log(log)
  File "/home/eirik/Projects/XAI/rl/src/managers/wandb_manager.py", line 59, in log
    wandb.log(data)
  File "/home/eirik/.cache/pypoetry/virtualenvs/xai-is73Zs3s-py3.11/lib/python3.11/site-packages/wandb/sdk/lib/preinit.py", line 36, in preinit_wrapper
    raise wandb.Error(f"You must call wandb.init() before {name}()")
wandb.errors.errors.Error: You must call wandb.init() before wandb.log()

WARNING: Error: Could not find wandb directory: ./wandb
WARNING: Error: Could not find wandb directory: ./wandb
ERROR: You must call wandb.init() before wandb.log()
ERROR: Traceback (most recent call last):
  File "/home/eirik/Projects/XAI/rl/src/dqn/wrapper/multi_agent_dqn.py", line 106, in learn
    self.wandb_manager.log(log)
  File "/home/eirik/Projects/XAI/rl/src/managers/wandb_manager.py", line 59, in log
    wandb.log(data)
  File "/home/eirik/.cache/pypoetry/virtualenvs/xai-is73Zs3s-py3.11/lib/python3.11/site-packages/wandb/sdk/lib/preinit.py", line 36, in preinit_wrapper
    raise wandb.Error(f"You must call wandb.init() before {name}()")
wandb.errors.errors.Error: You must call wandb.init() before wandb.log()

WARNING: Error: Could not find wandb directory: ./wandb
WARNING: Error: Could not find wandb directory: ./wandb
ERROR: You must call wandb.init() before wandb.log()
ERROR: Traceback (most recent call last):
  File "/home/eirik/Projects/XAI/rl/src/dqn/wrapper/multi_agent_dqn.py", line 106, in learn
    self.wandb_manager.log(log)
  File "/home/eirik/Projects/XAI/rl/src/managers/wandb_manager.py", line 59, in log
    wandb.log(data)
  File "/home/eirik/.cache/pypoetry/virtualenvs/xai-is73Zs3s-py3.11/lib/python3.11/site-packages/wandb/sdk/lib/preinit.py", line 36, in preinit_wrapper
    raise wandb.Error(f"You must call wandb.init() before {name}()")
wandb.errors.errors.Error: You must call wandb.init() before wandb.log()

WARNING: Error: Could not find wandb directory: ./wandb
WARNING: Error: Could not find wandb directory: ./wandb
ERROR: You must call wandb.init() before wandb.log()
ERROR: Traceback (most recent call last):
  File "/home/eirik/Projects/XAI/rl/src/dqn/wrapper/multi_agent_dqn.py", line 106, in learn
    self.wandb_manager.log(log)
  File "/home/eirik/Projects/XAI/rl/src/managers/wandb_manager.py", line 59, in log
    wandb.log(data)
  File "/home/eirik/.cache/pypoetry/virtualenvs/xai-is73Zs3s-py3.11/lib/python3.11/site-packages/wandb/sdk/lib/preinit.py", line 36, in preinit_wrapper
    raise wandb.Error(f"You must call wandb.init() before {name}()")
wandb.errors.errors.Error: You must call wandb.init() before wandb.log()

WARNING: Error: Could not find wandb directory: ./wandb
WARNING: Error: Could not find wandb directory: ./wandb
ERROR: You must call wandb.init() before wandb.log()
ERROR: Traceback (most recent call last):
  File "/home/eirik/Projects/XAI/rl/src/dqn/wrapper/multi_agent_dqn.py", line 106, in learn
    self.wandb_manager.log(log)
  File "/home/eirik/Projects/XAI/rl/src/managers/wandb_manager.py", line 59, in log
    wandb.log(data)
  File "/home/eirik/.cache/pypoetry/virtualenvs/xai-is73Zs3s-py3.11/lib/python3.11/site-packages/wandb/sdk/lib/preinit.py", line 36, in preinit_wrapper
    raise wandb.Error(f"You must call wandb.init() before {name}()")
wandb.errors.errors.Error: You must call wandb.init() before wandb.log()

WARNING: Error: Could not find wandb directory: ./wandb
WARNING: Error: Could not find wandb directory: ./wandb
ERROR: You must call wandb.init() before wandb.log()
ERROR: Traceback (most recent call last):
  File "/home/eirik/Projects/XAI/rl/src/dqn/wrapper/multi_agent_dqn.py", line 106, in learn
    self.wandb_manager.log(log)
  File "/home/eirik/Projects/XAI/rl/src/managers/wandb_manager.py", line 59, in log
    wandb.log(data)
  File "/home/eirik/.cache/pypoetry/virtualenvs/xai-is73Zs3s-py3.11/lib/python3.11/site-packages/wandb/sdk/lib/preinit.py", line 36, in preinit_wrapper
    raise wandb.Error(f"You must call wandb.init() before {name}()")
wandb.errors.errors.Error: You must call wandb.init() before wandb.log()

WARNING: Error: Could not find wandb directory: ./wandb
WARNING: Error: Could not find wandb directory: ./wandb
ERROR: You must call wandb.init() before wandb.log()
ERROR: Traceback (most recent call last):
  File "/home/eirik/Projects/XAI/rl/src/dqn/wrapper/multi_agent_dqn.py", line 106, in learn
    self.wandb_manager.log(log)
  File "/home/eirik/Projects/XAI/rl/src/managers/wandb_manager.py", line 59, in log
    wandb.log(data)
  File "/home/eirik/.cache/pypoetry/virtualenvs/xai-is73Zs3s-py3.11/lib/python3.11/site-packages/wandb/sdk/lib/preinit.py", line 36, in preinit_wrapper
    raise wandb.Error(f"You must call wandb.init() before {name}()")
wandb.errors.errors.Error: You must call wandb.init() before wandb.log()

WARNING: Error: Could not find wandb directory: ./wandb
WARNING: Error: Could not find wandb directory: ./wandb
INFO: Continuing with bootcamp BootcampName.SLOW_HIDER with slow factor: 20
ERROR: You must call wandb.init() before wandb.log()
ERROR: Traceback (most recent call last):
  File "/home/eirik/Projects/XAI/rl/src/dqn/wrapper/multi_agent_dqn.py", line 106, in learn
    self.wandb_manager.log(log)
  File "/home/eirik/Projects/XAI/rl/src/managers/wandb_manager.py", line 59, in log
    wandb.log(data)
  File "/home/eirik/.cache/pypoetry/virtualenvs/xai-is73Zs3s-py3.11/lib/python3.11/site-packages/wandb/sdk/lib/preinit.py", line 36, in preinit_wrapper
    raise wandb.Error(f"You must call wandb.init() before {name}()")
wandb.errors.errors.Error: You must call wandb.init() before wandb.log()

WARNING: Error: Could not find wandb directory: ./wandb
WARNING: Error: Could not find wandb directory: ./wandb
ERROR: You must call wandb.init() before wandb.log()
ERROR: Traceback (most recent call last):
  File "/home/eirik/Projects/XAI/rl/src/dqn/wrapper/multi_agent_dqn.py", line 106, in learn
    self.wandb_manager.log(log)
  File "/home/eirik/Projects/XAI/rl/src/managers/wandb_manager.py", line 59, in log
    wandb.log(data)
  File "/home/eirik/.cache/pypoetry/virtualenvs/xai-is73Zs3s-py3.11/lib/python3.11/site-packages/wandb/sdk/lib/preinit.py", line 36, in preinit_wrapper
    raise wandb.Error(f"You must call wandb.init() before {name}()")
wandb.errors.errors.Error: You must call wandb.init() before wandb.log()

WARNING: Error: Could not find wandb directory: ./wandb
WARNING: Error: Could not find wandb directory: ./wandb
ERROR: You must call wandb.init() before wandb.log()
ERROR: Traceback (most recent call last):
  File "/home/eirik/Projects/XAI/rl/src/dqn/wrapper/multi_agent_dqn.py", line 106, in learn
    self.wandb_manager.log(log)
  File "/home/eirik/Projects/XAI/rl/src/managers/wandb_manager.py", line 59, in log
    wandb.log(data)
  File "/home/eirik/.cache/pypoetry/virtualenvs/xai-is73Zs3s-py3.11/lib/python3.11/site-packages/wandb/sdk/lib/preinit.py", line 36, in preinit_wrapper
    raise wandb.Error(f"You must call wandb.init() before {name}()")
wandb.errors.errors.Error: You must call wandb.init() before wandb.log()

WARNING: Error: Could not find wandb directory: ./wandb
WARNING: Error: Could not find wandb directory: ./wandb
ERROR: You must call wandb.init() before wandb.log()
ERROR: Traceback (most recent call last):
  File "/home/eirik/Projects/XAI/rl/src/dqn/wrapper/multi_agent_dqn.py", line 106, in learn
    self.wandb_manager.log(log)
  File "/home/eirik/Projects/XAI/rl/src/managers/wandb_manager.py", line 59, in log
    wandb.log(data)
  File "/home/eirik/.cache/pypoetry/virtualenvs/xai-is73Zs3s-py3.11/lib/python3.11/site-packages/wandb/sdk/lib/preinit.py", line 36, in preinit_wrapper
    raise wandb.Error(f"You must call wandb.init() before {name}()")
wandb.errors.errors.Error: You must call wandb.init() before wandb.log()

WARNING: Error: Could not find wandb directory: ./wandb
WARNING: Error: Could not find wandb directory: ./wandb
ERROR: You must call wandb.init() before wandb.log()
ERROR: Traceback (most recent call last):
  File "/home/eirik/Projects/XAI/rl/src/dqn/wrapper/multi_agent_dqn.py", line 106, in learn
    self.wandb_manager.log(log)
  File "/home/eirik/Projects/XAI/rl/src/managers/wandb_manager.py", line 59, in log
    wandb.log(data)
  File "/home/eirik/.cache/pypoetry/virtualenvs/xai-is73Zs3s-py3.11/lib/python3.11/site-packages/wandb/sdk/lib/preinit.py", line 36, in preinit_wrapper
    raise wandb.Error(f"You must call wandb.init() before {name}()")
wandb.errors.errors.Error: You must call wandb.init() before wandb.log()

WARNING: Error: Could not find wandb directory: ./wandb
WARNING: Error: Could not find wandb directory: ./wandb
ERROR: You must call wandb.init() before wandb.log()
ERROR: Traceback (most recent call last):
  File "/home/eirik/Projects/XAI/rl/src/dqn/wrapper/multi_agent_dqn.py", line 106, in learn
    self.wandb_manager.log(log)
  File "/home/eirik/Projects/XAI/rl/src/managers/wandb_manager.py", line 59, in log
    wandb.log(data)
  File "/home/eirik/.cache/pypoetry/virtualenvs/xai-is73Zs3s-py3.11/lib/python3.11/site-packages/wandb/sdk/lib/preinit.py", line 36, in preinit_wrapper
    raise wandb.Error(f"You must call wandb.init() before {name}()")
wandb.errors.errors.Error: You must call wandb.init() before wandb.log()

WARNING: Error: Could not find wandb directory: ./wandb
WARNING: Error: Could not find wandb directory: ./wandb
ERROR: You must call wandb.init() before wandb.log()
ERROR: Traceback (most recent call last):
  File "/home/eirik/Projects/XAI/rl/src/dqn/wrapper/multi_agent_dqn.py", line 106, in learn
    self.wandb_manager.log(log)
  File "/home/eirik/Projects/XAI/rl/src/managers/wandb_manager.py", line 59, in log
    wandb.log(data)
  File "/home/eirik/.cache/pypoetry/virtualenvs/xai-is73Zs3s-py3.11/lib/python3.11/site-packages/wandb/sdk/lib/preinit.py", line 36, in preinit_wrapper
    raise wandb.Error(f"You must call wandb.init() before {name}()")
wandb.errors.errors.Error: You must call wandb.init() before wandb.log()

WARNING: Error: Could not find wandb directory: ./wandb
WARNING: Error: Could not find wandb directory: ./wandb
ERROR: You must call wandb.init() before wandb.log()
ERROR: Traceback (most recent call last):
  File "/home/eirik/Projects/XAI/rl/src/dqn/wrapper/multi_agent_dqn.py", line 106, in learn
    self.wandb_manager.log(log)
  File "/home/eirik/Projects/XAI/rl/src/managers/wandb_manager.py", line 59, in log
    wandb.log(data)
  File "/home/eirik/.cache/pypoetry/virtualenvs/xai-is73Zs3s-py3.11/lib/python3.11/site-packages/wandb/sdk/lib/preinit.py", line 36, in preinit_wrapper
    raise wandb.Error(f"You must call wandb.init() before {name}()")
wandb.errors.errors.Error: You must call wandb.init() before wandb.log()

WARNING: Error: Could not find wandb directory: ./wandb
WARNING: Error: Could not find wandb directory: ./wandb
ERROR: You must call wandb.init() before wandb.log()
ERROR: Traceback (most recent call last):
  File "/home/eirik/Projects/XAI/rl/src/dqn/wrapper/multi_agent_dqn.py", line 106, in learn
    self.wandb_manager.log(log)
  File "/home/eirik/Projects/XAI/rl/src/managers/wandb_manager.py", line 59, in log
    wandb.log(data)
  File "/home/eirik/.cache/pypoetry/virtualenvs/xai-is73Zs3s-py3.11/lib/python3.11/site-packages/wandb/sdk/lib/preinit.py", line 36, in preinit_wrapper
    raise wandb.Error(f"You must call wandb.init() before {name}()")
wandb.errors.errors.Error: You must call wandb.init() before wandb.log()

WARNING: Error: Could not find wandb directory: ./wandb
WARNING: Error: Could not find wandb directory: ./wandb
ERROR: You must call wandb.init() before wandb.log()
ERROR: Traceback (most recent call last):
  File "/home/eirik/Projects/XAI/rl/src/dqn/wrapper/multi_agent_dqn.py", line 106, in learn
    self.wandb_manager.log(log)
  File "/home/eirik/Projects/XAI/rl/src/managers/wandb_manager.py", line 59, in log
    wandb.log(data)
  File "/home/eirik/.cache/pypoetry/virtualenvs/xai-is73Zs3s-py3.11/lib/python3.11/site-packages/wandb/sdk/lib/preinit.py", line 36, in preinit_wrapper
    raise wandb.Error(f"You must call wandb.init() before {name}()")
wandb.errors.errors.Error: You must call wandb.init() before wandb.log()

WARNING: Error: Could not find wandb directory: ./wandb
WARNING: Error: Could not find wandb directory: ./wandb
ERROR: You must call wandb.init() before wandb.log()
ERROR: Traceback (most recent call last):
  File "/home/eirik/Projects/XAI/rl/src/dqn/wrapper/multi_agent_dqn.py", line 106, in learn
    self.wandb_manager.log(log)
  File "/home/eirik/Projects/XAI/rl/src/managers/wandb_manager.py", line 59, in log
    wandb.log(data)
  File "/home/eirik/.cache/pypoetry/virtualenvs/xai-is73Zs3s-py3.11/lib/python3.11/site-packages/wandb/sdk/lib/preinit.py", line 36, in preinit_wrapper
    raise wandb.Error(f"You must call wandb.init() before {name}()")
wandb.errors.errors.Error: You must call wandb.init() before wandb.log()

WARNING: Error: Could not find wandb directory: ./wandb
WARNING: Error: Could not find wandb directory: ./wandb
ERROR: You must call wandb.init() before wandb.log()
ERROR: Traceback (most recent call last):
  File "/home/eirik/Projects/XAI/rl/src/dqn/wrapper/multi_agent_dqn.py", line 106, in learn
    self.wandb_manager.log(log)
  File "/home/eirik/Projects/XAI/rl/src/managers/wandb_manager.py", line 59, in log
    wandb.log(data)
  File "/home/eirik/.cache/pypoetry/virtualenvs/xai-is73Zs3s-py3.11/lib/python3.11/site-packages/wandb/sdk/lib/preinit.py", line 36, in preinit_wrapper
    raise wandb.Error(f"You must call wandb.init() before {name}()")
wandb.errors.errors.Error: You must call wandb.init() before wandb.log()

WARNING: Error: Could not find wandb directory: ./wandb
WARNING: Error: Could not find wandb directory: ./wandb
INFO: Continuing with bootcamp BootcampName.SLOW_HIDER with slow factor: 20
ERROR: You must call wandb.init() before wandb.log()
ERROR: Traceback (most recent call last):
  File "/home/eirik/Projects/XAI/rl/src/dqn/wrapper/multi_agent_dqn.py", line 106, in learn
    self.wandb_manager.log(log)
  File "/home/eirik/Projects/XAI/rl/src/managers/wandb_manager.py", line 59, in log
    wandb.log(data)
  File "/home/eirik/.cache/pypoetry/virtualenvs/xai-is73Zs3s-py3.11/lib/python3.11/site-packages/wandb/sdk/lib/preinit.py", line 36, in preinit_wrapper
    raise wandb.Error(f"You must call wandb.init() before {name}()")
wandb.errors.errors.Error: You must call wandb.init() before wandb.log()

WARNING: Error: Could not find wandb directory: ./wandb
WARNING: Error: Could not find wandb directory: ./wandb
ERROR: You must call wandb.init() before wandb.log()
ERROR: Traceback (most recent call last):
  File "/home/eirik/Projects/XAI/rl/src/dqn/wrapper/multi_agent_dqn.py", line 106, in learn
    self.wandb_manager.log(log)
  File "/home/eirik/Projects/XAI/rl/src/managers/wandb_manager.py", line 59, in log
    wandb.log(data)
  File "/home/eirik/.cache/pypoetry/virtualenvs/xai-is73Zs3s-py3.11/lib/python3.11/site-packages/wandb/sdk/lib/preinit.py", line 36, in preinit_wrapper
    raise wandb.Error(f"You must call wandb.init() before {name}()")
wandb.errors.errors.Error: You must call wandb.init() before wandb.log()

WARNING: Error: Could not find wandb directory: ./wandb
WARNING: Error: Could not find wandb directory: ./wandb
ERROR: You must call wandb.init() before wandb.log()
ERROR: Traceback (most recent call last):
  File "/home/eirik/Projects/XAI/rl/src/dqn/wrapper/multi_agent_dqn.py", line 106, in learn
    self.wandb_manager.log(log)
  File "/home/eirik/Projects/XAI/rl/src/managers/wandb_manager.py", line 59, in log
    wandb.log(data)
  File "/home/eirik/.cache/pypoetry/virtualenvs/xai-is73Zs3s-py3.11/lib/python3.11/site-packages/wandb/sdk/lib/preinit.py", line 36, in preinit_wrapper
    raise wandb.Error(f"You must call wandb.init() before {name}()")
wandb.errors.errors.Error: You must call wandb.init() before wandb.log()

WARNING: Error: Could not find wandb directory: ./wandb
WARNING: Error: Could not find wandb directory: ./wandb
ERROR: You must call wandb.init() before wandb.log()
ERROR: Traceback (most recent call last):
  File "/home/eirik/Projects/XAI/rl/src/dqn/wrapper/multi_agent_dqn.py", line 106, in learn
    self.wandb_manager.log(log)
  File "/home/eirik/Projects/XAI/rl/src/managers/wandb_manager.py", line 59, in log
    wandb.log(data)
  File "/home/eirik/.cache/pypoetry/virtualenvs/xai-is73Zs3s-py3.11/lib/python3.11/site-packages/wandb/sdk/lib/preinit.py", line 36, in preinit_wrapper
    raise wandb.Error(f"You must call wandb.init() before {name}()")
wandb.errors.errors.Error: You must call wandb.init() before wandb.log()

WARNING: Error: Could not find wandb directory: ./wandb
WARNING: Error: Could not find wandb directory: ./wandb
ERROR: You must call wandb.init() before wandb.log()
ERROR: Traceback (most recent call last):
  File "/home/eirik/Projects/XAI/rl/src/dqn/wrapper/multi_agent_dqn.py", line 106, in learn
    self.wandb_manager.log(log)
  File "/home/eirik/Projects/XAI/rl/src/managers/wandb_manager.py", line 59, in log
    wandb.log(data)
  File "/home/eirik/.cache/pypoetry/virtualenvs/xai-is73Zs3s-py3.11/lib/python3.11/site-packages/wandb/sdk/lib/preinit.py", line 36, in preinit_wrapper
    raise wandb.Error(f"You must call wandb.init() before {name}()")
wandb.errors.errors.Error: You must call wandb.init() before wandb.log()

WARNING: Error: Could not find wandb directory: ./wandb
WARNING: Error: Could not find wandb directory: ./wandb
ERROR: You must call wandb.init() before wandb.log()
ERROR: Traceback (most recent call last):
  File "/home/eirik/Projects/XAI/rl/src/dqn/wrapper/multi_agent_dqn.py", line 106, in learn
    self.wandb_manager.log(log)
  File "/home/eirik/Projects/XAI/rl/src/managers/wandb_manager.py", line 59, in log
    wandb.log(data)
  File "/home/eirik/.cache/pypoetry/virtualenvs/xai-is73Zs3s-py3.11/lib/python3.11/site-packages/wandb/sdk/lib/preinit.py", line 36, in preinit_wrapper
    raise wandb.Error(f"You must call wandb.init() before {name}()")
wandb.errors.errors.Error: You must call wandb.init() before wandb.log()

WARNING: Error: Could not find wandb directory: ./wandb
WARNING: Error: Could not find wandb directory: ./wandb
ERROR: You must call wandb.init() before wandb.log()
ERROR: Traceback (most recent call last):
  File "/home/eirik/Projects/XAI/rl/src/dqn/wrapper/multi_agent_dqn.py", line 106, in learn
    self.wandb_manager.log(log)
  File "/home/eirik/Projects/XAI/rl/src/managers/wandb_manager.py", line 59, in log
    wandb.log(data)
  File "/home/eirik/.cache/pypoetry/virtualenvs/xai-is73Zs3s-py3.11/lib/python3.11/site-packages/wandb/sdk/lib/preinit.py", line 36, in preinit_wrapper
    raise wandb.Error(f"You must call wandb.init() before {name}()")
wandb.errors.errors.Error: You must call wandb.init() before wandb.log()

WARNING: Error: Could not find wandb directory: ./wandb
WARNING: Error: Could not find wandb directory: ./wandb
ERROR: You must call wandb.init() before wandb.log()
ERROR: Traceback (most recent call last):
  File "/home/eirik/Projects/XAI/rl/src/dqn/wrapper/multi_agent_dqn.py", line 106, in learn
    self.wandb_manager.log(log)
  File "/home/eirik/Projects/XAI/rl/src/managers/wandb_manager.py", line 59, in log
    wandb.log(data)
  File "/home/eirik/.cache/pypoetry/virtualenvs/xai-is73Zs3s-py3.11/lib/python3.11/site-packages/wandb/sdk/lib/preinit.py", line 36, in preinit_wrapper
    raise wandb.Error(f"You must call wandb.init() before {name}()")
wandb.errors.errors.Error: You must call wandb.init() before wandb.log()

WARNING: Error: Could not find wandb directory: ./wandb
WARNING: Error: Could not find wandb directory: ./wandb
ERROR: You must call wandb.init() before wandb.log()
ERROR: Traceback (most recent call last):
  File "/home/eirik/Projects/XAI/rl/src/dqn/wrapper/multi_agent_dqn.py", line 106, in learn
    self.wandb_manager.log(log)
  File "/home/eirik/Projects/XAI/rl/src/managers/wandb_manager.py", line 59, in log
    wandb.log(data)
  File "/home/eirik/.cache/pypoetry/virtualenvs/xai-is73Zs3s-py3.11/lib/python3.11/site-packages/wandb/sdk/lib/preinit.py", line 36, in preinit_wrapper
    raise wandb.Error(f"You must call wandb.init() before {name}()")
wandb.errors.errors.Error: You must call wandb.init() before wandb.log()

WARNING: Error: Could not find wandb directory: ./wandb
WARNING: Error: Could not find wandb directory: ./wandb
ERROR: You must call wandb.init() before wandb.log()
ERROR: Traceback (most recent call last):
  File "/home/eirik/Projects/XAI/rl/src/dqn/wrapper/multi_agent_dqn.py", line 106, in learn
    self.wandb_manager.log(log)
  File "/home/eirik/Projects/XAI/rl/src/managers/wandb_manager.py", line 59, in log
    wandb.log(data)
  File "/home/eirik/.cache/pypoetry/virtualenvs/xai-is73Zs3s-py3.11/lib/python3.11/site-packages/wandb/sdk/lib/preinit.py", line 36, in preinit_wrapper
    raise wandb.Error(f"You must call wandb.init() before {name}()")
wandb.errors.errors.Error: You must call wandb.init() before wandb.log()

WARNING: Error: Could not find wandb directory: ./wandb
WARNING: Error: Could not find wandb directory: ./wandb
ERROR: You must call wandb.init() before wandb.log()
ERROR: Traceback (most recent call last):
  File "/home/eirik/Projects/XAI/rl/src/dqn/wrapper/multi_agent_dqn.py", line 106, in learn
    self.wandb_manager.log(log)
  File "/home/eirik/Projects/XAI/rl/src/managers/wandb_manager.py", line 59, in log
    wandb.log(data)
  File "/home/eirik/.cache/pypoetry/virtualenvs/xai-is73Zs3s-py3.11/lib/python3.11/site-packages/wandb/sdk/lib/preinit.py", line 36, in preinit_wrapper
    raise wandb.Error(f"You must call wandb.init() before {name}()")
wandb.errors.errors.Error: You must call wandb.init() before wandb.log()

WARNING: Error: Could not find wandb directory: ./wandb
WARNING: Error: Could not find wandb directory: ./wandb
INFO: Continuing with bootcamp BootcampName.SLOW_HIDER with slow factor: 20
ERROR: You must call wandb.init() before wandb.log()
ERROR: Traceback (most recent call last):
  File "/home/eirik/Projects/XAI/rl/src/dqn/wrapper/multi_agent_dqn.py", line 106, in learn
    self.wandb_manager.log(log)
  File "/home/eirik/Projects/XAI/rl/src/managers/wandb_manager.py", line 59, in log
    wandb.log(data)
  File "/home/eirik/.cache/pypoetry/virtualenvs/xai-is73Zs3s-py3.11/lib/python3.11/site-packages/wandb/sdk/lib/preinit.py", line 36, in preinit_wrapper
    raise wandb.Error(f"You must call wandb.init() before {name}()")
wandb.errors.errors.Error: You must call wandb.init() before wandb.log()

WARNING: Error: Could not find wandb directory: ./wandb
WARNING: Error: Could not find wandb directory: ./wandb
ERROR: You must call wandb.init() before wandb.log()
ERROR: Traceback (most recent call last):
  File "/home/eirik/Projects/XAI/rl/src/dqn/wrapper/multi_agent_dqn.py", line 106, in learn
    self.wandb_manager.log(log)
  File "/home/eirik/Projects/XAI/rl/src/managers/wandb_manager.py", line 59, in log
    wandb.log(data)
  File "/home/eirik/.cache/pypoetry/virtualenvs/xai-is73Zs3s-py3.11/lib/python3.11/site-packages/wandb/sdk/lib/preinit.py", line 36, in preinit_wrapper
    raise wandb.Error(f"You must call wandb.init() before {name}()")
wandb.errors.errors.Error: You must call wandb.init() before wandb.log()

WARNING: Error: Could not find wandb directory: ./wandb
WARNING: Error: Could not find wandb directory: ./wandb
ERROR: You must call wandb.init() before wandb.log()
ERROR: Traceback (most recent call last):
  File "/home/eirik/Projects/XAI/rl/src/dqn/wrapper/multi_agent_dqn.py", line 106, in learn
    self.wandb_manager.log(log)
  File "/home/eirik/Projects/XAI/rl/src/managers/wandb_manager.py", line 59, in log
    wandb.log(data)
  File "/home/eirik/.cache/pypoetry/virtualenvs/xai-is73Zs3s-py3.11/lib/python3.11/site-packages/wandb/sdk/lib/preinit.py", line 36, in preinit_wrapper
    raise wandb.Error(f"You must call wandb.init() before {name}()")
wandb.errors.errors.Error: You must call wandb.init() before wandb.log()

WARNING: Error: Could not find wandb directory: ./wandb
WARNING: Error: Could not find wandb directory: ./wandb
ERROR: You must call wandb.init() before wandb.log()
ERROR: Traceback (most recent call last):
  File "/home/eirik/Projects/XAI/rl/src/dqn/wrapper/multi_agent_dqn.py", line 106, in learn
    self.wandb_manager.log(log)
  File "/home/eirik/Projects/XAI/rl/src/managers/wandb_manager.py", line 59, in log
    wandb.log(data)
  File "/home/eirik/.cache/pypoetry/virtualenvs/xai-is73Zs3s-py3.11/lib/python3.11/site-packages/wandb/sdk/lib/preinit.py", line 36, in preinit_wrapper
    raise wandb.Error(f"You must call wandb.init() before {name}()")
wandb.errors.errors.Error: You must call wandb.init() before wandb.log()

WARNING: Error: Could not find wandb directory: ./wandb
WARNING: Error: Could not find wandb directory: ./wandb
ERROR: You must call wandb.init() before wandb.log()
ERROR: Traceback (most recent call last):
  File "/home/eirik/Projects/XAI/rl/src/dqn/wrapper/multi_agent_dqn.py", line 106, in learn
    self.wandb_manager.log(log)
  File "/home/eirik/Projects/XAI/rl/src/managers/wandb_manager.py", line 59, in log
    wandb.log(data)
  File "/home/eirik/.cache/pypoetry/virtualenvs/xai-is73Zs3s-py3.11/lib/python3.11/site-packages/wandb/sdk/lib/preinit.py", line 36, in preinit_wrapper
    raise wandb.Error(f"You must call wandb.init() before {name}()")
wandb.errors.errors.Error: You must call wandb.init() before wandb.log()

WARNING: Error: Could not find wandb directory: ./wandb
WARNING: Error: Could not find wandb directory: ./wandb
ERROR: You must call wandb.init() before wandb.log()
ERROR: Traceback (most recent call last):
  File "/home/eirik/Projects/XAI/rl/src/dqn/wrapper/multi_agent_dqn.py", line 106, in learn
    self.wandb_manager.log(log)
  File "/home/eirik/Projects/XAI/rl/src/managers/wandb_manager.py", line 59, in log
    wandb.log(data)
  File "/home/eirik/.cache/pypoetry/virtualenvs/xai-is73Zs3s-py3.11/lib/python3.11/site-packages/wandb/sdk/lib/preinit.py", line 36, in preinit_wrapper
    raise wandb.Error(f"You must call wandb.init() before {name}()")
wandb.errors.errors.Error: You must call wandb.init() before wandb.log()

WARNING: Error: Could not find wandb directory: ./wandb
WARNING: Error: Could not find wandb directory: ./wandb
ERROR: You must call wandb.init() before wandb.log()
ERROR: Traceback (most recent call last):
  File "/home/eirik/Projects/XAI/rl/src/dqn/wrapper/multi_agent_dqn.py", line 106, in learn
    self.wandb_manager.log(log)
  File "/home/eirik/Projects/XAI/rl/src/managers/wandb_manager.py", line 59, in log
    wandb.log(data)
  File "/home/eirik/.cache/pypoetry/virtualenvs/xai-is73Zs3s-py3.11/lib/python3.11/site-packages/wandb/sdk/lib/preinit.py", line 36, in preinit_wrapper
    raise wandb.Error(f"You must call wandb.init() before {name}()")
wandb.errors.errors.Error: You must call wandb.init() before wandb.log()

WARNING: Error: Could not find wandb directory: ./wandb
WARNING: Error: Could not find wandb directory: ./wandb
ERROR: You must call wandb.init() before wandb.log()
ERROR: Traceback (most recent call last):
  File "/home/eirik/Projects/XAI/rl/src/dqn/wrapper/multi_agent_dqn.py", line 106, in learn
    self.wandb_manager.log(log)
  File "/home/eirik/Projects/XAI/rl/src/managers/wandb_manager.py", line 59, in log
    wandb.log(data)
  File "/home/eirik/.cache/pypoetry/virtualenvs/xai-is73Zs3s-py3.11/lib/python3.11/site-packages/wandb/sdk/lib/preinit.py", line 36, in preinit_wrapper
    raise wandb.Error(f"You must call wandb.init() before {name}()")
wandb.errors.errors.Error: You must call wandb.init() before wandb.log()

WARNING: Error: Could not find wandb directory: ./wandb
WARNING: Error: Could not find wandb directory: ./wandb
ERROR: You must call wandb.init() before wandb.log()
ERROR: Traceback (most recent call last):
  File "/home/eirik/Projects/XAI/rl/src/dqn/wrapper/multi_agent_dqn.py", line 106, in learn
    self.wandb_manager.log(log)
  File "/home/eirik/Projects/XAI/rl/src/managers/wandb_manager.py", line 59, in log
    wandb.log(data)
  File "/home/eirik/.cache/pypoetry/virtualenvs/xai-is73Zs3s-py3.11/lib/python3.11/site-packages/wandb/sdk/lib/preinit.py", line 36, in preinit_wrapper
    raise wandb.Error(f"You must call wandb.init() before {name}()")
wandb.errors.errors.Error: You must call wandb.init() before wandb.log()

WARNING: Error: Could not find wandb directory: ./wandb
WARNING: Error: Could not find wandb directory: ./wandb
ERROR: You must call wandb.init() before wandb.log()
ERROR: Traceback (most recent call last):
  File "/home/eirik/Projects/XAI/rl/src/dqn/wrapper/multi_agent_dqn.py", line 106, in learn
    self.wandb_manager.log(log)
  File "/home/eirik/Projects/XAI/rl/src/managers/wandb_manager.py", line 59, in log
    wandb.log(data)
  File "/home/eirik/.cache/pypoetry/virtualenvs/xai-is73Zs3s-py3.11/lib/python3.11/site-packages/wandb/sdk/lib/preinit.py", line 36, in preinit_wrapper
    raise wandb.Error(f"You must call wandb.init() before {name}()")
wandb.errors.errors.Error: You must call wandb.init() before wandb.log()

WARNING: Error: Could not find wandb directory: ./wandb
WARNING: Error: Could not find wandb directory: ./wandb
ERROR: You must call wandb.init() before wandb.log()
ERROR: Traceback (most recent call last):
  File "/home/eirik/Projects/XAI/rl/src/dqn/wrapper/multi_agent_dqn.py", line 106, in learn
    self.wandb_manager.log(log)
  File "/home/eirik/Projects/XAI/rl/src/managers/wandb_manager.py", line 59, in log
    wandb.log(data)
  File "/home/eirik/.cache/pypoetry/virtualenvs/xai-is73Zs3s-py3.11/lib/python3.11/site-packages/wandb/sdk/lib/preinit.py", line 36, in preinit_wrapper
    raise wandb.Error(f"You must call wandb.init() before {name}()")
wandb.errors.errors.Error: You must call wandb.init() before wandb.log()

WARNING: Error: Could not find wandb directory: ./wandb
WARNING: Error: Could not find wandb directory: ./wandb
ERROR: You must call wandb.init() before wandb.log()
ERROR: Traceback (most recent call last):
  File "/home/eirik/Projects/XAI/rl/src/dqn/wrapper/multi_agent_dqn.py", line 106, in learn
    self.wandb_manager.log(log)
  File "/home/eirik/Projects/XAI/rl/src/managers/wandb_manager.py", line 59, in log
    wandb.log(data)
  File "/home/eirik/.cache/pypoetry/virtualenvs/xai-is73Zs3s-py3.11/lib/python3.11/site-packages/wandb/sdk/lib/preinit.py", line 36, in preinit_wrapper
    raise wandb.Error(f"You must call wandb.init() before {name}()")
wandb.errors.errors.Error: You must call wandb.init() before wandb.log()

WARNING: Error: Could not find wandb directory: ./wandb
WARNING: Error: Could not find wandb directory: ./wandb
ERROR: You must call wandb.init() before wandb.log()
ERROR: Traceback (most recent call last):
  File "/home/eirik/Projects/XAI/rl/src/dqn/wrapper/multi_agent_dqn.py", line 106, in learn
    self.wandb_manager.log(log)
  File "/home/eirik/Projects/XAI/rl/src/managers/wandb_manager.py", line 59, in log
    wandb.log(data)
  File "/home/eirik/.cache/pypoetry/virtualenvs/xai-is73Zs3s-py3.11/lib/python3.11/site-packages/wandb/sdk/lib/preinit.py", line 36, in preinit_wrapper
    raise wandb.Error(f"You must call wandb.init() before {name}()")
wandb.errors.errors.Error: You must call wandb.init() before wandb.log()

WARNING: Error: Could not find wandb directory: ./wandb
WARNING: Error: Could not find wandb directory: ./wandb
ERROR: You must call wandb.init() before wandb.log()
ERROR: Traceback (most recent call last):
  File "/home/eirik/Projects/XAI/rl/src/dqn/wrapper/multi_agent_dqn.py", line 106, in learn
    self.wandb_manager.log(log)
  File "/home/eirik/Projects/XAI/rl/src/managers/wandb_manager.py", line 59, in log
    wandb.log(data)
  File "/home/eirik/.cache/pypoetry/virtualenvs/xai-is73Zs3s-py3.11/lib/python3.11/site-packages/wandb/sdk/lib/preinit.py", line 36, in preinit_wrapper
    raise wandb.Error(f"You must call wandb.init() before {name}()")
wandb.errors.errors.Error: You must call wandb.init() before wandb.log()

WARNING: Error: Could not find wandb directory: ./wandb
WARNING: Error: Could not find wandb directory: ./wandb
ERROR: You must call wandb.init() before wandb.log()
ERROR: Traceback (most recent call last):
  File "/home/eirik/Projects/XAI/rl/src/dqn/wrapper/multi_agent_dqn.py", line 106, in learn
    self.wandb_manager.log(log)
  File "/home/eirik/Projects/XAI/rl/src/managers/wandb_manager.py", line 59, in log
    wandb.log(data)
  File "/home/eirik/.cache/pypoetry/virtualenvs/xai-is73Zs3s-py3.11/lib/python3.11/site-packages/wandb/sdk/lib/preinit.py", line 36, in preinit_wrapper
    raise wandb.Error(f"You must call wandb.init() before {name}()")
wandb.errors.errors.Error: You must call wandb.init() before wandb.log()

WARNING: Error: Could not find wandb directory: ./wandb
WARNING: Error: Could not find wandb directory: ./wandb
ERROR: You must call wandb.init() before wandb.log()
ERROR: Traceback (most recent call last):
  File "/home/eirik/Projects/XAI/rl/src/dqn/wrapper/multi_agent_dqn.py", line 106, in learn
    self.wandb_manager.log(log)
  File "/home/eirik/Projects/XAI/rl/src/managers/wandb_manager.py", line 59, in log
    wandb.log(data)
  File "/home/eirik/.cache/pypoetry/virtualenvs/xai-is73Zs3s-py3.11/lib/python3.11/site-packages/wandb/sdk/lib/preinit.py", line 36, in preinit_wrapper
    raise wandb.Error(f"You must call wandb.init() before {name}()")
wandb.errors.errors.Error: You must call wandb.init() before wandb.log()

WARNING: Error: Could not find wandb directory: ./wandb
WARNING: Error: Could not find wandb directory: ./wandb
ERROR: You must call wandb.init() before wandb.log()
ERROR: Traceback (most recent call last):
  File "/home/eirik/Projects/XAI/rl/src/dqn/wrapper/multi_agent_dqn.py", line 106, in learn
    self.wandb_manager.log(log)
  File "/home/eirik/Projects/XAI/rl/src/managers/wandb_manager.py", line 59, in log
    wandb.log(data)
  File "/home/eirik/.cache/pypoetry/virtualenvs/xai-is73Zs3s-py3.11/lib/python3.11/site-packages/wandb/sdk/lib/preinit.py", line 36, in preinit_wrapper
    raise wandb.Error(f"You must call wandb.init() before {name}()")
wandb.errors.errors.Error: You must call wandb.init() before wandb.log()

WARNING: Error: Could not find wandb directory: ./wandb
WARNING: Error: Could not find wandb directory: ./wandb
ERROR: You must call wandb.init() before wandb.log()
ERROR: Traceback (most recent call last):
  File "/home/eirik/Projects/XAI/rl/src/dqn/wrapper/multi_agent_dqn.py", line 106, in learn
    self.wandb_manager.log(log)
  File "/home/eirik/Projects/XAI/rl/src/managers/wandb_manager.py", line 59, in log
    wandb.log(data)
  File "/home/eirik/.cache/pypoetry/virtualenvs/xai-is73Zs3s-py3.11/lib/python3.11/site-packages/wandb/sdk/lib/preinit.py", line 36, in preinit_wrapper
    raise wandb.Error(f"You must call wandb.init() before {name}()")
wandb.errors.errors.Error: You must call wandb.init() before wandb.log()

WARNING: Error: Could not find wandb directory: ./wandb
WARNING: Error: Could not find wandb directory: ./wandb
ERROR: You must call wandb.init() before wandb.log()
ERROR: Traceback (most recent call last):
  File "/home/eirik/Projects/XAI/rl/src/dqn/wrapper/multi_agent_dqn.py", line 106, in learn
    self.wandb_manager.log(log)
  File "/home/eirik/Projects/XAI/rl/src/managers/wandb_manager.py", line 59, in log
    wandb.log(data)
  File "/home/eirik/.cache/pypoetry/virtualenvs/xai-is73Zs3s-py3.11/lib/python3.11/site-packages/wandb/sdk/lib/preinit.py", line 36, in preinit_wrapper
    raise wandb.Error(f"You must call wandb.init() before {name}()")
wandb.errors.errors.Error: You must call wandb.init() before wandb.log()

WARNING: Error: Could not find wandb directory: ./wandb
WARNING: Error: Could not find wandb directory: ./wandb
INFO: Continuing with bootcamp BootcampName.SLOW_HIDER with slow factor: 20
ERROR: You must call wandb.init() before wandb.log()
ERROR: Traceback (most recent call last):
  File "/home/eirik/Projects/XAI/rl/src/dqn/wrapper/multi_agent_dqn.py", line 106, in learn
    self.wandb_manager.log(log)
  File "/home/eirik/Projects/XAI/rl/src/managers/wandb_manager.py", line 59, in log
    wandb.log(data)
  File "/home/eirik/.cache/pypoetry/virtualenvs/xai-is73Zs3s-py3.11/lib/python3.11/site-packages/wandb/sdk/lib/preinit.py", line 36, in preinit_wrapper
    raise wandb.Error(f"You must call wandb.init() before {name}()")
wandb.errors.errors.Error: You must call wandb.init() before wandb.log()

WARNING: Error: Could not find wandb directory: ./wandb
WARNING: Error: Could not find wandb directory: ./wandb
ERROR: You must call wandb.init() before wandb.log()
ERROR: Traceback (most recent call last):
  File "/home/eirik/Projects/XAI/rl/src/dqn/wrapper/multi_agent_dqn.py", line 106, in learn
    self.wandb_manager.log(log)
  File "/home/eirik/Projects/XAI/rl/src/managers/wandb_manager.py", line 59, in log
    wandb.log(data)
  File "/home/eirik/.cache/pypoetry/virtualenvs/xai-is73Zs3s-py3.11/lib/python3.11/site-packages/wandb/sdk/lib/preinit.py", line 36, in preinit_wrapper
    raise wandb.Error(f"You must call wandb.init() before {name}()")
wandb.errors.errors.Error: You must call wandb.init() before wandb.log()

WARNING: Error: Could not find wandb directory: ./wandb
WARNING: Error: Could not find wandb directory: ./wandb
ERROR: You must call wandb.init() before wandb.log()
ERROR: Traceback (most recent call last):
  File "/home/eirik/Projects/XAI/rl/src/dqn/wrapper/multi_agent_dqn.py", line 106, in learn
    self.wandb_manager.log(log)
  File "/home/eirik/Projects/XAI/rl/src/managers/wandb_manager.py", line 59, in log
    wandb.log(data)
  File "/home/eirik/.cache/pypoetry/virtualenvs/xai-is73Zs3s-py3.11/lib/python3.11/site-packages/wandb/sdk/lib/preinit.py", line 36, in preinit_wrapper
    raise wandb.Error(f"You must call wandb.init() before {name}()")
wandb.errors.errors.Error: You must call wandb.init() before wandb.log()

WARNING: Error: Could not find wandb directory: ./wandb
WARNING: Error: Could not find wandb directory: ./wandb
ERROR: You must call wandb.init() before wandb.log()
ERROR: Traceback (most recent call last):
  File "/home/eirik/Projects/XAI/rl/src/dqn/wrapper/multi_agent_dqn.py", line 106, in learn
    self.wandb_manager.log(log)
  File "/home/eirik/Projects/XAI/rl/src/managers/wandb_manager.py", line 59, in log
    wandb.log(data)
  File "/home/eirik/.cache/pypoetry/virtualenvs/xai-is73Zs3s-py3.11/lib/python3.11/site-packages/wandb/sdk/lib/preinit.py", line 36, in preinit_wrapper
    raise wandb.Error(f"You must call wandb.init() before {name}()")
wandb.errors.errors.Error: You must call wandb.init() before wandb.log()

WARNING: Error: Could not find wandb directory: ./wandb
WARNING: Error: Could not find wandb directory: ./wandb
ERROR: You must call wandb.init() before wandb.log()
ERROR: Traceback (most recent call last):
  File "/home/eirik/Projects/XAI/rl/src/dqn/wrapper/multi_agent_dqn.py", line 106, in learn
    self.wandb_manager.log(log)
  File "/home/eirik/Projects/XAI/rl/src/managers/wandb_manager.py", line 59, in log
    wandb.log(data)
  File "/home/eirik/.cache/pypoetry/virtualenvs/xai-is73Zs3s-py3.11/lib/python3.11/site-packages/wandb/sdk/lib/preinit.py", line 36, in preinit_wrapper
    raise wandb.Error(f"You must call wandb.init() before {name}()")
wandb.errors.errors.Error: You must call wandb.init() before wandb.log()

WARNING: Error: Could not find wandb directory: ./wandb
WARNING: Error: Could not find wandb directory: ./wandb
ERROR: You must call wandb.init() before wandb.log()
ERROR: Traceback (most recent call last):
  File "/home/eirik/Projects/XAI/rl/src/dqn/wrapper/multi_agent_dqn.py", line 106, in learn
    self.wandb_manager.log(log)
  File "/home/eirik/Projects/XAI/rl/src/managers/wandb_manager.py", line 59, in log
    wandb.log(data)
  File "/home/eirik/.cache/pypoetry/virtualenvs/xai-is73Zs3s-py3.11/lib/python3.11/site-packages/wandb/sdk/lib/preinit.py", line 36, in preinit_wrapper
    raise wandb.Error(f"You must call wandb.init() before {name}()")
wandb.errors.errors.Error: You must call wandb.init() before wandb.log()

WARNING: Error: Could not find wandb directory: ./wandb
WARNING: Error: Could not find wandb directory: ./wandb
ERROR: You must call wandb.init() before wandb.log()
ERROR: Traceback (most recent call last):
  File "/home/eirik/Projects/XAI/rl/src/dqn/wrapper/multi_agent_dqn.py", line 106, in learn
    self.wandb_manager.log(log)
  File "/home/eirik/Projects/XAI/rl/src/managers/wandb_manager.py", line 59, in log
    wandb.log(data)
  File "/home/eirik/.cache/pypoetry/virtualenvs/xai-is73Zs3s-py3.11/lib/python3.11/site-packages/wandb/sdk/lib/preinit.py", line 36, in preinit_wrapper
    raise wandb.Error(f"You must call wandb.init() before {name}()")
wandb.errors.errors.Error: You must call wandb.init() before wandb.log()

WARNING: Error: Could not find wandb directory: ./wandb
WARNING: Error: Could not find wandb directory: ./wandb
WARNING: Error: Could not find wandb directory: ./wandb
INFO: Number of parameters: 30085
INFO: QNetwork(
  (conv_feature): Sequential()
  (fc_feature): Sequential(
    (0): Linear(in_features=100, out_features=128, bias=True)
    (1): ReLU()
    (2): Linear(in_features=128, out_features=128, bias=True)
    (3): ReLU()
    (4): Linear(in_features=128, out_features=5, bias=True)
  )
)
WARNING: GIF is enabled but the environment does not support RGB array rendering.
INFO: Learning...
INFO: BootcampName.HIDER bootcamp completed, starting BootcampName.SEEKER bootcamp
ERROR: You must call wandb.init() before wandb.log()
ERROR: Traceback (most recent call last):
  File "/home/eirik/Projects/XAI/rl/src/dqn/wrapper/multi_agent_dqn.py", line 106, in learn
    self.wandb_manager.log(log)
  File "/home/eirik/Projects/XAI/rl/src/managers/wandb_manager.py", line 59, in log
    wandb.log(data)
  File "/home/eirik/.cache/pypoetry/virtualenvs/xai-is73Zs3s-py3.11/lib/python3.11/site-packages/wandb/sdk/lib/preinit.py", line 36, in preinit_wrapper
    raise wandb.Error(f"You must call wandb.init() before {name}()")
wandb.errors.errors.Error: You must call wandb.init() before wandb.log()

WARNING: Error: Could not find wandb directory: ./wandb
WARNING: Error: Could not find wandb directory: ./wandb
INFO: Number of parameters: 30085
INFO: QNetwork(
  (conv_feature): Sequential()
  (fc_feature): Sequential(
    (0): Linear(in_features=100, out_features=128, bias=True)
    (1): ReLU()
    (2): Linear(in_features=128, out_features=128, bias=True)
    (3): ReLU()
    (4): Linear(in_features=128, out_features=5, bias=True)
  )
)
WARNING: GIF is enabled but the environment does not support RGB array rendering.
INFO: Learning...
INFO: BootcampName.HIDER bootcamp completed, starting BootcampName.SEEKER bootcamp
ERROR: You must call wandb.init() before wandb.log()
ERROR: Traceback (most recent call last):
  File "/home/eirik/Projects/XAI/rl/src/dqn/wrapper/multi_agent_dqn.py", line 106, in learn
    self.wandb_manager.log(log)
  File "/home/eirik/Projects/XAI/rl/src/managers/wandb_manager.py", line 60, in log
    wandb.log(data)
  File "/home/eirik/.cache/pypoetry/virtualenvs/xai-is73Zs3s-py3.11/lib/python3.11/site-packages/wandb/sdk/lib/preinit.py", line 36, in preinit_wrapper
    raise wandb.Error(f"You must call wandb.init() before {name}()")
wandb.errors.errors.Error: You must call wandb.init() before wandb.log()

WARNING: Error: Could not find wandb directory: ./wandb
WARNING: Error: Could not find wandb directory: ./wandb
ERROR: You must call wandb.init() before wandb.log()
ERROR: Traceback (most recent call last):
  File "/home/eirik/Projects/XAI/rl/src/dqn/wrapper/multi_agent_dqn.py", line 106, in learn
    self.wandb_manager.log(log)
  File "/home/eirik/Projects/XAI/rl/src/managers/wandb_manager.py", line 60, in log
    wandb.log(data)
  File "/home/eirik/.cache/pypoetry/virtualenvs/xai-is73Zs3s-py3.11/lib/python3.11/site-packages/wandb/sdk/lib/preinit.py", line 36, in preinit_wrapper
    raise wandb.Error(f"You must call wandb.init() before {name}()")
wandb.errors.errors.Error: You must call wandb.init() before wandb.log()

WARNING: Error: Could not find wandb directory: ./wandb
WARNING: Error: Could not find wandb directory: ./wandb
ERROR: You must call wandb.init() before wandb.log()
ERROR: Traceback (most recent call last):
  File "/home/eirik/Projects/XAI/rl/src/dqn/wrapper/multi_agent_dqn.py", line 106, in learn
    self.wandb_manager.log(log)
  File "/home/eirik/Projects/XAI/rl/src/managers/wandb_manager.py", line 60, in log
    wandb.log(data)
  File "/home/eirik/.cache/pypoetry/virtualenvs/xai-is73Zs3s-py3.11/lib/python3.11/site-packages/wandb/sdk/lib/preinit.py", line 36, in preinit_wrapper
    raise wandb.Error(f"You must call wandb.init() before {name}()")
wandb.errors.errors.Error: You must call wandb.init() before wandb.log()

WARNING: Error: Could not find wandb directory: ./wandb
WARNING: Error: Could not find wandb directory: ./wandb
ERROR: You must call wandb.init() before wandb.log()
ERROR: Traceback (most recent call last):
  File "/home/eirik/Projects/XAI/rl/src/dqn/wrapper/multi_agent_dqn.py", line 106, in learn
    self.wandb_manager.log(log)
  File "/home/eirik/Projects/XAI/rl/src/managers/wandb_manager.py", line 60, in log
    wandb.log(data)
  File "/home/eirik/.cache/pypoetry/virtualenvs/xai-is73Zs3s-py3.11/lib/python3.11/site-packages/wandb/sdk/lib/preinit.py", line 36, in preinit_wrapper
    raise wandb.Error(f"You must call wandb.init() before {name}()")
wandb.errors.errors.Error: You must call wandb.init() before wandb.log()

WARNING: Error: Could not find wandb directory: ./wandb
WARNING: Error: Could not find wandb directory: ./wandb
ERROR: You must call wandb.init() before wandb.log()
ERROR: Traceback (most recent call last):
  File "/home/eirik/Projects/XAI/rl/src/dqn/wrapper/multi_agent_dqn.py", line 106, in learn
    self.wandb_manager.log(log)
  File "/home/eirik/Projects/XAI/rl/src/managers/wandb_manager.py", line 60, in log
    wandb.log(data)
  File "/home/eirik/.cache/pypoetry/virtualenvs/xai-is73Zs3s-py3.11/lib/python3.11/site-packages/wandb/sdk/lib/preinit.py", line 36, in preinit_wrapper
    raise wandb.Error(f"You must call wandb.init() before {name}()")
wandb.errors.errors.Error: You must call wandb.init() before wandb.log()

WARNING: Error: Could not find wandb directory: ./wandb
WARNING: Error: Could not find wandb directory: ./wandb
WARNING: Error: Could not find wandb directory: ./wandb
INFO: Number of parameters: 30085
INFO: QNetwork(
  (conv_feature): Sequential()
  (fc_feature): Sequential(
    (0): Linear(in_features=100, out_features=128, bias=True)
    (1): ReLU()
    (2): Linear(in_features=128, out_features=128, bias=True)
    (3): ReLU()
    (4): Linear(in_features=128, out_features=5, bias=True)
  )
)
WARNING: GIF is enabled but the environment does not support RGB array rendering.
INFO: Learning...
INFO: BootcampName.HIDER bootcamp completed, starting BootcampName.SEEKER bootcamp
INFO: BootcampName.SEEKER bootcamp completed, starting BootcampName.SLOW_HIDER bootcamp
INFO: Continuing with bootcamp BootcampName.SLOW_HIDER with slow factor: 20
INFO: Continuing with bootcamp BootcampName.SLOW_HIDER with slow factor: 20
INFO: Continuing with bootcamp BootcampName.SLOW_HIDER with slow factor: 20
INFO: Number of parameters: 30085
INFO: QNetwork(
  (conv_feature): Sequential()
  (fc_feature): Sequential(
    (0): Linear(in_features=100, out_features=128, bias=True)
    (1): ReLU()
    (2): Linear(in_features=128, out_features=128, bias=True)
    (3): ReLU()
    (4): Linear(in_features=128, out_features=5, bias=True)
  )
)
WARNING: GIF is enabled but the environment does not support RGB array rendering.
INFO: Learning...
INFO: BootcampName.HIDER bootcamp completed, starting BootcampName.SEEKER bootcamp
INFO: BootcampName.SEEKER bootcamp completed, starting BootcampName.SLOW_AGENT bootcamp
WARNING: No frames in gif to save.
WARNING: No frames in gif to save.
INFO: Continuing with bootcamp BootcampName.SLOW_AGENT with slow factor: 20
WARNING: No frames in gif to save.
WARNING: No frames in gif to save.
INFO: Continuing with bootcamp BootcampName.SLOW_AGENT with slow factor: 20
WARNING: No frames in gif to save.
WARNING: No frames in gif to save.
INFO: Number of parameters: 30085
INFO: QNetwork(
  (conv_feature): Sequential()
  (fc_feature): Sequential(
    (0): Linear(in_features=100, out_features=128, bias=True)
    (1): ReLU()
    (2): Linear(in_features=128, out_features=128, bias=True)
    (3): ReLU()
    (4): Linear(in_features=128, out_features=5, bias=True)
  )
)
WARNING: GIF is enabled but the environment does not support RGB array rendering.
INFO: Learning...
INFO: BootcampName.HIDER bootcamp completed, starting BootcampName.SEEKER bootcamp
INFO: BootcampName.SEEKER bootcamp completed, starting BootcampName.SLOW_AGENT bootcamp
INFO: Continuing with bootcamp BootcampName.SLOW_AGENT with slow factor: 20
INFO: Continuing with bootcamp BootcampName.SLOW_AGENT with slow factor: 20
INFO: Continuing with bootcamp BootcampName.SLOW_AGENT with slow factor: 20
INFO: Continuing with bootcamp BootcampName.SLOW_AGENT with slow factor: 20
INFO: Continuing with bootcamp BootcampName.SLOW_AGENT with slow factor: 20
INFO: Continuing with bootcamp BootcampName.SLOW_AGENT with slow factor: 20
INFO: Number of parameters: 30085
INFO: QNetwork(
  (conv_feature): Sequential()
  (fc_feature): Sequential(
    (0): Linear(in_features=100, out_features=128, bias=True)
    (1): ReLU()
    (2): Linear(in_features=128, out_features=128, bias=True)
    (3): ReLU()
    (4): Linear(in_features=128, out_features=5, bias=True)
  )
)
WARNING: GIF is enabled but the environment does not support RGB array rendering.
INFO: Learning...
INFO: BootcampName.HIDER bootcamp completed, starting BootcampName.SEEKER bootcamp
INFO: Number of parameters: 30085
INFO: QNetwork(
  (conv_feature): Sequential()
  (fc_feature): Sequential(
    (0): Linear(in_features=100, out_features=128, bias=True)
    (1): ReLU()
    (2): Linear(in_features=128, out_features=128, bias=True)
    (3): ReLU()
    (4): Linear(in_features=128, out_features=5, bias=True)
  )
)
WARNING: GIF is enabled but the environment does not support RGB array rendering.
INFO: Learning...
INFO: BootcampName.HIDER bootcamp completed, starting BootcampName.SEEKER bootcamp
INFO: BootcampName.SEEKER bootcamp completed, starting BootcampName.SLOW_AGENT bootcamp
INFO: Continuing with bootcamp BootcampName.SLOW_AGENT with slow factor: 20
INFO: Continuing with bootcamp BootcampName.SLOW_AGENT with slow factor: 20
INFO: Continuing with bootcamp BootcampName.SLOW_AGENT with slow factor: 20
INFO: Continuing with bootcamp BootcampName.SLOW_AGENT with slow factor: 20
INFO: Continuing with bootcamp BootcampName.SLOW_AGENT with slow factor: 20
INFO: Continuing with bootcamp BootcampName.SLOW_AGENT with slow factor: 20
INFO: Continuing with bootcamp BootcampName.SLOW_AGENT with slow factor: 20
INFO: Continuing with bootcamp BootcampName.SLOW_AGENT with slow factor: 20
INFO: Continuing with bootcamp BootcampName.SLOW_AGENT with slow factor: 20
INFO: Continuing with bootcamp BootcampName.SLOW_AGENT with slow factor: 20
INFO: Continuing with bootcamp BootcampName.SLOW_AGENT with slow factor: 20
INFO: Continuing with bootcamp BootcampName.SLOW_AGENT with slow factor: 20
WARNING: No frames in gif to save.
WARNING: No frames in gif to save.
INFO: Continuing with bootcamp BootcampName.SLOW_AGENT with slow factor: 20
INFO: Continuing with bootcamp BootcampName.SLOW_AGENT with slow factor: 20
INFO: Number of parameters: 30085
INFO: QNetwork(
  (conv_feature): Sequential()
  (fc_feature): Sequential(
    (0): Linear(in_features=100, out_features=128, bias=True)
    (1): ReLU()
    (2): Linear(in_features=128, out_features=128, bias=True)
    (3): ReLU()
    (4): Linear(in_features=128, out_features=5, bias=True)
  )
)
WARNING: GIF is enabled but the environment does not support RGB array rendering.
INFO: Learning...
INFO: BootcampName.HIDER bootcamp completed, starting BootcampName.SEEKER bootcamp
INFO: BootcampName.SEEKER bootcamp completed, starting BootcampName.SLOW_AGENT bootcamp
INFO: Continuing with bootcamp BootcampName.SLOW_AGENT with slow factor: 20
INFO: Continuing with bootcamp BootcampName.SLOW_AGENT with slow factor: 20
INFO: Continuing with bootcamp BootcampName.SLOW_AGENT with slow factor: 20
INFO: Number of parameters: 30085
INFO: QNetwork(
  (conv_feature): Sequential()
  (fc_feature): Sequential(
    (0): Linear(in_features=100, out_features=128, bias=True)
    (1): ReLU()
    (2): Linear(in_features=128, out_features=128, bias=True)
    (3): ReLU()
    (4): Linear(in_features=128, out_features=5, bias=True)
  )
)
WARNING: GIF is enabled but the environment does not support RGB array rendering.
INFO: Learning...
INFO: BootcampName.HIDER bootcamp completed, starting BootcampName.SEEKER bootcamp
INFO: BootcampName.SEEKER bootcamp completed, starting BootcampName.SLOW_AGENT bootcamp
INFO: Continuing with bootcamp BootcampName.SLOW_AGENT with slow factor: 20 for agent 0
INFO: Continuing with bootcamp BootcampName.SLOW_AGENT with slow factor: 20 for agent 0
INFO: Continuing with bootcamp BootcampName.SLOW_AGENT with slow factor: 20 for agent 0
INFO: Continuing with bootcamp BootcampName.SLOW_AGENT with slow factor: 20 for agent 0
INFO: Continuing with bootcamp BootcampName.SLOW_AGENT with slow factor: 20 for agent 0
INFO: Continuing with bootcamp BootcampName.SLOW_AGENT with slow factor: 20 for agent 0
INFO: Continuing with bootcamp BootcampName.SLOW_AGENT with slow factor: 20 for agent 0
INFO: Continuing with bootcamp BootcampName.SLOW_AGENT with slow factor: 20 for agent 0
INFO: Continuing with bootcamp BootcampName.SLOW_AGENT with slow factor: 20 for agent 0
INFO: Continuing with bootcamp BootcampName.SLOW_AGENT with slow factor: 20 for agent 0
INFO: Continuing with bootcamp BootcampName.SLOW_AGENT with slow factor: 20 for agent 0
WARNING: No frames in gif to save.
WARNING: No frames in gif to save.
INFO: Continuing with bootcamp BootcampName.SLOW_AGENT with slow factor: 20 for agent 0
INFO: Continuing with bootcamp BootcampName.SLOW_AGENT with slow factor: 20 for agent 0
INFO: Continuing with bootcamp BootcampName.SLOW_AGENT with slow factor: 20 for agent 0
INFO: Continuing with bootcamp BootcampName.SLOW_AGENT with slow factor: 20 for agent 0
INFO: Continuing with bootcamp BootcampName.SLOW_AGENT with slow factor: 20 for agent 0
INFO: Continuing with bootcamp BootcampName.SLOW_AGENT with slow factor: 20 for agent 0
WARNING: No frames in gif to save.
WARNING: No frames in gif to save.
INFO: Continuing with bootcamp BootcampName.SLOW_AGENT with slow factor: 20 for agent 0
INFO: Continuing with bootcamp BootcampName.SLOW_AGENT with slow factor: 20 for agent 0
INFO: Continuing with bootcamp BootcampName.SLOW_AGENT with slow factor: 20 for agent 0
INFO: Continuing with bootcamp BootcampName.SLOW_AGENT with slow factor: 20 for agent 0
INFO: Continuing with bootcamp BootcampName.SLOW_AGENT with slow factor: 20 for agent 0
WARNING: No frames in gif to save.
WARNING: No frames in gif to save.
INFO: Continuing with bootcamp BootcampName.SLOW_AGENT with slow factor: 20 for agent 0
INFO: Continuing with bootcamp BootcampName.SLOW_AGENT with slow factor: 20 for agent 0
WARNING: No frames in gif to save.
WARNING: No frames in gif to save.
INFO: Continuing with bootcamp BootcampName.SLOW_AGENT with slow factor: 20 for agent 0
INFO: Continuing with bootcamp BootcampName.SLOW_AGENT with slow factor: 20 for agent 0
INFO: Continuing with bootcamp BootcampName.SLOW_AGENT with slow factor: 20 for agent 0
WARNING: No frames in gif to save.
WARNING: No frames in gif to save.
INFO: Number of parameters: 30085
INFO: QNetwork(
  (conv_feature): Sequential()
  (fc_feature): Sequential(
    (0): Linear(in_features=100, out_features=128, bias=True)
    (1): ReLU()
    (2): Linear(in_features=128, out_features=128, bias=True)
    (3): ReLU()
    (4): Linear(in_features=128, out_features=5, bias=True)
  )
)
WARNING: GIF is enabled but the environment does not support RGB array rendering.
INFO: Learning...
INFO: BootcampName.HIDER bootcamp completed, starting BootcampName.SEEKER bootcamp
INFO: BootcampName.SEEKER bootcamp completed, starting BootcampName.SLOW_AGENT bootcamp
INFO: Continuing with bootcamp BootcampName.SLOW_AGENT with slow factor: 20 for agent 0
INFO: Continuing with bootcamp BootcampName.SLOW_AGENT with slow factor: 20 for agent 0
INFO: Continuing with bootcamp BootcampName.SLOW_AGENT with slow factor: 20 for agent 0
INFO: Continuing with bootcamp BootcampName.SLOW_AGENT with slow factor: 20 for agent 0
INFO: Continuing with bootcamp BootcampName.SLOW_AGENT with slow factor: 20 for agent 0
INFO: Number of parameters: 30085
INFO: QNetwork(
  (conv_feature): Sequential()
  (fc_feature): Sequential(
    (0): Linear(in_features=100, out_features=128, bias=True)
    (1): ReLU()
    (2): Linear(in_features=128, out_features=128, bias=True)
    (3): ReLU()
    (4): Linear(in_features=128, out_features=5, bias=True)
  )
)
WARNING: GIF is enabled but the environment does not support RGB array rendering.
INFO: Learning...
INFO: BootcampName.HIDER bootcamp completed, starting BootcampName.SEEKER bootcamp
INFO: BootcampName.SEEKER bootcamp completed, starting BootcampName.SLOW_AGENT bootcamp
INFO: Continuing with bootcamp BootcampName.SLOW_AGENT with slow factor: 20 for agent 0
INFO: Number of parameters: 30085
INFO: QNetwork(
  (conv_feature): Sequential()
  (fc_feature): Sequential(
    (0): Linear(in_features=100, out_features=128, bias=True)
    (1): ReLU()
    (2): Linear(in_features=128, out_features=128, bias=True)
    (3): ReLU()
    (4): Linear(in_features=128, out_features=5, bias=True)
  )
)
WARNING: GIF is enabled but the environment does not support RGB array rendering.
INFO: Learning...
INFO: BootcampName.HIDER bootcamp completed, starting BootcampName.SEEKER bootcamp
INFO: BootcampName.SEEKER bootcamp completed, starting BootcampName.SLOW_AGENT bootcamp
INFO: Continuing with bootcamp BootcampName.SLOW_AGENT with slow factor: 20 for agent 0
INFO: Continuing with bootcamp BootcampName.SLOW_AGENT with slow factor: 20 for agent 0
INFO: Number of parameters: 30085
INFO: QNetwork(
  (conv_feature): Sequential()
  (fc_feature): Sequential(
    (0): Linear(in_features=100, out_features=128, bias=True)
    (1): ReLU()
    (2): Linear(in_features=128, out_features=128, bias=True)
    (3): ReLU()
    (4): Linear(in_features=128, out_features=5, bias=True)
  )
)
WARNING: GIF is enabled but the environment does not support RGB array rendering.
INFO: Learning...
INFO: BootcampName.HIDER bootcamp completed, starting BootcampName.SEEKER bootcamp
INFO: BootcampName.SEEKER bootcamp completed, starting BootcampName.SLOW_AGENT bootcamp
INFO: Continuing with bootcamp BootcampName.SLOW_AGENT with slow factor: 19 for agent 1
INFO: Continuing with bootcamp BootcampName.SLOW_AGENT with slow factor: 19 for agent 0
INFO: Continuing with bootcamp BootcampName.SLOW_AGENT with slow factor: 18 for agent 1
INFO: Continuing with bootcamp BootcampName.SLOW_AGENT with slow factor: 18 for agent 0
INFO: Continuing with bootcamp BootcampName.SLOW_AGENT with slow factor: 17 for agent 1
INFO: Continuing with bootcamp BootcampName.SLOW_AGENT with slow factor: 17 for agent 0
INFO: Continuing with bootcamp BootcampName.SLOW_AGENT with slow factor: 16 for agent 1
INFO: Continuing with bootcamp BootcampName.SLOW_AGENT with slow factor: 16 for agent 0
INFO: Continuing with bootcamp BootcampName.SLOW_AGENT with slow factor: 15 for agent 1
INFO: Continuing with bootcamp BootcampName.SLOW_AGENT with slow factor: 15 for agent 0
INFO: Continuing with bootcamp BootcampName.SLOW_AGENT with slow factor: 14 for agent 1
INFO: Number of parameters: 30085
INFO: QNetwork(
  (conv_feature): Sequential()
  (fc_feature): Sequential(
    (0): Linear(in_features=100, out_features=128, bias=True)
    (1): ReLU()
    (2): Linear(in_features=128, out_features=128, bias=True)
    (3): ReLU()
    (4): Linear(in_features=128, out_features=5, bias=True)
  )
)
WARNING: GIF is enabled but the environment does not support RGB array rendering.
INFO: Learning...
INFO: BootcampName.HIDER bootcamp completed, starting BootcampName.SEEKER bootcamp
INFO: BootcampName.SEEKER bootcamp completed, starting BootcampName.SLOW_AGENT bootcamp
INFO: Continuing with bootcamp BootcampName.SLOW_AGENT with slow factor: 19 for agent 1
INFO: Continuing with bootcamp BootcampName.SLOW_AGENT with slow factor: 19 for agent 0
INFO: Continuing with bootcamp BootcampName.SLOW_AGENT with slow factor: 18 for agent 1
INFO: Continuing with bootcamp BootcampName.SLOW_AGENT with slow factor: 18 for agent 0
INFO: Continuing with bootcamp BootcampName.SLOW_AGENT with slow factor: 17 for agent 1
INFO: Continuing with bootcamp BootcampName.SLOW_AGENT with slow factor: 17 for agent 0
INFO: Continuing with bootcamp BootcampName.SLOW_AGENT with slow factor: 16 for agent 1
INFO: Continuing with bootcamp BootcampName.SLOW_AGENT with slow factor: 16 for agent 0
INFO: Continuing with bootcamp BootcampName.SLOW_AGENT with slow factor: 15 for agent 1
INFO: Continuing with bootcamp BootcampName.SLOW_AGENT with slow factor: 15 for agent 0
INFO: Continuing with bootcamp BootcampName.SLOW_AGENT with slow factor: 14 for agent 1
INFO: Continuing with bootcamp BootcampName.SLOW_AGENT with slow factor: 14 for agent 0
INFO: Number of parameters: 30085
INFO: QNetwork(
  (conv_feature): Sequential()
  (fc_feature): Sequential(
    (0): Linear(in_features=100, out_features=128, bias=True)
    (1): ReLU()
    (2): Linear(in_features=128, out_features=128, bias=True)
    (3): ReLU()
    (4): Linear(in_features=128, out_features=5, bias=True)
  )
)
WARNING: GIF is enabled but the environment does not support RGB array rendering.
INFO: Learning...
INFO: BootcampName.HIDER bootcamp completed, starting BootcampName.SEEKER bootcamp
INFO: BootcampName.SEEKER bootcamp completed, starting BootcampName.SLOW_AGENT bootcamp
INFO: Continuing with bootcamp BootcampName.SLOW_AGENT with slow factor: 19 for agent 1
INFO: Continuing with bootcamp BootcampName.SLOW_AGENT with slow factor: 19 for agent 0
INFO: Continuing with bootcamp BootcampName.SLOW_AGENT with slow factor: 18 for agent 1
INFO: Continuing with bootcamp BootcampName.SLOW_AGENT with slow factor: 18 for agent 0
INFO: Number of parameters: 30085
INFO: QNetwork(
  (conv_feature): Sequential()
  (fc_feature): Sequential(
    (0): Linear(in_features=100, out_features=128, bias=True)
    (1): ReLU()
    (2): Linear(in_features=128, out_features=128, bias=True)
    (3): ReLU()
    (4): Linear(in_features=128, out_features=5, bias=True)
  )
)
WARNING: GIF is enabled but the environment does not support RGB array rendering.
INFO: Learning...
INFO: BootcampName.HIDER bootcamp completed, starting BootcampName.SEEKER bootcamp
INFO: BootcampName.SEEKER bootcamp completed, starting BootcampName.SLOW_AGENT bootcamp
INFO: Number of parameters: 30085
INFO: QNetwork(
  (conv_feature): Sequential()
  (fc_feature): Sequential(
    (0): Linear(in_features=100, out_features=128, bias=True)
    (1): ReLU()
    (2): Linear(in_features=128, out_features=128, bias=True)
    (3): ReLU()
    (4): Linear(in_features=128, out_features=5, bias=True)
  )
)
WARNING: GIF is enabled but the environment does not support RGB array rendering.
INFO: Learning...
INFO: BootcampName.HIDER bootcamp completed, starting BootcampName.SEEKER bootcamp
INFO: BootcampName.SEEKER bootcamp completed, starting BootcampName.SLOW_AGENT bootcamp
INFO: Continuing with bootcamp BootcampName.SLOW_AGENT with slow factor: 19 for agent 1
INFO: Continuing with bootcamp BootcampName.SLOW_AGENT with slow factor: 19 for agent 0
INFO: Continuing with bootcamp BootcampName.SLOW_AGENT with slow factor: 18 for agent 1
INFO: Continuing with bootcamp BootcampName.SLOW_AGENT with slow factor: 18 for agent 0
INFO: Continuing with bootcamp BootcampName.SLOW_AGENT with slow factor: 17 for agent 1
INFO: Continuing with bootcamp BootcampName.SLOW_AGENT with slow factor: 17 for agent 0
INFO: Continuing with bootcamp BootcampName.SLOW_AGENT with slow factor: 16 for agent 1
INFO: Continuing with bootcamp BootcampName.SLOW_AGENT with slow factor: 16 for agent 0
INFO: Continuing with bootcamp BootcampName.SLOW_AGENT with slow factor: 15 for agent 1
INFO: Continuing with bootcamp BootcampName.SLOW_AGENT with slow factor: 15 for agent 0
INFO: Continuing with bootcamp BootcampName.SLOW_AGENT with slow factor: 14 for agent 1
INFO: Continuing with bootcamp BootcampName.SLOW_AGENT with slow factor: 14 for agent 0
INFO: Continuing with bootcamp BootcampName.SLOW_AGENT with slow factor: 13 for agent 1
WARNING: No frames in gif to save.
WARNING: No frames in gif to save.
INFO: Continuing with bootcamp BootcampName.SLOW_AGENT with slow factor: 13 for agent 0
INFO: Continuing with bootcamp BootcampName.SLOW_AGENT with slow factor: 12 for agent 1
INFO: Continuing with bootcamp BootcampName.SLOW_AGENT with slow factor: 12 for agent 0
INFO: Continuing with bootcamp BootcampName.SLOW_AGENT with slow factor: 11 for agent 1
INFO: Continuing with bootcamp BootcampName.SLOW_AGENT with slow factor: 11 for agent 0
INFO: Continuing with bootcamp BootcampName.SLOW_AGENT with slow factor: 10 for agent 1
INFO: Continuing with bootcamp BootcampName.SLOW_AGENT with slow factor: 10 for agent 0
INFO: Continuing with bootcamp BootcampName.SLOW_AGENT with slow factor: 9 for agent 1
INFO: Continuing with bootcamp BootcampName.SLOW_AGENT with slow factor: 9 for agent 0
INFO: Continuing with bootcamp BootcampName.SLOW_AGENT with slow factor: 8 for agent 1
INFO: Continuing with bootcamp BootcampName.SLOW_AGENT with slow factor: 8 for agent 0
INFO: Continuing with bootcamp BootcampName.SLOW_AGENT with slow factor: 7 for agent 1
INFO: Continuing with bootcamp BootcampName.SLOW_AGENT with slow factor: 7 for agent 0
WARNING: No frames in gif to save.
WARNING: No frames in gif to save.
INFO: Continuing with bootcamp BootcampName.SLOW_AGENT with slow factor: 6 for agent 1
INFO: Continuing with bootcamp BootcampName.SLOW_AGENT with slow factor: 6 for agent 0
INFO: Continuing with bootcamp BootcampName.SLOW_AGENT with slow factor: 5 for agent 1
INFO: Continuing with bootcamp BootcampName.SLOW_AGENT with slow factor: 5 for agent 0
INFO: Continuing with bootcamp BootcampName.SLOW_AGENT with slow factor: 4 for agent 1
INFO: Continuing with bootcamp BootcampName.SLOW_AGENT with slow factor: 4 for agent 0
INFO: Continuing with bootcamp BootcampName.SLOW_AGENT with slow factor: 3 for agent 1
INFO: Continuing with bootcamp BootcampName.SLOW_AGENT with slow factor: 3 for agent 0
INFO: Continuing with bootcamp BootcampName.SLOW_AGENT with slow factor: 2 for agent 1
INFO: Continuing with bootcamp BootcampName.SLOW_AGENT with slow factor: 2 for agent 0
INFO: BootcampName.SLOW_AGENT bootcamp completed, starting BootcampName.COMBINED bootcamp
WARNING: No frames in gif to save.
WARNING: No frames in gif to save.
INFO: Number of parameters: 30085
INFO: QNetwork(
  (conv_feature): Sequential()
  (fc_feature): Sequential(
    (0): Linear(in_features=100, out_features=128, bias=True)
    (1): ReLU()
    (2): Linear(in_features=128, out_features=128, bias=True)
    (3): ReLU()
    (4): Linear(in_features=128, out_features=5, bias=True)
  )
)
WARNING: GIF is enabled but the environment does not support RGB array rendering.
INFO: Learning...
INFO: BootcampName.HIDER bootcamp completed, starting BootcampName.SEEKER bootcamp
INFO: BootcampName.SEEKER bootcamp completed, starting BootcampName.SLOW_AGENT bootcamp
INFO: Continuing with bootcamp BootcampName.SLOW_AGENT with slow factor: 19 for agent 1
INFO: Continuing with bootcamp BootcampName.SLOW_AGENT with slow factor: 19 for agent 0
INFO: Continuing with bootcamp BootcampName.SLOW_AGENT with slow factor: 18 for agent 1
INFO: Continuing with bootcamp BootcampName.SLOW_AGENT with slow factor: 18 for agent 0
INFO: Continuing with bootcamp BootcampName.SLOW_AGENT with slow factor: 17 for agent 1
INFO: Continuing with bootcamp BootcampName.SLOW_AGENT with slow factor: 17 for agent 0
INFO: Continuing with bootcamp BootcampName.SLOW_AGENT with slow factor: 16 for agent 1
INFO: Continuing with bootcamp BootcampName.SLOW_AGENT with slow factor: 16 for agent 0
INFO: Continuing with bootcamp BootcampName.SLOW_AGENT with slow factor: 15 for agent 1
INFO: Continuing with bootcamp BootcampName.SLOW_AGENT with slow factor: 15 for agent 0
INFO: Continuing with bootcamp BootcampName.SLOW_AGENT with slow factor: 14 for agent 1
INFO: Continuing with bootcamp BootcampName.SLOW_AGENT with slow factor: 14 for agent 0
WARNING: No frames in gif to save.
WARNING: No frames in gif to save.
INFO: Continuing with bootcamp BootcampName.SLOW_AGENT with slow factor: 13 for agent 1
INFO: Continuing with bootcamp BootcampName.SLOW_AGENT with slow factor: 13 for agent 0
INFO: Continuing with bootcamp BootcampName.SLOW_AGENT with slow factor: 12 for agent 1
INFO: Continuing with bootcamp BootcampName.SLOW_AGENT with slow factor: 12 for agent 0
INFO: Continuing with bootcamp BootcampName.SLOW_AGENT with slow factor: 11 for agent 1
INFO: Continuing with bootcamp BootcampName.SLOW_AGENT with slow factor: 11 for agent 0
WARNING: No frames in gif to save.
WARNING: No frames in gif to save.
INFO: Continuing with bootcamp BootcampName.SLOW_AGENT with slow factor: 10 for agent 1
INFO: Continuing with bootcamp BootcampName.SLOW_AGENT with slow factor: 10 for agent 0
INFO: Continuing with bootcamp BootcampName.SLOW_AGENT with slow factor: 9 for agent 1
INFO: Continuing with bootcamp BootcampName.SLOW_AGENT with slow factor: 9 for agent 0
INFO: Continuing with bootcamp BootcampName.SLOW_AGENT with slow factor: 8 for agent 1
INFO: Continuing with bootcamp BootcampName.SLOW_AGENT with slow factor: 8 for agent 0
INFO: Continuing with bootcamp BootcampName.SLOW_AGENT with slow factor: 7 for agent 1
INFO: Continuing with bootcamp BootcampName.SLOW_AGENT with slow factor: 7 for agent 0
WARNING: No frames in gif to save.
WARNING: No frames in gif to save.
INFO: Continuing with bootcamp BootcampName.SLOW_AGENT with slow factor: 6 for agent 1
INFO: Continuing with bootcamp BootcampName.SLOW_AGENT with slow factor: 6 for agent 0
INFO: Continuing with bootcamp BootcampName.SLOW_AGENT with slow factor: 5 for agent 1
INFO: Continuing with bootcamp BootcampName.SLOW_AGENT with slow factor: 5 for agent 0
INFO: Continuing with bootcamp BootcampName.SLOW_AGENT with slow factor: 4 for agent 1
INFO: Continuing with bootcamp BootcampName.SLOW_AGENT with slow factor: 4 for agent 0
INFO: Continuing with bootcamp BootcampName.SLOW_AGENT with slow factor: 3 for agent 1
INFO: Continuing with bootcamp BootcampName.SLOW_AGENT with slow factor: 3 for agent 0
INFO: Continuing with bootcamp BootcampName.SLOW_AGENT with slow factor: 2 for agent 1
INFO: Continuing with bootcamp BootcampName.SLOW_AGENT with slow factor: 2 for agent 0
INFO: BootcampName.SLOW_AGENT bootcamp completed, starting BootcampName.COMBINED bootcamp
WARNING: No frames in gif to save.
WARNING: No frames in gif to save.
WARNING: No frames in gif to save.
WARNING: No frames in gif to save.
INFO: Number of parameters: 30085
INFO: QNetwork(
  (conv_feature): Sequential()
  (fc_feature): Sequential(
    (0): Linear(in_features=100, out_features=128, bias=True)
    (1): ReLU()
    (2): Linear(in_features=128, out_features=128, bias=True)
    (3): ReLU()
    (4): Linear(in_features=128, out_features=5, bias=True)
  )
)
WARNING: GIF is enabled but the environment does not support RGB array rendering.
INFO: Learning...
INFO: BootcampName.HIDER bootcamp completed, starting BootcampName.SEEKER bootcamp
INFO: BootcampName.SEEKER bootcamp completed, starting BootcampName.SLOW_AGENT bootcamp
INFO: Continuing with bootcamp BootcampName.SLOW_AGENT with slow factor: 19 for agent 1
INFO: Continuing with bootcamp BootcampName.SLOW_AGENT with slow factor: 19 for agent 0
INFO: Continuing with bootcamp BootcampName.SLOW_AGENT with slow factor: 18 for agent 1
INFO: Continuing with bootcamp BootcampName.SLOW_AGENT with slow factor: 18 for agent 0
INFO: Continuing with bootcamp BootcampName.SLOW_AGENT with slow factor: 17 for agent 1
INFO: Continuing with bootcamp BootcampName.SLOW_AGENT with slow factor: 17 for agent 0
INFO: Continuing with bootcamp BootcampName.SLOW_AGENT with slow factor: 16 for agent 1
INFO: Number of parameters: 30085
INFO: QNetwork(
  (conv_feature): Sequential()
  (fc_feature): Sequential(
    (0): Linear(in_features=100, out_features=128, bias=True)
    (1): ReLU()
    (2): Linear(in_features=128, out_features=128, bias=True)
    (3): ReLU()
    (4): Linear(in_features=128, out_features=5, bias=True)
  )
)
WARNING: GIF is enabled but the environment does not support RGB array rendering.
INFO: Learning...
INFO: BootcampName.HIDER bootcamp completed, starting BootcampName.SEEKER bootcamp
INFO: BootcampName.SEEKER bootcamp completed, starting BootcampName.SLOW_AGENT bootcamp
INFO: Continuing with bootcamp BootcampName.SLOW_AGENT with slow factor: 19 for agent 1
INFO: Continuing with bootcamp BootcampName.SLOW_AGENT with slow factor: 19 for agent 0
INFO: Continuing with bootcamp BootcampName.SLOW_AGENT with slow factor: 18 for agent 1
INFO: Continuing with bootcamp BootcampName.SLOW_AGENT with slow factor: 18 for agent 0
INFO: Continuing with bootcamp BootcampName.SLOW_AGENT with slow factor: 17 for agent 1
INFO: Continuing with bootcamp BootcampName.SLOW_AGENT with slow factor: 17 for agent 0
INFO: Continuing with bootcamp BootcampName.SLOW_AGENT with slow factor: 16 for agent 1
INFO: Continuing with bootcamp BootcampName.SLOW_AGENT with slow factor: 16 for agent 0
INFO: Continuing with bootcamp BootcampName.SLOW_AGENT with slow factor: 15 for agent 1
INFO: Continuing with bootcamp BootcampName.SLOW_AGENT with slow factor: 15 for agent 0
INFO: Continuing with bootcamp BootcampName.SLOW_AGENT with slow factor: 14 for agent 1
INFO: Continuing with bootcamp BootcampName.SLOW_AGENT with slow factor: 14 for agent 0
INFO: Continuing with bootcamp BootcampName.SLOW_AGENT with slow factor: 13 for agent 1
INFO: Continuing with bootcamp BootcampName.SLOW_AGENT with slow factor: 13 for agent 0
INFO: Continuing with bootcamp BootcampName.SLOW_AGENT with slow factor: 12 for agent 1
INFO: Continuing with bootcamp BootcampName.SLOW_AGENT with slow factor: 12 for agent 0
INFO: Number of parameters: 30085
INFO: QNetwork(
  (conv_feature): Sequential()
  (fc_feature): Sequential(
    (0): Linear(in_features=100, out_features=128, bias=True)
    (1): ReLU()
    (2): Linear(in_features=128, out_features=128, bias=True)
    (3): ReLU()
    (4): Linear(in_features=128, out_features=5, bias=True)
  )
)
WARNING: GIF is enabled but the environment does not support RGB array rendering.
INFO: Learning...
INFO: BootcampName.HIDER bootcamp completed, starting BootcampName.SEEKER bootcamp
INFO: BootcampName.SEEKER bootcamp completed, starting BootcampName.SLOW_AGENT bootcamp
INFO: Continuing with bootcamp BootcampName.SLOW_AGENT with slow factor: 19 for agent 1
INFO: Continuing with bootcamp BootcampName.SLOW_AGENT with slow factor: 19 for agent 0
INFO: Continuing with bootcamp BootcampName.SLOW_AGENT with slow factor: 18 for agent 1
INFO: Continuing with bootcamp BootcampName.SLOW_AGENT with slow factor: 18 for agent 0
INFO: Continuing with bootcamp BootcampName.SLOW_AGENT with slow factor: 17 for agent 1
INFO: Continuing with bootcamp BootcampName.SLOW_AGENT with slow factor: 17 for agent 0
INFO: Continuing with bootcamp BootcampName.SLOW_AGENT with slow factor: 16 for agent 1
INFO: Continuing with bootcamp BootcampName.SLOW_AGENT with slow factor: 16 for agent 0
INFO: Continuing with bootcamp BootcampName.SLOW_AGENT with slow factor: 15 for agent 1
INFO: Continuing with bootcamp BootcampName.SLOW_AGENT with slow factor: 15 for agent 0
INFO: Continuing with bootcamp BootcampName.SLOW_AGENT with slow factor: 14 for agent 1
INFO: Continuing with bootcamp BootcampName.SLOW_AGENT with slow factor: 14 for agent 0
WARNING: No frames in gif to save.
WARNING: No frames in gif to save.
INFO: Continuing with bootcamp BootcampName.SLOW_AGENT with slow factor: 13 for agent 1
INFO: Continuing with bootcamp BootcampName.SLOW_AGENT with slow factor: 13 for agent 0
INFO: Continuing with bootcamp BootcampName.SLOW_AGENT with slow factor: 12 for agent 1
INFO: Continuing with bootcamp BootcampName.SLOW_AGENT with slow factor: 12 for agent 0
INFO: Continuing with bootcamp BootcampName.SLOW_AGENT with slow factor: 11 for agent 1
INFO: Continuing with bootcamp BootcampName.SLOW_AGENT with slow factor: 11 for agent 0
WARNING: No frames in gif to save.
WARNING: No frames in gif to save.
INFO: Continuing with bootcamp BootcampName.SLOW_AGENT with slow factor: 10 for agent 1
INFO: Continuing with bootcamp BootcampName.SLOW_AGENT with slow factor: 10 for agent 0
INFO: Continuing with bootcamp BootcampName.SLOW_AGENT with slow factor: 9 for agent 1
INFO: Continuing with bootcamp BootcampName.SLOW_AGENT with slow factor: 9 for agent 0
INFO: Continuing with bootcamp BootcampName.SLOW_AGENT with slow factor: 8 for agent 1
INFO: Continuing with bootcamp BootcampName.SLOW_AGENT with slow factor: 8 for agent 0
INFO: Continuing with bootcamp BootcampName.SLOW_AGENT with slow factor: 7 for agent 1
WARNING: No frames in gif to save.
WARNING: No frames in gif to save.
INFO: Continuing with bootcamp BootcampName.SLOW_AGENT with slow factor: 7 for agent 0
INFO: Continuing with bootcamp BootcampName.SLOW_AGENT with slow factor: 6 for agent 1
INFO: Continuing with bootcamp BootcampName.SLOW_AGENT with slow factor: 6 for agent 0
INFO: Continuing with bootcamp BootcampName.SLOW_AGENT with slow factor: 5 for agent 1
INFO: Continuing with bootcamp BootcampName.SLOW_AGENT with slow factor: 5 for agent 0
INFO: Continuing with bootcamp BootcampName.SLOW_AGENT with slow factor: 4 for agent 1
INFO: Continuing with bootcamp BootcampName.SLOW_AGENT with slow factor: 4 for agent 0
INFO: Continuing with bootcamp BootcampName.SLOW_AGENT with slow factor: 3 for agent 1
INFO: Continuing with bootcamp BootcampName.SLOW_AGENT with slow factor: 3 for agent 0
INFO: Continuing with bootcamp BootcampName.SLOW_AGENT with slow factor: 2 for agent 1
WARNING: No frames in gif to save.
WARNING: No frames in gif to save.
INFO: Continuing with bootcamp BootcampName.SLOW_AGENT with slow factor: 2 for agent 0
INFO: BootcampName.SLOW_AGENT bootcamp completed, starting BootcampName.COMBINED bootcamp
WARNING: No frames in gif to save.
WARNING: No frames in gif to save.
WARNING: No frames in gif to save.
WARNING: No frames in gif to save.
WARNING: No frames in gif to save.
WARNING: No frames in gif to save.
WARNING: No frames in gif to save.
WARNING: No frames in gif to save.
WARNING: No frames in gif to save.
WARNING: No frames in gif to save.
WARNING: No frames in gif to save.
WARNING: No frames in gif to save.
WARNING: No frames in gif to save.
WARNING: No frames in gif to save.
INFO: Cleaning cache: /home/eirik/.cache/wandb/artifacts/obj 0.00390625 MB
INFO: cleaning local: /home/eirik/.local/share/wandb/artifacts/staging 0.00390625 MB
WARNING: No frames in gif to save.
WARNING: No frames in gif to save.
WARNING: No frames in gif to save.
WARNING: No frames in gif to save.
INFO: Number of parameters: 30085
INFO: QNetwork(
  (conv_feature): Sequential()
  (fc_feature): Sequential(
    (0): Linear(in_features=100, out_features=128, bias=True)
    (1): ReLU()
    (2): Linear(in_features=128, out_features=128, bias=True)
    (3): ReLU()
    (4): Linear(in_features=128, out_features=5, bias=True)
  )
)
WARNING: GIF is enabled but the environment does not support RGB array rendering.
INFO: Learning...
INFO: BootcampName.HIDER bootcamp completed, starting BootcampName.SEEKER bootcamp
INFO: BootcampName.SEEKER bootcamp completed, starting BootcampName.SLOW_AGENT bootcamp
INFO: Continuing with bootcamp BootcampName.SLOW_AGENT with slow factor: 19 for agent 1
INFO: Continuing with bootcamp BootcampName.SLOW_AGENT with slow factor: 19 for agent 0
INFO: Continuing with bootcamp BootcampName.SLOW_AGENT with slow factor: 18 for agent 1
INFO: Continuing with bootcamp BootcampName.SLOW_AGENT with slow factor: 18 for agent 0
INFO: Continuing with bootcamp BootcampName.SLOW_AGENT with slow factor: 17 for agent 1
INFO: Continuing with bootcamp BootcampName.SLOW_AGENT with slow factor: 17 for agent 0
INFO: Continuing with bootcamp BootcampName.SLOW_AGENT with slow factor: 16 for agent 1
INFO: Continuing with bootcamp BootcampName.SLOW_AGENT with slow factor: 16 for agent 0
INFO: Continuing with bootcamp BootcampName.SLOW_AGENT with slow factor: 15 for agent 1
INFO: Continuing with bootcamp BootcampName.SLOW_AGENT with slow factor: 15 for agent 0
WARNING: No frames in gif to save.
WARNING: No frames in gif to save.
INFO: Continuing with bootcamp BootcampName.SLOW_AGENT with slow factor: 14 for agent 1
INFO: Continuing with bootcamp BootcampName.SLOW_AGENT with slow factor: 14 for agent 0
INFO: Continuing with bootcamp BootcampName.SLOW_AGENT with slow factor: 13 for agent 1
INFO: Continuing with bootcamp BootcampName.SLOW_AGENT with slow factor: 13 for agent 0
INFO: Continuing with bootcamp BootcampName.SLOW_AGENT with slow factor: 12 for agent 1
INFO: Continuing with bootcamp BootcampName.SLOW_AGENT with slow factor: 12 for agent 0
INFO: Continuing with bootcamp BootcampName.SLOW_AGENT with slow factor: 11 for agent 1
INFO: Continuing with bootcamp BootcampName.SLOW_AGENT with slow factor: 11 for agent 0
WARNING: No frames in gif to save.
WARNING: No frames in gif to save.
INFO: Continuing with bootcamp BootcampName.SLOW_AGENT with slow factor: 10 for agent 1
INFO: Number of parameters: 30085
INFO: QNetwork(
  (conv_feature): Sequential()
  (fc_feature): Sequential(
    (0): Linear(in_features=100, out_features=128, bias=True)
    (1): ReLU()
    (2): Linear(in_features=128, out_features=128, bias=True)
    (3): ReLU()
    (4): Linear(in_features=128, out_features=5, bias=True)
  )
)
WARNING: GIF is enabled but the environment does not support RGB array rendering.
INFO: Learning...
INFO: BootcampName.HIDER bootcamp completed, starting BootcampName.SEEKER bootcamp
INFO: BootcampName.SEEKER bootcamp completed, starting BootcampName.SLOW_AGENT bootcamp
INFO: Continuing with bootcamp BootcampName.SLOW_AGENT with slow factor: 19 for agent 1
INFO: Continuing with bootcamp BootcampName.SLOW_AGENT with slow factor: 19 for agent 0
INFO: Continuing with bootcamp BootcampName.SLOW_AGENT with slow factor: 18 for agent 1
INFO: Continuing with bootcamp BootcampName.SLOW_AGENT with slow factor: 18 for agent 0
INFO: Continuing with bootcamp BootcampName.SLOW_AGENT with slow factor: 17 for agent 1
INFO: Continuing with bootcamp BootcampName.SLOW_AGENT with slow factor: 17 for agent 0
WARNING: No frames in gif to save.
WARNING: No frames in gif to save.
INFO: Continuing with bootcamp BootcampName.SLOW_AGENT with slow factor: 16 for agent 1
INFO: Continuing with bootcamp BootcampName.SLOW_AGENT with slow factor: 16 for agent 0
INFO: Continuing with bootcamp BootcampName.SLOW_AGENT with slow factor: 15 for agent 1
INFO: Continuing with bootcamp BootcampName.SLOW_AGENT with slow factor: 15 for agent 0
WARNING: No frames in gif to save.
WARNING: No frames in gif to save.
INFO: Continuing with bootcamp BootcampName.SLOW_AGENT with slow factor: 14 for agent 1
INFO: Continuing with bootcamp BootcampName.SLOW_AGENT with slow factor: 14 for agent 0
WARNING: No frames in gif to save.
WARNING: No frames in gif to save.
INFO: Continuing with bootcamp BootcampName.SLOW_AGENT with slow factor: 13 for agent 1
INFO: Continuing with bootcamp BootcampName.SLOW_AGENT with slow factor: 13 for agent 0
WARNING: No frames in gif to save.
WARNING: No frames in gif to save.
INFO: Continuing with bootcamp BootcampName.SLOW_AGENT with slow factor: 12 for agent 1
INFO: Continuing with bootcamp BootcampName.SLOW_AGENT with slow factor: 12 for agent 0
WARNING: No frames in gif to save.
WARNING: No frames in gif to save.
INFO: Continuing with bootcamp BootcampName.SLOW_AGENT with slow factor: 11 for agent 1
INFO: Continuing with bootcamp BootcampName.SLOW_AGENT with slow factor: 11 for agent 0
WARNING: No frames in gif to save.
WARNING: No frames in gif to save.
INFO: Continuing with bootcamp BootcampName.SLOW_AGENT with slow factor: 10 for agent 1
INFO: Continuing with bootcamp BootcampName.SLOW_AGENT with slow factor: 10 for agent 0
INFO: Continuing with bootcamp BootcampName.SLOW_AGENT with slow factor: 9 for agent 1
INFO: Continuing with bootcamp BootcampName.SLOW_AGENT with slow factor: 9 for agent 0
WARNING: No frames in gif to save.
WARNING: No frames in gif to save.
INFO: Continuing with bootcamp BootcampName.SLOW_AGENT with slow factor: 8 for agent 1
WARNING: No frames in gif to save.
WARNING: No frames in gif to save.
INFO: Continuing with bootcamp BootcampName.SLOW_AGENT with slow factor: 8 for agent 0
INFO: Continuing with bootcamp BootcampName.SLOW_AGENT with slow factor: 7 for agent 1
INFO: Continuing with bootcamp BootcampName.SLOW_AGENT with slow factor: 7 for agent 0
WARNING: No frames in gif to save.
WARNING: No frames in gif to save.
INFO: Continuing with bootcamp BootcampName.SLOW_AGENT with slow factor: 6 for agent 1
INFO: Continuing with bootcamp BootcampName.SLOW_AGENT with slow factor: 6 for agent 0
INFO: Continuing with bootcamp BootcampName.SLOW_AGENT with slow factor: 5 for agent 1
INFO: Continuing with bootcamp BootcampName.SLOW_AGENT with slow factor: 5 for agent 0
INFO: Continuing with bootcamp BootcampName.SLOW_AGENT with slow factor: 4 for agent 1
WARNING: No frames in gif to save.
WARNING: No frames in gif to save.
INFO: Continuing with bootcamp BootcampName.SLOW_AGENT with slow factor: 4 for agent 0
INFO: Continuing with bootcamp BootcampName.SLOW_AGENT with slow factor: 3 for agent 1
INFO: Continuing with bootcamp BootcampName.SLOW_AGENT with slow factor: 3 for agent 0
INFO: Continuing with bootcamp BootcampName.SLOW_AGENT with slow factor: 2 for agent 1
INFO: Continuing with bootcamp BootcampName.SLOW_AGENT with slow factor: 2 for agent 0
INFO: BootcampName.SLOW_AGENT bootcamp completed, starting BootcampName.COMBINED bootcamp
WARNING: No frames in gif to save.
WARNING: No frames in gif to save.
INFO: Cleaning cache: /home/eirik/.cache/wandb/artifacts/obj 0.00390625 MB
INFO: cleaning local: /home/eirik/.local/share/wandb/artifacts/staging 0.00390625 MB
WARNING: No frames in gif to save.
WARNING: No frames in gif to save.
WARNING: No frames in gif to save.
WARNING: No frames in gif to save.
INFO: Number of parameters: 30085
INFO: QNetwork(
  (conv_feature): Sequential()
  (fc_feature): Sequential(
    (0): Linear(in_features=100, out_features=128, bias=True)
    (1): ReLU()
    (2): Linear(in_features=128, out_features=128, bias=True)
    (3): ReLU()
    (4): Linear(in_features=128, out_features=5, bias=True)
  )
)
INFO: Learning...
INFO: BootcampName.HIDER bootcamp completed, starting BootcampName.SEEKER bootcamp
INFO: BootcampName.SEEKER bootcamp completed, starting BootcampName.SLOW_AGENT bootcamp
INFO: Continuing with bootcamp BootcampName.SLOW_AGENT with slow factor: 19 for agent 1
INFO: Continuing with bootcamp BootcampName.SLOW_AGENT with slow factor: 19 for agent 0
INFO: Continuing with bootcamp BootcampName.SLOW_AGENT with slow factor: 18 for agent 1
INFO: Continuing with bootcamp BootcampName.SLOW_AGENT with slow factor: 18 for agent 0
INFO: Continuing with bootcamp BootcampName.SLOW_AGENT with slow factor: 17 for agent 1
INFO: Continuing with bootcamp BootcampName.SLOW_AGENT with slow factor: 17 for agent 0
INFO: Continuing with bootcamp BootcampName.SLOW_AGENT with slow factor: 16 for agent 1
INFO: Continuing with bootcamp BootcampName.SLOW_AGENT with slow factor: 16 for agent 0
INFO: Continuing with bootcamp BootcampName.SLOW_AGENT with slow factor: 15 for agent 1
INFO: Continuing with bootcamp BootcampName.SLOW_AGENT with slow factor: 15 for agent 0
INFO: Continuing with bootcamp BootcampName.SLOW_AGENT with slow factor: 14 for agent 1
INFO: Continuing with bootcamp BootcampName.SLOW_AGENT with slow factor: 14 for agent 0
INFO: Continuing with bootcamp BootcampName.SLOW_AGENT with slow factor: 13 for agent 1
INFO: Continuing with bootcamp BootcampName.SLOW_AGENT with slow factor: 13 for agent 0
INFO: Continuing with bootcamp BootcampName.SLOW_AGENT with slow factor: 12 for agent 1
INFO: Continuing with bootcamp BootcampName.SLOW_AGENT with slow factor: 12 for agent 0
INFO: Cleaning cache: /home/eirik/.cache/wandb/artifacts/obj 0.00390625 MB
INFO: cleaning local: /home/eirik/.local/share/wandb/artifacts/staging 0.00390625 MB
INFO: Continuing with bootcamp BootcampName.SLOW_AGENT with slow factor: 11 for agent 1
INFO: Continuing with bootcamp BootcampName.SLOW_AGENT with slow factor: 11 for agent 0
INFO: Continuing with bootcamp BootcampName.SLOW_AGENT with slow factor: 10 for agent 1
INFO: Continuing with bootcamp BootcampName.SLOW_AGENT with slow factor: 10 for agent 0
INFO: Continuing with bootcamp BootcampName.SLOW_AGENT with slow factor: 9 for agent 1
INFO: Continuing with bootcamp BootcampName.SLOW_AGENT with slow factor: 9 for agent 0
INFO: Continuing with bootcamp BootcampName.SLOW_AGENT with slow factor: 8 for agent 1
INFO: Continuing with bootcamp BootcampName.SLOW_AGENT with slow factor: 8 for agent 0
INFO: Continuing with bootcamp BootcampName.SLOW_AGENT with slow factor: 7 for agent 1
INFO: Continuing with bootcamp BootcampName.SLOW_AGENT with slow factor: 7 for agent 0
INFO: Continuing with bootcamp BootcampName.SLOW_AGENT with slow factor: 6 for agent 1
INFO: Cleaning cache: /home/eirik/.cache/wandb/artifacts/obj 0.00390625 MB
INFO: cleaning local: /home/eirik/.local/share/wandb/artifacts/staging 0.00390625 MB
INFO: Continuing with bootcamp BootcampName.SLOW_AGENT with slow factor: 6 for agent 0
INFO: Continuing with bootcamp BootcampName.SLOW_AGENT with slow factor: 5 for agent 1
INFO: Continuing with bootcamp BootcampName.SLOW_AGENT with slow factor: 5 for agent 0
INFO: Continuing with bootcamp BootcampName.SLOW_AGENT with slow factor: 4 for agent 1
INFO: Continuing with bootcamp BootcampName.SLOW_AGENT with slow factor: 4 for agent 0
INFO: Continuing with bootcamp BootcampName.SLOW_AGENT with slow factor: 3 for agent 1
INFO: Continuing with bootcamp BootcampName.SLOW_AGENT with slow factor: 3 for agent 0
INFO: Continuing with bootcamp BootcampName.SLOW_AGENT with slow factor: 2 for agent 1
INFO: Continuing with bootcamp BootcampName.SLOW_AGENT with slow factor: 2 for agent 0
INFO: BootcampName.SLOW_AGENT bootcamp completed, starting BootcampName.COMBINED bootcamp
INFO: Number of parameters: 30085
INFO: QNetwork(
  (conv_feature): Sequential()
  (fc_feature): Sequential(
    (0): Linear(in_features=100, out_features=128, bias=True)
    (1): ReLU()
    (2): Linear(in_features=128, out_features=128, bias=True)
    (3): ReLU()
    (4): Linear(in_features=128, out_features=5, bias=True)
  )
)
INFO: Learning...
INFO: BootcampName.HIDER bootcamp completed, starting BootcampName.SEEKER bootcamp
INFO: BootcampName.SEEKER bootcamp completed, starting BootcampName.SLOW_AGENT bootcamp
INFO: Continuing with bootcamp BootcampName.SLOW_AGENT with slow factor: 19 for agent 1
INFO: Number of parameters: 30085
INFO: QNetwork(
  (conv_feature): Sequential()
  (fc_feature): Sequential(
    (0): Linear(in_features=100, out_features=128, bias=True)
    (1): ReLU()
    (2): Linear(in_features=128, out_features=128, bias=True)
    (3): ReLU()
    (4): Linear(in_features=128, out_features=5, bias=True)
  )
)
INFO: Learning...
INFO: BootcampName.HIDER bootcamp completed, starting BootcampName.SEEKER bootcamp
INFO: BootcampName.SEEKER bootcamp completed, starting BootcampName.SLOW_AGENT bootcamp
INFO: Continuing with bootcamp BootcampName.SLOW_AGENT with slow factor: 19 for agent 1
INFO: Continuing with bootcamp BootcampName.SLOW_AGENT with slow factor: 19 for agent 0
INFO: Continuing with bootcamp BootcampName.SLOW_AGENT with slow factor: 18 for agent 1
INFO: Continuing with bootcamp BootcampName.SLOW_AGENT with slow factor: 18 for agent 0
INFO: Continuing with bootcamp BootcampName.SLOW_AGENT with slow factor: 17 for agent 1
INFO: Continuing with bootcamp BootcampName.SLOW_AGENT with slow factor: 17 for agent 0
INFO: Continuing with bootcamp BootcampName.SLOW_AGENT with slow factor: 16 for agent 1
INFO: Continuing with bootcamp BootcampName.SLOW_AGENT with slow factor: 16 for agent 0
INFO: Continuing with bootcamp BootcampName.SLOW_AGENT with slow factor: 15 for agent 1
INFO: Continuing with bootcamp BootcampName.SLOW_AGENT with slow factor: 15 for agent 0
INFO: Continuing with bootcamp BootcampName.SLOW_AGENT with slow factor: 14 for agent 1
INFO: Continuing with bootcamp BootcampName.SLOW_AGENT with slow factor: 14 for agent 0
INFO: Continuing with bootcamp BootcampName.SLOW_AGENT with slow factor: 13 for agent 1
INFO: Continuing with bootcamp BootcampName.SLOW_AGENT with slow factor: 13 for agent 0
INFO: Continuing with bootcamp BootcampName.SLOW_AGENT with slow factor: 12 for agent 1
INFO: Number of parameters: 30085
INFO: QNetwork(
  (conv_feature): Sequential()
  (fc_feature): Sequential(
    (0): Linear(in_features=100, out_features=128, bias=True)
    (1): ReLU()
    (2): Linear(in_features=128, out_features=128, bias=True)
    (3): ReLU()
    (4): Linear(in_features=128, out_features=5, bias=True)
  )
)
INFO: Learning...
INFO: BootcampName.HIDER bootcamp completed, starting BootcampName.SEEKER bootcamp
INFO: BootcampName.SEEKER bootcamp completed, starting BootcampName.SLOW_AGENT bootcamp
INFO: Continuing with bootcamp BootcampName.SLOW_AGENT with slow factor: 19 for agent 1
INFO: Continuing with bootcamp BootcampName.SLOW_AGENT with slow factor: 19 for agent 0
INFO: Continuing with bootcamp BootcampName.SLOW_AGENT with slow factor: 18 for agent 1
INFO: Number of parameters: 30085
INFO: QNetwork(
  (conv_feature): Sequential()
  (fc_feature): Sequential(
    (0): Linear(in_features=100, out_features=128, bias=True)
    (1): ReLU()
    (2): Linear(in_features=128, out_features=128, bias=True)
    (3): ReLU()
    (4): Linear(in_features=128, out_features=5, bias=True)
  )
)
INFO: Learning...
INFO: BootcampName.HIDER bootcamp completed, starting BootcampName.SEEKER bootcamp
INFO: BootcampName.SEEKER bootcamp completed, starting BootcampName.SLOW_AGENT bootcamp
INFO: Continuing with bootcamp BootcampName.SLOW_AGENT with slow factor: 19 for agent 1
INFO: Continuing with bootcamp BootcampName.SLOW_AGENT with slow factor: 19 for agent 0
INFO: Continuing with bootcamp BootcampName.SLOW_AGENT with slow factor: 18 for agent 1
INFO: Continuing with bootcamp BootcampName.SLOW_AGENT with slow factor: 18 for agent 0
INFO: Continuing with bootcamp BootcampName.SLOW_AGENT with slow factor: 17 for agent 1
INFO: Continuing with bootcamp BootcampName.SLOW_AGENT with slow factor: 17 for agent 0
INFO: Continuing with bootcamp BootcampName.SLOW_AGENT with slow factor: 16 for agent 1
INFO: Number of parameters: 30085
INFO: QNetwork(
  (conv_feature): Sequential()
  (fc_feature): Sequential(
    (0): Linear(in_features=100, out_features=128, bias=True)
    (1): ReLU()
    (2): Linear(in_features=128, out_features=128, bias=True)
    (3): ReLU()
    (4): Linear(in_features=128, out_features=5, bias=True)
  )
)
INFO: Learning...
INFO: BootcampName.HIDER bootcamp completed, starting BootcampName.SEEKER bootcamp
INFO: BootcampName.SEEKER bootcamp completed, starting BootcampName.SLOW_AGENT bootcamp
INFO: Continuing with bootcamp BootcampName.SLOW_AGENT with slow factor: 9 for agent 1
INFO: Continuing with bootcamp BootcampName.SLOW_AGENT with slow factor: 9 for agent 0
INFO: Number of parameters: 30085
INFO: QNetwork(
  (conv_feature): Sequential()
  (fc_feature): Sequential(
    (0): Linear(in_features=100, out_features=128, bias=True)
    (1): ReLU()
    (2): Linear(in_features=128, out_features=128, bias=True)
    (3): ReLU()
    (4): Linear(in_features=128, out_features=5, bias=True)
  )
)
INFO: Learning...
INFO: BootcampName.HIDER bootcamp completed, starting BootcampName.SEEKER bootcamp
INFO: BootcampName.SEEKER bootcamp completed, starting BootcampName.SLOW_AGENT bootcamp
INFO: Continuing with bootcamp BootcampName.SLOW_AGENT with slow factor: 9 for agent 1
INFO: Continuing with bootcamp BootcampName.SLOW_AGENT with slow factor: 9 for agent 0
INFO: Continuing with bootcamp BootcampName.SLOW_AGENT with slow factor: 8 for agent 1
INFO: Continuing with bootcamp BootcampName.SLOW_AGENT with slow factor: 8 for agent 0
INFO: Continuing with bootcamp BootcampName.SLOW_AGENT with slow factor: 7 for agent 1
INFO: Continuing with bootcamp BootcampName.SLOW_AGENT with slow factor: 7 for agent 0
INFO: Continuing with bootcamp BootcampName.SLOW_AGENT with slow factor: 6 for agent 1
INFO: Continuing with bootcamp BootcampName.SLOW_AGENT with slow factor: 6 for agent 0
INFO: Continuing with bootcamp BootcampName.SLOW_AGENT with slow factor: 5 for agent 1
INFO: Continuing with bootcamp BootcampName.SLOW_AGENT with slow factor: 5 for agent 0
INFO: Continuing with bootcamp BootcampName.SLOW_AGENT with slow factor: 4 for agent 1
INFO: Continuing with bootcamp BootcampName.SLOW_AGENT with slow factor: 4 for agent 0
INFO: Continuing with bootcamp BootcampName.SLOW_AGENT with slow factor: 3 for agent 1
INFO: Continuing with bootcamp BootcampName.SLOW_AGENT with slow factor: 3 for agent 0
INFO: Continuing with bootcamp BootcampName.SLOW_AGENT with slow factor: 2 for agent 1
INFO: Continuing with bootcamp BootcampName.SLOW_AGENT with slow factor: 2 for agent 0
INFO: BootcampName.SLOW_AGENT bootcamp completed, starting BootcampName.COMBINED bootcamp
INFO: Number of parameters: 30085
INFO: QNetwork(
  (conv_feature): Sequential()
  (fc_feature): Sequential(
    (0): Linear(in_features=100, out_features=128, bias=True)
    (1): ReLU()
    (2): Linear(in_features=128, out_features=128, bias=True)
    (3): ReLU()
    (4): Linear(in_features=128, out_features=5, bias=True)
  )
)
INFO: Learning...
INFO: BootcampName.HIDER bootcamp completed, starting BootcampName.SEEKER bootcamp #0 for 0 days
INFO: BootcampName.SEEKER bootcamp completed, starting BootcampName.SLOW_AGENT bootcamp #0 for 0 days
INFO: Continuing with bootcamp BootcampName.SLOW_AGENT with slow factor: 9 for agent 1
INFO: Continuing with bootcamp BootcampName.SLOW_AGENT with slow factor: 9 for agent 0
INFO: Continuing with bootcamp BootcampName.SLOW_AGENT with slow factor: 8 for agent 1
INFO: Continuing with bootcamp BootcampName.SLOW_AGENT with slow factor: 8 for agent 0
INFO: Continuing with bootcamp BootcampName.SLOW_AGENT with slow factor: 7 for agent 1
INFO: Continuing with bootcamp BootcampName.SLOW_AGENT with slow factor: 7 for agent 0
INFO: Continuing with bootcamp BootcampName.SLOW_AGENT with slow factor: 6 for agent 1
INFO: Continuing with bootcamp BootcampName.SLOW_AGENT with slow factor: 6 for agent 0
INFO: Continuing with bootcamp BootcampName.SLOW_AGENT with slow factor: 5 for agent 1
INFO: Continuing with bootcamp BootcampName.SLOW_AGENT with slow factor: 5 for agent 0
INFO: Continuing with bootcamp BootcampName.SLOW_AGENT with slow factor: 4 for agent 1
INFO: Continuing with bootcamp BootcampName.SLOW_AGENT with slow factor: 4 for agent 0
INFO: Continuing with bootcamp BootcampName.SLOW_AGENT with slow factor: 3 for agent 1
INFO: Continuing with bootcamp BootcampName.SLOW_AGENT with slow factor: 3 for agent 0
INFO: Continuing with bootcamp BootcampName.SLOW_AGENT with slow factor: 2 for agent 1
INFO: Continuing with bootcamp BootcampName.SLOW_AGENT with slow factor: 2 for agent 0
INFO: BootcampName.SLOW_AGENT bootcamp completed, starting BootcampName.COMBINED bootcamp #0 for 0 days
INFO: BootcampName.COMBINED bootcamp completed, starting BootcampName.FINISHED bootcamp #0 for 0 days
INFO: Bootcamp finished
INFO: Starting bootcamp 1
INFO: Starting bootcamp 1
INFO: BootcampName.HIDER bootcamp completed, starting BootcampName.SEEKER bootcamp #1 for 0 days
INFO: BootcampName.SEEKER bootcamp completed, starting BootcampName.SLOW_AGENT bootcamp #1 for 0 days
INFO: BootcampName.SLOW_AGENT bootcamp completed, starting BootcampName.COMBINED bootcamp #1 for 0 days
INFO: BootcampName.COMBINED bootcamp completed, starting BootcampName.FINISHED bootcamp #1 for 0 days
INFO: Bootcamp finished
INFO: Starting bootcamp 2
INFO: Starting bootcamp 2
INFO: BootcampName.HIDER bootcamp completed, starting BootcampName.SEEKER bootcamp #2 for 0 days
INFO: BootcampName.SEEKER bootcamp completed, starting BootcampName.SLOW_AGENT bootcamp #2 for 0 days
INFO: BootcampName.SLOW_AGENT bootcamp completed, starting BootcampName.COMBINED bootcamp #2 for 0 days
INFO: BootcampName.COMBINED bootcamp completed, starting BootcampName.FINISHED bootcamp #2 for 0 days
INFO: Bootcamp finished
INFO: Starting bootcamp 3
INFO: Starting bootcamp 3
INFO: BootcampName.HIDER bootcamp completed, starting BootcampName.SEEKER bootcamp #3 for 0 days
INFO: BootcampName.SEEKER bootcamp completed, starting BootcampName.SLOW_AGENT bootcamp #3 for 0 days
ERROR: integer modulo by zero
ERROR: Traceback (most recent call last):
  File "/home/eirik/Projects/XAI/rl/src/dqn/wrapper/multi_agent_dqn.py", line 75, in learn
    self._collect_rollouts()
  File "/home/eirik/Projects/XAI/rl/src/dqn/wrapper/multi_agent_dqn.py", line 144, in _collect_rollouts
    ) = self.env.get_wrapper_attr("step_multiple")(actions)
        ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/eirik/Projects/XAI/environments/gymnasium/wrappers/multi_agent_env.py", line 29, in step_multiple
    observation, reward, terminated, trunc, info = self.env.step(action)
                                                   ^^^^^^^^^^^^^^^^^^^^^
  File "/home/eirik/.cache/pypoetry/virtualenvs/xai-is73Zs3s-py3.11/lib/python3.11/site-packages/gymnasium/wrappers/order_enforcing.py", line 56, in step
    return self.env.step(action)
           ^^^^^^^^^^^^^^^^^^^^^
  File "/home/eirik/.cache/pypoetry/virtualenvs/xai-is73Zs3s-py3.11/lib/python3.11/site-packages/gymnasium/wrappers/env_checker.py", line 51, in step
    return self.env.step(action)
           ^^^^^^^^^^^^^^^^^^^^^
  File "/home/eirik/Projects/XAI/environments/gymnasium/envs/tag/tag.py", line 103, in step
    and not self.bootcamp.move_hider(self.steps)
            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/eirik/Projects/XAI/environments/gymnasium/envs/tag/utils/bootcamp.py", line 55, in move_hider
    if self.name == BootcampName.SLOW_AGENT and steps % self.slow_factor == 0:
                                                ~~~~~~^~~~~~~~~~~~~~~~~~
ZeroDivisionError: integer modulo by zero

WARNING: Error: Could not find wandb directory: ./wandb
INFO: Number of parameters: 30085
INFO: QNetwork(
  (conv_feature): Sequential()
  (fc_feature): Sequential(
    (0): Linear(in_features=100, out_features=128, bias=True)
    (1): ReLU()
    (2): Linear(in_features=128, out_features=128, bias=True)
    (3): ReLU()
    (4): Linear(in_features=128, out_features=5, bias=True)
  )
)
INFO: Learning...
INFO: BootcampName.HIDER Bootcamp completed, starting BootcampName.SEEKER Bootcamp #0 for 1 days
INFO: BootcampName.SEEKER Bootcamp completed, starting BootcampName.SLOW_AGENT Bootcamp #0 for 1 days
INFO: Continuing with Bootcamp #0 BootcampName.SLOW_AGENT with slow factor: 9 for agent 1
INFO: Continuing with Bootcamp #0 BootcampName.SLOW_AGENT with slow factor: 9 for agent 0
INFO: Continuing with Bootcamp #0 BootcampName.SLOW_AGENT with slow factor: 8 for agent 1
INFO: Continuing with Bootcamp #0 BootcampName.SLOW_AGENT with slow factor: 8 for agent 0
INFO: Continuing with Bootcamp #0 BootcampName.SLOW_AGENT with slow factor: 7 for agent 1
INFO: Continuing with Bootcamp #0 BootcampName.SLOW_AGENT with slow factor: 7 for agent 0
INFO: Continuing with Bootcamp #0 BootcampName.SLOW_AGENT with slow factor: 6 for agent 1
INFO: Continuing with Bootcamp #0 BootcampName.SLOW_AGENT with slow factor: 6 for agent 0
INFO: Continuing with Bootcamp #0 BootcampName.SLOW_AGENT with slow factor: 5 for agent 1
INFO: Continuing with Bootcamp #0 BootcampName.SLOW_AGENT with slow factor: 5 for agent 0
INFO: Continuing with Bootcamp #0 BootcampName.SLOW_AGENT with slow factor: 4 for agent 1
INFO: Continuing with Bootcamp #0 BootcampName.SLOW_AGENT with slow factor: 4 for agent 0
INFO: Continuing with Bootcamp #0 BootcampName.SLOW_AGENT with slow factor: 3 for agent 1
INFO: Continuing with Bootcamp #0 BootcampName.SLOW_AGENT with slow factor: 3 for agent 0
INFO: Continuing with Bootcamp #0 BootcampName.SLOW_AGENT with slow factor: 2 for agent 1
INFO: Continuing with Bootcamp #0 BootcampName.SLOW_AGENT with slow factor: 2 for agent 0
INFO: BootcampName.SLOW_AGENT Bootcamp completed, starting BootcampName.COMBINED Bootcamp #0 for 10 days
INFO: BootcampName.COMBINED Bootcamp completed, starting BootcampName.FINISHED Bootcamp #0 for 500 days
INFO: Bootcamp #0 BootcampName.HIDER finished, starting Bootcamp #1 BootcampName.HIDER
INFO: BootcampName.HIDER Bootcamp completed, starting BootcampName.SEEKER Bootcamp #1 for 1 days
INFO: BootcampName.SEEKER Bootcamp completed, starting BootcampName.SLOW_AGENT Bootcamp #1 for 1 days
INFO: BootcampName.SLOW_AGENT Bootcamp completed, starting BootcampName.COMBINED Bootcamp #1 for 10 days
INFO: BootcampName.COMBINED Bootcamp completed, starting BootcampName.FINISHED Bootcamp #1 for 500 days
INFO: Bootcamp #1 BootcampName.HIDER finished, starting Bootcamp #2 BootcampName.HIDER
INFO: BootcampName.HIDER Bootcamp completed, starting BootcampName.SEEKER Bootcamp #2 for 1 days
INFO: BootcampName.SEEKER Bootcamp completed, starting BootcampName.SLOW_AGENT Bootcamp #2 for 1 days
INFO: BootcampName.SLOW_AGENT Bootcamp completed, starting BootcampName.COMBINED Bootcamp #2 for 10 days
INFO: Number of parameters: 30085
INFO: QNetwork(
  (conv_feature): Sequential()
  (fc_feature): Sequential(
    (0): Linear(in_features=100, out_features=128, bias=True)
    (1): ReLU()
    (2): Linear(in_features=128, out_features=128, bias=True)
    (3): ReLU()
    (4): Linear(in_features=128, out_features=5, bias=True)
  )
)
INFO: Learning...
INFO: BootcampName.HIDER Bootcamp completed, starting BootcampName.SEEKER Bootcamp #0 for 1 days
INFO: BootcampName.SEEKER Bootcamp completed, starting BootcampName.SLOW_AGENT Bootcamp #0 for 1 days
INFO: Continuing with Bootcamp #0 BootcampName.SLOW_AGENT with slow factor: 9 for agent 1
INFO: Continuing with Bootcamp #0 BootcampName.SLOW_AGENT with slow factor: 9 for agent 0
INFO: Continuing with Bootcamp #0 BootcampName.SLOW_AGENT with slow factor: 8 for agent 1
INFO: Continuing with Bootcamp #0 BootcampName.SLOW_AGENT with slow factor: 8 for agent 0
INFO: Continuing with Bootcamp #0 BootcampName.SLOW_AGENT with slow factor: 7 for agent 1
INFO: Continuing with Bootcamp #0 BootcampName.SLOW_AGENT with slow factor: 7 for agent 0
INFO: Continuing with Bootcamp #0 BootcampName.SLOW_AGENT with slow factor: 6 for agent 1
INFO: Continuing with Bootcamp #0 BootcampName.SLOW_AGENT with slow factor: 6 for agent 0
INFO: Continuing with Bootcamp #0 BootcampName.SLOW_AGENT with slow factor: 5 for agent 1
INFO: Continuing with Bootcamp #0 BootcampName.SLOW_AGENT with slow factor: 5 for agent 0
INFO: Continuing with Bootcamp #0 BootcampName.SLOW_AGENT with slow factor: 4 for agent 1
INFO: Continuing with Bootcamp #0 BootcampName.SLOW_AGENT with slow factor: 4 for agent 0
INFO: Continuing with Bootcamp #0 BootcampName.SLOW_AGENT with slow factor: 3 for agent 1
INFO: Continuing with Bootcamp #0 BootcampName.SLOW_AGENT with slow factor: 3 for agent 0
INFO: Continuing with Bootcamp #0 BootcampName.SLOW_AGENT with slow factor: 2 for agent 1
INFO: Continuing with Bootcamp #0 BootcampName.SLOW_AGENT with slow factor: 2 for agent 0
INFO: BootcampName.SLOW_AGENT Bootcamp completed, starting BootcampName.COMBINED Bootcamp #0 for 10 days
INFO: BootcampName.COMBINED Bootcamp completed, starting BootcampName.FINISHED Bootcamp #0 for 500 days
INFO: Bootcamp #0 BootcampName.HIDER finished, starting Bootcamp #1 BootcampName.HIDER
INFO: BootcampName.HIDER Bootcamp completed, starting BootcampName.SEEKER Bootcamp #1 for 1 days
INFO: BootcampName.SEEKER Bootcamp completed, starting BootcampName.SLOW_AGENT Bootcamp #1 for 1 days
INFO: BootcampName.SLOW_AGENT Bootcamp completed, starting BootcampName.COMBINED Bootcamp #1 for 10 days
INFO: BootcampName.COMBINED Bootcamp completed, starting BootcampName.FINISHED Bootcamp #1 for 500 days
INFO: Bootcamp #1 BootcampName.HIDER finished, starting Bootcamp #2 BootcampName.HIDER
INFO: BootcampName.HIDER Bootcamp completed, starting BootcampName.SEEKER Bootcamp #2 for 1 days
INFO: BootcampName.SEEKER Bootcamp completed, starting BootcampName.SLOW_AGENT Bootcamp #2 for 1 days
INFO: BootcampName.SLOW_AGENT Bootcamp completed, starting BootcampName.COMBINED Bootcamp #2 for 10 days
INFO: Number of parameters: 30085
INFO: QNetwork(
  (conv_feature): Sequential()
  (fc_feature): Sequential(
    (0): Linear(in_features=100, out_features=128, bias=True)
    (1): ReLU()
    (2): Linear(in_features=128, out_features=128, bias=True)
    (3): ReLU()
    (4): Linear(in_features=128, out_features=5, bias=True)
  )
)
INFO: Learning...
INFO: BootcampName.HIDER Bootcamp completed, starting BootcampName.SEEKER Bootcamp #0 for 1 days
INFO: BootcampName.SEEKER Bootcamp completed, starting BootcampName.SLOW_AGENT Bootcamp #0 for 1 days
INFO: Continuing with Bootcamp #0 BootcampName.SLOW_AGENT with slow factor: 9 for agent 1
INFO: Continuing with Bootcamp #0 BootcampName.SLOW_AGENT with slow factor: 9 for agent 0
INFO: Continuing with Bootcamp #0 BootcampName.SLOW_AGENT with slow factor: 8 for agent 1
INFO: Continuing with Bootcamp #0 BootcampName.SLOW_AGENT with slow factor: 8 for agent 0
INFO: Continuing with Bootcamp #0 BootcampName.SLOW_AGENT with slow factor: 7 for agent 1
INFO: Continuing with Bootcamp #0 BootcampName.SLOW_AGENT with slow factor: 7 for agent 0
INFO: Continuing with Bootcamp #0 BootcampName.SLOW_AGENT with slow factor: 6 for agent 1
INFO: Continuing with Bootcamp #0 BootcampName.SLOW_AGENT with slow factor: 6 for agent 0
INFO: Continuing with Bootcamp #0 BootcampName.SLOW_AGENT with slow factor: 5 for agent 1
INFO: Continuing with Bootcamp #0 BootcampName.SLOW_AGENT with slow factor: 5 for agent 0
INFO: Continuing with Bootcamp #0 BootcampName.SLOW_AGENT with slow factor: 4 for agent 1
INFO: Continuing with Bootcamp #0 BootcampName.SLOW_AGENT with slow factor: 4 for agent 0
INFO: Continuing with Bootcamp #0 BootcampName.SLOW_AGENT with slow factor: 3 for agent 1
INFO: Continuing with Bootcamp #0 BootcampName.SLOW_AGENT with slow factor: 3 for agent 0
INFO: Continuing with Bootcamp #0 BootcampName.SLOW_AGENT with slow factor: 2 for agent 1
INFO: Continuing with Bootcamp #0 BootcampName.SLOW_AGENT with slow factor: 2 for agent 0
INFO: BootcampName.SLOW_AGENT Bootcamp completed, starting BootcampName.COMBINED Bootcamp #0 for 10 days
INFO: BootcampName.COMBINED Bootcamp completed, starting BootcampName.FINISHED Bootcamp #0 for 500 days
INFO: Bootcamp #0 BootcampName.HIDER finished, starting Bootcamp #1 BootcampName.HIDER
INFO: BootcampName.HIDER Bootcamp completed, starting BootcampName.SEEKER Bootcamp #1 for 1 days
INFO: BootcampName.SEEKER Bootcamp completed, starting BootcampName.SLOW_AGENT Bootcamp #1 for 1 days
INFO: Continuing with Bootcamp #1 BootcampName.SLOW_AGENT with slow factor: 10 for agent 0
INFO: Continuing with Bootcamp #1 BootcampName.SLOW_AGENT with slow factor: 9 for agent 1
INFO: Continuing with Bootcamp #1 BootcampName.SLOW_AGENT with slow factor: 9 for agent 0
INFO: Continuing with Bootcamp #1 BootcampName.SLOW_AGENT with slow factor: 8 for agent 1
INFO: Continuing with Bootcamp #1 BootcampName.SLOW_AGENT with slow factor: 8 for agent 0
INFO: Continuing with Bootcamp #1 BootcampName.SLOW_AGENT with slow factor: 7 for agent 1
INFO: Continuing with Bootcamp #1 BootcampName.SLOW_AGENT with slow factor: 7 for agent 0
INFO: Continuing with Bootcamp #1 BootcampName.SLOW_AGENT with slow factor: 6 for agent 1
INFO: Continuing with Bootcamp #1 BootcampName.SLOW_AGENT with slow factor: 6 for agent 0
INFO: Continuing with Bootcamp #1 BootcampName.SLOW_AGENT with slow factor: 5 for agent 1
INFO: Continuing with Bootcamp #1 BootcampName.SLOW_AGENT with slow factor: 5 for agent 0
INFO: Continuing with Bootcamp #1 BootcampName.SLOW_AGENT with slow factor: 4 for agent 1
INFO: Continuing with Bootcamp #1 BootcampName.SLOW_AGENT with slow factor: 4 for agent 0
INFO: Continuing with Bootcamp #1 BootcampName.SLOW_AGENT with slow factor: 3 for agent 1
INFO: Continuing with Bootcamp #1 BootcampName.SLOW_AGENT with slow factor: 3 for agent 0
INFO: Continuing with Bootcamp #1 BootcampName.SLOW_AGENT with slow factor: 2 for agent 1
INFO: Continuing with Bootcamp #1 BootcampName.SLOW_AGENT with slow factor: 2 for agent 0
INFO: BootcampName.SLOW_AGENT Bootcamp completed, starting BootcampName.COMBINED Bootcamp #1 for 10 days
INFO: Number of parameters: 30085
INFO: QNetwork(
  (conv_feature): Sequential()
  (fc_feature): Sequential(
    (0): Linear(in_features=100, out_features=128, bias=True)
    (1): ReLU()
    (2): Linear(in_features=128, out_features=128, bias=True)
    (3): ReLU()
    (4): Linear(in_features=128, out_features=5, bias=True)
  )
)
INFO: Learning...
INFO: BootcampName.HIDER Bootcamp completed, starting BootcampName.SEEKER Bootcamp #0 for 1 days
INFO: BootcampName.SEEKER Bootcamp completed, starting BootcampName.SLOW_AGENT Bootcamp #0 for 1 days
INFO: Continuing with Bootcamp #0 BootcampName.SLOW_AGENT with slow factor: 9 for agent 1
INFO: Continuing with Bootcamp #0 BootcampName.SLOW_AGENT with slow factor: 9 for agent 0
INFO: Continuing with Bootcamp #0 BootcampName.SLOW_AGENT with slow factor: 8 for agent 1
INFO: Continuing with Bootcamp #0 BootcampName.SLOW_AGENT with slow factor: 8 for agent 0
INFO: Continuing with Bootcamp #0 BootcampName.SLOW_AGENT with slow factor: 7 for agent 1
INFO: Continuing with Bootcamp #0 BootcampName.SLOW_AGENT with slow factor: 7 for agent 0
INFO: Continuing with Bootcamp #0 BootcampName.SLOW_AGENT with slow factor: 6 for agent 1
INFO: Continuing with Bootcamp #0 BootcampName.SLOW_AGENT with slow factor: 6 for agent 0
INFO: Continuing with Bootcamp #0 BootcampName.SLOW_AGENT with slow factor: 5 for agent 1
INFO: Continuing with Bootcamp #0 BootcampName.SLOW_AGENT with slow factor: 5 for agent 0
INFO: Continuing with Bootcamp #0 BootcampName.SLOW_AGENT with slow factor: 4 for agent 1
INFO: Continuing with Bootcamp #0 BootcampName.SLOW_AGENT with slow factor: 4 for agent 0
INFO: Continuing with Bootcamp #0 BootcampName.SLOW_AGENT with slow factor: 3 for agent 1
INFO: Continuing with Bootcamp #0 BootcampName.SLOW_AGENT with slow factor: 3 for agent 0
INFO: Continuing with Bootcamp #0 BootcampName.SLOW_AGENT with slow factor: 2 for agent 1
INFO: Continuing with Bootcamp #0 BootcampName.SLOW_AGENT with slow factor: 2 for agent 0
INFO: BootcampName.SLOW_AGENT Bootcamp completed, starting BootcampName.COMBINED Bootcamp #0 for 10 days
INFO: Bootcamp #0 BootcampName.HIDER finished, starting Bootcamp #1 BootcampName.HIDER
INFO: BootcampName.COMBINED Bootcamp completed, starting BootcampName.HIDER Bootcamp #1 for 500 days
INFO: BootcampName.HIDER Bootcamp completed, starting BootcampName.SEEKER Bootcamp #1 for 1 days
INFO: BootcampName.SEEKER Bootcamp completed, starting BootcampName.SLOW_AGENT Bootcamp #1 for 1 days
INFO: Continuing with Bootcamp #1 BootcampName.SLOW_AGENT with slow factor: 10 for agent 0
INFO: Continuing with Bootcamp #1 BootcampName.SLOW_AGENT with slow factor: 9 for agent 1
INFO: Continuing with Bootcamp #1 BootcampName.SLOW_AGENT with slow factor: 9 for agent 0
INFO: Continuing with Bootcamp #1 BootcampName.SLOW_AGENT with slow factor: 8 for agent 1
INFO: Continuing with Bootcamp #1 BootcampName.SLOW_AGENT with slow factor: 8 for agent 0
INFO: Continuing with Bootcamp #1 BootcampName.SLOW_AGENT with slow factor: 7 for agent 1
INFO: Continuing with Bootcamp #1 BootcampName.SLOW_AGENT with slow factor: 7 for agent 0
INFO: Continuing with Bootcamp #1 BootcampName.SLOW_AGENT with slow factor: 6 for agent 1
INFO: Continuing with Bootcamp #1 BootcampName.SLOW_AGENT with slow factor: 6 for agent 0
INFO: Continuing with Bootcamp #1 BootcampName.SLOW_AGENT with slow factor: 5 for agent 1
INFO: Continuing with Bootcamp #1 BootcampName.SLOW_AGENT with slow factor: 5 for agent 0
INFO: Continuing with Bootcamp #1 BootcampName.SLOW_AGENT with slow factor: 4 for agent 1
INFO: Continuing with Bootcamp #1 BootcampName.SLOW_AGENT with slow factor: 4 for agent 0
INFO: Continuing with Bootcamp #1 BootcampName.SLOW_AGENT with slow factor: 3 for agent 1
INFO: Continuing with Bootcamp #1 BootcampName.SLOW_AGENT with slow factor: 3 for agent 0
INFO: Continuing with Bootcamp #1 BootcampName.SLOW_AGENT with slow factor: 2 for agent 1
INFO: Continuing with Bootcamp #1 BootcampName.SLOW_AGENT with slow factor: 2 for agent 0
INFO: BootcampName.SLOW_AGENT Bootcamp completed, starting BootcampName.COMBINED Bootcamp #1 for 10 days
INFO: Number of parameters: 30085
INFO: QNetwork(
  (conv_feature): Sequential()
  (fc_feature): Sequential(
    (0): Linear(in_features=100, out_features=128, bias=True)
    (1): ReLU()
    (2): Linear(in_features=128, out_features=128, bias=True)
    (3): ReLU()
    (4): Linear(in_features=128, out_features=5, bias=True)
  )
)
INFO: Number of parameters: 30085
INFO: QNetwork(
  (conv_feature): Sequential()
  (fc_feature): Sequential(
    (0): Linear(in_features=100, out_features=128, bias=True)
    (1): ReLU()
    (2): Linear(in_features=128, out_features=128, bias=True)
    (3): ReLU()
    (4): Linear(in_features=128, out_features=5, bias=True)
  )
)
INFO: Number of parameters: 30085
INFO: QNetwork(
  (conv_feature): Sequential()
  (fc_feature): Sequential(
    (0): Linear(in_features=100, out_features=128, bias=True)
    (1): ReLU()
    (2): Linear(in_features=128, out_features=128, bias=True)
    (3): ReLU()
    (4): Linear(in_features=128, out_features=5, bias=True)
  )
)
INFO: Learning...
INFO: BootcampName.HIDER Bootcamp completed, starting BootcampName.SEEKER Bootcamp #0 for 1 days
INFO: BootcampName.SEEKER Bootcamp completed, starting BootcampName.SLOW_AGENT Bootcamp #0 for 1 days
INFO: BootcampName.SLOW_AGENT Bootcamp completed, starting BootcampName.COMBINED Bootcamp #0 for 10 days
INFO: Bootcamp #0 BootcampName.FINISHED finished, starting Bootcamp #1 BootcampName.HIDER
INFO: BootcampName.COMBINED Bootcamp completed, starting BootcampName.HIDER Bootcamp #1 for 500 days
INFO: BootcampName.HIDER Bootcamp completed, starting BootcampName.SEEKER Bootcamp #1 for 1 days
INFO: BootcampName.SEEKER Bootcamp completed, starting BootcampName.SLOW_AGENT Bootcamp #1 for 1 days
INFO: BootcampName.SLOW_AGENT Bootcamp completed, starting BootcampName.COMBINED Bootcamp #1 for 10 days
INFO: Number of parameters: 30085
INFO: QNetwork(
  (conv_feature): Sequential()
  (fc_feature): Sequential(
    (0): Linear(in_features=100, out_features=128, bias=True)
    (1): ReLU()
    (2): Linear(in_features=128, out_features=128, bias=True)
    (3): ReLU()
    (4): Linear(in_features=128, out_features=5, bias=True)
  )
)
INFO: Learning...
INFO: BootcampName.HIDER Bootcamp completed, starting BootcampName.SEEKER Bootcamp #0 for 1 days
INFO: BootcampName.SEEKER Bootcamp completed, starting BootcampName.SLOW_AGENT Bootcamp #0 for 1 days
INFO: BootcampName.SLOW_AGENT Bootcamp completed, starting BootcampName.COMBINED Bootcamp #0 for 10 days
INFO: Number of parameters: 30085
INFO: QNetwork(
  (conv_feature): Sequential()
  (fc_feature): Sequential(
    (0): Linear(in_features=100, out_features=128, bias=True)
    (1): ReLU()
    (2): Linear(in_features=128, out_features=128, bias=True)
    (3): ReLU()
    (4): Linear(in_features=128, out_features=5, bias=True)
  )
)
INFO: Number of parameters: 30085
INFO: QNetwork(
  (conv_feature): Sequential()
  (fc_feature): Sequential(
    (0): Linear(in_features=100, out_features=128, bias=True)
    (1): ReLU()
    (2): Linear(in_features=128, out_features=128, bias=True)
    (3): ReLU()
    (4): Linear(in_features=128, out_features=5, bias=True)
  )
)
INFO: Learning...
INFO: BootcampName.HIDER Bootcamp completed, starting BootcampName.SEEKER Bootcamp #0 for 1 days
INFO: BootcampName.SEEKER Bootcamp completed, starting BootcampName.SLOW_AGENT Bootcamp #0 for 1 days
INFO: Continuing with Bootcamp #0 BootcampName.SLOW_AGENT with slow factor: 9 for agent 1
INFO: Continuing with Bootcamp #0 BootcampName.SLOW_AGENT with slow factor: 9 for agent 0
INFO: Continuing with Bootcamp #0 BootcampName.SLOW_AGENT with slow factor: 8 for agent 1
INFO: Continuing with Bootcamp #0 BootcampName.SLOW_AGENT with slow factor: 8 for agent 0
INFO: Continuing with Bootcamp #0 BootcampName.SLOW_AGENT with slow factor: 7 for agent 1
INFO: Continuing with Bootcamp #0 BootcampName.SLOW_AGENT with slow factor: 7 for agent 0
INFO: Continuing with Bootcamp #0 BootcampName.SLOW_AGENT with slow factor: 6 for agent 1
INFO: Continuing with Bootcamp #0 BootcampName.SLOW_AGENT with slow factor: 6 for agent 0
INFO: Continuing with Bootcamp #0 BootcampName.SLOW_AGENT with slow factor: 5 for agent 1
INFO: Continuing with Bootcamp #0 BootcampName.SLOW_AGENT with slow factor: 5 for agent 0
INFO: Continuing with Bootcamp #0 BootcampName.SLOW_AGENT with slow factor: 4 for agent 1
INFO: Continuing with Bootcamp #0 BootcampName.SLOW_AGENT with slow factor: 4 for agent 0
INFO: Continuing with Bootcamp #0 BootcampName.SLOW_AGENT with slow factor: 3 for agent 1
INFO: Continuing with Bootcamp #0 BootcampName.SLOW_AGENT with slow factor: 3 for agent 0
INFO: Continuing with Bootcamp #0 BootcampName.SLOW_AGENT with slow factor: 2 for agent 1
INFO: Continuing with Bootcamp #0 BootcampName.SLOW_AGENT with slow factor: 2 for agent 0
INFO: Number of parameters: 30085
INFO: QNetwork(
  (conv_feature): Sequential()
  (fc_feature): Sequential(
    (0): Linear(in_features=100, out_features=128, bias=True)
    (1): ReLU()
    (2): Linear(in_features=128, out_features=128, bias=True)
    (3): ReLU()
    (4): Linear(in_features=128, out_features=5, bias=True)
  )
)
INFO: Learning...
INFO: BootcampName.HIDER Bootcamp completed, starting BootcampName.SEEKER Bootcamp #0 for 1 days
INFO: BootcampName.SEEKER Bootcamp completed, starting BootcampName.SLOW_AGENT Bootcamp #0 for 1 days
INFO: Continuing with Bootcamp #0 BootcampName.SLOW_AGENT with slow factor: 9 for agent 1
INFO: Continuing with Bootcamp #0 BootcampName.SLOW_AGENT with slow factor: 9 for agent 0
INFO: Continuing with Bootcamp #0 BootcampName.SLOW_AGENT with slow factor: 8 for agent 1
INFO: Continuing with Bootcamp #0 BootcampName.SLOW_AGENT with slow factor: 8 for agent 0
INFO: Continuing with Bootcamp #0 BootcampName.SLOW_AGENT with slow factor: 7 for agent 1
INFO: Continuing with Bootcamp #0 BootcampName.SLOW_AGENT with slow factor: 7 for agent 0
INFO: Continuing with Bootcamp #0 BootcampName.SLOW_AGENT with slow factor: 6 for agent 1
INFO: Continuing with Bootcamp #0 BootcampName.SLOW_AGENT with slow factor: 6 for agent 0
INFO: Continuing with Bootcamp #0 BootcampName.SLOW_AGENT with slow factor: 5 for agent 1
INFO: Continuing with Bootcamp #0 BootcampName.SLOW_AGENT with slow factor: 5 for agent 0
INFO: Continuing with Bootcamp #0 BootcampName.SLOW_AGENT with slow factor: 4 for agent 1
INFO: Continuing with Bootcamp #0 BootcampName.SLOW_AGENT with slow factor: 4 for agent 0
INFO: Continuing with Bootcamp #0 BootcampName.SLOW_AGENT with slow factor: 3 for agent 1
INFO: Continuing with Bootcamp #0 BootcampName.SLOW_AGENT with slow factor: 3 for agent 0
INFO: Continuing with Bootcamp #0 BootcampName.SLOW_AGENT with slow factor: 2 for agent 1
INFO: Continuing with Bootcamp #0 BootcampName.SLOW_AGENT with slow factor: 2 for agent 0
INFO: BootcampName.SLOW_AGENT Bootcamp completed, starting BootcampName.COMBINED Bootcamp #0 for 10 days
INFO: Bootcamp #0 BootcampName.FINISHED finished, starting Bootcamp #1 BootcampName.HIDER
INFO: BootcampName.COMBINED Bootcamp completed, starting BootcampName.HIDER Bootcamp #1 for 500 days
INFO: BootcampName.HIDER Bootcamp completed, starting BootcampName.SEEKER Bootcamp #1 for 1 days
INFO: BootcampName.SEEKER Bootcamp completed, starting BootcampName.SLOW_AGENT Bootcamp #1 for 1 days
INFO: BootcampName.SLOW_AGENT Bootcamp completed, starting BootcampName.COMBINED Bootcamp #1 for 10 days
INFO: Bootcamp #1 BootcampName.FINISHED finished, starting Bootcamp #2 BootcampName.HIDER
INFO: BootcampName.COMBINED Bootcamp completed, starting BootcampName.HIDER Bootcamp #2 for 500 days
INFO: BootcampName.HIDER Bootcamp completed, starting BootcampName.SEEKER Bootcamp #2 for 1 days
INFO: BootcampName.SEEKER Bootcamp completed, starting BootcampName.SLOW_AGENT Bootcamp #2 for 1 days
INFO: BootcampName.SLOW_AGENT Bootcamp completed, starting BootcampName.COMBINED Bootcamp #2 for 10 days
INFO: Number of parameters: 30085
INFO: QNetwork(
  (conv_feature): Sequential()
  (fc_feature): Sequential(
    (0): Linear(in_features=100, out_features=128, bias=True)
    (1): ReLU()
    (2): Linear(in_features=128, out_features=128, bias=True)
    (3): ReLU()
    (4): Linear(in_features=128, out_features=5, bias=True)
  )
)
INFO: Learning...
INFO: BootcampName.HIDER Bootcamp completed, starting BootcampName.SEEKER Bootcamp #0 for 1 days
INFO: BootcampName.SEEKER Bootcamp completed, starting BootcampName.SLOW_AGENT Bootcamp #0 for 1 days
INFO: Continuing with Bootcamp #0 BootcampName.SLOW_AGENT with slow factor: 9 for agent 1
INFO: Continuing with Bootcamp #0 BootcampName.SLOW_AGENT with slow factor: 9 for agent 0
INFO: Continuing with Bootcamp #0 BootcampName.SLOW_AGENT with slow factor: 8 for agent 1
INFO: Continuing with Bootcamp #0 BootcampName.SLOW_AGENT with slow factor: 8 for agent 0
INFO: Continuing with Bootcamp #0 BootcampName.SLOW_AGENT with slow factor: 7 for agent 1
INFO: Continuing with Bootcamp #0 BootcampName.SLOW_AGENT with slow factor: 7 for agent 0
INFO: Continuing with Bootcamp #0 BootcampName.SLOW_AGENT with slow factor: 6 for agent 1
INFO: Continuing with Bootcamp #0 BootcampName.SLOW_AGENT with slow factor: 6 for agent 0
INFO: Continuing with Bootcamp #0 BootcampName.SLOW_AGENT with slow factor: 5 for agent 1
INFO: Continuing with Bootcamp #0 BootcampName.SLOW_AGENT with slow factor: 5 for agent 0
INFO: Continuing with Bootcamp #0 BootcampName.SLOW_AGENT with slow factor: 4 for agent 1
INFO: Continuing with Bootcamp #0 BootcampName.SLOW_AGENT with slow factor: 4 for agent 0
INFO: Continuing with Bootcamp #0 BootcampName.SLOW_AGENT with slow factor: 3 for agent 1
INFO: Continuing with Bootcamp #0 BootcampName.SLOW_AGENT with slow factor: 3 for agent 0
INFO: Continuing with Bootcamp #0 BootcampName.SLOW_AGENT with slow factor: 2 for agent 1
INFO: Continuing with Bootcamp #0 BootcampName.SLOW_AGENT with slow factor: 2 for agent 0
INFO: BootcampName.SLOW_AGENT Bootcamp completed, starting BootcampName.COMBINED Bootcamp #0 for 10 days
INFO: Starting Bootcamp #1, starting Bootcamp #1 BootcampName.HIDER
INFO: BootcampName.COMBINED Bootcamp completed, starting BootcampName.HIDER Bootcamp #1 for 500 days
INFO: BootcampName.HIDER Bootcamp completed, starting BootcampName.SEEKER Bootcamp #1 for 1 days
INFO: BootcampName.SEEKER Bootcamp completed, starting BootcampName.SLOW_AGENT Bootcamp #1 for 1 days
INFO: BootcampName.SLOW_AGENT Bootcamp completed, starting BootcampName.COMBINED Bootcamp #1 for 10 days
INFO: Starting Bootcamp #2, starting Bootcamp #2 BootcampName.HIDER
INFO: BootcampName.COMBINED Bootcamp completed, starting BootcampName.HIDER Bootcamp #2 for 500 days
INFO: BootcampName.HIDER Bootcamp completed, starting BootcampName.SEEKER Bootcamp #2 for 1 days
INFO: BootcampName.SEEKER Bootcamp completed, starting BootcampName.SLOW_AGENT Bootcamp #2 for 1 days
INFO: BootcampName.SLOW_AGENT Bootcamp completed, starting BootcampName.COMBINED Bootcamp #2 for 10 days
INFO: Starting Bootcamp #3, starting Bootcamp #3 BootcampName.HIDER
INFO: BootcampName.COMBINED Bootcamp completed, starting BootcampName.HIDER Bootcamp #3 for 500 days
INFO: BootcampName.HIDER Bootcamp completed, starting BootcampName.SEEKER Bootcamp #3 for 1 days
INFO: BootcampName.SEEKER Bootcamp completed, starting BootcampName.SLOW_AGENT Bootcamp #3 for 1 days
ERROR: integer modulo by zero
ERROR: Traceback (most recent call last):
  File "/home/eirik/Projects/XAI/rl/src/dqn/wrapper/multi_agent_dqn.py", line 75, in learn
    self._collect_rollouts()
  File "/home/eirik/Projects/XAI/rl/src/dqn/wrapper/multi_agent_dqn.py", line 144, in _collect_rollouts
    ) = self.env.get_wrapper_attr("step_multiple")(actions)
        ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/eirik/Projects/XAI/environments/gymnasium/wrappers/multi_agent_env.py", line 29, in step_multiple
    observation, reward, terminated, trunc, info = self.env.step(action)
                                                   ^^^^^^^^^^^^^^^^^^^^^
  File "/home/eirik/.cache/pypoetry/virtualenvs/xai-is73Zs3s-py3.11/lib/python3.11/site-packages/gymnasium/wrappers/order_enforcing.py", line 56, in step
    return self.env.step(action)
           ^^^^^^^^^^^^^^^^^^^^^
  File "/home/eirik/.cache/pypoetry/virtualenvs/xai-is73Zs3s-py3.11/lib/python3.11/site-packages/gymnasium/wrappers/env_checker.py", line 51, in step
    return self.env.step(action)
           ^^^^^^^^^^^^^^^^^^^^^
  File "/home/eirik/Projects/XAI/environments/gymnasium/envs/tag/tag.py", line 103, in step
    and not self.bootcamp.move_hider(self.steps)
            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/eirik/Projects/XAI/environments/gymnasium/envs/tag/utils/bootcamp.py", line 59, in move_hider
    if self.name == BootcampName.SLOW_AGENT and steps % self.slow_factor == 0:
                                                ~~~~~~^~~~~~~~~~~~~~~~~~
ZeroDivisionError: integer modulo by zero

WARNING: Error: Could not find wandb directory: ./wandb
INFO: Number of parameters: 30085
INFO: QNetwork(
  (conv_feature): Sequential()
  (fc_feature): Sequential(
    (0): Linear(in_features=100, out_features=128, bias=True)
    (1): ReLU()
    (2): Linear(in_features=128, out_features=128, bias=True)
    (3): ReLU()
    (4): Linear(in_features=128, out_features=5, bias=True)
  )
)
INFO: Learning...
INFO: BootcampName.HIDER Bootcamp completed, starting BootcampName.SEEKER Bootcamp #0 for 1 days
INFO: BootcampName.SEEKER Bootcamp completed, starting BootcampName.SLOW_AGENT Bootcamp #0 for 10 days
INFO: Continuing with Bootcamp #0 BootcampName.SLOW_AGENT with slow factor: 9 for agent 1
INFO: Continuing with Bootcamp #0 BootcampName.SLOW_AGENT with slow factor: 9 for agent 0
INFO: Continuing with Bootcamp #0 BootcampName.SLOW_AGENT with slow factor: 8 for agent 1
INFO: Continuing with Bootcamp #0 BootcampName.SLOW_AGENT with slow factor: 8 for agent 0
INFO: Continuing with Bootcamp #0 BootcampName.SLOW_AGENT with slow factor: 7 for agent 1
INFO: Continuing with Bootcamp #0 BootcampName.SLOW_AGENT with slow factor: 7 for agent 0
INFO: Continuing with Bootcamp #0 BootcampName.SLOW_AGENT with slow factor: 6 for agent 1
INFO: Continuing with Bootcamp #0 BootcampName.SLOW_AGENT with slow factor: 6 for agent 0
INFO: Continuing with Bootcamp #0 BootcampName.SLOW_AGENT with slow factor: 5 for agent 1
INFO: Continuing with Bootcamp #0 BootcampName.SLOW_AGENT with slow factor: 5 for agent 0
INFO: Continuing with Bootcamp #0 BootcampName.SLOW_AGENT with slow factor: 4 for agent 1
INFO: Continuing with Bootcamp #0 BootcampName.SLOW_AGENT with slow factor: 4 for agent 0
INFO: Continuing with Bootcamp #0 BootcampName.SLOW_AGENT with slow factor: 3 for agent 1
INFO: Continuing with Bootcamp #0 BootcampName.SLOW_AGENT with slow factor: 3 for agent 0
INFO: Continuing with Bootcamp #0 BootcampName.SLOW_AGENT with slow factor: 2 for agent 1
INFO: Continuing with Bootcamp #0 BootcampName.SLOW_AGENT with slow factor: 2 for agent 0
INFO: BootcampName.SLOW_AGENT Bootcamp completed, starting BootcampName.COMBINED Bootcamp #0 for 500 days
INFO: Starting Bootcamp #1, starting Bootcamp #1 BootcampName.HIDER
INFO: BootcampName.COMBINED Bootcamp completed, starting BootcampName.HIDER Bootcamp #1 for 1 days
INFO: BootcampName.HIDER Bootcamp completed, starting BootcampName.SEEKER Bootcamp #1 for 1 days
INFO: BootcampName.SEEKER Bootcamp completed, starting BootcampName.SLOW_AGENT Bootcamp #1 for 10 days
INFO: BootcampName.SLOW_AGENT Bootcamp completed, starting BootcampName.COMBINED Bootcamp #1 for 500 days
INFO: Starting Bootcamp #2, starting Bootcamp #2 BootcampName.HIDER
INFO: BootcampName.COMBINED Bootcamp completed, starting BootcampName.HIDER Bootcamp #2 for 1 days
INFO: BootcampName.HIDER Bootcamp completed, starting BootcampName.SEEKER Bootcamp #2 for 1 days
INFO: BootcampName.SEEKER Bootcamp completed, starting BootcampName.SLOW_AGENT Bootcamp #2 for 10 days
INFO: BootcampName.SLOW_AGENT Bootcamp completed, starting BootcampName.COMBINED Bootcamp #2 for 500 days
INFO: Number of parameters: 30085
INFO: QNetwork(
  (conv_feature): Sequential()
  (fc_feature): Sequential(
    (0): Linear(in_features=100, out_features=128, bias=True)
    (1): ReLU()
    (2): Linear(in_features=128, out_features=128, bias=True)
    (3): ReLU()
    (4): Linear(in_features=128, out_features=5, bias=True)
  )
)
INFO: Learning...
INFO: BootcampName.HIDER Bootcamp completed, starting BootcampName.SEEKER Bootcamp #0 for 1 days
INFO: BootcampName.SEEKER Bootcamp completed, starting BootcampName.SLOW_AGENT Bootcamp #0 for 10 days
INFO: Continuing with Bootcamp #0 BootcampName.SLOW_AGENT with slow factor: 9 for agent 1
INFO: Continuing with Bootcamp #0 BootcampName.SLOW_AGENT with slow factor: 9 for agent 0
INFO: Continuing with Bootcamp #0 BootcampName.SLOW_AGENT with slow factor: 8 for agent 1
INFO: Continuing with Bootcamp #0 BootcampName.SLOW_AGENT with slow factor: 8 for agent 0
INFO: Continuing with Bootcamp #0 BootcampName.SLOW_AGENT with slow factor: 7 for agent 1
INFO: Continuing with Bootcamp #0 BootcampName.SLOW_AGENT with slow factor: 7 for agent 0
INFO: Continuing with Bootcamp #0 BootcampName.SLOW_AGENT with slow factor: 6 for agent 1
INFO: Continuing with Bootcamp #0 BootcampName.SLOW_AGENT with slow factor: 6 for agent 0
INFO: Continuing with Bootcamp #0 BootcampName.SLOW_AGENT with slow factor: 5 for agent 1
INFO: Continuing with Bootcamp #0 BootcampName.SLOW_AGENT with slow factor: 5 for agent 0
INFO: Continuing with Bootcamp #0 BootcampName.SLOW_AGENT with slow factor: 4 for agent 1
INFO: Continuing with Bootcamp #0 BootcampName.SLOW_AGENT with slow factor: 4 for agent 0
INFO: Continuing with Bootcamp #0 BootcampName.SLOW_AGENT with slow factor: 3 for agent 1
INFO: Continuing with Bootcamp #0 BootcampName.SLOW_AGENT with slow factor: 3 for agent 0
INFO: Continuing with Bootcamp #0 BootcampName.SLOW_AGENT with slow factor: 2 for agent 1
INFO: Continuing with Bootcamp #0 BootcampName.SLOW_AGENT with slow factor: 2 for agent 0
INFO: BootcampName.SLOW_AGENT Bootcamp completed, starting BootcampName.COMBINED Bootcamp #0 for 500 days
INFO: Starting Bootcamp #1, starting Bootcamp #1 BootcampName.HIDER
INFO: BootcampName.COMBINED Bootcamp completed, starting BootcampName.HIDER Bootcamp #1 for 1 days
INFO: BootcampName.HIDER Bootcamp completed, starting BootcampName.SEEKER Bootcamp #1 for 1 days
INFO: BootcampName.SEEKER Bootcamp completed, starting BootcampName.SLOW_AGENT Bootcamp #1 for 10 days
INFO: Continuing with Bootcamp #1 BootcampName.SLOW_AGENT with slow factor: 7 for agent 0
INFO: Continuing with Bootcamp #1 BootcampName.SLOW_AGENT with slow factor: 6 for agent 1
INFO: Continuing with Bootcamp #1 BootcampName.SLOW_AGENT with slow factor: 6 for agent 0
INFO: Continuing with Bootcamp #1 BootcampName.SLOW_AGENT with slow factor: 5 for agent 1
INFO: Continuing with Bootcamp #1 BootcampName.SLOW_AGENT with slow factor: 5 for agent 0
INFO: Continuing with Bootcamp #1 BootcampName.SLOW_AGENT with slow factor: 4 for agent 1
INFO: Continuing with Bootcamp #1 BootcampName.SLOW_AGENT with slow factor: 4 for agent 0
INFO: Continuing with Bootcamp #1 BootcampName.SLOW_AGENT with slow factor: 3 for agent 1
INFO: Continuing with Bootcamp #1 BootcampName.SLOW_AGENT with slow factor: 3 for agent 0
INFO: Continuing with Bootcamp #1 BootcampName.SLOW_AGENT with slow factor: 2 for agent 1
INFO: Continuing with Bootcamp #1 BootcampName.SLOW_AGENT with slow factor: 2 for agent 0
INFO: BootcampName.SLOW_AGENT Bootcamp completed, starting BootcampName.COMBINED Bootcamp #1 for 500 days
INFO: Starting Bootcamp #2, starting Bootcamp #2 BootcampName.HIDER
INFO: BootcampName.COMBINED Bootcamp completed, starting BootcampName.HIDER Bootcamp #2 for 1 days
INFO: BootcampName.HIDER Bootcamp completed, starting BootcampName.SEEKER Bootcamp #2 for 1 days
INFO: BootcampName.SEEKER Bootcamp completed, starting BootcampName.SLOW_AGENT Bootcamp #2 for 10 days
INFO: Continuing with Bootcamp #2 BootcampName.SLOW_AGENT with slow factor: 4 for agent 0
INFO: Continuing with Bootcamp #2 BootcampName.SLOW_AGENT with slow factor: 3 for agent 1
INFO: Continuing with Bootcamp #2 BootcampName.SLOW_AGENT with slow factor: 3 for agent 0
INFO: Continuing with Bootcamp #2 BootcampName.SLOW_AGENT with slow factor: 2 for agent 1
INFO: Continuing with Bootcamp #2 BootcampName.SLOW_AGENT with slow factor: 2 for agent 0
INFO: BootcampName.SLOW_AGENT Bootcamp completed, starting BootcampName.COMBINED Bootcamp #2 for 500 days
INFO: Starting Bootcamp #3, starting Bootcamp #3 BootcampName.HIDER
INFO: BootcampName.COMBINED Bootcamp completed, starting BootcampName.HIDER Bootcamp #3 for 1 days
INFO: BootcampName.HIDER Bootcamp completed, starting BootcampName.SEEKER Bootcamp #3 for 1 days
INFO: BootcampName.SEEKER Bootcamp completed, starting BootcampName.SLOW_AGENT Bootcamp #3 for 10 days
INFO: BootcampName.SLOW_AGENT Bootcamp completed, starting BootcampName.COMBINED Bootcamp #3 for 500 days
INFO: Number of parameters: 30085
INFO: QNetwork(
  (conv_feature): Sequential()
  (fc_feature): Sequential(
    (0): Linear(in_features=100, out_features=128, bias=True)
    (1): ReLU()
    (2): Linear(in_features=128, out_features=128, bias=True)
    (3): ReLU()
    (4): Linear(in_features=128, out_features=5, bias=True)
  )
)
INFO: Learning...
INFO: BootcampName.HIDER Bootcamp completed, starting BootcampName.SEEKER Bootcamp #0 for 500 days
INFO: BootcampName.SEEKER Bootcamp completed, starting BootcampName.SLOW_AGENT Bootcamp #0 for 1000 days
INFO: Number of parameters: 30085
INFO: QNetwork(
  (conv_feature): Sequential()
  (fc_feature): Sequential(
    (0): Linear(in_features=100, out_features=128, bias=True)
    (1): ReLU()
    (2): Linear(in_features=128, out_features=128, bias=True)
    (3): ReLU()
    (4): Linear(in_features=128, out_features=5, bias=True)
  )
)
INFO: Learning...
INFO: Number of parameters: 30085
INFO: QNetwork(
  (conv_feature): Sequential()
  (fc_feature): Sequential(
    (0): Linear(in_features=100, out_features=128, bias=True)
    (1): ReLU()
    (2): Linear(in_features=128, out_features=128, bias=True)
    (3): ReLU()
    (4): Linear(in_features=128, out_features=5, bias=True)
  )
)
INFO: Learning...
INFO: Number of parameters: 30085
INFO: QNetwork(
  (conv_feature): Sequential()
  (fc_feature): Sequential(
    (0): Linear(in_features=100, out_features=128, bias=True)
    (1): ReLU()
    (2): Linear(in_features=128, out_features=128, bias=True)
    (3): ReLU()
    (4): Linear(in_features=128, out_features=5, bias=True)
  )
)
INFO: Learning...
INFO: BootcampName.HIDER Bootcamp completed, starting BootcampName.SEEKER Bootcamp #0 for 500 days
INFO: Number of parameters: 30085
INFO: QNetwork(
  (conv_feature): Sequential()
  (fc_feature): Sequential(
    (0): Linear(in_features=100, out_features=128, bias=True)
    (1): ReLU()
    (2): Linear(in_features=128, out_features=128, bias=True)
    (3): ReLU()
    (4): Linear(in_features=128, out_features=5, bias=True)
  )
)
INFO: Learning...
INFO: BootcampName.HIDER Bootcamp completed, starting BootcampName.SEEKER Bootcamp #0 for 5 days
INFO: BootcampName.SEEKER Bootcamp completed, starting BootcampName.SLOW_AGENT Bootcamp #0 for 10 days
INFO: Continuing with Bootcamp #0 BootcampName.SLOW_AGENT with slow factor: 3 for agent 1
INFO: Continuing with Bootcamp #0 BootcampName.SLOW_AGENT with slow factor: 3 for agent 0
INFO: Continuing with Bootcamp #0 BootcampName.SLOW_AGENT with slow factor: 2 for agent 1
INFO: Continuing with Bootcamp #0 BootcampName.SLOW_AGENT with slow factor: 2 for agent 0
INFO: BootcampName.SLOW_AGENT Bootcamp completed, starting BootcampName.COMBINED Bootcamp #0 for 10 days
INFO: Starting Bootcamp #1, starting Bootcamp #1 BootcampName.HIDER
INFO: BootcampName.COMBINED Bootcamp completed, starting BootcampName.HIDER Bootcamp #1 for 5 days
INFO: BootcampName.HIDER Bootcamp completed, starting BootcampName.SEEKER Bootcamp #1 for 5 days
INFO: BootcampName.SEEKER Bootcamp completed, starting BootcampName.SLOW_AGENT Bootcamp #1 for 10 days
INFO: Continuing with Bootcamp #1 BootcampName.SLOW_AGENT with slow factor: 3 for agent 0
INFO: Continuing with Bootcamp #1 BootcampName.SLOW_AGENT with slow factor: 2 for agent 1
INFO: Continuing with Bootcamp #1 BootcampName.SLOW_AGENT with slow factor: 2 for agent 0
INFO: BootcampName.SLOW_AGENT Bootcamp completed, starting BootcampName.COMBINED Bootcamp #1 for 10 days
INFO: Starting Bootcamp #2, starting Bootcamp #2 BootcampName.HIDER
INFO: BootcampName.COMBINED Bootcamp completed, starting BootcampName.HIDER Bootcamp #2 for 5 days
INFO: BootcampName.HIDER Bootcamp completed, starting BootcampName.SEEKER Bootcamp #2 for 5 days
INFO: BootcampName.SEEKER Bootcamp completed, starting BootcampName.SLOW_AGENT Bootcamp #2 for 10 days
INFO: Continuing with Bootcamp #2 BootcampName.SLOW_AGENT with slow factor: 2 for agent 0
INFO: BootcampName.SLOW_AGENT Bootcamp completed, starting BootcampName.COMBINED Bootcamp #2 for 10 days
INFO: Starting Bootcamp #3, starting Bootcamp #3 BootcampName.HIDER
INFO: BootcampName.COMBINED Bootcamp completed, starting BootcampName.HIDER Bootcamp #3 for 5 days
INFO: BootcampName.HIDER Bootcamp completed, starting BootcampName.SEEKER Bootcamp #3 for 5 days
INFO: BootcampName.SEEKER Bootcamp completed, starting BootcampName.SLOW_AGENT Bootcamp #3 for 10 days
INFO: BootcampName.SLOW_AGENT Bootcamp completed, starting BootcampName.COMBINED Bootcamp #3 for 10 days
INFO: Starting Bootcamp #4, starting Bootcamp #4 BootcampName.HIDER
INFO: BootcampName.COMBINED Bootcamp completed, starting BootcampName.HIDER Bootcamp #4 for 5 days
ERROR: list index out of range
ERROR: Traceback (most recent call last):
  File "/home/eirik/Projects/XAI/rl/src/dqn/wrapper/multi_agent_dqn.py", line 75, in learn
    self._collect_rollouts()
  File "/home/eirik/Projects/XAI/rl/src/dqn/wrapper/multi_agent_dqn.py", line 144, in _collect_rollouts
    ) = self.env.get_wrapper_attr("step_multiple")(actions)
        ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/eirik/Projects/XAI/environments/gymnasium/wrappers/multi_agent_env.py", line 29, in step_multiple
    observation, reward, terminated, trunc, info = self.env.step(action)
                                                   ^^^^^^^^^^^^^^^^^^^^^
  File "/home/eirik/.cache/pypoetry/virtualenvs/xai-is73Zs3s-py3.11/lib/python3.11/site-packages/gymnasium/wrappers/order_enforcing.py", line 56, in step
    return self.env.step(action)
           ^^^^^^^^^^^^^^^^^^^^^
  File "/home/eirik/.cache/pypoetry/virtualenvs/xai-is73Zs3s-py3.11/lib/python3.11/site-packages/gymnasium/wrappers/env_checker.py", line 51, in step
    return self.env.step(action)
           ^^^^^^^^^^^^^^^^^^^^^
  File "/home/eirik/Projects/XAI/environments/gymnasium/envs/tag/tag.py", line 173, in step
    "agent_slow_factor": self.bootcamp.agent_slow_factor(
                         ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/eirik/Projects/XAI/environments/gymnasium/envs/tag/utils/bootcamp.py", line 91, in agent_slow_factor
    return max(self.slow_factor, self.slow_hider_factor)
               ^^^^^^^^^^^^^^^^
  File "/home/eirik/Projects/XAI/environments/gymnasium/envs/tag/utils/bootcamp.py", line 156, in slow_factor
    return self.slow_factors[self._bootcamp_num]
           ~~~~~~~~~~~~~~~~~^^^^^^^^^^^^^^^^^^^^
IndexError: list index out of range

WARNING: Error: Could not find wandb directory: ./wandb
INFO: Number of parameters: 30085
INFO: QNetwork(
  (conv_feature): Sequential()
  (fc_feature): Sequential(
    (0): Linear(in_features=100, out_features=128, bias=True)
    (1): ReLU()
    (2): Linear(in_features=128, out_features=128, bias=True)
    (3): ReLU()
    (4): Linear(in_features=128, out_features=5, bias=True)
  )
)
INFO: Learning...
INFO: BootcampName.HIDER Bootcamp completed, starting BootcampName.SEEKER Bootcamp #0 for 5 days
INFO: BootcampName.SEEKER Bootcamp completed, starting BootcampName.SLOW_AGENT Bootcamp #0 for 10 days
INFO: Continuing with Bootcamp #0 BootcampName.SLOW_AGENT with slow factor: 3 for agent 1
INFO: Continuing with Bootcamp #0 BootcampName.SLOW_AGENT with slow factor: 3 for agent 0
INFO: Continuing with Bootcamp #0 BootcampName.SLOW_AGENT with slow factor: 2 for agent 1
INFO: Continuing with Bootcamp #0 BootcampName.SLOW_AGENT with slow factor: 2 for agent 0
INFO: BootcampName.SLOW_AGENT Bootcamp completed, starting BootcampName.COMBINED Bootcamp #0 for 10 days
INFO: Starting Bootcamp #1, starting Bootcamp #1 BootcampName.HIDER
INFO: BootcampName.COMBINED Bootcamp completed, starting BootcampName.HIDER Bootcamp #1 for 5 days
INFO: BootcampName.HIDER Bootcamp completed, starting BootcampName.SEEKER Bootcamp #1 for 5 days
INFO: BootcampName.SEEKER Bootcamp completed, starting BootcampName.SLOW_AGENT Bootcamp #1 for 10 days
INFO: Continuing with Bootcamp #1 BootcampName.SLOW_AGENT with slow factor: 3 for agent 0
INFO: Continuing with Bootcamp #1 BootcampName.SLOW_AGENT with slow factor: 2 for agent 1
INFO: Continuing with Bootcamp #1 BootcampName.SLOW_AGENT with slow factor: 2 for agent 0
INFO: BootcampName.SLOW_AGENT Bootcamp completed, starting BootcampName.COMBINED Bootcamp #1 for 10 days
INFO: Starting Bootcamp #2, starting Bootcamp #2 BootcampName.HIDER
INFO: BootcampName.COMBINED Bootcamp completed, starting BootcampName.HIDER Bootcamp #2 for 5 days
INFO: BootcampName.HIDER Bootcamp completed, starting BootcampName.SEEKER Bootcamp #2 for 5 days
INFO: BootcampName.SEEKER Bootcamp completed, starting BootcampName.SLOW_AGENT Bootcamp #2 for 10 days
INFO: Continuing with Bootcamp #2 BootcampName.SLOW_AGENT with slow factor: 2 for agent 0
INFO: BootcampName.SLOW_AGENT Bootcamp completed, starting BootcampName.COMBINED Bootcamp #2 for 10 days
INFO: Starting Bootcamp #3, starting Bootcamp #3 BootcampName.HIDER
INFO: BootcampName.COMBINED Bootcamp completed, starting BootcampName.HIDER Bootcamp #3 for 5 days
INFO: BootcampName.HIDER Bootcamp completed, starting BootcampName.SEEKER Bootcamp #3 for 5 days
INFO: BootcampName.SEEKER Bootcamp completed, starting BootcampName.SLOW_AGENT Bootcamp #3 for 10 days
INFO: BootcampName.SLOW_AGENT Bootcamp completed, starting BootcampName.COMBINED Bootcamp #3 for 10 days
INFO: Bootcamp #3 BootcampName.FINISHED finished
INFO: BootcampName.COMBINED Bootcamp completed, starting BootcampName.FINISHED Bootcamp #3 for 0 days
INFO: Bootcamp #3 BootcampName.FINISHED finished
INFO: Bootcamp #3 BootcampName.FINISHED finished
INFO: Bootcamp #3 BootcampName.FINISHED finished
INFO: Bootcamp #3 BootcampName.FINISHED finished
INFO: Bootcamp #3 BootcampName.FINISHED finished
INFO: Bootcamp #3 BootcampName.FINISHED finished
INFO: Bootcamp #3 BootcampName.FINISHED finished
INFO: Bootcamp #3 BootcampName.FINISHED finished
INFO: Bootcamp #3 BootcampName.FINISHED finished
INFO: Bootcamp #3 BootcampName.FINISHED finished
INFO: Bootcamp #3 BootcampName.FINISHED finished
INFO: Bootcamp #3 BootcampName.FINISHED finished
INFO: Bootcamp #3 BootcampName.FINISHED finished
INFO: Bootcamp #3 BootcampName.FINISHED finished
INFO: Bootcamp #3 BootcampName.FINISHED finished
INFO: Bootcamp #3 BootcampName.FINISHED finished
INFO: Bootcamp #3 BootcampName.FINISHED finished
INFO: Bootcamp #3 BootcampName.FINISHED finished
INFO: Bootcamp #3 BootcampName.FINISHED finished
INFO: Bootcamp #3 BootcampName.FINISHED finished
INFO: Bootcamp #3 BootcampName.FINISHED finished
INFO: Bootcamp #3 BootcampName.FINISHED finished
INFO: Bootcamp #3 BootcampName.FINISHED finished
INFO: Bootcamp #3 BootcampName.FINISHED finished
INFO: Bootcamp #3 BootcampName.FINISHED finished
INFO: Bootcamp #3 BootcampName.FINISHED finished
INFO: Bootcamp #3 BootcampName.FINISHED finished
INFO: Bootcamp #3 BootcampName.FINISHED finished
INFO: Bootcamp #3 BootcampName.FINISHED finished
INFO: Bootcamp #3 BootcampName.FINISHED finished
INFO: Bootcamp #3 BootcampName.FINISHED finished
INFO: Bootcamp #3 BootcampName.FINISHED finished
INFO: Bootcamp #3 BootcampName.FINISHED finished
INFO: Bootcamp #3 BootcampName.FINISHED finished
INFO: Bootcamp #3 BootcampName.FINISHED finished
INFO: Bootcamp #3 BootcampName.FINISHED finished
INFO: Bootcamp #3 BootcampName.FINISHED finished
INFO: Bootcamp #3 BootcampName.FINISHED finished
INFO: Bootcamp #3 BootcampName.FINISHED finished
INFO: Bootcamp #3 BootcampName.FINISHED finished
INFO: Bootcamp #3 BootcampName.FINISHED finished
INFO: Bootcamp #3 BootcampName.FINISHED finished
INFO: Bootcamp #3 BootcampName.FINISHED finished
INFO: Bootcamp #3 BootcampName.FINISHED finished
INFO: Bootcamp #3 BootcampName.FINISHED finished
INFO: Bootcamp #3 BootcampName.FINISHED finished
INFO: Bootcamp #3 BootcampName.FINISHED finished
INFO: Bootcamp #3 BootcampName.FINISHED finished
INFO: Bootcamp #3 BootcampName.FINISHED finished
INFO: Bootcamp #3 BootcampName.FINISHED finished
INFO: Bootcamp #3 BootcampName.FINISHED finished
INFO: Bootcamp #3 BootcampName.FINISHED finished
INFO: Bootcamp #3 BootcampName.FINISHED finished
INFO: Bootcamp #3 BootcampName.FINISHED finished
INFO: Bootcamp #3 BootcampName.FINISHED finished
INFO: Bootcamp #3 BootcampName.FINISHED finished
INFO: Bootcamp #3 BootcampName.FINISHED finished
INFO: Bootcamp #3 BootcampName.FINISHED finished
INFO: Bootcamp #3 BootcampName.FINISHED finished
INFO: Bootcamp #3 BootcampName.FINISHED finished
INFO: Bootcamp #3 BootcampName.FINISHED finished
INFO: Bootcamp #3 BootcampName.FINISHED finished
INFO: Bootcamp #3 BootcampName.FINISHED finished
INFO: Bootcamp #3 BootcampName.FINISHED finished
INFO: Bootcamp #3 BootcampName.FINISHED finished
INFO: Bootcamp #3 BootcampName.FINISHED finished
INFO: Bootcamp #3 BootcampName.FINISHED finished
INFO: Bootcamp #3 BootcampName.FINISHED finished
INFO: Bootcamp #3 BootcampName.FINISHED finished
INFO: Bootcamp #3 BootcampName.FINISHED finished
INFO: Bootcamp #3 BootcampName.FINISHED finished
INFO: Bootcamp #3 BootcampName.FINISHED finished
INFO: Bootcamp #3 BootcampName.FINISHED finished
INFO: Bootcamp #3 BootcampName.FINISHED finished
INFO: Bootcamp #3 BootcampName.FINISHED finished
INFO: Bootcamp #3 BootcampName.FINISHED finished
INFO: Bootcamp #3 BootcampName.FINISHED finished
INFO: Bootcamp #3 BootcampName.FINISHED finished
INFO: Bootcamp #3 BootcampName.FINISHED finished
INFO: Bootcamp #3 BootcampName.FINISHED finished
INFO: Bootcamp #3 BootcampName.FINISHED finished
INFO: Bootcamp #3 BootcampName.FINISHED finished
INFO: Bootcamp #3 BootcampName.FINISHED finished
INFO: Bootcamp #3 BootcampName.FINISHED finished
INFO: Bootcamp #3 BootcampName.FINISHED finished
INFO: Bootcamp #3 BootcampName.FINISHED finished
INFO: Bootcamp #3 BootcampName.FINISHED finished
INFO: Bootcamp #3 BootcampName.FINISHED finished
INFO: Bootcamp #3 BootcampName.FINISHED finished
INFO: Bootcamp #3 BootcampName.FINISHED finished
INFO: Bootcamp #3 BootcampName.FINISHED finished
INFO: Bootcamp #3 BootcampName.FINISHED finished
INFO: Bootcamp #3 BootcampName.FINISHED finished
INFO: Bootcamp #3 BootcampName.FINISHED finished
INFO: Bootcamp #3 BootcampName.FINISHED finished
INFO: Bootcamp #3 BootcampName.FINISHED finished
INFO: Bootcamp #3 BootcampName.FINISHED finished
INFO: Bootcamp #3 BootcampName.FINISHED finished
INFO: Bootcamp #3 BootcampName.FINISHED finished
INFO: Bootcamp #3 BootcampName.FINISHED finished
INFO: Bootcamp #3 BootcampName.FINISHED finished
INFO: Bootcamp #3 BootcampName.FINISHED finished
INFO: Bootcamp #3 BootcampName.FINISHED finished
INFO: Bootcamp #3 BootcampName.FINISHED finished
INFO: Bootcamp #3 BootcampName.FINISHED finished
INFO: Bootcamp #3 BootcampName.FINISHED finished
INFO: Bootcamp #3 BootcampName.FINISHED finished
INFO: Bootcamp #3 BootcampName.FINISHED finished
INFO: Bootcamp #3 BootcampName.FINISHED finished
INFO: Bootcamp #3 BootcampName.FINISHED finished
INFO: Bootcamp #3 BootcampName.FINISHED finished
INFO: Bootcamp #3 BootcampName.FINISHED finished
INFO: Bootcamp #3 BootcampName.FINISHED finished
INFO: Bootcamp #3 BootcampName.FINISHED finished
INFO: Bootcamp #3 BootcampName.FINISHED finished
INFO: Bootcamp #3 BootcampName.FINISHED finished
INFO: Bootcamp #3 BootcampName.FINISHED finished
INFO: Bootcamp #3 BootcampName.FINISHED finished
INFO: Bootcamp #3 BootcampName.FINISHED finished
INFO: Bootcamp #3 BootcampName.FINISHED finished
INFO: Bootcamp #3 BootcampName.FINISHED finished
INFO: Bootcamp #3 BootcampName.FINISHED finished
INFO: Bootcamp #3 BootcampName.FINISHED finished
INFO: Bootcamp #3 BootcampName.FINISHED finished
INFO: Bootcamp #3 BootcampName.FINISHED finished
INFO: Bootcamp #3 BootcampName.FINISHED finished
INFO: Bootcamp #3 BootcampName.FINISHED finished
INFO: Bootcamp #3 BootcampName.FINISHED finished
INFO: Bootcamp #3 BootcampName.FINISHED finished
INFO: Bootcamp #3 BootcampName.FINISHED finished
INFO: Bootcamp #3 BootcampName.FINISHED finished
INFO: Bootcamp #3 BootcampName.FINISHED finished
INFO: Bootcamp #3 BootcampName.FINISHED finished
INFO: Bootcamp #3 BootcampName.FINISHED finished
INFO: Bootcamp #3 BootcampName.FINISHED finished
INFO: Bootcamp #3 BootcampName.FINISHED finished
INFO: Bootcamp #3 BootcampName.FINISHED finished
INFO: Bootcamp #3 BootcampName.FINISHED finished
INFO: Bootcamp #3 BootcampName.FINISHED finished
INFO: Bootcamp #3 BootcampName.FINISHED finished
INFO: Bootcamp #3 BootcampName.FINISHED finished
INFO: Bootcamp #3 BootcampName.FINISHED finished
INFO: Bootcamp #3 BootcampName.FINISHED finished
INFO: Bootcamp #3 BootcampName.FINISHED finished
INFO: Bootcamp #3 BootcampName.FINISHED finished
INFO: Bootcamp #3 BootcampName.FINISHED finished
INFO: Bootcamp #3 BootcampName.FINISHED finished
INFO: Bootcamp #3 BootcampName.FINISHED finished
INFO: Bootcamp #3 BootcampName.FINISHED finished
INFO: Bootcamp #3 BootcampName.FINISHED finished
INFO: Bootcamp #3 BootcampName.FINISHED finished
INFO: Bootcamp #3 BootcampName.FINISHED finished
INFO: Bootcamp #3 BootcampName.FINISHED finished
INFO: Bootcamp #3 BootcampName.FINISHED finished
INFO: Bootcamp #3 BootcampName.FINISHED finished
INFO: Bootcamp #3 BootcampName.FINISHED finished
INFO: Bootcamp #3 BootcampName.FINISHED finished
INFO: Bootcamp #3 BootcampName.FINISHED finished
INFO: Bootcamp #3 BootcampName.FINISHED finished
INFO: Bootcamp #3 BootcampName.FINISHED finished
INFO: Bootcamp #3 BootcampName.FINISHED finished
INFO: Bootcamp #3 BootcampName.FINISHED finished
INFO: Bootcamp #3 BootcampName.FINISHED finished
INFO: Bootcamp #3 BootcampName.FINISHED finished
INFO: Bootcamp #3 BootcampName.FINISHED finished
INFO: Bootcamp #3 BootcampName.FINISHED finished
INFO: Bootcamp #3 BootcampName.FINISHED finished
INFO: Bootcamp #3 BootcampName.FINISHED finished
INFO: Bootcamp #3 BootcampName.FINISHED finished
INFO: Bootcamp #3 BootcampName.FINISHED finished
INFO: Bootcamp #3 BootcampName.FINISHED finished
INFO: Bootcamp #3 BootcampName.FINISHED finished
INFO: Bootcamp #3 BootcampName.FINISHED finished
INFO: Bootcamp #3 BootcampName.FINISHED finished
INFO: Bootcamp #3 BootcampName.FINISHED finished
INFO: Bootcamp #3 BootcampName.FINISHED finished
INFO: Bootcamp #3 BootcampName.FINISHED finished
INFO: Bootcamp #3 BootcampName.FINISHED finished
INFO: Bootcamp #3 BootcampName.FINISHED finished
INFO: Bootcamp #3 BootcampName.FINISHED finished
INFO: Bootcamp #3 BootcampName.FINISHED finished
INFO: Bootcamp #3 BootcampName.FINISHED finished
INFO: Bootcamp #3 BootcampName.FINISHED finished
INFO: Bootcamp #3 BootcampName.FINISHED finished
INFO: Bootcamp #3 BootcampName.FINISHED finished
INFO: Bootcamp #3 BootcampName.FINISHED finished
INFO: Bootcamp #3 BootcampName.FINISHED finished
INFO: Bootcamp #3 BootcampName.FINISHED finished
INFO: Bootcamp #3 BootcampName.FINISHED finished
INFO: Bootcamp #3 BootcampName.FINISHED finished
INFO: Bootcamp #3 BootcampName.FINISHED finished
INFO: Bootcamp #3 BootcampName.FINISHED finished
INFO: Bootcamp #3 BootcampName.FINISHED finished
INFO: Bootcamp #3 BootcampName.FINISHED finished
INFO: Bootcamp #3 BootcampName.FINISHED finished
INFO: Bootcamp #3 BootcampName.FINISHED finished
INFO: Bootcamp #3 BootcampName.FINISHED finished
INFO: Bootcamp #3 BootcampName.FINISHED finished
INFO: Bootcamp #3 BootcampName.FINISHED finished
INFO: Bootcamp #3 BootcampName.FINISHED finished
INFO: Bootcamp #3 BootcampName.FINISHED finished
INFO: Bootcamp #3 BootcampName.FINISHED finished
INFO: Bootcamp #3 BootcampName.FINISHED finished
INFO: Bootcamp #3 BootcampName.FINISHED finished
INFO: Bootcamp #3 BootcampName.FINISHED finished
INFO: Bootcamp #3 BootcampName.FINISHED finished
INFO: Bootcamp #3 BootcampName.FINISHED finished
INFO: Bootcamp #3 BootcampName.FINISHED finished
INFO: Bootcamp #3 BootcampName.FINISHED finished
INFO: Bootcamp #3 BootcampName.FINISHED finished
INFO: Bootcamp #3 BootcampName.FINISHED finished
INFO: Bootcamp #3 BootcampName.FINISHED finished
INFO: Bootcamp #3 BootcampName.FINISHED finished
INFO: Bootcamp #3 BootcampName.FINISHED finished
INFO: Bootcamp #3 BootcampName.FINISHED finished
INFO: Bootcamp #3 BootcampName.FINISHED finished
INFO: Bootcamp #3 BootcampName.FINISHED finished
INFO: Bootcamp #3 BootcampName.FINISHED finished
INFO: Bootcamp #3 BootcampName.FINISHED finished
INFO: Bootcamp #3 BootcampName.FINISHED finished
INFO: Bootcamp #3 BootcampName.FINISHED finished
INFO: Bootcamp #3 BootcampName.FINISHED finished
INFO: Bootcamp #3 BootcampName.FINISHED finished
INFO: Bootcamp #3 BootcampName.FINISHED finished
INFO: Bootcamp #3 BootcampName.FINISHED finished
INFO: Bootcamp #3 BootcampName.FINISHED finished
INFO: Bootcamp #3 BootcampName.FINISHED finished
INFO: Bootcamp #3 BootcampName.FINISHED finished
INFO: Bootcamp #3 BootcampName.FINISHED finished
INFO: Bootcamp #3 BootcampName.FINISHED finished
INFO: Bootcamp #3 BootcampName.FINISHED finished
INFO: Bootcamp #3 BootcampName.FINISHED finished
INFO: Bootcamp #3 BootcampName.FINISHED finished
INFO: Bootcamp #3 BootcampName.FINISHED finished
INFO: Bootcamp #3 BootcampName.FINISHED finished
INFO: Bootcamp #3 BootcampName.FINISHED finished
INFO: Bootcamp #3 BootcampName.FINISHED finished
INFO: Bootcamp #3 BootcampName.FINISHED finished
INFO: Bootcamp #3 BootcampName.FINISHED finished
INFO: Bootcamp #3 BootcampName.FINISHED finished
INFO: Bootcamp #3 BootcampName.FINISHED finished
INFO: Bootcamp #3 BootcampName.FINISHED finished
INFO: Bootcamp #3 BootcampName.FINISHED finished
INFO: Bootcamp #3 BootcampName.FINISHED finished
INFO: Bootcamp #3 BootcampName.FINISHED finished
INFO: Bootcamp #3 BootcampName.FINISHED finished
INFO: Bootcamp #3 BootcampName.FINISHED finished
INFO: Bootcamp #3 BootcampName.FINISHED finished
INFO: Bootcamp #3 BootcampName.FINISHED finished
INFO: Bootcamp #3 BootcampName.FINISHED finished
INFO: Bootcamp #3 BootcampName.FINISHED finished
INFO: Bootcamp #3 BootcampName.FINISHED finished
INFO: Bootcamp #3 BootcampName.FINISHED finished
INFO: Bootcamp #3 BootcampName.FINISHED finished
INFO: Bootcamp #3 BootcampName.FINISHED finished
INFO: Bootcamp #3 BootcampName.FINISHED finished
INFO: Bootcamp #3 BootcampName.FINISHED finished
INFO: Bootcamp #3 BootcampName.FINISHED finished
INFO: Bootcamp #3 BootcampName.FINISHED finished
INFO: Bootcamp #3 BootcampName.FINISHED finished
INFO: Bootcamp #3 BootcampName.FINISHED finished
INFO: Bootcamp #3 BootcampName.FINISHED finished
INFO: Bootcamp #3 BootcampName.FINISHED finished
INFO: Bootcamp #3 BootcampName.FINISHED finished
INFO: Bootcamp #3 BootcampName.FINISHED finished
INFO: Bootcamp #3 BootcampName.FINISHED finished
INFO: Bootcamp #3 BootcampName.FINISHED finished
INFO: Bootcamp #3 BootcampName.FINISHED finished
INFO: Bootcamp #3 BootcampName.FINISHED finished
INFO: Bootcamp #3 BootcampName.FINISHED finished
INFO: Bootcamp #3 BootcampName.FINISHED finished
INFO: Bootcamp #3 BootcampName.FINISHED finished
INFO: Bootcamp #3 BootcampName.FINISHED finished
INFO: Bootcamp #3 BootcampName.FINISHED finished
INFO: Bootcamp #3 BootcampName.FINISHED finished
INFO: Bootcamp #3 BootcampName.FINISHED finished
INFO: Bootcamp #3 BootcampName.FINISHED finished
INFO: Bootcamp #3 BootcampName.FINISHED finished
INFO: Bootcamp #3 BootcampName.FINISHED finished
INFO: Bootcamp #3 BootcampName.FINISHED finished
INFO: Bootcamp #3 BootcampName.FINISHED finished
INFO: Bootcamp #3 BootcampName.FINISHED finished
INFO: Bootcamp #3 BootcampName.FINISHED finished
INFO: Bootcamp #3 BootcampName.FINISHED finished
INFO: Bootcamp #3 BootcampName.FINISHED finished
INFO: Bootcamp #3 BootcampName.FINISHED finished
INFO: Bootcamp #3 BootcampName.FINISHED finished
INFO: Bootcamp #3 BootcampName.FINISHED finished
INFO: Bootcamp #3 BootcampName.FINISHED finished
INFO: Bootcamp #3 BootcampName.FINISHED finished
INFO: Bootcamp #3 BootcampName.FINISHED finished
INFO: Bootcamp #3 BootcampName.FINISHED finished
INFO: Bootcamp #3 BootcampName.FINISHED finished
INFO: Bootcamp #3 BootcampName.FINISHED finished
INFO: Bootcamp #3 BootcampName.FINISHED finished
INFO: Bootcamp #3 BootcampName.FINISHED finished
INFO: Bootcamp #3 BootcampName.FINISHED finished
INFO: Bootcamp #3 BootcampName.FINISHED finished
INFO: Bootcamp #3 BootcampName.FINISHED finished
INFO: Bootcamp #3 BootcampName.FINISHED finished
INFO: Bootcamp #3 BootcampName.FINISHED finished
INFO: Bootcamp #3 BootcampName.FINISHED finished
INFO: Bootcamp #3 BootcampName.FINISHED finished
INFO: Bootcamp #3 BootcampName.FINISHED finished
INFO: Bootcamp #3 BootcampName.FINISHED finished
INFO: Bootcamp #3 BootcampName.FINISHED finished
INFO: Bootcamp #3 BootcampName.FINISHED finished
INFO: Bootcamp #3 BootcampName.FINISHED finished
INFO: Bootcamp #3 BootcampName.FINISHED finished
INFO: Bootcamp #3 BootcampName.FINISHED finished
INFO: Hyperparameters: lr=0.0001, gamma=0.99, eps_start=0.9, eps_end=0.05, eps_decay=50000, batch_size=32, tau=0.005,hidden_layers=[128, 128], conv_layers=[]
INFO: Hyperparameters: lr=0.0001, gamma=0.99, eps_start=0.9, eps_end=0.05, eps_decay=50000, batch_size=32, tau=0.005,hidden_layers=[128, 128], conv_layers=[]
INFO: Number of parameters: 30085
INFO: QNetwork(
  (conv_feature): Sequential()
  (fc_feature): Sequential(
    (0): Linear(in_features=100, out_features=128, bias=True)
    (1): ReLU()
    (2): Linear(in_features=128, out_features=128, bias=True)
    (3): ReLU()
    (4): Linear(in_features=128, out_features=5, bias=True)
  )
)
INFO: Hyperparameters: lr=0.0001, gamma=0.99, eps_start=0.9, eps_end=0.05, eps_decay=50000, batch_size=32, tau=0.005,hidden_layers=[128, 128], conv_layers=[]
INFO: Learning...
INFO: BootcampName.HIDER Bootcamp completed, starting BootcampName.SEEKER Bootcamp #0 for 500 days
INFO: Hyperparameters: lr=0.0001, gamma=0.99, eps_start=0.9, eps_end=0.05, eps_decay=50000, batch_size=32, tau=0.005,hidden_layers=[128, 128], conv_layers=[]
INFO: Number of parameters: 30085
INFO: QNetwork(
  (conv_feature): Sequential()
  (fc_feature): Sequential(
    (0): Linear(in_features=100, out_features=128, bias=True)
    (1): ReLU()
    (2): Linear(in_features=128, out_features=128, bias=True)
    (3): ReLU()
    (4): Linear(in_features=128, out_features=5, bias=True)
  )
)
INFO: Hyperparameters: lr=0.0001, gamma=0.99, eps_start=0.9, eps_end=0.05, eps_decay=50000, batch_size=32, tau=0.005,hidden_layers=[128, 128], conv_layers=[]
INFO: Learning...
INFO: Hyperparameters: lr=0.0001, gamma=0.99, eps_start=0.9, eps_end=0.05, eps_decay=50000, batch_size=32, tau=0.005,hidden_layers=[128, 128], conv_layers=[]
INFO: Number of parameters: 30085
INFO: QNetwork(
  (conv_feature): Sequential()
  (fc_feature): Sequential(
    (0): Linear(in_features=100, out_features=128, bias=True)
    (1): ReLU()
    (2): Linear(in_features=128, out_features=128, bias=True)
    (3): ReLU()
    (4): Linear(in_features=128, out_features=5, bias=True)
  )
)
INFO: Hyperparameters: lr=0.0001, gamma=0.99, eps_start=0.9, eps_end=0.05, eps_decay=50000, batch_size=32, tau=0.005,hidden_layers=[128, 128], conv_layers=[]
INFO: Learning...
INFO: Hyperparameters: lr=0.0001, gamma=0.99, eps_start=0.9, eps_end=0.05, eps_decay=50000, batch_size=32, tau=0.005,hidden_layers=[128, 128], conv_layers=[]
INFO: Number of parameters: 30085
INFO: QNetwork(
  (conv_feature): Sequential()
  (fc_feature): Sequential(
    (0): Linear(in_features=100, out_features=128, bias=True)
    (1): ReLU()
    (2): Linear(in_features=128, out_features=128, bias=True)
    (3): ReLU()
    (4): Linear(in_features=128, out_features=5, bias=True)
  )
)
INFO: Hyperparameters: lr=0.0001, gamma=0.99, eps_start=0.9, eps_end=0.05, eps_decay=50000, batch_size=32, tau=0.005,hidden_layers=[128, 128], conv_layers=[]
INFO: Learning...
INFO: Hyperparameters: lr=0.0001, gamma=0.99, eps_start=0.9, eps_end=0.05, eps_decay=50000, batch_size=32, tau=0.005,hidden_layers=[128, 128], conv_layers=[]
INFO: Number of parameters: 30085
INFO: QNetwork(
  (conv_feature): Sequential()
  (fc_feature): Sequential(
    (0): Linear(in_features=100, out_features=128, bias=True)
    (1): ReLU()
    (2): Linear(in_features=128, out_features=128, bias=True)
    (3): ReLU()
    (4): Linear(in_features=128, out_features=5, bias=True)
  )
)
INFO: Hyperparameters: lr=0.0001, gamma=0.99, eps_start=0.9, eps_end=0.05, eps_decay=50000, batch_size=32, tau=0.005,hidden_layers=[128, 128], conv_layers=[]
INFO: Learning...
INFO: Hyperparameters: lr=0.0001, gamma=0.99, eps_start=0.9, eps_end=0.05, eps_decay=50000, batch_size=32, tau=0.005,hidden_layers=[128, 128], conv_layers=[]
INFO: Number of parameters: 30085
INFO: QNetwork(
  (conv_feature): Sequential()
  (fc_feature): Sequential(
    (0): Linear(in_features=100, out_features=128, bias=True)
    (1): ReLU()
    (2): Linear(in_features=128, out_features=128, bias=True)
    (3): ReLU()
    (4): Linear(in_features=128, out_features=5, bias=True)
  )
)
INFO: Hyperparameters: lr=0.0001, gamma=0.99, eps_start=0.9, eps_end=0.05, eps_decay=50000, batch_size=32, tau=0.005,hidden_layers=[128, 128], conv_layers=[]
INFO: Learning...
INFO: Hyperparameters: lr=0.0001, gamma=0.99, eps_start=0.9, eps_end=0.05, eps_decay=50000, batch_size=32, tau=0.005,hidden_layers=[128, 128], conv_layers=[]
INFO: Number of parameters: 30085
INFO: QNetwork(
  (conv_feature): Sequential()
  (fc_feature): Sequential(
    (0): Linear(in_features=100, out_features=128, bias=True)
    (1): ReLU()
    (2): Linear(in_features=128, out_features=128, bias=True)
    (3): ReLU()
    (4): Linear(in_features=128, out_features=5, bias=True)
  )
)
INFO: Hyperparameters: lr=0.0001, gamma=0.99, eps_start=0.9, eps_end=0.05, eps_decay=50000, batch_size=32, tau=0.005,hidden_layers=[128, 128], conv_layers=[]
INFO: Learning...
INFO: Hyperparameters: lr=0.0001, gamma=0.99, eps_start=0.9, eps_end=0.05, eps_decay=50000, batch_size=32, tau=0.005,hidden_layers=[128, 128], conv_layers=[]
INFO: Number of parameters: 30085
INFO: QNetwork(
  (conv_feature): Sequential()
  (fc_feature): Sequential(
    (0): Linear(in_features=100, out_features=128, bias=True)
    (1): ReLU()
    (2): Linear(in_features=128, out_features=128, bias=True)
    (3): ReLU()
    (4): Linear(in_features=128, out_features=5, bias=True)
  )
)
INFO: Hyperparameters: lr=0.0001, gamma=0.99, eps_start=0.9, eps_end=0.05, eps_decay=50000, batch_size=32, tau=0.005,hidden_layers=[128, 128], conv_layers=[]
INFO: Learning...
INFO: Hyperparameters: lr=0.0001, gamma=0.99, eps_start=0.9, eps_end=0.05, eps_decay=50000, batch_size=32, tau=0.005,hidden_layers=[128, 128], conv_layers=[]
INFO: Number of parameters: 30085
INFO: QNetwork(
  (conv_feature): Sequential()
  (fc_feature): Sequential(
    (0): Linear(in_features=100, out_features=128, bias=True)
    (1): ReLU()
    (2): Linear(in_features=128, out_features=128, bias=True)
    (3): ReLU()
    (4): Linear(in_features=128, out_features=5, bias=True)
  )
)
INFO: Hyperparameters: lr=0.0001, gamma=0.99, eps_start=0.9, eps_end=0.05, eps_decay=50000, batch_size=32, tau=0.005,hidden_layers=[128, 128], conv_layers=[]
INFO: Learning...
INFO: Hyperparameters: lr=0.0001, gamma=0.99, eps_start=0.9, eps_end=0.05, eps_decay=50000, batch_size=32, tau=0.005,hidden_layers=[128, 128], conv_layers=[]
INFO: Number of parameters: 30085
INFO: QNetwork(
  (conv_feature): Sequential()
  (fc_feature): Sequential(
    (0): Linear(in_features=100, out_features=128, bias=True)
    (1): ReLU()
    (2): Linear(in_features=128, out_features=128, bias=True)
    (3): ReLU()
    (4): Linear(in_features=128, out_features=5, bias=True)
  )
)
INFO: Hyperparameters: lr=0.0001, gamma=0.99, eps_start=0.9, eps_end=0.05, eps_decay=50000, batch_size=32, tau=0.005,hidden_layers=[128, 128], conv_layers=[]
INFO: Learning...
INFO: Hyperparameters: lr=0.0001, gamma=0.99, eps_start=0.9, eps_end=0.05, eps_decay=50000, batch_size=32, tau=0.005,hidden_layers=[128, 128], conv_layers=[]
INFO: Number of parameters: 30085
INFO: QNetwork(
  (conv_feature): Sequential()
  (fc_feature): Sequential(
    (0): Linear(in_features=100, out_features=128, bias=True)
    (1): ReLU()
    (2): Linear(in_features=128, out_features=128, bias=True)
    (3): ReLU()
    (4): Linear(in_features=128, out_features=5, bias=True)
  )
)
INFO: Hyperparameters: lr=0.0001, gamma=0.99, eps_start=0.9, eps_end=0.05, eps_decay=50000, batch_size=32, tau=0.005,hidden_layers=[128, 128], conv_layers=[]
INFO: Learning...
INFO: Hyperparameters: lr=0.0001, gamma=0.99, eps_start=0.9, eps_end=0.05, eps_decay=50000, batch_size=32, tau=0.005,hidden_layers=[128, 128], conv_layers=[]
INFO: Number of parameters: 30085
INFO: QNetwork(
  (conv_feature): Sequential()
  (fc_feature): Sequential(
    (0): Linear(in_features=100, out_features=128, bias=True)
    (1): ReLU()
    (2): Linear(in_features=128, out_features=128, bias=True)
    (3): ReLU()
    (4): Linear(in_features=128, out_features=5, bias=True)
  )
)
INFO: Hyperparameters: lr=0.0001, gamma=0.99, eps_start=0.9, eps_end=0.05, eps_decay=50000, batch_size=32, tau=0.005,hidden_layers=[128, 128], conv_layers=[]
INFO: Learning...
INFO: Hyperparameters: lr=0.0001, gamma=0.99, eps_start=0.9, eps_end=0.05, eps_decay=50000, batch_size=32, tau=0.005,hidden_layers=[128, 128], conv_layers=[]
INFO: Number of parameters: 30085
INFO: QNetwork(
  (conv_feature): Sequential()
  (fc_feature): Sequential(
    (0): Linear(in_features=100, out_features=128, bias=True)
    (1): ReLU()
    (2): Linear(in_features=128, out_features=128, bias=True)
    (3): ReLU()
    (4): Linear(in_features=128, out_features=5, bias=True)
  )
)
INFO: Hyperparameters: lr=0.0001, gamma=0.99, eps_start=0.9, eps_end=0.05, eps_decay=50000, batch_size=32, tau=0.005,hidden_layers=[128, 128], conv_layers=[]
INFO: Learning...
ERROR: [Errno 32] Broken pipe
ERROR: Traceback (most recent call last):
  File "/home/eirik/Projects/XAI/rl/src/dqn/wrapper/multi_agent_dqn.py", line 108, in learn
    self.wandb_manager.log(log)
  File "/home/eirik/Projects/XAI/rl/src/managers/wandb_manager.py", line 83, in log
    wandb.log(data)
  File "/home/eirik/.cache/pypoetry/virtualenvs/xai-is73Zs3s-py3.11/lib/python3.11/site-packages/wandb/sdk/wandb_run.py", line 452, in wrapper
    return func(self, *args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/eirik/.cache/pypoetry/virtualenvs/xai-is73Zs3s-py3.11/lib/python3.11/site-packages/wandb/sdk/wandb_run.py", line 403, in wrapper_fn
    return func(self, *args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/eirik/.cache/pypoetry/virtualenvs/xai-is73Zs3s-py3.11/lib/python3.11/site-packages/wandb/sdk/wandb_run.py", line 393, in wrapper
    return func(self, *args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/eirik/.cache/pypoetry/virtualenvs/xai-is73Zs3s-py3.11/lib/python3.11/site-packages/wandb/sdk/wandb_run.py", line 1933, in log
    self._log(data=data, step=step, commit=commit)
  File "/home/eirik/.cache/pypoetry/virtualenvs/xai-is73Zs3s-py3.11/lib/python3.11/site-packages/wandb/sdk/wandb_run.py", line 1652, in _log
    self._partial_history_callback(data, step, commit)
  File "/home/eirik/.cache/pypoetry/virtualenvs/xai-is73Zs3s-py3.11/lib/python3.11/site-packages/wandb/sdk/wandb_run.py", line 1524, in _partial_history_callback
    self._backend.interface.publish_partial_history(
  File "/home/eirik/.cache/pypoetry/virtualenvs/xai-is73Zs3s-py3.11/lib/python3.11/site-packages/wandb/sdk/interface/interface.py", line 647, in publish_partial_history
    self._publish_partial_history(partial_history)
  File "/home/eirik/.cache/pypoetry/virtualenvs/xai-is73Zs3s-py3.11/lib/python3.11/site-packages/wandb/sdk/interface/interface_shared.py", line 89, in _publish_partial_history
    self._publish(rec)
  File "/home/eirik/.cache/pypoetry/virtualenvs/xai-is73Zs3s-py3.11/lib/python3.11/site-packages/wandb/sdk/interface/interface_sock.py", line 51, in _publish
    self._sock_client.send_record_publish(record)
  File "/home/eirik/.cache/pypoetry/virtualenvs/xai-is73Zs3s-py3.11/lib/python3.11/site-packages/wandb/sdk/lib/sock_client.py", line 225, in send_record_publish
    self.send_server_request(server_req)
  File "/home/eirik/.cache/pypoetry/virtualenvs/xai-is73Zs3s-py3.11/lib/python3.11/site-packages/wandb/sdk/lib/sock_client.py", line 157, in send_server_request
    self._send_message(msg)
  File "/home/eirik/.cache/pypoetry/virtualenvs/xai-is73Zs3s-py3.11/lib/python3.11/site-packages/wandb/sdk/lib/sock_client.py", line 154, in _send_message
    self._sendall_with_error_handle(header + data)
  File "/home/eirik/.cache/pypoetry/virtualenvs/xai-is73Zs3s-py3.11/lib/python3.11/site-packages/wandb/sdk/lib/sock_client.py", line 132, in _sendall_with_error_handle
    sent = self._sock.send(data)
           ^^^^^^^^^^^^^^^^^^^^^
BrokenPipeError: [Errno 32] Broken pipe

ERROR: [Errno 32] Broken pipe
ERROR: Traceback (most recent call last):
  File "/home/eirik/Projects/XAI/rl/src/dqn/wrapper/multi_agent_dqn.py", line 108, in learn
    self.wandb_manager.log(log)
  File "/home/eirik/Projects/XAI/rl/src/managers/wandb_manager.py", line 83, in log
    wandb.log(data)
  File "/home/eirik/.cache/pypoetry/virtualenvs/xai-is73Zs3s-py3.11/lib/python3.11/site-packages/wandb/sdk/wandb_run.py", line 452, in wrapper
    return func(self, *args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/eirik/.cache/pypoetry/virtualenvs/xai-is73Zs3s-py3.11/lib/python3.11/site-packages/wandb/sdk/wandb_run.py", line 403, in wrapper_fn
    return func(self, *args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/eirik/.cache/pypoetry/virtualenvs/xai-is73Zs3s-py3.11/lib/python3.11/site-packages/wandb/sdk/wandb_run.py", line 393, in wrapper
    return func(self, *args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/eirik/.cache/pypoetry/virtualenvs/xai-is73Zs3s-py3.11/lib/python3.11/site-packages/wandb/sdk/wandb_run.py", line 1933, in log
    self._log(data=data, step=step, commit=commit)
  File "/home/eirik/.cache/pypoetry/virtualenvs/xai-is73Zs3s-py3.11/lib/python3.11/site-packages/wandb/sdk/wandb_run.py", line 1652, in _log
    self._partial_history_callback(data, step, commit)
  File "/home/eirik/.cache/pypoetry/virtualenvs/xai-is73Zs3s-py3.11/lib/python3.11/site-packages/wandb/sdk/wandb_run.py", line 1524, in _partial_history_callback
    self._backend.interface.publish_partial_history(
  File "/home/eirik/.cache/pypoetry/virtualenvs/xai-is73Zs3s-py3.11/lib/python3.11/site-packages/wandb/sdk/interface/interface.py", line 647, in publish_partial_history
    self._publish_partial_history(partial_history)
  File "/home/eirik/.cache/pypoetry/virtualenvs/xai-is73Zs3s-py3.11/lib/python3.11/site-packages/wandb/sdk/interface/interface_shared.py", line 89, in _publish_partial_history
    self._publish(rec)
  File "/home/eirik/.cache/pypoetry/virtualenvs/xai-is73Zs3s-py3.11/lib/python3.11/site-packages/wandb/sdk/interface/interface_sock.py", line 51, in _publish
    self._sock_client.send_record_publish(record)
  File "/home/eirik/.cache/pypoetry/virtualenvs/xai-is73Zs3s-py3.11/lib/python3.11/site-packages/wandb/sdk/lib/sock_client.py", line 225, in send_record_publish
    self.send_server_request(server_req)
  File "/home/eirik/.cache/pypoetry/virtualenvs/xai-is73Zs3s-py3.11/lib/python3.11/site-packages/wandb/sdk/lib/sock_client.py", line 157, in send_server_request
    self._send_message(msg)
  File "/home/eirik/.cache/pypoetry/virtualenvs/xai-is73Zs3s-py3.11/lib/python3.11/site-packages/wandb/sdk/lib/sock_client.py", line 154, in _send_message
    self._sendall_with_error_handle(header + data)
  File "/home/eirik/.cache/pypoetry/virtualenvs/xai-is73Zs3s-py3.11/lib/python3.11/site-packages/wandb/sdk/lib/sock_client.py", line 132, in _sendall_with_error_handle
    sent = self._sock.send(data)
           ^^^^^^^^^^^^^^^^^^^^^
BrokenPipeError: [Errno 32] Broken pipe

INFO: Hyperparameters: lr=0.0001, gamma=0.99, eps_start=0.9, eps_end=0.05, eps_decay=50000, batch_size=32, tau=0.005,hidden_layers=[128, 128], conv_layers=[]
INFO: Number of parameters: 30085
INFO: QNetwork(
  (conv_feature): Sequential()
  (fc_feature): Sequential(
    (0): Linear(in_features=100, out_features=128, bias=True)
    (1): ReLU()
    (2): Linear(in_features=128, out_features=128, bias=True)
    (3): ReLU()
    (4): Linear(in_features=128, out_features=5, bias=True)
  )
)
INFO: Hyperparameters: lr=0.0001, gamma=0.99, eps_start=0.9, eps_end=0.05, eps_decay=50000, batch_size=32, tau=0.005,hidden_layers=[128, 128], conv_layers=[]
INFO: Learning...
ERROR: [Errno 32] Broken pipe
ERROR: Traceback (most recent call last):
  File "/home/eirik/Projects/XAI/rl/src/dqn/wrapper/multi_agent_dqn.py", line 108, in learn
    self.wandb_manager.log(log)
  File "/home/eirik/Projects/XAI/rl/src/managers/wandb_manager.py", line 83, in log
    wandb.log(data)
  File "/home/eirik/.cache/pypoetry/virtualenvs/xai-is73Zs3s-py3.11/lib/python3.11/site-packages/wandb/sdk/wandb_run.py", line 452, in wrapper
    return func(self, *args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/eirik/.cache/pypoetry/virtualenvs/xai-is73Zs3s-py3.11/lib/python3.11/site-packages/wandb/sdk/wandb_run.py", line 403, in wrapper_fn
    return func(self, *args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/eirik/.cache/pypoetry/virtualenvs/xai-is73Zs3s-py3.11/lib/python3.11/site-packages/wandb/sdk/wandb_run.py", line 393, in wrapper
    return func(self, *args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/eirik/.cache/pypoetry/virtualenvs/xai-is73Zs3s-py3.11/lib/python3.11/site-packages/wandb/sdk/wandb_run.py", line 1933, in log
    self._log(data=data, step=step, commit=commit)
  File "/home/eirik/.cache/pypoetry/virtualenvs/xai-is73Zs3s-py3.11/lib/python3.11/site-packages/wandb/sdk/wandb_run.py", line 1652, in _log
    self._partial_history_callback(data, step, commit)
  File "/home/eirik/.cache/pypoetry/virtualenvs/xai-is73Zs3s-py3.11/lib/python3.11/site-packages/wandb/sdk/wandb_run.py", line 1524, in _partial_history_callback
    self._backend.interface.publish_partial_history(
  File "/home/eirik/.cache/pypoetry/virtualenvs/xai-is73Zs3s-py3.11/lib/python3.11/site-packages/wandb/sdk/interface/interface.py", line 647, in publish_partial_history
    self._publish_partial_history(partial_history)
  File "/home/eirik/.cache/pypoetry/virtualenvs/xai-is73Zs3s-py3.11/lib/python3.11/site-packages/wandb/sdk/interface/interface_shared.py", line 89, in _publish_partial_history
    self._publish(rec)
  File "/home/eirik/.cache/pypoetry/virtualenvs/xai-is73Zs3s-py3.11/lib/python3.11/site-packages/wandb/sdk/interface/interface_sock.py", line 51, in _publish
    self._sock_client.send_record_publish(record)
  File "/home/eirik/.cache/pypoetry/virtualenvs/xai-is73Zs3s-py3.11/lib/python3.11/site-packages/wandb/sdk/lib/sock_client.py", line 225, in send_record_publish
    self.send_server_request(server_req)
  File "/home/eirik/.cache/pypoetry/virtualenvs/xai-is73Zs3s-py3.11/lib/python3.11/site-packages/wandb/sdk/lib/sock_client.py", line 157, in send_server_request
    self._send_message(msg)
  File "/home/eirik/.cache/pypoetry/virtualenvs/xai-is73Zs3s-py3.11/lib/python3.11/site-packages/wandb/sdk/lib/sock_client.py", line 154, in _send_message
    self._sendall_with_error_handle(header + data)
  File "/home/eirik/.cache/pypoetry/virtualenvs/xai-is73Zs3s-py3.11/lib/python3.11/site-packages/wandb/sdk/lib/sock_client.py", line 132, in _sendall_with_error_handle
    sent = self._sock.send(data)
           ^^^^^^^^^^^^^^^^^^^^^
BrokenPipeError: [Errno 32] Broken pipe

INFO: Hyperparameters: lr=0.0001, gamma=0.99, eps_start=0.9, eps_end=0.05, eps_decay=50000, batch_size=32, tau=0.005,hidden_layers=[128, 128], conv_layers=[]
INFO: Number of parameters: 30085
INFO: QNetwork(
  (conv_feature): Sequential()
  (fc_feature): Sequential(
    (0): Linear(in_features=100, out_features=128, bias=True)
    (1): ReLU()
    (2): Linear(in_features=128, out_features=128, bias=True)
    (3): ReLU()
    (4): Linear(in_features=128, out_features=5, bias=True)
  )
)
INFO: Hyperparameters: lr=0.0001, gamma=0.99, eps_start=0.9, eps_end=0.05, eps_decay=50000, batch_size=32, tau=0.005,hidden_layers=[128, 128], conv_layers=[]
INFO: Learning...
INFO: BootcampName.HIDER Bootcamp completed, starting BootcampName.SEEKER Bootcamp #0 for 500 days
INFO: BootcampName.SEEKER Bootcamp completed, starting BootcampName.SLOW_AGENT Bootcamp #0 for 1000 days
INFO: Continuing with Bootcamp #0 BootcampName.SLOW_AGENT with slow factor: 9 for agent 1
INFO: Continuing with Bootcamp #0 BootcampName.SLOW_AGENT with slow factor: 9 for agent 0
INFO: Continuing with Bootcamp #0 BootcampName.SLOW_AGENT with slow factor: 8 for agent 1
INFO: Continuing with Bootcamp #0 BootcampName.SLOW_AGENT with slow factor: 8 for agent 0
INFO: Continuing with Bootcamp #0 BootcampName.SLOW_AGENT with slow factor: 7 for agent 1
INFO: Continuing with Bootcamp #0 BootcampName.SLOW_AGENT with slow factor: 7 for agent 0
INFO: Continuing with Bootcamp #0 BootcampName.SLOW_AGENT with slow factor: 6 for agent 1
INFO: Continuing with Bootcamp #0 BootcampName.SLOW_AGENT with slow factor: 6 for agent 0
INFO: Hyperparameters: lr=0.0001, gamma=0.99, eps_start=0.9, eps_end=0.05, eps_decay=50000, batch_size=32, tau=0.005,hidden_layers=[128, 128], conv_layers=[]
INFO: Number of parameters: 30085
INFO: QNetwork(
  (conv_feature): Sequential()
  (fc_feature): Sequential(
    (0): Linear(in_features=100, out_features=128, bias=True)
    (1): ReLU()
    (2): Linear(in_features=128, out_features=128, bias=True)
    (3): ReLU()
    (4): Linear(in_features=128, out_features=5, bias=True)
  )
)
INFO: Hyperparameters: lr=0.0001, gamma=0.99, eps_start=0.9, eps_end=0.05, eps_decay=50000, batch_size=32, tau=0.005,hidden_layers=[128, 128], conv_layers=[]
INFO: Learning...
ERROR: [Errno 32] Broken pipe
ERROR: Traceback (most recent call last):
  File "/home/eirik/Projects/XAI/rl/src/dqn/wrapper/multi_agent_dqn.py", line 108, in learn
    self.wandb_manager.log(log)
  File "/home/eirik/Projects/XAI/rl/src/managers/wandb_manager.py", line 83, in log
    wandb.log(data)
  File "/home/eirik/.cache/pypoetry/virtualenvs/xai-is73Zs3s-py3.11/lib/python3.11/site-packages/wandb/sdk/wandb_run.py", line 452, in wrapper
    return func(self, *args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/eirik/.cache/pypoetry/virtualenvs/xai-is73Zs3s-py3.11/lib/python3.11/site-packages/wandb/sdk/wandb_run.py", line 403, in wrapper_fn
    return func(self, *args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/eirik/.cache/pypoetry/virtualenvs/xai-is73Zs3s-py3.11/lib/python3.11/site-packages/wandb/sdk/wandb_run.py", line 393, in wrapper
    return func(self, *args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/eirik/.cache/pypoetry/virtualenvs/xai-is73Zs3s-py3.11/lib/python3.11/site-packages/wandb/sdk/wandb_run.py", line 1933, in log
    self._log(data=data, step=step, commit=commit)
  File "/home/eirik/.cache/pypoetry/virtualenvs/xai-is73Zs3s-py3.11/lib/python3.11/site-packages/wandb/sdk/wandb_run.py", line 1652, in _log
    self._partial_history_callback(data, step, commit)
  File "/home/eirik/.cache/pypoetry/virtualenvs/xai-is73Zs3s-py3.11/lib/python3.11/site-packages/wandb/sdk/wandb_run.py", line 1524, in _partial_history_callback
    self._backend.interface.publish_partial_history(
  File "/home/eirik/.cache/pypoetry/virtualenvs/xai-is73Zs3s-py3.11/lib/python3.11/site-packages/wandb/sdk/interface/interface.py", line 647, in publish_partial_history
    self._publish_partial_history(partial_history)
  File "/home/eirik/.cache/pypoetry/virtualenvs/xai-is73Zs3s-py3.11/lib/python3.11/site-packages/wandb/sdk/interface/interface_shared.py", line 89, in _publish_partial_history
    self._publish(rec)
  File "/home/eirik/.cache/pypoetry/virtualenvs/xai-is73Zs3s-py3.11/lib/python3.11/site-packages/wandb/sdk/interface/interface_sock.py", line 51, in _publish
    self._sock_client.send_record_publish(record)
  File "/home/eirik/.cache/pypoetry/virtualenvs/xai-is73Zs3s-py3.11/lib/python3.11/site-packages/wandb/sdk/lib/sock_client.py", line 225, in send_record_publish
    self.send_server_request(server_req)
  File "/home/eirik/.cache/pypoetry/virtualenvs/xai-is73Zs3s-py3.11/lib/python3.11/site-packages/wandb/sdk/lib/sock_client.py", line 157, in send_server_request
    self._send_message(msg)
  File "/home/eirik/.cache/pypoetry/virtualenvs/xai-is73Zs3s-py3.11/lib/python3.11/site-packages/wandb/sdk/lib/sock_client.py", line 154, in _send_message
    self._sendall_with_error_handle(header + data)
  File "/home/eirik/.cache/pypoetry/virtualenvs/xai-is73Zs3s-py3.11/lib/python3.11/site-packages/wandb/sdk/lib/sock_client.py", line 132, in _sendall_with_error_handle
    sent = self._sock.send(data)
           ^^^^^^^^^^^^^^^^^^^^^
BrokenPipeError: [Errno 32] Broken pipe

INFO: Hyperparameters: lr=0.0001, gamma=0.99, eps_start=0.9, eps_end=0.05, eps_decay=50000, batch_size=32, tau=0.005,hidden_layers=[128, 128], conv_layers=[]
INFO: Number of parameters: 30085
INFO: QNetwork(
  (conv_feature): Sequential()
  (fc_feature): Sequential(
    (0): Linear(in_features=100, out_features=128, bias=True)
    (1): ReLU()
    (2): Linear(in_features=128, out_features=128, bias=True)
    (3): ReLU()
    (4): Linear(in_features=128, out_features=5, bias=True)
  )
)
INFO: Hyperparameters: lr=0.0001, gamma=0.99, eps_start=0.9, eps_end=0.05, eps_decay=50000, batch_size=32, tau=0.005,hidden_layers=[128, 128], conv_layers=[]
INFO: Number of parameters: 30085
INFO: QNetwork(
  (conv_feature): Sequential()
  (fc_feature): Sequential(
    (0): Linear(in_features=100, out_features=128, bias=True)
    (1): ReLU()
    (2): Linear(in_features=128, out_features=128, bias=True)
    (3): ReLU()
    (4): Linear(in_features=128, out_features=5, bias=True)
  )
)
INFO: Hyperparameters: lr=0.0001, gamma=0.99, eps_start=0.9, eps_end=0.05, eps_decay=50000, batch_size=32, tau=0.005,hidden_layers=[128, 128], conv_layers=[]
INFO: Learning...
ERROR: [Errno 32] Broken pipe
ERROR: Traceback (most recent call last):
  File "/home/eirik/Projects/XAI/rl/src/dqn/wrapper/multi_agent_dqn.py", line 108, in learn
    self.wandb_manager.log(log)
  File "/home/eirik/Projects/XAI/rl/src/managers/wandb_manager.py", line 83, in log
    wandb.log(data)
  File "/home/eirik/.cache/pypoetry/virtualenvs/xai-is73Zs3s-py3.11/lib/python3.11/site-packages/wandb/sdk/wandb_run.py", line 452, in wrapper
    return func(self, *args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/eirik/.cache/pypoetry/virtualenvs/xai-is73Zs3s-py3.11/lib/python3.11/site-packages/wandb/sdk/wandb_run.py", line 403, in wrapper_fn
    return func(self, *args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/eirik/.cache/pypoetry/virtualenvs/xai-is73Zs3s-py3.11/lib/python3.11/site-packages/wandb/sdk/wandb_run.py", line 393, in wrapper
    return func(self, *args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/eirik/.cache/pypoetry/virtualenvs/xai-is73Zs3s-py3.11/lib/python3.11/site-packages/wandb/sdk/wandb_run.py", line 1933, in log
    self._log(data=data, step=step, commit=commit)
  File "/home/eirik/.cache/pypoetry/virtualenvs/xai-is73Zs3s-py3.11/lib/python3.11/site-packages/wandb/sdk/wandb_run.py", line 1652, in _log
    self._partial_history_callback(data, step, commit)
  File "/home/eirik/.cache/pypoetry/virtualenvs/xai-is73Zs3s-py3.11/lib/python3.11/site-packages/wandb/sdk/wandb_run.py", line 1524, in _partial_history_callback
    self._backend.interface.publish_partial_history(
  File "/home/eirik/.cache/pypoetry/virtualenvs/xai-is73Zs3s-py3.11/lib/python3.11/site-packages/wandb/sdk/interface/interface.py", line 647, in publish_partial_history
    self._publish_partial_history(partial_history)
  File "/home/eirik/.cache/pypoetry/virtualenvs/xai-is73Zs3s-py3.11/lib/python3.11/site-packages/wandb/sdk/interface/interface_shared.py", line 89, in _publish_partial_history
    self._publish(rec)
  File "/home/eirik/.cache/pypoetry/virtualenvs/xai-is73Zs3s-py3.11/lib/python3.11/site-packages/wandb/sdk/interface/interface_sock.py", line 51, in _publish
    self._sock_client.send_record_publish(record)
  File "/home/eirik/.cache/pypoetry/virtualenvs/xai-is73Zs3s-py3.11/lib/python3.11/site-packages/wandb/sdk/lib/sock_client.py", line 225, in send_record_publish
    self.send_server_request(server_req)
  File "/home/eirik/.cache/pypoetry/virtualenvs/xai-is73Zs3s-py3.11/lib/python3.11/site-packages/wandb/sdk/lib/sock_client.py", line 157, in send_server_request
    self._send_message(msg)
  File "/home/eirik/.cache/pypoetry/virtualenvs/xai-is73Zs3s-py3.11/lib/python3.11/site-packages/wandb/sdk/lib/sock_client.py", line 154, in _send_message
    self._sendall_with_error_handle(header + data)
  File "/home/eirik/.cache/pypoetry/virtualenvs/xai-is73Zs3s-py3.11/lib/python3.11/site-packages/wandb/sdk/lib/sock_client.py", line 132, in _sendall_with_error_handle
    sent = self._sock.send(data)
           ^^^^^^^^^^^^^^^^^^^^^
BrokenPipeError: [Errno 32] Broken pipe

ERROR: [Errno 32] Broken pipe
ERROR: Traceback (most recent call last):
  File "/home/eirik/Projects/XAI/rl/src/dqn/wrapper/multi_agent_dqn.py", line 108, in learn
    self.wandb_manager.log(log)
  File "/home/eirik/Projects/XAI/rl/src/managers/wandb_manager.py", line 83, in log
    wandb.log(data)
  File "/home/eirik/.cache/pypoetry/virtualenvs/xai-is73Zs3s-py3.11/lib/python3.11/site-packages/wandb/sdk/wandb_run.py", line 452, in wrapper
    return func(self, *args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/eirik/.cache/pypoetry/virtualenvs/xai-is73Zs3s-py3.11/lib/python3.11/site-packages/wandb/sdk/wandb_run.py", line 403, in wrapper_fn
    return func(self, *args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/eirik/.cache/pypoetry/virtualenvs/xai-is73Zs3s-py3.11/lib/python3.11/site-packages/wandb/sdk/wandb_run.py", line 393, in wrapper
    return func(self, *args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/eirik/.cache/pypoetry/virtualenvs/xai-is73Zs3s-py3.11/lib/python3.11/site-packages/wandb/sdk/wandb_run.py", line 1933, in log
    self._log(data=data, step=step, commit=commit)
  File "/home/eirik/.cache/pypoetry/virtualenvs/xai-is73Zs3s-py3.11/lib/python3.11/site-packages/wandb/sdk/wandb_run.py", line 1652, in _log
    self._partial_history_callback(data, step, commit)
  File "/home/eirik/.cache/pypoetry/virtualenvs/xai-is73Zs3s-py3.11/lib/python3.11/site-packages/wandb/sdk/wandb_run.py", line 1524, in _partial_history_callback
    self._backend.interface.publish_partial_history(
  File "/home/eirik/.cache/pypoetry/virtualenvs/xai-is73Zs3s-py3.11/lib/python3.11/site-packages/wandb/sdk/interface/interface.py", line 647, in publish_partial_history
    self._publish_partial_history(partial_history)
  File "/home/eirik/.cache/pypoetry/virtualenvs/xai-is73Zs3s-py3.11/lib/python3.11/site-packages/wandb/sdk/interface/interface_shared.py", line 89, in _publish_partial_history
    self._publish(rec)
  File "/home/eirik/.cache/pypoetry/virtualenvs/xai-is73Zs3s-py3.11/lib/python3.11/site-packages/wandb/sdk/interface/interface_sock.py", line 51, in _publish
    self._sock_client.send_record_publish(record)
  File "/home/eirik/.cache/pypoetry/virtualenvs/xai-is73Zs3s-py3.11/lib/python3.11/site-packages/wandb/sdk/lib/sock_client.py", line 225, in send_record_publish
    self.send_server_request(server_req)
  File "/home/eirik/.cache/pypoetry/virtualenvs/xai-is73Zs3s-py3.11/lib/python3.11/site-packages/wandb/sdk/lib/sock_client.py", line 157, in send_server_request
    self._send_message(msg)
  File "/home/eirik/.cache/pypoetry/virtualenvs/xai-is73Zs3s-py3.11/lib/python3.11/site-packages/wandb/sdk/lib/sock_client.py", line 154, in _send_message
    self._sendall_with_error_handle(header + data)
  File "/home/eirik/.cache/pypoetry/virtualenvs/xai-is73Zs3s-py3.11/lib/python3.11/site-packages/wandb/sdk/lib/sock_client.py", line 132, in _sendall_with_error_handle
    sent = self._sock.send(data)
           ^^^^^^^^^^^^^^^^^^^^^
BrokenPipeError: [Errno 32] Broken pipe

INFO: Hyperparameters: lr=0.0001, gamma=0.99, eps_start=0.9, eps_end=0.05, eps_decay=50000, batch_size=32, tau=0.005,hidden_layers=[128, 128], conv_layers=[]
INFO: Number of parameters: 30085
INFO: QNetwork(
  (conv_feature): Sequential()
  (fc_feature): Sequential(
    (0): Linear(in_features=100, out_features=128, bias=True)
    (1): ReLU()
    (2): Linear(in_features=128, out_features=128, bias=True)
    (3): ReLU()
    (4): Linear(in_features=128, out_features=5, bias=True)
  )
)
INFO: Hyperparameters: lr=0.0001, gamma=0.99, eps_start=0.9, eps_end=0.05, eps_decay=50000, batch_size=32, tau=0.005,hidden_layers=[128, 128], conv_layers=[]
INFO: Learning...
INFO: Hyperparameters: lr=0.0001, gamma=0.99, eps_start=0.9, eps_end=0.05, eps_decay=50000, batch_size=32, tau=0.005,hidden_layers=[128, 128], conv_layers=[]
INFO: Number of parameters: 30085
INFO: QNetwork(
  (conv_feature): Sequential()
  (fc_feature): Sequential(
    (0): Linear(in_features=100, out_features=128, bias=True)
    (1): ReLU()
    (2): Linear(in_features=128, out_features=128, bias=True)
    (3): ReLU()
    (4): Linear(in_features=128, out_features=5, bias=True)
  )
)
INFO: Hyperparameters: lr=0.0001, gamma=0.99, eps_start=0.9, eps_end=0.05, eps_decay=50000, batch_size=32, tau=0.005,hidden_layers=[128, 128], conv_layers=[]
INFO: Learning...
ERROR: [Errno 32] Broken pipe
ERROR: Traceback (most recent call last):
  File "/home/eirik/Projects/XAI/rl/src/dqn/wrapper/multi_agent_dqn.py", line 109, in learn
    self.wandb_manager.log(log)
  File "/home/eirik/Projects/XAI/rl/src/managers/wandb_manager.py", line 83, in log
    wandb.log(data)
  File "/home/eirik/.cache/pypoetry/virtualenvs/xai-is73Zs3s-py3.11/lib/python3.11/site-packages/wandb/sdk/wandb_run.py", line 452, in wrapper
    return func(self, *args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/eirik/.cache/pypoetry/virtualenvs/xai-is73Zs3s-py3.11/lib/python3.11/site-packages/wandb/sdk/wandb_run.py", line 403, in wrapper_fn
    return func(self, *args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/eirik/.cache/pypoetry/virtualenvs/xai-is73Zs3s-py3.11/lib/python3.11/site-packages/wandb/sdk/wandb_run.py", line 393, in wrapper
    return func(self, *args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/eirik/.cache/pypoetry/virtualenvs/xai-is73Zs3s-py3.11/lib/python3.11/site-packages/wandb/sdk/wandb_run.py", line 1933, in log
    self._log(data=data, step=step, commit=commit)
  File "/home/eirik/.cache/pypoetry/virtualenvs/xai-is73Zs3s-py3.11/lib/python3.11/site-packages/wandb/sdk/wandb_run.py", line 1652, in _log
    self._partial_history_callback(data, step, commit)
  File "/home/eirik/.cache/pypoetry/virtualenvs/xai-is73Zs3s-py3.11/lib/python3.11/site-packages/wandb/sdk/wandb_run.py", line 1524, in _partial_history_callback
    self._backend.interface.publish_partial_history(
  File "/home/eirik/.cache/pypoetry/virtualenvs/xai-is73Zs3s-py3.11/lib/python3.11/site-packages/wandb/sdk/interface/interface.py", line 647, in publish_partial_history
    self._publish_partial_history(partial_history)
  File "/home/eirik/.cache/pypoetry/virtualenvs/xai-is73Zs3s-py3.11/lib/python3.11/site-packages/wandb/sdk/interface/interface_shared.py", line 89, in _publish_partial_history
    self._publish(rec)
  File "/home/eirik/.cache/pypoetry/virtualenvs/xai-is73Zs3s-py3.11/lib/python3.11/site-packages/wandb/sdk/interface/interface_sock.py", line 51, in _publish
    self._sock_client.send_record_publish(record)
  File "/home/eirik/.cache/pypoetry/virtualenvs/xai-is73Zs3s-py3.11/lib/python3.11/site-packages/wandb/sdk/lib/sock_client.py", line 225, in send_record_publish
    self.send_server_request(server_req)
  File "/home/eirik/.cache/pypoetry/virtualenvs/xai-is73Zs3s-py3.11/lib/python3.11/site-packages/wandb/sdk/lib/sock_client.py", line 157, in send_server_request
    self._send_message(msg)
  File "/home/eirik/.cache/pypoetry/virtualenvs/xai-is73Zs3s-py3.11/lib/python3.11/site-packages/wandb/sdk/lib/sock_client.py", line 154, in _send_message
    self._sendall_with_error_handle(header + data)
  File "/home/eirik/.cache/pypoetry/virtualenvs/xai-is73Zs3s-py3.11/lib/python3.11/site-packages/wandb/sdk/lib/sock_client.py", line 132, in _sendall_with_error_handle
    sent = self._sock.send(data)
           ^^^^^^^^^^^^^^^^^^^^^
BrokenPipeError: [Errno 32] Broken pipe

ERROR: [Errno 32] Broken pipe
ERROR: Traceback (most recent call last):
  File "/home/eirik/Projects/XAI/rl/src/dqn/wrapper/multi_agent_dqn.py", line 109, in learn
    self.wandb_manager.log(log)
  File "/home/eirik/Projects/XAI/rl/src/managers/wandb_manager.py", line 83, in log
    wandb.log(data)
  File "/home/eirik/.cache/pypoetry/virtualenvs/xai-is73Zs3s-py3.11/lib/python3.11/site-packages/wandb/sdk/wandb_run.py", line 452, in wrapper
    return func(self, *args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/eirik/.cache/pypoetry/virtualenvs/xai-is73Zs3s-py3.11/lib/python3.11/site-packages/wandb/sdk/wandb_run.py", line 403, in wrapper_fn
    return func(self, *args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/eirik/.cache/pypoetry/virtualenvs/xai-is73Zs3s-py3.11/lib/python3.11/site-packages/wandb/sdk/wandb_run.py", line 393, in wrapper
    return func(self, *args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/eirik/.cache/pypoetry/virtualenvs/xai-is73Zs3s-py3.11/lib/python3.11/site-packages/wandb/sdk/wandb_run.py", line 1933, in log
    self._log(data=data, step=step, commit=commit)
  File "/home/eirik/.cache/pypoetry/virtualenvs/xai-is73Zs3s-py3.11/lib/python3.11/site-packages/wandb/sdk/wandb_run.py", line 1652, in _log
    self._partial_history_callback(data, step, commit)
  File "/home/eirik/.cache/pypoetry/virtualenvs/xai-is73Zs3s-py3.11/lib/python3.11/site-packages/wandb/sdk/wandb_run.py", line 1524, in _partial_history_callback
    self._backend.interface.publish_partial_history(
  File "/home/eirik/.cache/pypoetry/virtualenvs/xai-is73Zs3s-py3.11/lib/python3.11/site-packages/wandb/sdk/interface/interface.py", line 647, in publish_partial_history
    self._publish_partial_history(partial_history)
  File "/home/eirik/.cache/pypoetry/virtualenvs/xai-is73Zs3s-py3.11/lib/python3.11/site-packages/wandb/sdk/interface/interface_shared.py", line 89, in _publish_partial_history
    self._publish(rec)
  File "/home/eirik/.cache/pypoetry/virtualenvs/xai-is73Zs3s-py3.11/lib/python3.11/site-packages/wandb/sdk/interface/interface_sock.py", line 51, in _publish
    self._sock_client.send_record_publish(record)
  File "/home/eirik/.cache/pypoetry/virtualenvs/xai-is73Zs3s-py3.11/lib/python3.11/site-packages/wandb/sdk/lib/sock_client.py", line 225, in send_record_publish
    self.send_server_request(server_req)
  File "/home/eirik/.cache/pypoetry/virtualenvs/xai-is73Zs3s-py3.11/lib/python3.11/site-packages/wandb/sdk/lib/sock_client.py", line 157, in send_server_request
    self._send_message(msg)
  File "/home/eirik/.cache/pypoetry/virtualenvs/xai-is73Zs3s-py3.11/lib/python3.11/site-packages/wandb/sdk/lib/sock_client.py", line 154, in _send_message
    self._sendall_with_error_handle(header + data)
  File "/home/eirik/.cache/pypoetry/virtualenvs/xai-is73Zs3s-py3.11/lib/python3.11/site-packages/wandb/sdk/lib/sock_client.py", line 132, in _sendall_with_error_handle
    sent = self._sock.send(data)
           ^^^^^^^^^^^^^^^^^^^^^
BrokenPipeError: [Errno 32] Broken pipe

INFO: Hyperparameters: lr=0.0001, gamma=0.99, eps_start=0.9, eps_end=0.05, eps_decay=50000, batch_size=32, tau=0.005,hidden_layers=[128, 128], conv_layers=[]
INFO: Number of parameters: 30085
INFO: QNetwork(
  (conv_feature): Sequential()
  (fc_feature): Sequential(
    (0): Linear(in_features=100, out_features=128, bias=True)
    (1): ReLU()
    (2): Linear(in_features=128, out_features=128, bias=True)
    (3): ReLU()
    (4): Linear(in_features=128, out_features=5, bias=True)
  )
)
INFO: Hyperparameters: lr=0.0001, gamma=0.99, eps_start=0.9, eps_end=0.05, eps_decay=50000, batch_size=32, tau=0.005,hidden_layers=[128, 128], conv_layers=[]
INFO: Learning...
ERROR: [Errno 32] Broken pipe
ERROR: Traceback (most recent call last):
  File "/home/eirik/Projects/XAI/rl/src/dqn/wrapper/multi_agent_dqn.py", line 108, in learn
    self.wandb_manager.log(log)
  File "/home/eirik/Projects/XAI/rl/src/managers/wandb_manager.py", line 83, in log
    wandb.log(data)
  File "/home/eirik/.cache/pypoetry/virtualenvs/xai-is73Zs3s-py3.11/lib/python3.11/site-packages/wandb/sdk/wandb_run.py", line 452, in wrapper
    return func(self, *args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/eirik/.cache/pypoetry/virtualenvs/xai-is73Zs3s-py3.11/lib/python3.11/site-packages/wandb/sdk/wandb_run.py", line 403, in wrapper_fn
    return func(self, *args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/eirik/.cache/pypoetry/virtualenvs/xai-is73Zs3s-py3.11/lib/python3.11/site-packages/wandb/sdk/wandb_run.py", line 393, in wrapper
    return func(self, *args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/eirik/.cache/pypoetry/virtualenvs/xai-is73Zs3s-py3.11/lib/python3.11/site-packages/wandb/sdk/wandb_run.py", line 1933, in log
    self._log(data=data, step=step, commit=commit)
  File "/home/eirik/.cache/pypoetry/virtualenvs/xai-is73Zs3s-py3.11/lib/python3.11/site-packages/wandb/sdk/wandb_run.py", line 1652, in _log
    self._partial_history_callback(data, step, commit)
  File "/home/eirik/.cache/pypoetry/virtualenvs/xai-is73Zs3s-py3.11/lib/python3.11/site-packages/wandb/sdk/wandb_run.py", line 1524, in _partial_history_callback
    self._backend.interface.publish_partial_history(
  File "/home/eirik/.cache/pypoetry/virtualenvs/xai-is73Zs3s-py3.11/lib/python3.11/site-packages/wandb/sdk/interface/interface.py", line 647, in publish_partial_history
    self._publish_partial_history(partial_history)
  File "/home/eirik/.cache/pypoetry/virtualenvs/xai-is73Zs3s-py3.11/lib/python3.11/site-packages/wandb/sdk/interface/interface_shared.py", line 89, in _publish_partial_history
    self._publish(rec)
  File "/home/eirik/.cache/pypoetry/virtualenvs/xai-is73Zs3s-py3.11/lib/python3.11/site-packages/wandb/sdk/interface/interface_sock.py", line 51, in _publish
    self._sock_client.send_record_publish(record)
  File "/home/eirik/.cache/pypoetry/virtualenvs/xai-is73Zs3s-py3.11/lib/python3.11/site-packages/wandb/sdk/lib/sock_client.py", line 225, in send_record_publish
    self.send_server_request(server_req)
  File "/home/eirik/.cache/pypoetry/virtualenvs/xai-is73Zs3s-py3.11/lib/python3.11/site-packages/wandb/sdk/lib/sock_client.py", line 157, in send_server_request
    self._send_message(msg)
  File "/home/eirik/.cache/pypoetry/virtualenvs/xai-is73Zs3s-py3.11/lib/python3.11/site-packages/wandb/sdk/lib/sock_client.py", line 154, in _send_message
    self._sendall_with_error_handle(header + data)
  File "/home/eirik/.cache/pypoetry/virtualenvs/xai-is73Zs3s-py3.11/lib/python3.11/site-packages/wandb/sdk/lib/sock_client.py", line 132, in _sendall_with_error_handle
    sent = self._sock.send(data)
           ^^^^^^^^^^^^^^^^^^^^^
BrokenPipeError: [Errno 32] Broken pipe

INFO: Hyperparameters: lr=0.0001, gamma=0.99, eps_start=0.9, eps_end=0.05, eps_decay=50000, batch_size=32, tau=0.005,hidden_layers=[128, 128], conv_layers=[]
INFO: Number of parameters: 30085
INFO: QNetwork(
  (conv_feature): Sequential()
  (fc_feature): Sequential(
    (0): Linear(in_features=100, out_features=128, bias=True)
    (1): ReLU()
    (2): Linear(in_features=128, out_features=128, bias=True)
    (3): ReLU()
    (4): Linear(in_features=128, out_features=5, bias=True)
  )
)
INFO: Hyperparameters: lr=0.0001, gamma=0.99, eps_start=0.9, eps_end=0.05, eps_decay=50000, batch_size=32, tau=0.005,hidden_layers=[128, 128], conv_layers=[]
INFO: Learning...
INFO: BootcampName.HIDER Bootcamp completed, starting BootcampName.SEEKER Bootcamp #0 for 500 days
INFO: Hyperparameters: lr=0.0001, gamma=0.99, eps_start=0.9, eps_end=0.05, eps_decay=50000, batch_size=32, tau=0.005,hidden_layers=[128, 128], conv_layers=[]
INFO: Number of parameters: 30085
INFO: QNetwork(
  (conv_feature): Sequential()
  (fc_feature): Sequential(
    (0): Linear(in_features=100, out_features=128, bias=True)
    (1): ReLU()
    (2): Linear(in_features=128, out_features=128, bias=True)
    (3): ReLU()
    (4): Linear(in_features=128, out_features=5, bias=True)
  )
)
INFO: Hyperparameters: lr=0.0001, gamma=0.99, eps_start=0.9, eps_end=0.05, eps_decay=50000, batch_size=32, tau=0.005,hidden_layers=[128, 128], conv_layers=[]
INFO: Learning...
INFO: BootcampName.HIDER Bootcamp completed, starting BootcampName.SEEKER Bootcamp #0 for 500 days
INFO: BootcampName.SEEKER Bootcamp completed, starting BootcampName.SLOW_AGENT Bootcamp #0 for 1000 days
INFO: Hyperparameters: lr=0.0001, gamma=0.99, eps_start=0.9, eps_end=0.05, eps_decay=50000, batch_size=32, tau=0.005,hidden_layers=[128, 128], conv_layers=[]
INFO: Number of parameters: 30085
INFO: QNetwork(
  (conv_feature): Sequential()
  (fc_feature): Sequential(
    (0): Linear(in_features=100, out_features=128, bias=True)
    (1): ReLU()
    (2): Linear(in_features=128, out_features=128, bias=True)
    (3): ReLU()
    (4): Linear(in_features=128, out_features=5, bias=True)
  )
)
INFO: Hyperparameters: lr=0.0001, gamma=0.99, eps_start=0.9, eps_end=0.05, eps_decay=50000, batch_size=32, tau=0.005,hidden_layers=[128, 128], conv_layers=[]
INFO: Learning...
ERROR: [Errno 32] Broken pipe
ERROR: Traceback (most recent call last):
  File "/home/eirik/Projects/XAI/rl/src/dqn/wrapper/multi_agent_dqn.py", line 108, in learn
    self.wandb_manager.log(log)
  File "/home/eirik/Projects/XAI/rl/src/managers/wandb_manager.py", line 84, in log
    wandb.log(data)
  File "/home/eirik/.cache/pypoetry/virtualenvs/xai-is73Zs3s-py3.11/lib/python3.11/site-packages/wandb/sdk/wandb_run.py", line 452, in wrapper
    return func(self, *args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/eirik/.cache/pypoetry/virtualenvs/xai-is73Zs3s-py3.11/lib/python3.11/site-packages/wandb/sdk/wandb_run.py", line 403, in wrapper_fn
    return func(self, *args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/eirik/.cache/pypoetry/virtualenvs/xai-is73Zs3s-py3.11/lib/python3.11/site-packages/wandb/sdk/wandb_run.py", line 393, in wrapper
    return func(self, *args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/eirik/.cache/pypoetry/virtualenvs/xai-is73Zs3s-py3.11/lib/python3.11/site-packages/wandb/sdk/wandb_run.py", line 1933, in log
    self._log(data=data, step=step, commit=commit)
  File "/home/eirik/.cache/pypoetry/virtualenvs/xai-is73Zs3s-py3.11/lib/python3.11/site-packages/wandb/sdk/wandb_run.py", line 1652, in _log
    self._partial_history_callback(data, step, commit)
  File "/home/eirik/.cache/pypoetry/virtualenvs/xai-is73Zs3s-py3.11/lib/python3.11/site-packages/wandb/sdk/wandb_run.py", line 1524, in _partial_history_callback
    self._backend.interface.publish_partial_history(
  File "/home/eirik/.cache/pypoetry/virtualenvs/xai-is73Zs3s-py3.11/lib/python3.11/site-packages/wandb/sdk/interface/interface.py", line 647, in publish_partial_history
    self._publish_partial_history(partial_history)
  File "/home/eirik/.cache/pypoetry/virtualenvs/xai-is73Zs3s-py3.11/lib/python3.11/site-packages/wandb/sdk/interface/interface_shared.py", line 89, in _publish_partial_history
    self._publish(rec)
  File "/home/eirik/.cache/pypoetry/virtualenvs/xai-is73Zs3s-py3.11/lib/python3.11/site-packages/wandb/sdk/interface/interface_sock.py", line 51, in _publish
    self._sock_client.send_record_publish(record)
  File "/home/eirik/.cache/pypoetry/virtualenvs/xai-is73Zs3s-py3.11/lib/python3.11/site-packages/wandb/sdk/lib/sock_client.py", line 225, in send_record_publish
    self.send_server_request(server_req)
  File "/home/eirik/.cache/pypoetry/virtualenvs/xai-is73Zs3s-py3.11/lib/python3.11/site-packages/wandb/sdk/lib/sock_client.py", line 157, in send_server_request
    self._send_message(msg)
  File "/home/eirik/.cache/pypoetry/virtualenvs/xai-is73Zs3s-py3.11/lib/python3.11/site-packages/wandb/sdk/lib/sock_client.py", line 154, in _send_message
    self._sendall_with_error_handle(header + data)
  File "/home/eirik/.cache/pypoetry/virtualenvs/xai-is73Zs3s-py3.11/lib/python3.11/site-packages/wandb/sdk/lib/sock_client.py", line 132, in _sendall_with_error_handle
    sent = self._sock.send(data)
           ^^^^^^^^^^^^^^^^^^^^^
BrokenPipeError: [Errno 32] Broken pipe

INFO: Hyperparameters: lr=0.0001, gamma=0.99, eps_start=0.9, eps_end=0.05, eps_decay=50000, batch_size=32, tau=0.005,hidden_layers=[128, 128], conv_layers=[]
INFO: Number of parameters: 30085
INFO: QNetwork(
  (conv_feature): Sequential()
  (fc_feature): Sequential(
    (0): Linear(in_features=100, out_features=128, bias=True)
    (1): ReLU()
    (2): Linear(in_features=128, out_features=128, bias=True)
    (3): ReLU()
    (4): Linear(in_features=128, out_features=5, bias=True)
  )
)
INFO: Hyperparameters: lr=0.0001, gamma=0.99, eps_start=0.9, eps_end=0.05, eps_decay=50000, batch_size=32, tau=0.005,hidden_layers=[128, 128], conv_layers=[]
INFO: Learning...
ERROR: [Errno 32] Broken pipe
ERROR: Traceback (most recent call last):
  File "/home/eirik/Projects/XAI/rl/src/dqn/wrapper/multi_agent_dqn.py", line 109, in learn
    self.wandb_manager.log(log)
  File "/home/eirik/Projects/XAI/rl/src/managers/wandb_manager.py", line 83, in log
    wandb.log(data)
  File "/home/eirik/.cache/pypoetry/virtualenvs/xai-is73Zs3s-py3.11/lib/python3.11/site-packages/wandb/sdk/wandb_run.py", line 452, in wrapper
    return func(self, *args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/eirik/.cache/pypoetry/virtualenvs/xai-is73Zs3s-py3.11/lib/python3.11/site-packages/wandb/sdk/wandb_run.py", line 403, in wrapper_fn
    return func(self, *args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/eirik/.cache/pypoetry/virtualenvs/xai-is73Zs3s-py3.11/lib/python3.11/site-packages/wandb/sdk/wandb_run.py", line 393, in wrapper
    return func(self, *args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/eirik/.cache/pypoetry/virtualenvs/xai-is73Zs3s-py3.11/lib/python3.11/site-packages/wandb/sdk/wandb_run.py", line 1933, in log
    self._log(data=data, step=step, commit=commit)
  File "/home/eirik/.cache/pypoetry/virtualenvs/xai-is73Zs3s-py3.11/lib/python3.11/site-packages/wandb/sdk/wandb_run.py", line 1652, in _log
    self._partial_history_callback(data, step, commit)
  File "/home/eirik/.cache/pypoetry/virtualenvs/xai-is73Zs3s-py3.11/lib/python3.11/site-packages/wandb/sdk/wandb_run.py", line 1524, in _partial_history_callback
    self._backend.interface.publish_partial_history(
  File "/home/eirik/.cache/pypoetry/virtualenvs/xai-is73Zs3s-py3.11/lib/python3.11/site-packages/wandb/sdk/interface/interface.py", line 647, in publish_partial_history
    self._publish_partial_history(partial_history)
  File "/home/eirik/.cache/pypoetry/virtualenvs/xai-is73Zs3s-py3.11/lib/python3.11/site-packages/wandb/sdk/interface/interface_shared.py", line 89, in _publish_partial_history
    self._publish(rec)
  File "/home/eirik/.cache/pypoetry/virtualenvs/xai-is73Zs3s-py3.11/lib/python3.11/site-packages/wandb/sdk/interface/interface_sock.py", line 51, in _publish
    self._sock_client.send_record_publish(record)
  File "/home/eirik/.cache/pypoetry/virtualenvs/xai-is73Zs3s-py3.11/lib/python3.11/site-packages/wandb/sdk/lib/sock_client.py", line 225, in send_record_publish
    self.send_server_request(server_req)
  File "/home/eirik/.cache/pypoetry/virtualenvs/xai-is73Zs3s-py3.11/lib/python3.11/site-packages/wandb/sdk/lib/sock_client.py", line 157, in send_server_request
    self._send_message(msg)
  File "/home/eirik/.cache/pypoetry/virtualenvs/xai-is73Zs3s-py3.11/lib/python3.11/site-packages/wandb/sdk/lib/sock_client.py", line 154, in _send_message
    self._sendall_with_error_handle(header + data)
  File "/home/eirik/.cache/pypoetry/virtualenvs/xai-is73Zs3s-py3.11/lib/python3.11/site-packages/wandb/sdk/lib/sock_client.py", line 132, in _sendall_with_error_handle
    sent = self._sock.send(data)
           ^^^^^^^^^^^^^^^^^^^^^
BrokenPipeError: [Errno 32] Broken pipe

INFO: Hyperparameters: lr=0.0001, gamma=0.99, eps_start=0.9, eps_end=0.05, eps_decay=50000, batch_size=32, tau=0.005,hidden_layers=[128, 128], conv_layers=[]
INFO: Number of parameters: 30085
INFO: QNetwork(
  (conv_feature): Sequential()
  (fc_feature): Sequential(
    (0): Linear(in_features=100, out_features=128, bias=True)
    (1): ReLU()
    (2): Linear(in_features=128, out_features=128, bias=True)
    (3): ReLU()
    (4): Linear(in_features=128, out_features=5, bias=True)
  )
)
INFO: Hyperparameters: lr=0.0001, gamma=0.99, eps_start=0.9, eps_end=0.05, eps_decay=50000, batch_size=32, tau=0.005,hidden_layers=[128, 128], conv_layers=[]
INFO: Learning...
INFO: BootcampName.HIDER Bootcamp completed, starting BootcampName.SEEKER Bootcamp #0 for 500 days
INFO: BootcampName.SEEKER Bootcamp completed, starting BootcampName.SLOW_AGENT Bootcamp #0 for 1000 days
INFO: Hyperparameters: lr=0.0001, gamma=0.99, eps_start=0.9, eps_end=0.05, eps_decay=50000, batch_size=32, tau=0.005,hidden_layers=[128, 128], conv_layers=[]
INFO: Number of parameters: 30085
INFO: QNetwork(
  (conv_feature): Sequential()
  (fc_feature): Sequential(
    (0): Linear(in_features=100, out_features=128, bias=True)
    (1): ReLU()
    (2): Linear(in_features=128, out_features=128, bias=True)
    (3): ReLU()
    (4): Linear(in_features=128, out_features=5, bias=True)
  )
)
INFO: Hyperparameters: lr=0.0001, gamma=0.99, eps_start=0.9, eps_end=0.05, eps_decay=50000, batch_size=32, tau=0.005,hidden_layers=[128, 128], conv_layers=[]
INFO: Learning...
ERROR: [Errno 32] Broken pipe
ERROR: Traceback (most recent call last):
  File "/home/eirik/Projects/XAI/rl/src/dqn/wrapper/multi_agent_dqn.py", line 108, in learn
    self.wandb_manager.log(log)
  File "/home/eirik/Projects/XAI/rl/src/managers/wandb_manager.py", line 83, in log
    wandb.log(data)
  File "/home/eirik/.cache/pypoetry/virtualenvs/xai-is73Zs3s-py3.11/lib/python3.11/site-packages/wandb/sdk/wandb_run.py", line 452, in wrapper
    return func(self, *args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/eirik/.cache/pypoetry/virtualenvs/xai-is73Zs3s-py3.11/lib/python3.11/site-packages/wandb/sdk/wandb_run.py", line 403, in wrapper_fn
    return func(self, *args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/eirik/.cache/pypoetry/virtualenvs/xai-is73Zs3s-py3.11/lib/python3.11/site-packages/wandb/sdk/wandb_run.py", line 393, in wrapper
    return func(self, *args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/eirik/.cache/pypoetry/virtualenvs/xai-is73Zs3s-py3.11/lib/python3.11/site-packages/wandb/sdk/wandb_run.py", line 1933, in log
    self._log(data=data, step=step, commit=commit)
  File "/home/eirik/.cache/pypoetry/virtualenvs/xai-is73Zs3s-py3.11/lib/python3.11/site-packages/wandb/sdk/wandb_run.py", line 1652, in _log
    self._partial_history_callback(data, step, commit)
  File "/home/eirik/.cache/pypoetry/virtualenvs/xai-is73Zs3s-py3.11/lib/python3.11/site-packages/wandb/sdk/wandb_run.py", line 1524, in _partial_history_callback
    self._backend.interface.publish_partial_history(
  File "/home/eirik/.cache/pypoetry/virtualenvs/xai-is73Zs3s-py3.11/lib/python3.11/site-packages/wandb/sdk/interface/interface.py", line 647, in publish_partial_history
    self._publish_partial_history(partial_history)
  File "/home/eirik/.cache/pypoetry/virtualenvs/xai-is73Zs3s-py3.11/lib/python3.11/site-packages/wandb/sdk/interface/interface_shared.py", line 89, in _publish_partial_history
    self._publish(rec)
  File "/home/eirik/.cache/pypoetry/virtualenvs/xai-is73Zs3s-py3.11/lib/python3.11/site-packages/wandb/sdk/interface/interface_sock.py", line 51, in _publish
    self._sock_client.send_record_publish(record)
  File "/home/eirik/.cache/pypoetry/virtualenvs/xai-is73Zs3s-py3.11/lib/python3.11/site-packages/wandb/sdk/lib/sock_client.py", line 225, in send_record_publish
    self.send_server_request(server_req)
  File "/home/eirik/.cache/pypoetry/virtualenvs/xai-is73Zs3s-py3.11/lib/python3.11/site-packages/wandb/sdk/lib/sock_client.py", line 157, in send_server_request
    self._send_message(msg)
  File "/home/eirik/.cache/pypoetry/virtualenvs/xai-is73Zs3s-py3.11/lib/python3.11/site-packages/wandb/sdk/lib/sock_client.py", line 154, in _send_message
    self._sendall_with_error_handle(header + data)
  File "/home/eirik/.cache/pypoetry/virtualenvs/xai-is73Zs3s-py3.11/lib/python3.11/site-packages/wandb/sdk/lib/sock_client.py", line 132, in _sendall_with_error_handle
    sent = self._sock.send(data)
           ^^^^^^^^^^^^^^^^^^^^^
BrokenPipeError: [Errno 32] Broken pipe

INFO: Hyperparameters: lr=0.0001, gamma=0.99, eps_start=0.9, eps_end=0.05, eps_decay=50000, batch_size=32, tau=0.005,hidden_layers=[128, 128], conv_layers=[]
INFO: Number of parameters: 30085
INFO: QNetwork(
  (conv_feature): Sequential()
  (fc_feature): Sequential(
    (0): Linear(in_features=100, out_features=128, bias=True)
    (1): ReLU()
    (2): Linear(in_features=128, out_features=128, bias=True)
    (3): ReLU()
    (4): Linear(in_features=128, out_features=5, bias=True)
  )
)
INFO: Hyperparameters: lr=0.0001, gamma=0.99, eps_start=0.9, eps_end=0.05, eps_decay=50000, batch_size=32, tau=0.005,hidden_layers=[128, 128], conv_layers=[]
INFO: Learning...
ERROR: [Errno 32] Broken pipe
ERROR: Traceback (most recent call last):
  File "/home/eirik/Projects/XAI/rl/src/dqn/wrapper/multi_agent_dqn.py", line 108, in learn
    self.wandb_manager.log(log)
  File "/home/eirik/Projects/XAI/rl/src/managers/wandb_manager.py", line 83, in log
    wandb.log(data)
  File "/home/eirik/.cache/pypoetry/virtualenvs/xai-is73Zs3s-py3.11/lib/python3.11/site-packages/wandb/sdk/wandb_run.py", line 452, in wrapper
    return func(self, *args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/eirik/.cache/pypoetry/virtualenvs/xai-is73Zs3s-py3.11/lib/python3.11/site-packages/wandb/sdk/wandb_run.py", line 403, in wrapper_fn
    return func(self, *args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/eirik/.cache/pypoetry/virtualenvs/xai-is73Zs3s-py3.11/lib/python3.11/site-packages/wandb/sdk/wandb_run.py", line 393, in wrapper
    return func(self, *args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/eirik/.cache/pypoetry/virtualenvs/xai-is73Zs3s-py3.11/lib/python3.11/site-packages/wandb/sdk/wandb_run.py", line 1933, in log
    self._log(data=data, step=step, commit=commit)
  File "/home/eirik/.cache/pypoetry/virtualenvs/xai-is73Zs3s-py3.11/lib/python3.11/site-packages/wandb/sdk/wandb_run.py", line 1652, in _log
    self._partial_history_callback(data, step, commit)
  File "/home/eirik/.cache/pypoetry/virtualenvs/xai-is73Zs3s-py3.11/lib/python3.11/site-packages/wandb/sdk/wandb_run.py", line 1524, in _partial_history_callback
    self._backend.interface.publish_partial_history(
  File "/home/eirik/.cache/pypoetry/virtualenvs/xai-is73Zs3s-py3.11/lib/python3.11/site-packages/wandb/sdk/interface/interface.py", line 647, in publish_partial_history
    self._publish_partial_history(partial_history)
  File "/home/eirik/.cache/pypoetry/virtualenvs/xai-is73Zs3s-py3.11/lib/python3.11/site-packages/wandb/sdk/interface/interface_shared.py", line 89, in _publish_partial_history
    self._publish(rec)
  File "/home/eirik/.cache/pypoetry/virtualenvs/xai-is73Zs3s-py3.11/lib/python3.11/site-packages/wandb/sdk/interface/interface_sock.py", line 51, in _publish
    self._sock_client.send_record_publish(record)
  File "/home/eirik/.cache/pypoetry/virtualenvs/xai-is73Zs3s-py3.11/lib/python3.11/site-packages/wandb/sdk/lib/sock_client.py", line 225, in send_record_publish
    self.send_server_request(server_req)
  File "/home/eirik/.cache/pypoetry/virtualenvs/xai-is73Zs3s-py3.11/lib/python3.11/site-packages/wandb/sdk/lib/sock_client.py", line 157, in send_server_request
    self._send_message(msg)
  File "/home/eirik/.cache/pypoetry/virtualenvs/xai-is73Zs3s-py3.11/lib/python3.11/site-packages/wandb/sdk/lib/sock_client.py", line 154, in _send_message
    self._sendall_with_error_handle(header + data)
  File "/home/eirik/.cache/pypoetry/virtualenvs/xai-is73Zs3s-py3.11/lib/python3.11/site-packages/wandb/sdk/lib/sock_client.py", line 132, in _sendall_with_error_handle
    sent = self._sock.send(data)
           ^^^^^^^^^^^^^^^^^^^^^
BrokenPipeError: [Errno 32] Broken pipe

INFO: Hyperparameters: lr=0.0001, gamma=0.99, eps_start=0.9, eps_end=0.05, eps_decay=50000, batch_size=32, tau=0.005,hidden_layers=[128, 128], conv_layers=[]
INFO: Number of parameters: 30085
INFO: QNetwork(
  (conv_feature): Sequential()
  (fc_feature): Sequential(
    (0): Linear(in_features=100, out_features=128, bias=True)
    (1): ReLU()
    (2): Linear(in_features=128, out_features=128, bias=True)
    (3): ReLU()
    (4): Linear(in_features=128, out_features=5, bias=True)
  )
)
INFO: Hyperparameters: lr=0.0001, gamma=0.99, eps_start=0.9, eps_end=0.05, eps_decay=50000, batch_size=32, tau=0.005,hidden_layers=[128, 128], conv_layers=[]
INFO: Learning...
ERROR: [Errno 32] Broken pipe
ERROR: Traceback (most recent call last):
  File "/home/eirik/Projects/XAI/rl/src/dqn/wrapper/multi_agent_dqn.py", line 108, in learn
    self.wandb_manager.log(log)
  File "/home/eirik/Projects/XAI/rl/src/managers/wandb_manager.py", line 84, in log
    wandb.log(data)
  File "/home/eirik/.cache/pypoetry/virtualenvs/xai-is73Zs3s-py3.11/lib/python3.11/site-packages/wandb/sdk/wandb_run.py", line 452, in wrapper
    return func(self, *args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/eirik/.cache/pypoetry/virtualenvs/xai-is73Zs3s-py3.11/lib/python3.11/site-packages/wandb/sdk/wandb_run.py", line 403, in wrapper_fn
    return func(self, *args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/eirik/.cache/pypoetry/virtualenvs/xai-is73Zs3s-py3.11/lib/python3.11/site-packages/wandb/sdk/wandb_run.py", line 393, in wrapper
    return func(self, *args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/eirik/.cache/pypoetry/virtualenvs/xai-is73Zs3s-py3.11/lib/python3.11/site-packages/wandb/sdk/wandb_run.py", line 1933, in log
    self._log(data=data, step=step, commit=commit)
  File "/home/eirik/.cache/pypoetry/virtualenvs/xai-is73Zs3s-py3.11/lib/python3.11/site-packages/wandb/sdk/wandb_run.py", line 1652, in _log
    self._partial_history_callback(data, step, commit)
  File "/home/eirik/.cache/pypoetry/virtualenvs/xai-is73Zs3s-py3.11/lib/python3.11/site-packages/wandb/sdk/wandb_run.py", line 1524, in _partial_history_callback
    self._backend.interface.publish_partial_history(
  File "/home/eirik/.cache/pypoetry/virtualenvs/xai-is73Zs3s-py3.11/lib/python3.11/site-packages/wandb/sdk/interface/interface.py", line 647, in publish_partial_history
    self._publish_partial_history(partial_history)
  File "/home/eirik/.cache/pypoetry/virtualenvs/xai-is73Zs3s-py3.11/lib/python3.11/site-packages/wandb/sdk/interface/interface_shared.py", line 89, in _publish_partial_history
    self._publish(rec)
  File "/home/eirik/.cache/pypoetry/virtualenvs/xai-is73Zs3s-py3.11/lib/python3.11/site-packages/wandb/sdk/interface/interface_sock.py", line 51, in _publish
    self._sock_client.send_record_publish(record)
  File "/home/eirik/.cache/pypoetry/virtualenvs/xai-is73Zs3s-py3.11/lib/python3.11/site-packages/wandb/sdk/lib/sock_client.py", line 225, in send_record_publish
    self.send_server_request(server_req)
  File "/home/eirik/.cache/pypoetry/virtualenvs/xai-is73Zs3s-py3.11/lib/python3.11/site-packages/wandb/sdk/lib/sock_client.py", line 157, in send_server_request
    self._send_message(msg)
  File "/home/eirik/.cache/pypoetry/virtualenvs/xai-is73Zs3s-py3.11/lib/python3.11/site-packages/wandb/sdk/lib/sock_client.py", line 154, in _send_message
    self._sendall_with_error_handle(header + data)
  File "/home/eirik/.cache/pypoetry/virtualenvs/xai-is73Zs3s-py3.11/lib/python3.11/site-packages/wandb/sdk/lib/sock_client.py", line 132, in _sendall_with_error_handle
    sent = self._sock.send(data)
           ^^^^^^^^^^^^^^^^^^^^^
BrokenPipeError: [Errno 32] Broken pipe

INFO: Hyperparameters: lr=0.0001, gamma=0.99, eps_start=0.9, eps_end=0.05, eps_decay=50000, batch_size=32, tau=0.005,hidden_layers=[128, 128], conv_layers=[]
INFO: Number of parameters: 30085
INFO: QNetwork(
  (conv_feature): Sequential()
  (fc_feature): Sequential(
    (0): Linear(in_features=100, out_features=128, bias=True)
    (1): ReLU()
    (2): Linear(in_features=128, out_features=128, bias=True)
    (3): ReLU()
    (4): Linear(in_features=128, out_features=5, bias=True)
  )
)
INFO: Hyperparameters: lr=0.0001, gamma=0.99, eps_start=0.9, eps_end=0.05, eps_decay=50000, batch_size=32, tau=0.005,hidden_layers=[128, 128], conv_layers=[]
INFO: Learning...
ERROR: [Errno 32] Broken pipe
ERROR: Traceback (most recent call last):
  File "/home/eirik/Projects/XAI/rl/src/dqn/wrapper/multi_agent_dqn.py", line 108, in learn
    self.wandb_manager.log(log)
  File "/home/eirik/Projects/XAI/rl/src/managers/wandb_manager.py", line 83, in log
    wandb.log(data)
  File "/home/eirik/.cache/pypoetry/virtualenvs/xai-is73Zs3s-py3.11/lib/python3.11/site-packages/wandb/sdk/wandb_run.py", line 452, in wrapper
    return func(self, *args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/eirik/.cache/pypoetry/virtualenvs/xai-is73Zs3s-py3.11/lib/python3.11/site-packages/wandb/sdk/wandb_run.py", line 403, in wrapper_fn
    return func(self, *args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/eirik/.cache/pypoetry/virtualenvs/xai-is73Zs3s-py3.11/lib/python3.11/site-packages/wandb/sdk/wandb_run.py", line 393, in wrapper
    return func(self, *args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/eirik/.cache/pypoetry/virtualenvs/xai-is73Zs3s-py3.11/lib/python3.11/site-packages/wandb/sdk/wandb_run.py", line 1933, in log
    self._log(data=data, step=step, commit=commit)
  File "/home/eirik/.cache/pypoetry/virtualenvs/xai-is73Zs3s-py3.11/lib/python3.11/site-packages/wandb/sdk/wandb_run.py", line 1652, in _log
    self._partial_history_callback(data, step, commit)
  File "/home/eirik/.cache/pypoetry/virtualenvs/xai-is73Zs3s-py3.11/lib/python3.11/site-packages/wandb/sdk/wandb_run.py", line 1524, in _partial_history_callback
    self._backend.interface.publish_partial_history(
  File "/home/eirik/.cache/pypoetry/virtualenvs/xai-is73Zs3s-py3.11/lib/python3.11/site-packages/wandb/sdk/interface/interface.py", line 647, in publish_partial_history
    self._publish_partial_history(partial_history)
  File "/home/eirik/.cache/pypoetry/virtualenvs/xai-is73Zs3s-py3.11/lib/python3.11/site-packages/wandb/sdk/interface/interface_shared.py", line 89, in _publish_partial_history
    self._publish(rec)
  File "/home/eirik/.cache/pypoetry/virtualenvs/xai-is73Zs3s-py3.11/lib/python3.11/site-packages/wandb/sdk/interface/interface_sock.py", line 51, in _publish
    self._sock_client.send_record_publish(record)
  File "/home/eirik/.cache/pypoetry/virtualenvs/xai-is73Zs3s-py3.11/lib/python3.11/site-packages/wandb/sdk/lib/sock_client.py", line 225, in send_record_publish
    self.send_server_request(server_req)
  File "/home/eirik/.cache/pypoetry/virtualenvs/xai-is73Zs3s-py3.11/lib/python3.11/site-packages/wandb/sdk/lib/sock_client.py", line 157, in send_server_request
    self._send_message(msg)
  File "/home/eirik/.cache/pypoetry/virtualenvs/xai-is73Zs3s-py3.11/lib/python3.11/site-packages/wandb/sdk/lib/sock_client.py", line 154, in _send_message
    self._sendall_with_error_handle(header + data)
  File "/home/eirik/.cache/pypoetry/virtualenvs/xai-is73Zs3s-py3.11/lib/python3.11/site-packages/wandb/sdk/lib/sock_client.py", line 132, in _sendall_with_error_handle
    sent = self._sock.send(data)
           ^^^^^^^^^^^^^^^^^^^^^
BrokenPipeError: [Errno 32] Broken pipe

INFO: Hyperparameters: lr=0.0001, gamma=0.99, eps_start=0.9, eps_end=0.05, eps_decay=50000, batch_size=32, tau=0.005,hidden_layers=[128, 128], conv_layers=[]
INFO: Number of parameters: 30085
INFO: QNetwork(
  (conv_feature): Sequential()
  (fc_feature): Sequential(
    (0): Linear(in_features=100, out_features=128, bias=True)
    (1): ReLU()
    (2): Linear(in_features=128, out_features=128, bias=True)
    (3): ReLU()
    (4): Linear(in_features=128, out_features=5, bias=True)
  )
)
INFO: Hyperparameters: lr=0.0001, gamma=0.99, eps_start=0.9, eps_end=0.05, eps_decay=50000, batch_size=32, tau=0.005,hidden_layers=[128, 128], conv_layers=[]
INFO: Learning...
INFO: Hyperparameters: lr=0.0001, gamma=0.99, eps_start=0.9, eps_end=0.05, eps_decay=50000, batch_size=32, tau=0.005,hidden_layers=[128, 128], conv_layers=[]
INFO: Number of parameters: 30085
INFO: QNetwork(
  (conv_feature): Sequential()
  (fc_feature): Sequential(
    (0): Linear(in_features=100, out_features=128, bias=True)
    (1): ReLU()
    (2): Linear(in_features=128, out_features=128, bias=True)
    (3): ReLU()
    (4): Linear(in_features=128, out_features=5, bias=True)
  )
)
INFO: Hyperparameters: lr=0.0001, gamma=0.99, eps_start=0.9, eps_end=0.05, eps_decay=50000, batch_size=32, tau=0.005,hidden_layers=[128, 128], conv_layers=[]
INFO: Learning...
ERROR: [Errno 32] Broken pipe
ERROR: Traceback (most recent call last):
  File "/home/eirik/Projects/XAI/rl/src/dqn/wrapper/multi_agent_dqn.py", line 108, in learn
    self.wandb_manager.log(log)
  File "/home/eirik/Projects/XAI/rl/src/managers/wandb_manager.py", line 83, in log
    wandb.log(data, commit=False)
  File "/home/eirik/.cache/pypoetry/virtualenvs/xai-is73Zs3s-py3.11/lib/python3.11/site-packages/wandb/sdk/wandb_run.py", line 452, in wrapper
    return func(self, *args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/eirik/.cache/pypoetry/virtualenvs/xai-is73Zs3s-py3.11/lib/python3.11/site-packages/wandb/sdk/wandb_run.py", line 403, in wrapper_fn
    return func(self, *args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/eirik/.cache/pypoetry/virtualenvs/xai-is73Zs3s-py3.11/lib/python3.11/site-packages/wandb/sdk/wandb_run.py", line 393, in wrapper
    return func(self, *args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/eirik/.cache/pypoetry/virtualenvs/xai-is73Zs3s-py3.11/lib/python3.11/site-packages/wandb/sdk/wandb_run.py", line 1933, in log
    self._log(data=data, step=step, commit=commit)
  File "/home/eirik/.cache/pypoetry/virtualenvs/xai-is73Zs3s-py3.11/lib/python3.11/site-packages/wandb/sdk/wandb_run.py", line 1652, in _log
    self._partial_history_callback(data, step, commit)
  File "/home/eirik/.cache/pypoetry/virtualenvs/xai-is73Zs3s-py3.11/lib/python3.11/site-packages/wandb/sdk/wandb_run.py", line 1524, in _partial_history_callback
    self._backend.interface.publish_partial_history(
  File "/home/eirik/.cache/pypoetry/virtualenvs/xai-is73Zs3s-py3.11/lib/python3.11/site-packages/wandb/sdk/interface/interface.py", line 647, in publish_partial_history
    self._publish_partial_history(partial_history)
  File "/home/eirik/.cache/pypoetry/virtualenvs/xai-is73Zs3s-py3.11/lib/python3.11/site-packages/wandb/sdk/interface/interface_shared.py", line 89, in _publish_partial_history
    self._publish(rec)
  File "/home/eirik/.cache/pypoetry/virtualenvs/xai-is73Zs3s-py3.11/lib/python3.11/site-packages/wandb/sdk/interface/interface_sock.py", line 51, in _publish
    self._sock_client.send_record_publish(record)
  File "/home/eirik/.cache/pypoetry/virtualenvs/xai-is73Zs3s-py3.11/lib/python3.11/site-packages/wandb/sdk/lib/sock_client.py", line 225, in send_record_publish
    self.send_server_request(server_req)
  File "/home/eirik/.cache/pypoetry/virtualenvs/xai-is73Zs3s-py3.11/lib/python3.11/site-packages/wandb/sdk/lib/sock_client.py", line 157, in send_server_request
    self._send_message(msg)
  File "/home/eirik/.cache/pypoetry/virtualenvs/xai-is73Zs3s-py3.11/lib/python3.11/site-packages/wandb/sdk/lib/sock_client.py", line 154, in _send_message
    self._sendall_with_error_handle(header + data)
  File "/home/eirik/.cache/pypoetry/virtualenvs/xai-is73Zs3s-py3.11/lib/python3.11/site-packages/wandb/sdk/lib/sock_client.py", line 132, in _sendall_with_error_handle
    sent = self._sock.send(data)
           ^^^^^^^^^^^^^^^^^^^^^
BrokenPipeError: [Errno 32] Broken pipe

INFO: Hyperparameters: lr=0.0001, gamma=0.99, eps_start=0.9, eps_end=0.05, eps_decay=50000, batch_size=32, tau=0.005,hidden_layers=[128, 128], conv_layers=[]
INFO: Number of parameters: 30085
INFO: QNetwork(
  (conv_feature): Sequential()
  (fc_feature): Sequential(
    (0): Linear(in_features=100, out_features=128, bias=True)
    (1): ReLU()
    (2): Linear(in_features=128, out_features=128, bias=True)
    (3): ReLU()
    (4): Linear(in_features=128, out_features=5, bias=True)
  )
)
INFO: Hyperparameters: lr=0.0001, gamma=0.99, eps_start=0.9, eps_end=0.05, eps_decay=50000, batch_size=32, tau=0.005,hidden_layers=[128, 128], conv_layers=[]
INFO: Learning...
ERROR: [Errno 32] Broken pipe
ERROR: Traceback (most recent call last):
  File "/home/eirik/Projects/XAI/rl/src/dqn/wrapper/multi_agent_dqn.py", line 109, in learn
    self.wandb_manager.log(log)
  File "/home/eirik/Projects/XAI/rl/src/managers/wandb_manager.py", line 83, in log
    wandb.log(data, commit=False)
  File "/home/eirik/.cache/pypoetry/virtualenvs/xai-is73Zs3s-py3.11/lib/python3.11/site-packages/wandb/sdk/wandb_run.py", line 452, in wrapper
    return func(self, *args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/eirik/.cache/pypoetry/virtualenvs/xai-is73Zs3s-py3.11/lib/python3.11/site-packages/wandb/sdk/wandb_run.py", line 403, in wrapper_fn
    return func(self, *args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/eirik/.cache/pypoetry/virtualenvs/xai-is73Zs3s-py3.11/lib/python3.11/site-packages/wandb/sdk/wandb_run.py", line 393, in wrapper
    return func(self, *args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/eirik/.cache/pypoetry/virtualenvs/xai-is73Zs3s-py3.11/lib/python3.11/site-packages/wandb/sdk/wandb_run.py", line 1933, in log
    self._log(data=data, step=step, commit=commit)
  File "/home/eirik/.cache/pypoetry/virtualenvs/xai-is73Zs3s-py3.11/lib/python3.11/site-packages/wandb/sdk/wandb_run.py", line 1652, in _log
    self._partial_history_callback(data, step, commit)
  File "/home/eirik/.cache/pypoetry/virtualenvs/xai-is73Zs3s-py3.11/lib/python3.11/site-packages/wandb/sdk/wandb_run.py", line 1524, in _partial_history_callback
    self._backend.interface.publish_partial_history(
  File "/home/eirik/.cache/pypoetry/virtualenvs/xai-is73Zs3s-py3.11/lib/python3.11/site-packages/wandb/sdk/interface/interface.py", line 647, in publish_partial_history
    self._publish_partial_history(partial_history)
  File "/home/eirik/.cache/pypoetry/virtualenvs/xai-is73Zs3s-py3.11/lib/python3.11/site-packages/wandb/sdk/interface/interface_shared.py", line 89, in _publish_partial_history
    self._publish(rec)
  File "/home/eirik/.cache/pypoetry/virtualenvs/xai-is73Zs3s-py3.11/lib/python3.11/site-packages/wandb/sdk/interface/interface_sock.py", line 51, in _publish
    self._sock_client.send_record_publish(record)
  File "/home/eirik/.cache/pypoetry/virtualenvs/xai-is73Zs3s-py3.11/lib/python3.11/site-packages/wandb/sdk/lib/sock_client.py", line 225, in send_record_publish
    self.send_server_request(server_req)
  File "/home/eirik/.cache/pypoetry/virtualenvs/xai-is73Zs3s-py3.11/lib/python3.11/site-packages/wandb/sdk/lib/sock_client.py", line 157, in send_server_request
    self._send_message(msg)
  File "/home/eirik/.cache/pypoetry/virtualenvs/xai-is73Zs3s-py3.11/lib/python3.11/site-packages/wandb/sdk/lib/sock_client.py", line 154, in _send_message
    self._sendall_with_error_handle(header + data)
  File "/home/eirik/.cache/pypoetry/virtualenvs/xai-is73Zs3s-py3.11/lib/python3.11/site-packages/wandb/sdk/lib/sock_client.py", line 132, in _sendall_with_error_handle
    sent = self._sock.send(data)
           ^^^^^^^^^^^^^^^^^^^^^
BrokenPipeError: [Errno 32] Broken pipe

INFO: Hyperparameters: lr=0.0001, gamma=0.99, eps_start=0.9, eps_end=0.05, eps_decay=50000, batch_size=32, tau=0.005,hidden_layers=[128, 128], conv_layers=[]
INFO: Number of parameters: 30085
INFO: QNetwork(
  (conv_feature): Sequential()
  (fc_feature): Sequential(
    (0): Linear(in_features=100, out_features=128, bias=True)
    (1): ReLU()
    (2): Linear(in_features=128, out_features=128, bias=True)
    (3): ReLU()
    (4): Linear(in_features=128, out_features=5, bias=True)
  )
)
INFO: Hyperparameters: lr=0.0001, gamma=0.99, eps_start=0.9, eps_end=0.05, eps_decay=50000, batch_size=32, tau=0.005,hidden_layers=[128, 128], conv_layers=[]
INFO: Learning...
ERROR: [Errno 32] Broken pipe
ERROR: Traceback (most recent call last):
  File "/home/eirik/Projects/XAI/rl/src/dqn/wrapper/multi_agent_dqn.py", line 109, in learn
    self.wandb_manager.log(log)
  File "/home/eirik/Projects/XAI/rl/src/managers/wandb_manager.py", line 83, in log
    wandb.log(data, commit=False)
  File "/home/eirik/.cache/pypoetry/virtualenvs/xai-is73Zs3s-py3.11/lib/python3.11/site-packages/wandb/sdk/wandb_run.py", line 452, in wrapper
    return func(self, *args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/eirik/.cache/pypoetry/virtualenvs/xai-is73Zs3s-py3.11/lib/python3.11/site-packages/wandb/sdk/wandb_run.py", line 403, in wrapper_fn
    return func(self, *args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/eirik/.cache/pypoetry/virtualenvs/xai-is73Zs3s-py3.11/lib/python3.11/site-packages/wandb/sdk/wandb_run.py", line 393, in wrapper
    return func(self, *args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/eirik/.cache/pypoetry/virtualenvs/xai-is73Zs3s-py3.11/lib/python3.11/site-packages/wandb/sdk/wandb_run.py", line 1933, in log
    self._log(data=data, step=step, commit=commit)
  File "/home/eirik/.cache/pypoetry/virtualenvs/xai-is73Zs3s-py3.11/lib/python3.11/site-packages/wandb/sdk/wandb_run.py", line 1652, in _log
    self._partial_history_callback(data, step, commit)
  File "/home/eirik/.cache/pypoetry/virtualenvs/xai-is73Zs3s-py3.11/lib/python3.11/site-packages/wandb/sdk/wandb_run.py", line 1524, in _partial_history_callback
    self._backend.interface.publish_partial_history(
  File "/home/eirik/.cache/pypoetry/virtualenvs/xai-is73Zs3s-py3.11/lib/python3.11/site-packages/wandb/sdk/interface/interface.py", line 647, in publish_partial_history
    self._publish_partial_history(partial_history)
  File "/home/eirik/.cache/pypoetry/virtualenvs/xai-is73Zs3s-py3.11/lib/python3.11/site-packages/wandb/sdk/interface/interface_shared.py", line 89, in _publish_partial_history
    self._publish(rec)
  File "/home/eirik/.cache/pypoetry/virtualenvs/xai-is73Zs3s-py3.11/lib/python3.11/site-packages/wandb/sdk/interface/interface_sock.py", line 51, in _publish
    self._sock_client.send_record_publish(record)
  File "/home/eirik/.cache/pypoetry/virtualenvs/xai-is73Zs3s-py3.11/lib/python3.11/site-packages/wandb/sdk/lib/sock_client.py", line 225, in send_record_publish
    self.send_server_request(server_req)
  File "/home/eirik/.cache/pypoetry/virtualenvs/xai-is73Zs3s-py3.11/lib/python3.11/site-packages/wandb/sdk/lib/sock_client.py", line 157, in send_server_request
    self._send_message(msg)
  File "/home/eirik/.cache/pypoetry/virtualenvs/xai-is73Zs3s-py3.11/lib/python3.11/site-packages/wandb/sdk/lib/sock_client.py", line 154, in _send_message
    self._sendall_with_error_handle(header + data)
  File "/home/eirik/.cache/pypoetry/virtualenvs/xai-is73Zs3s-py3.11/lib/python3.11/site-packages/wandb/sdk/lib/sock_client.py", line 132, in _sendall_with_error_handle
    sent = self._sock.send(data)
           ^^^^^^^^^^^^^^^^^^^^^
BrokenPipeError: [Errno 32] Broken pipe

INFO: Hyperparameters: lr=0.0001, gamma=0.99, eps_start=0.9, eps_end=0.05, eps_decay=50000, batch_size=32, tau=0.005,hidden_layers=[128, 128], conv_layers=[]
INFO: Number of parameters: 30085
INFO: QNetwork(
  (conv_feature): Sequential()
  (fc_feature): Sequential(
    (0): Linear(in_features=100, out_features=128, bias=True)
    (1): ReLU()
    (2): Linear(in_features=128, out_features=128, bias=True)
    (3): ReLU()
    (4): Linear(in_features=128, out_features=5, bias=True)
  )
)
INFO: Hyperparameters: lr=0.0001, gamma=0.99, eps_start=0.9, eps_end=0.05, eps_decay=50000, batch_size=32, tau=0.005,hidden_layers=[128, 128], conv_layers=[]
INFO: Learning...
ERROR: [Errno 32] Broken pipe
ERROR: Traceback (most recent call last):
  File "/home/eirik/Projects/XAI/rl/src/dqn/wrapper/multi_agent_dqn.py", line 109, in learn
    self.wandb_manager.log(log)
  File "/home/eirik/Projects/XAI/rl/src/managers/wandb_manager.py", line 83, in log
    wandb.log(data, commit=False)
  File "/home/eirik/.cache/pypoetry/virtualenvs/xai-is73Zs3s-py3.11/lib/python3.11/site-packages/wandb/sdk/wandb_run.py", line 452, in wrapper
    return func(self, *args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/eirik/.cache/pypoetry/virtualenvs/xai-is73Zs3s-py3.11/lib/python3.11/site-packages/wandb/sdk/wandb_run.py", line 403, in wrapper_fn
    return func(self, *args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/eirik/.cache/pypoetry/virtualenvs/xai-is73Zs3s-py3.11/lib/python3.11/site-packages/wandb/sdk/wandb_run.py", line 393, in wrapper
    return func(self, *args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/eirik/.cache/pypoetry/virtualenvs/xai-is73Zs3s-py3.11/lib/python3.11/site-packages/wandb/sdk/wandb_run.py", line 1933, in log
    self._log(data=data, step=step, commit=commit)
  File "/home/eirik/.cache/pypoetry/virtualenvs/xai-is73Zs3s-py3.11/lib/python3.11/site-packages/wandb/sdk/wandb_run.py", line 1652, in _log
    self._partial_history_callback(data, step, commit)
  File "/home/eirik/.cache/pypoetry/virtualenvs/xai-is73Zs3s-py3.11/lib/python3.11/site-packages/wandb/sdk/wandb_run.py", line 1524, in _partial_history_callback
    self._backend.interface.publish_partial_history(
  File "/home/eirik/.cache/pypoetry/virtualenvs/xai-is73Zs3s-py3.11/lib/python3.11/site-packages/wandb/sdk/interface/interface.py", line 647, in publish_partial_history
    self._publish_partial_history(partial_history)
  File "/home/eirik/.cache/pypoetry/virtualenvs/xai-is73Zs3s-py3.11/lib/python3.11/site-packages/wandb/sdk/interface/interface_shared.py", line 89, in _publish_partial_history
    self._publish(rec)
  File "/home/eirik/.cache/pypoetry/virtualenvs/xai-is73Zs3s-py3.11/lib/python3.11/site-packages/wandb/sdk/interface/interface_sock.py", line 51, in _publish
    self._sock_client.send_record_publish(record)
  File "/home/eirik/.cache/pypoetry/virtualenvs/xai-is73Zs3s-py3.11/lib/python3.11/site-packages/wandb/sdk/lib/sock_client.py", line 225, in send_record_publish
    self.send_server_request(server_req)
  File "/home/eirik/.cache/pypoetry/virtualenvs/xai-is73Zs3s-py3.11/lib/python3.11/site-packages/wandb/sdk/lib/sock_client.py", line 157, in send_server_request
    self._send_message(msg)
  File "/home/eirik/.cache/pypoetry/virtualenvs/xai-is73Zs3s-py3.11/lib/python3.11/site-packages/wandb/sdk/lib/sock_client.py", line 154, in _send_message
    self._sendall_with_error_handle(header + data)
  File "/home/eirik/.cache/pypoetry/virtualenvs/xai-is73Zs3s-py3.11/lib/python3.11/site-packages/wandb/sdk/lib/sock_client.py", line 132, in _sendall_with_error_handle
    sent = self._sock.send(data)
           ^^^^^^^^^^^^^^^^^^^^^
BrokenPipeError: [Errno 32] Broken pipe

INFO: Hyperparameters: lr=0.0001, gamma=0.99, eps_start=0.9, eps_end=0.05, eps_decay=50000, batch_size=32, tau=0.005,hidden_layers=[128, 128], conv_layers=[]
INFO: Number of parameters: 30085
INFO: QNetwork(
  (conv_feature): Sequential()
  (fc_feature): Sequential(
    (0): Linear(in_features=100, out_features=128, bias=True)
    (1): ReLU()
    (2): Linear(in_features=128, out_features=128, bias=True)
    (3): ReLU()
    (4): Linear(in_features=128, out_features=5, bias=True)
  )
)
INFO: Hyperparameters: lr=0.0001, gamma=0.99, eps_start=0.9, eps_end=0.05, eps_decay=50000, batch_size=32, tau=0.005,hidden_layers=[128, 128], conv_layers=[]
INFO: Learning...
INFO: Hyperparameters: lr=0.0001, gamma=0.99, eps_start=0.9, eps_end=0.05, eps_decay=50000, batch_size=32, tau=0.005,hidden_layers=[128, 128], conv_layers=[]
INFO: Number of parameters: 30085
INFO: QNetwork(
  (conv_feature): Sequential()
  (fc_feature): Sequential(
    (0): Linear(in_features=100, out_features=128, bias=True)
    (1): ReLU()
    (2): Linear(in_features=128, out_features=128, bias=True)
    (3): ReLU()
    (4): Linear(in_features=128, out_features=5, bias=True)
  )
)
INFO: Hyperparameters: lr=0.0001, gamma=0.99, eps_start=0.9, eps_end=0.05, eps_decay=50000, batch_size=32, tau=0.005,hidden_layers=[128, 128], conv_layers=[]
INFO: Learning...
INFO: Hyperparameters: lr=0.0001, gamma=0.99, eps_start=0.9, eps_end=0.05, eps_decay=50000, batch_size=32, tau=0.005,hidden_layers=[128, 128], conv_layers=[]
INFO: Number of parameters: 30085
INFO: QNetwork(
  (conv_feature): Sequential()
  (fc_feature): Sequential(
    (0): Linear(in_features=100, out_features=128, bias=True)
    (1): ReLU()
    (2): Linear(in_features=128, out_features=128, bias=True)
    (3): ReLU()
    (4): Linear(in_features=128, out_features=5, bias=True)
  )
)
INFO: Hyperparameters: lr=0.0001, gamma=0.99, eps_start=0.9, eps_end=0.05, eps_decay=50000, batch_size=32, tau=0.005,hidden_layers=[128, 128], conv_layers=[]
INFO: Learning...
ERROR: [Errno 32] Broken pipe
ERROR: Traceback (most recent call last):
  File "/home/eirik/Projects/XAI/rl/src/dqn/wrapper/multi_agent_dqn.py", line 109, in learn
    self.wandb_manager.log(log)
  File "/home/eirik/Projects/XAI/rl/src/managers/wandb_manager.py", line 84, in log
    wandb.log(data, commit=False)
  File "/home/eirik/.cache/pypoetry/virtualenvs/xai-is73Zs3s-py3.11/lib/python3.11/site-packages/wandb/sdk/wandb_run.py", line 452, in wrapper
    return func(self, *args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/eirik/.cache/pypoetry/virtualenvs/xai-is73Zs3s-py3.11/lib/python3.11/site-packages/wandb/sdk/wandb_run.py", line 403, in wrapper_fn
    return func(self, *args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/eirik/.cache/pypoetry/virtualenvs/xai-is73Zs3s-py3.11/lib/python3.11/site-packages/wandb/sdk/wandb_run.py", line 393, in wrapper
    return func(self, *args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/eirik/.cache/pypoetry/virtualenvs/xai-is73Zs3s-py3.11/lib/python3.11/site-packages/wandb/sdk/wandb_run.py", line 1933, in log
    self._log(data=data, step=step, commit=commit)
  File "/home/eirik/.cache/pypoetry/virtualenvs/xai-is73Zs3s-py3.11/lib/python3.11/site-packages/wandb/sdk/wandb_run.py", line 1652, in _log
    self._partial_history_callback(data, step, commit)
  File "/home/eirik/.cache/pypoetry/virtualenvs/xai-is73Zs3s-py3.11/lib/python3.11/site-packages/wandb/sdk/wandb_run.py", line 1524, in _partial_history_callback
    self._backend.interface.publish_partial_history(
  File "/home/eirik/.cache/pypoetry/virtualenvs/xai-is73Zs3s-py3.11/lib/python3.11/site-packages/wandb/sdk/interface/interface.py", line 647, in publish_partial_history
    self._publish_partial_history(partial_history)
  File "/home/eirik/.cache/pypoetry/virtualenvs/xai-is73Zs3s-py3.11/lib/python3.11/site-packages/wandb/sdk/interface/interface_shared.py", line 89, in _publish_partial_history
    self._publish(rec)
  File "/home/eirik/.cache/pypoetry/virtualenvs/xai-is73Zs3s-py3.11/lib/python3.11/site-packages/wandb/sdk/interface/interface_sock.py", line 51, in _publish
    self._sock_client.send_record_publish(record)
  File "/home/eirik/.cache/pypoetry/virtualenvs/xai-is73Zs3s-py3.11/lib/python3.11/site-packages/wandb/sdk/lib/sock_client.py", line 225, in send_record_publish
    self.send_server_request(server_req)
  File "/home/eirik/.cache/pypoetry/virtualenvs/xai-is73Zs3s-py3.11/lib/python3.11/site-packages/wandb/sdk/lib/sock_client.py", line 157, in send_server_request
    self._send_message(msg)
  File "/home/eirik/.cache/pypoetry/virtualenvs/xai-is73Zs3s-py3.11/lib/python3.11/site-packages/wandb/sdk/lib/sock_client.py", line 154, in _send_message
    self._sendall_with_error_handle(header + data)
  File "/home/eirik/.cache/pypoetry/virtualenvs/xai-is73Zs3s-py3.11/lib/python3.11/site-packages/wandb/sdk/lib/sock_client.py", line 132, in _sendall_with_error_handle
    sent = self._sock.send(data)
           ^^^^^^^^^^^^^^^^^^^^^
BrokenPipeError: [Errno 32] Broken pipe

INFO: Hyperparameters: lr=0.0001, gamma=0.99, eps_start=0.9, eps_end=0.05, eps_decay=50000, batch_size=32, tau=0.005,hidden_layers=[128, 128], conv_layers=[]
INFO: Number of parameters: 18052
INFO: QNetwork(
  (conv_feature): Sequential()
  (fc_feature): Sequential(
    (0): Linear(in_features=7, out_features=128, bias=True)
    (1): ReLU()
    (2): Linear(in_features=128, out_features=128, bias=True)
    (3): ReLU()
    (4): Linear(in_features=128, out_features=4, bias=True)
  )
)
ERROR: Error: Could not load model with artifact: eirikreiestad-ntnu/maze-v0-local/model_200:latest
ERROR: Error: artifact 'model_200:latest' not found in 'eirikreiestad-ntnu/maze-v0-local'
INFO: Complete
INFO: Hyperparameters: lr=0.0001, gamma=0.99, eps_start=0.9, eps_end=0.05, eps_decay=50000, batch_size=32, tau=0.005,hidden_layers=[128, 128], conv_layers=[]
INFO: Number of parameters: 30085
INFO: QNetwork(
  (conv_feature): Sequential()
  (fc_feature): Sequential(
    (0): Linear(in_features=100, out_features=128, bias=True)
    (1): ReLU()
    (2): Linear(in_features=128, out_features=128, bias=True)
    (3): ReLU()
    (4): Linear(in_features=128, out_features=5, bias=True)
  )
)
INFO: Hyperparameters: lr=0.0001, gamma=0.99, eps_start=0.9, eps_end=0.05, eps_decay=50000, batch_size=32, tau=0.005,hidden_layers=[128, 128], conv_layers=[]
INFO: Learning...
ERROR: [Errno 32] Broken pipe
ERROR: Traceback (most recent call last):
  File "/home/eirik/Projects/XAI/rl/src/dqn/wrapper/multi_agent_dqn.py", line 109, in learn
    self.wandb_manager.log(log)
  File "/home/eirik/Projects/XAI/rl/src/managers/wandb_manager.py", line 84, in log
    wandb.log(data, commit=False)
  File "/home/eirik/.cache/pypoetry/virtualenvs/xai-is73Zs3s-py3.11/lib/python3.11/site-packages/wandb/sdk/wandb_run.py", line 452, in wrapper
    return func(self, *args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/eirik/.cache/pypoetry/virtualenvs/xai-is73Zs3s-py3.11/lib/python3.11/site-packages/wandb/sdk/wandb_run.py", line 403, in wrapper_fn
    return func(self, *args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/eirik/.cache/pypoetry/virtualenvs/xai-is73Zs3s-py3.11/lib/python3.11/site-packages/wandb/sdk/wandb_run.py", line 393, in wrapper
    return func(self, *args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/eirik/.cache/pypoetry/virtualenvs/xai-is73Zs3s-py3.11/lib/python3.11/site-packages/wandb/sdk/wandb_run.py", line 1933, in log
    self._log(data=data, step=step, commit=commit)
  File "/home/eirik/.cache/pypoetry/virtualenvs/xai-is73Zs3s-py3.11/lib/python3.11/site-packages/wandb/sdk/wandb_run.py", line 1652, in _log
    self._partial_history_callback(data, step, commit)
  File "/home/eirik/.cache/pypoetry/virtualenvs/xai-is73Zs3s-py3.11/lib/python3.11/site-packages/wandb/sdk/wandb_run.py", line 1524, in _partial_history_callback
    self._backend.interface.publish_partial_history(
  File "/home/eirik/.cache/pypoetry/virtualenvs/xai-is73Zs3s-py3.11/lib/python3.11/site-packages/wandb/sdk/interface/interface.py", line 647, in publish_partial_history
    self._publish_partial_history(partial_history)
  File "/home/eirik/.cache/pypoetry/virtualenvs/xai-is73Zs3s-py3.11/lib/python3.11/site-packages/wandb/sdk/interface/interface_shared.py", line 89, in _publish_partial_history
    self._publish(rec)
  File "/home/eirik/.cache/pypoetry/virtualenvs/xai-is73Zs3s-py3.11/lib/python3.11/site-packages/wandb/sdk/interface/interface_sock.py", line 51, in _publish
    self._sock_client.send_record_publish(record)
  File "/home/eirik/.cache/pypoetry/virtualenvs/xai-is73Zs3s-py3.11/lib/python3.11/site-packages/wandb/sdk/lib/sock_client.py", line 225, in send_record_publish
    self.send_server_request(server_req)
  File "/home/eirik/.cache/pypoetry/virtualenvs/xai-is73Zs3s-py3.11/lib/python3.11/site-packages/wandb/sdk/lib/sock_client.py", line 157, in send_server_request
    self._send_message(msg)
  File "/home/eirik/.cache/pypoetry/virtualenvs/xai-is73Zs3s-py3.11/lib/python3.11/site-packages/wandb/sdk/lib/sock_client.py", line 154, in _send_message
    self._sendall_with_error_handle(header + data)
  File "/home/eirik/.cache/pypoetry/virtualenvs/xai-is73Zs3s-py3.11/lib/python3.11/site-packages/wandb/sdk/lib/sock_client.py", line 132, in _sendall_with_error_handle
    sent = self._sock.send(data)
           ^^^^^^^^^^^^^^^^^^^^^
BrokenPipeError: [Errno 32] Broken pipe

INFO: Hyperparameters: lr=0.0001, gamma=0.99, eps_start=0.9, eps_end=0.05, eps_decay=50000, batch_size=32, tau=0.005,hidden_layers=[128, 128], conv_layers=[]
INFO: Number of parameters: 30085
INFO: QNetwork(
  (conv_feature): Sequential()
  (fc_feature): Sequential(
    (0): Linear(in_features=100, out_features=128, bias=True)
    (1): ReLU()
    (2): Linear(in_features=128, out_features=128, bias=True)
    (3): ReLU()
    (4): Linear(in_features=128, out_features=5, bias=True)
  )
)
INFO: Hyperparameters: lr=0.0001, gamma=0.99, eps_start=0.9, eps_end=0.05, eps_decay=50000, batch_size=32, tau=0.005,hidden_layers=[128, 128], conv_layers=[]
INFO: Learning...
INFO: Hyperparameters: lr=0.0001, gamma=0.99, eps_start=0.9, eps_end=0.05, eps_decay=50000, batch_size=32, tau=0.005,hidden_layers=[128, 128], conv_layers=[]
INFO: Number of parameters: 30085
INFO: QNetwork(
  (conv_feature): Sequential()
  (fc_feature): Sequential(
    (0): Linear(in_features=100, out_features=128, bias=True)
    (1): ReLU()
    (2): Linear(in_features=128, out_features=128, bias=True)
    (3): ReLU()
    (4): Linear(in_features=128, out_features=5, bias=True)
  )
)
INFO: Hyperparameters: lr=0.0001, gamma=0.99, eps_start=0.9, eps_end=0.05, eps_decay=50000, batch_size=32, tau=0.005,hidden_layers=[128, 128], conv_layers=[]
INFO: Learning...
ERROR: [Errno 32] Broken pipe
ERROR: Traceback (most recent call last):
  File "/home/eirik/Projects/XAI/rl/src/dqn/wrapper/multi_agent_dqn.py", line 111, in learn
    self.wandb_manager.log(log)
  File "/home/eirik/Projects/XAI/rl/src/managers/wandb_manager.py", line 84, in log
    wandb.log(data, commit=False)
  File "/home/eirik/.cache/pypoetry/virtualenvs/xai-is73Zs3s-py3.11/lib/python3.11/site-packages/wandb/sdk/wandb_run.py", line 452, in wrapper
    return func(self, *args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/eirik/.cache/pypoetry/virtualenvs/xai-is73Zs3s-py3.11/lib/python3.11/site-packages/wandb/sdk/wandb_run.py", line 403, in wrapper_fn
    return func(self, *args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/eirik/.cache/pypoetry/virtualenvs/xai-is73Zs3s-py3.11/lib/python3.11/site-packages/wandb/sdk/wandb_run.py", line 393, in wrapper
    return func(self, *args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/eirik/.cache/pypoetry/virtualenvs/xai-is73Zs3s-py3.11/lib/python3.11/site-packages/wandb/sdk/wandb_run.py", line 1933, in log
    self._log(data=data, step=step, commit=commit)
  File "/home/eirik/.cache/pypoetry/virtualenvs/xai-is73Zs3s-py3.11/lib/python3.11/site-packages/wandb/sdk/wandb_run.py", line 1652, in _log
    self._partial_history_callback(data, step, commit)
  File "/home/eirik/.cache/pypoetry/virtualenvs/xai-is73Zs3s-py3.11/lib/python3.11/site-packages/wandb/sdk/wandb_run.py", line 1524, in _partial_history_callback
    self._backend.interface.publish_partial_history(
  File "/home/eirik/.cache/pypoetry/virtualenvs/xai-is73Zs3s-py3.11/lib/python3.11/site-packages/wandb/sdk/interface/interface.py", line 647, in publish_partial_history
    self._publish_partial_history(partial_history)
  File "/home/eirik/.cache/pypoetry/virtualenvs/xai-is73Zs3s-py3.11/lib/python3.11/site-packages/wandb/sdk/interface/interface_shared.py", line 89, in _publish_partial_history
    self._publish(rec)
  File "/home/eirik/.cache/pypoetry/virtualenvs/xai-is73Zs3s-py3.11/lib/python3.11/site-packages/wandb/sdk/interface/interface_sock.py", line 51, in _publish
    self._sock_client.send_record_publish(record)
  File "/home/eirik/.cache/pypoetry/virtualenvs/xai-is73Zs3s-py3.11/lib/python3.11/site-packages/wandb/sdk/lib/sock_client.py", line 225, in send_record_publish
    self.send_server_request(server_req)
  File "/home/eirik/.cache/pypoetry/virtualenvs/xai-is73Zs3s-py3.11/lib/python3.11/site-packages/wandb/sdk/lib/sock_client.py", line 157, in send_server_request
    self._send_message(msg)
  File "/home/eirik/.cache/pypoetry/virtualenvs/xai-is73Zs3s-py3.11/lib/python3.11/site-packages/wandb/sdk/lib/sock_client.py", line 154, in _send_message
    self._sendall_with_error_handle(header + data)
  File "/home/eirik/.cache/pypoetry/virtualenvs/xai-is73Zs3s-py3.11/lib/python3.11/site-packages/wandb/sdk/lib/sock_client.py", line 132, in _sendall_with_error_handle
    sent = self._sock.send(data)
           ^^^^^^^^^^^^^^^^^^^^^
BrokenPipeError: [Errno 32] Broken pipe

INFO: Hyperparameters: lr=0.0001, gamma=0.99, eps_start=0.9, eps_end=0.05, eps_decay=50000, batch_size=32, tau=0.005,hidden_layers=[128, 128], conv_layers=[]
INFO: Number of parameters: 30085
INFO: QNetwork(
  (conv_feature): Sequential()
  (fc_feature): Sequential(
    (0): Linear(in_features=100, out_features=128, bias=True)
    (1): ReLU()
    (2): Linear(in_features=128, out_features=128, bias=True)
    (3): ReLU()
    (4): Linear(in_features=128, out_features=5, bias=True)
  )
)
INFO: Hyperparameters: lr=0.0001, gamma=0.99, eps_start=0.9, eps_end=0.05, eps_decay=50000, batch_size=32, tau=0.005,hidden_layers=[128, 128], conv_layers=[]
INFO: Learning...
ERROR: [Errno 32] Broken pipe
ERROR: Traceback (most recent call last):
  File "/home/eirik/Projects/XAI/rl/src/dqn/wrapper/multi_agent_dqn.py", line 108, in learn
    self.wandb_manager.log(log)
  File "/home/eirik/Projects/XAI/rl/src/managers/wandb_manager.py", line 85, in log
    wandb.log(data, commit=False)
  File "/home/eirik/.cache/pypoetry/virtualenvs/xai-is73Zs3s-py3.11/lib/python3.11/site-packages/wandb/sdk/wandb_run.py", line 452, in wrapper
    return func(self, *args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/eirik/.cache/pypoetry/virtualenvs/xai-is73Zs3s-py3.11/lib/python3.11/site-packages/wandb/sdk/wandb_run.py", line 403, in wrapper_fn
    return func(self, *args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/eirik/.cache/pypoetry/virtualenvs/xai-is73Zs3s-py3.11/lib/python3.11/site-packages/wandb/sdk/wandb_run.py", line 393, in wrapper
    return func(self, *args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/eirik/.cache/pypoetry/virtualenvs/xai-is73Zs3s-py3.11/lib/python3.11/site-packages/wandb/sdk/wandb_run.py", line 1933, in log
    self._log(data=data, step=step, commit=commit)
  File "/home/eirik/.cache/pypoetry/virtualenvs/xai-is73Zs3s-py3.11/lib/python3.11/site-packages/wandb/sdk/wandb_run.py", line 1652, in _log
    self._partial_history_callback(data, step, commit)
  File "/home/eirik/.cache/pypoetry/virtualenvs/xai-is73Zs3s-py3.11/lib/python3.11/site-packages/wandb/sdk/wandb_run.py", line 1524, in _partial_history_callback
    self._backend.interface.publish_partial_history(
  File "/home/eirik/.cache/pypoetry/virtualenvs/xai-is73Zs3s-py3.11/lib/python3.11/site-packages/wandb/sdk/interface/interface.py", line 647, in publish_partial_history
    self._publish_partial_history(partial_history)
  File "/home/eirik/.cache/pypoetry/virtualenvs/xai-is73Zs3s-py3.11/lib/python3.11/site-packages/wandb/sdk/interface/interface_shared.py", line 89, in _publish_partial_history
    self._publish(rec)
  File "/home/eirik/.cache/pypoetry/virtualenvs/xai-is73Zs3s-py3.11/lib/python3.11/site-packages/wandb/sdk/interface/interface_sock.py", line 51, in _publish
    self._sock_client.send_record_publish(record)
  File "/home/eirik/.cache/pypoetry/virtualenvs/xai-is73Zs3s-py3.11/lib/python3.11/site-packages/wandb/sdk/lib/sock_client.py", line 225, in send_record_publish
    self.send_server_request(server_req)
  File "/home/eirik/.cache/pypoetry/virtualenvs/xai-is73Zs3s-py3.11/lib/python3.11/site-packages/wandb/sdk/lib/sock_client.py", line 157, in send_server_request
    self._send_message(msg)
  File "/home/eirik/.cache/pypoetry/virtualenvs/xai-is73Zs3s-py3.11/lib/python3.11/site-packages/wandb/sdk/lib/sock_client.py", line 154, in _send_message
    self._sendall_with_error_handle(header + data)
  File "/home/eirik/.cache/pypoetry/virtualenvs/xai-is73Zs3s-py3.11/lib/python3.11/site-packages/wandb/sdk/lib/sock_client.py", line 132, in _sendall_with_error_handle
    sent = self._sock.send(data)
           ^^^^^^^^^^^^^^^^^^^^^
BrokenPipeError: [Errno 32] Broken pipe

INFO: Hyperparameters: lr=0.0001, gamma=0.99, eps_start=0.9, eps_end=0.05, eps_decay=50000, batch_size=32, tau=0.005,hidden_layers=[128, 128], conv_layers=[]
INFO: Number of parameters: 30085
INFO: QNetwork(
  (conv_feature): Sequential()
  (fc_feature): Sequential(
    (0): Linear(in_features=100, out_features=128, bias=True)
    (1): ReLU()
    (2): Linear(in_features=128, out_features=128, bias=True)
    (3): ReLU()
    (4): Linear(in_features=128, out_features=5, bias=True)
  )
)
INFO: Hyperparameters: lr=0.0001, gamma=0.99, eps_start=0.9, eps_end=0.05, eps_decay=50000, batch_size=32, tau=0.005,hidden_layers=[128, 128], conv_layers=[]
INFO: Learning...
ERROR: [Errno 32] Broken pipe
ERROR: Traceback (most recent call last):
  File "/home/eirik/Projects/XAI/rl/src/dqn/wrapper/multi_agent_dqn.py", line 108, in learn
    self.wandb_manager.log(log)
  File "/home/eirik/Projects/XAI/rl/src/managers/wandb_manager.py", line 89, in log
    wandb.log(data, commit=False)
  File "/home/eirik/.cache/pypoetry/virtualenvs/xai-is73Zs3s-py3.11/lib/python3.11/site-packages/wandb/sdk/wandb_run.py", line 452, in wrapper
    return func(self, *args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/eirik/.cache/pypoetry/virtualenvs/xai-is73Zs3s-py3.11/lib/python3.11/site-packages/wandb/sdk/wandb_run.py", line 403, in wrapper_fn
    return func(self, *args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/eirik/.cache/pypoetry/virtualenvs/xai-is73Zs3s-py3.11/lib/python3.11/site-packages/wandb/sdk/wandb_run.py", line 393, in wrapper
    return func(self, *args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/eirik/.cache/pypoetry/virtualenvs/xai-is73Zs3s-py3.11/lib/python3.11/site-packages/wandb/sdk/wandb_run.py", line 1933, in log
    self._log(data=data, step=step, commit=commit)
  File "/home/eirik/.cache/pypoetry/virtualenvs/xai-is73Zs3s-py3.11/lib/python3.11/site-packages/wandb/sdk/wandb_run.py", line 1652, in _log
    self._partial_history_callback(data, step, commit)
  File "/home/eirik/.cache/pypoetry/virtualenvs/xai-is73Zs3s-py3.11/lib/python3.11/site-packages/wandb/sdk/wandb_run.py", line 1524, in _partial_history_callback
    self._backend.interface.publish_partial_history(
  File "/home/eirik/.cache/pypoetry/virtualenvs/xai-is73Zs3s-py3.11/lib/python3.11/site-packages/wandb/sdk/interface/interface.py", line 647, in publish_partial_history
    self._publish_partial_history(partial_history)
  File "/home/eirik/.cache/pypoetry/virtualenvs/xai-is73Zs3s-py3.11/lib/python3.11/site-packages/wandb/sdk/interface/interface_shared.py", line 89, in _publish_partial_history
    self._publish(rec)
  File "/home/eirik/.cache/pypoetry/virtualenvs/xai-is73Zs3s-py3.11/lib/python3.11/site-packages/wandb/sdk/interface/interface_sock.py", line 51, in _publish
    self._sock_client.send_record_publish(record)
  File "/home/eirik/.cache/pypoetry/virtualenvs/xai-is73Zs3s-py3.11/lib/python3.11/site-packages/wandb/sdk/lib/sock_client.py", line 225, in send_record_publish
    self.send_server_request(server_req)
  File "/home/eirik/.cache/pypoetry/virtualenvs/xai-is73Zs3s-py3.11/lib/python3.11/site-packages/wandb/sdk/lib/sock_client.py", line 157, in send_server_request
    self._send_message(msg)
  File "/home/eirik/.cache/pypoetry/virtualenvs/xai-is73Zs3s-py3.11/lib/python3.11/site-packages/wandb/sdk/lib/sock_client.py", line 154, in _send_message
    self._sendall_with_error_handle(header + data)
  File "/home/eirik/.cache/pypoetry/virtualenvs/xai-is73Zs3s-py3.11/lib/python3.11/site-packages/wandb/sdk/lib/sock_client.py", line 132, in _sendall_with_error_handle
    sent = self._sock.send(data)
           ^^^^^^^^^^^^^^^^^^^^^
BrokenPipeError: [Errno 32] Broken pipe

INFO: Hyperparameters: lr=0.0001, gamma=0.99, eps_start=0.9, eps_end=0.05, eps_decay=50000, batch_size=32, tau=0.005,hidden_layers=[128, 128], conv_layers=[]
INFO: Number of parameters: 30085
INFO: QNetwork(
  (conv_feature): Sequential()
  (fc_feature): Sequential(
    (0): Linear(in_features=100, out_features=128, bias=True)
    (1): ReLU()
    (2): Linear(in_features=128, out_features=128, bias=True)
    (3): ReLU()
    (4): Linear(in_features=128, out_features=5, bias=True)
  )
)
INFO: Hyperparameters: lr=0.0001, gamma=0.99, eps_start=0.9, eps_end=0.05, eps_decay=50000, batch_size=32, tau=0.005,hidden_layers=[128, 128], conv_layers=[]
INFO: Learning...
ERROR: [Errno 32] Broken pipe
ERROR: Traceback (most recent call last):
  File "/home/eirik/Projects/XAI/rl/src/dqn/wrapper/multi_agent_dqn.py", line 108, in learn
    self.wandb_manager.log(log)
  File "/home/eirik/Projects/XAI/rl/src/managers/wandb_manager.py", line 90, in log
    wandb.log(data, commit=False)
  File "/home/eirik/.cache/pypoetry/virtualenvs/xai-is73Zs3s-py3.11/lib/python3.11/site-packages/wandb/sdk/wandb_run.py", line 452, in wrapper
    return func(self, *args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/eirik/.cache/pypoetry/virtualenvs/xai-is73Zs3s-py3.11/lib/python3.11/site-packages/wandb/sdk/wandb_run.py", line 403, in wrapper_fn
    return func(self, *args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/eirik/.cache/pypoetry/virtualenvs/xai-is73Zs3s-py3.11/lib/python3.11/site-packages/wandb/sdk/wandb_run.py", line 393, in wrapper
    return func(self, *args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/eirik/.cache/pypoetry/virtualenvs/xai-is73Zs3s-py3.11/lib/python3.11/site-packages/wandb/sdk/wandb_run.py", line 1933, in log
    self._log(data=data, step=step, commit=commit)
  File "/home/eirik/.cache/pypoetry/virtualenvs/xai-is73Zs3s-py3.11/lib/python3.11/site-packages/wandb/sdk/wandb_run.py", line 1652, in _log
    self._partial_history_callback(data, step, commit)
  File "/home/eirik/.cache/pypoetry/virtualenvs/xai-is73Zs3s-py3.11/lib/python3.11/site-packages/wandb/sdk/wandb_run.py", line 1524, in _partial_history_callback
    self._backend.interface.publish_partial_history(
  File "/home/eirik/.cache/pypoetry/virtualenvs/xai-is73Zs3s-py3.11/lib/python3.11/site-packages/wandb/sdk/interface/interface.py", line 647, in publish_partial_history
    self._publish_partial_history(partial_history)
  File "/home/eirik/.cache/pypoetry/virtualenvs/xai-is73Zs3s-py3.11/lib/python3.11/site-packages/wandb/sdk/interface/interface_shared.py", line 89, in _publish_partial_history
    self._publish(rec)
  File "/home/eirik/.cache/pypoetry/virtualenvs/xai-is73Zs3s-py3.11/lib/python3.11/site-packages/wandb/sdk/interface/interface_sock.py", line 51, in _publish
    self._sock_client.send_record_publish(record)
  File "/home/eirik/.cache/pypoetry/virtualenvs/xai-is73Zs3s-py3.11/lib/python3.11/site-packages/wandb/sdk/lib/sock_client.py", line 225, in send_record_publish
    self.send_server_request(server_req)
  File "/home/eirik/.cache/pypoetry/virtualenvs/xai-is73Zs3s-py3.11/lib/python3.11/site-packages/wandb/sdk/lib/sock_client.py", line 157, in send_server_request
    self._send_message(msg)
  File "/home/eirik/.cache/pypoetry/virtualenvs/xai-is73Zs3s-py3.11/lib/python3.11/site-packages/wandb/sdk/lib/sock_client.py", line 154, in _send_message
    self._sendall_with_error_handle(header + data)
  File "/home/eirik/.cache/pypoetry/virtualenvs/xai-is73Zs3s-py3.11/lib/python3.11/site-packages/wandb/sdk/lib/sock_client.py", line 132, in _sendall_with_error_handle
    sent = self._sock.send(data)
           ^^^^^^^^^^^^^^^^^^^^^
BrokenPipeError: [Errno 32] Broken pipe

INFO: Hyperparameters: lr=0.0001, gamma=0.99, eps_start=0.9, eps_end=0.05, eps_decay=50000, batch_size=32, tau=0.005,hidden_layers=[128, 128], conv_layers=[]
INFO: Number of parameters: 30085
INFO: QNetwork(
  (conv_feature): Sequential()
  (fc_feature): Sequential(
    (0): Linear(in_features=100, out_features=128, bias=True)
    (1): ReLU()
    (2): Linear(in_features=128, out_features=128, bias=True)
    (3): ReLU()
    (4): Linear(in_features=128, out_features=5, bias=True)
  )
)
INFO: Hyperparameters: lr=0.0001, gamma=0.99, eps_start=0.9, eps_end=0.05, eps_decay=50000, batch_size=32, tau=0.005,hidden_layers=[128, 128], conv_layers=[]
INFO: Learning...
ERROR: [Errno 32] Broken pipe
ERROR: Traceback (most recent call last):
  File "/home/eirik/Projects/XAI/rl/src/dqn/wrapper/multi_agent_dqn.py", line 108, in learn
    self.wandb_manager.log(log)
  File "/home/eirik/Projects/XAI/rl/src/managers/wandb_manager.py", line 89, in log
    wandb.log(data, commit=False)
  File "/home/eirik/.cache/pypoetry/virtualenvs/xai-is73Zs3s-py3.11/lib/python3.11/site-packages/wandb/sdk/wandb_run.py", line 452, in wrapper
    return func(self, *args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/eirik/.cache/pypoetry/virtualenvs/xai-is73Zs3s-py3.11/lib/python3.11/site-packages/wandb/sdk/wandb_run.py", line 403, in wrapper_fn
    return func(self, *args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/eirik/.cache/pypoetry/virtualenvs/xai-is73Zs3s-py3.11/lib/python3.11/site-packages/wandb/sdk/wandb_run.py", line 393, in wrapper
    return func(self, *args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/eirik/.cache/pypoetry/virtualenvs/xai-is73Zs3s-py3.11/lib/python3.11/site-packages/wandb/sdk/wandb_run.py", line 1933, in log
    self._log(data=data, step=step, commit=commit)
  File "/home/eirik/.cache/pypoetry/virtualenvs/xai-is73Zs3s-py3.11/lib/python3.11/site-packages/wandb/sdk/wandb_run.py", line 1652, in _log
    self._partial_history_callback(data, step, commit)
  File "/home/eirik/.cache/pypoetry/virtualenvs/xai-is73Zs3s-py3.11/lib/python3.11/site-packages/wandb/sdk/wandb_run.py", line 1524, in _partial_history_callback
    self._backend.interface.publish_partial_history(
  File "/home/eirik/.cache/pypoetry/virtualenvs/xai-is73Zs3s-py3.11/lib/python3.11/site-packages/wandb/sdk/interface/interface.py", line 647, in publish_partial_history
    self._publish_partial_history(partial_history)
  File "/home/eirik/.cache/pypoetry/virtualenvs/xai-is73Zs3s-py3.11/lib/python3.11/site-packages/wandb/sdk/interface/interface_shared.py", line 89, in _publish_partial_history
    self._publish(rec)
  File "/home/eirik/.cache/pypoetry/virtualenvs/xai-is73Zs3s-py3.11/lib/python3.11/site-packages/wandb/sdk/interface/interface_sock.py", line 51, in _publish
    self._sock_client.send_record_publish(record)
  File "/home/eirik/.cache/pypoetry/virtualenvs/xai-is73Zs3s-py3.11/lib/python3.11/site-packages/wandb/sdk/lib/sock_client.py", line 225, in send_record_publish
    self.send_server_request(server_req)
  File "/home/eirik/.cache/pypoetry/virtualenvs/xai-is73Zs3s-py3.11/lib/python3.11/site-packages/wandb/sdk/lib/sock_client.py", line 157, in send_server_request
    self._send_message(msg)
  File "/home/eirik/.cache/pypoetry/virtualenvs/xai-is73Zs3s-py3.11/lib/python3.11/site-packages/wandb/sdk/lib/sock_client.py", line 154, in _send_message
    self._sendall_with_error_handle(header + data)
  File "/home/eirik/.cache/pypoetry/virtualenvs/xai-is73Zs3s-py3.11/lib/python3.11/site-packages/wandb/sdk/lib/sock_client.py", line 132, in _sendall_with_error_handle
    sent = self._sock.send(data)
           ^^^^^^^^^^^^^^^^^^^^^
BrokenPipeError: [Errno 32] Broken pipe

INFO: Hyperparameters: lr=0.0001, gamma=0.99, eps_start=0.9, eps_end=0.05, eps_decay=50000, batch_size=32, tau=0.005,hidden_layers=[128, 128], conv_layers=[]
INFO: Number of parameters: 30085
INFO: QNetwork(
  (conv_feature): Sequential()
  (fc_feature): Sequential(
    (0): Linear(in_features=100, out_features=128, bias=True)
    (1): ReLU()
    (2): Linear(in_features=128, out_features=128, bias=True)
    (3): ReLU()
    (4): Linear(in_features=128, out_features=5, bias=True)
  )
)
INFO: Hyperparameters: lr=0.0001, gamma=0.99, eps_start=0.9, eps_end=0.05, eps_decay=50000, batch_size=32, tau=0.005,hidden_layers=[128, 128], conv_layers=[]
INFO: Learning...
ERROR: [Errno 32] Broken pipe
ERROR: Traceback (most recent call last):
  File "/home/eirik/Projects/XAI/rl/src/dqn/wrapper/multi_agent_dqn.py", line 108, in learn
    self.wandb_manager.log(log)
  File "/home/eirik/Projects/XAI/rl/src/managers/wandb_manager.py", line 89, in log
    wandb.log(data, commit=False)
  File "/home/eirik/.cache/pypoetry/virtualenvs/xai-is73Zs3s-py3.11/lib/python3.11/site-packages/wandb/sdk/wandb_run.py", line 452, in wrapper
    return func(self, *args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/eirik/.cache/pypoetry/virtualenvs/xai-is73Zs3s-py3.11/lib/python3.11/site-packages/wandb/sdk/wandb_run.py", line 403, in wrapper_fn
    return func(self, *args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/eirik/.cache/pypoetry/virtualenvs/xai-is73Zs3s-py3.11/lib/python3.11/site-packages/wandb/sdk/wandb_run.py", line 393, in wrapper
    return func(self, *args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/eirik/.cache/pypoetry/virtualenvs/xai-is73Zs3s-py3.11/lib/python3.11/site-packages/wandb/sdk/wandb_run.py", line 1933, in log
    self._log(data=data, step=step, commit=commit)
  File "/home/eirik/.cache/pypoetry/virtualenvs/xai-is73Zs3s-py3.11/lib/python3.11/site-packages/wandb/sdk/wandb_run.py", line 1652, in _log
    self._partial_history_callback(data, step, commit)
  File "/home/eirik/.cache/pypoetry/virtualenvs/xai-is73Zs3s-py3.11/lib/python3.11/site-packages/wandb/sdk/wandb_run.py", line 1524, in _partial_history_callback
    self._backend.interface.publish_partial_history(
  File "/home/eirik/.cache/pypoetry/virtualenvs/xai-is73Zs3s-py3.11/lib/python3.11/site-packages/wandb/sdk/interface/interface.py", line 647, in publish_partial_history
    self._publish_partial_history(partial_history)
  File "/home/eirik/.cache/pypoetry/virtualenvs/xai-is73Zs3s-py3.11/lib/python3.11/site-packages/wandb/sdk/interface/interface_shared.py", line 89, in _publish_partial_history
    self._publish(rec)
  File "/home/eirik/.cache/pypoetry/virtualenvs/xai-is73Zs3s-py3.11/lib/python3.11/site-packages/wandb/sdk/interface/interface_sock.py", line 51, in _publish
    self._sock_client.send_record_publish(record)
  File "/home/eirik/.cache/pypoetry/virtualenvs/xai-is73Zs3s-py3.11/lib/python3.11/site-packages/wandb/sdk/lib/sock_client.py", line 225, in send_record_publish
    self.send_server_request(server_req)
  File "/home/eirik/.cache/pypoetry/virtualenvs/xai-is73Zs3s-py3.11/lib/python3.11/site-packages/wandb/sdk/lib/sock_client.py", line 157, in send_server_request
    self._send_message(msg)
  File "/home/eirik/.cache/pypoetry/virtualenvs/xai-is73Zs3s-py3.11/lib/python3.11/site-packages/wandb/sdk/lib/sock_client.py", line 154, in _send_message
    self._sendall_with_error_handle(header + data)
  File "/home/eirik/.cache/pypoetry/virtualenvs/xai-is73Zs3s-py3.11/lib/python3.11/site-packages/wandb/sdk/lib/sock_client.py", line 132, in _sendall_with_error_handle
    sent = self._sock.send(data)
           ^^^^^^^^^^^^^^^^^^^^^
BrokenPipeError: [Errno 32] Broken pipe

INFO: Hyperparameters: lr=0.0001, gamma=0.99, eps_start=0.9, eps_end=0.05, eps_decay=50000, batch_size=32, tau=0.005,hidden_layers=[128, 128], conv_layers=[]
INFO: Number of parameters: 30085
INFO: QNetwork(
  (conv_feature): Sequential()
  (fc_feature): Sequential(
    (0): Linear(in_features=100, out_features=128, bias=True)
    (1): ReLU()
    (2): Linear(in_features=128, out_features=128, bias=True)
    (3): ReLU()
    (4): Linear(in_features=128, out_features=5, bias=True)
  )
)
INFO: Hyperparameters: lr=0.0001, gamma=0.99, eps_start=0.9, eps_end=0.05, eps_decay=50000, batch_size=32, tau=0.005,hidden_layers=[128, 128], conv_layers=[]
INFO: Learning...
ERROR: [Errno 32] Broken pipe
ERROR: Traceback (most recent call last):
  File "/home/eirik/Projects/XAI/rl/src/dqn/wrapper/multi_agent_dqn.py", line 108, in learn
    self.wandb_manager.log(log)
  File "/home/eirik/Projects/XAI/rl/src/managers/wandb_manager.py", line 90, in log
    wandb.log(data, commit=False)
  File "/home/eirik/.cache/pypoetry/virtualenvs/xai-is73Zs3s-py3.11/lib/python3.11/site-packages/wandb/sdk/wandb_run.py", line 452, in wrapper
    return func(self, *args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/eirik/.cache/pypoetry/virtualenvs/xai-is73Zs3s-py3.11/lib/python3.11/site-packages/wandb/sdk/wandb_run.py", line 403, in wrapper_fn
    return func(self, *args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/eirik/.cache/pypoetry/virtualenvs/xai-is73Zs3s-py3.11/lib/python3.11/site-packages/wandb/sdk/wandb_run.py", line 393, in wrapper
    return func(self, *args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/eirik/.cache/pypoetry/virtualenvs/xai-is73Zs3s-py3.11/lib/python3.11/site-packages/wandb/sdk/wandb_run.py", line 1933, in log
    self._log(data=data, step=step, commit=commit)
  File "/home/eirik/.cache/pypoetry/virtualenvs/xai-is73Zs3s-py3.11/lib/python3.11/site-packages/wandb/sdk/wandb_run.py", line 1652, in _log
    self._partial_history_callback(data, step, commit)
  File "/home/eirik/.cache/pypoetry/virtualenvs/xai-is73Zs3s-py3.11/lib/python3.11/site-packages/wandb/sdk/wandb_run.py", line 1524, in _partial_history_callback
    self._backend.interface.publish_partial_history(
  File "/home/eirik/.cache/pypoetry/virtualenvs/xai-is73Zs3s-py3.11/lib/python3.11/site-packages/wandb/sdk/interface/interface.py", line 647, in publish_partial_history
    self._publish_partial_history(partial_history)
  File "/home/eirik/.cache/pypoetry/virtualenvs/xai-is73Zs3s-py3.11/lib/python3.11/site-packages/wandb/sdk/interface/interface_shared.py", line 89, in _publish_partial_history
    self._publish(rec)
  File "/home/eirik/.cache/pypoetry/virtualenvs/xai-is73Zs3s-py3.11/lib/python3.11/site-packages/wandb/sdk/interface/interface_sock.py", line 51, in _publish
    self._sock_client.send_record_publish(record)
  File "/home/eirik/.cache/pypoetry/virtualenvs/xai-is73Zs3s-py3.11/lib/python3.11/site-packages/wandb/sdk/lib/sock_client.py", line 225, in send_record_publish
    self.send_server_request(server_req)
  File "/home/eirik/.cache/pypoetry/virtualenvs/xai-is73Zs3s-py3.11/lib/python3.11/site-packages/wandb/sdk/lib/sock_client.py", line 157, in send_server_request
    self._send_message(msg)
  File "/home/eirik/.cache/pypoetry/virtualenvs/xai-is73Zs3s-py3.11/lib/python3.11/site-packages/wandb/sdk/lib/sock_client.py", line 154, in _send_message
    self._sendall_with_error_handle(header + data)
  File "/home/eirik/.cache/pypoetry/virtualenvs/xai-is73Zs3s-py3.11/lib/python3.11/site-packages/wandb/sdk/lib/sock_client.py", line 132, in _sendall_with_error_handle
    sent = self._sock.send(data)
           ^^^^^^^^^^^^^^^^^^^^^
BrokenPipeError: [Errno 32] Broken pipe

INFO: Hyperparameters: lr=0.0001, gamma=0.99, eps_start=0.9, eps_end=0.05, eps_decay=50000, batch_size=32, tau=0.005,hidden_layers=[128, 128], conv_layers=[]
INFO: Number of parameters: 30085
INFO: QNetwork(
  (conv_feature): Sequential()
  (fc_feature): Sequential(
    (0): Linear(in_features=100, out_features=128, bias=True)
    (1): ReLU()
    (2): Linear(in_features=128, out_features=128, bias=True)
    (3): ReLU()
    (4): Linear(in_features=128, out_features=5, bias=True)
  )
)
INFO: Hyperparameters: lr=0.0001, gamma=0.99, eps_start=0.9, eps_end=0.05, eps_decay=50000, batch_size=32, tau=0.005,hidden_layers=[128, 128], conv_layers=[]
INFO: Learning...
ERROR: [Errno 32] Broken pipe
ERROR: Traceback (most recent call last):
  File "/home/eirik/Projects/XAI/rl/src/dqn/wrapper/multi_agent_dqn.py", line 108, in learn
    self.wandb_manager.log(log)
  File "/home/eirik/Projects/XAI/rl/src/managers/wandb_manager.py", line 91, in log
    wandb.log(data, commit=False)
  File "/home/eirik/.cache/pypoetry/virtualenvs/xai-is73Zs3s-py3.11/lib/python3.11/site-packages/wandb/sdk/wandb_run.py", line 452, in wrapper
    return func(self, *args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/eirik/.cache/pypoetry/virtualenvs/xai-is73Zs3s-py3.11/lib/python3.11/site-packages/wandb/sdk/wandb_run.py", line 403, in wrapper_fn
    return func(self, *args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/eirik/.cache/pypoetry/virtualenvs/xai-is73Zs3s-py3.11/lib/python3.11/site-packages/wandb/sdk/wandb_run.py", line 393, in wrapper
    return func(self, *args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/eirik/.cache/pypoetry/virtualenvs/xai-is73Zs3s-py3.11/lib/python3.11/site-packages/wandb/sdk/wandb_run.py", line 1933, in log
    self._log(data=data, step=step, commit=commit)
  File "/home/eirik/.cache/pypoetry/virtualenvs/xai-is73Zs3s-py3.11/lib/python3.11/site-packages/wandb/sdk/wandb_run.py", line 1652, in _log
    self._partial_history_callback(data, step, commit)
  File "/home/eirik/.cache/pypoetry/virtualenvs/xai-is73Zs3s-py3.11/lib/python3.11/site-packages/wandb/sdk/wandb_run.py", line 1524, in _partial_history_callback
    self._backend.interface.publish_partial_history(
  File "/home/eirik/.cache/pypoetry/virtualenvs/xai-is73Zs3s-py3.11/lib/python3.11/site-packages/wandb/sdk/interface/interface.py", line 647, in publish_partial_history
    self._publish_partial_history(partial_history)
  File "/home/eirik/.cache/pypoetry/virtualenvs/xai-is73Zs3s-py3.11/lib/python3.11/site-packages/wandb/sdk/interface/interface_shared.py", line 89, in _publish_partial_history
    self._publish(rec)
  File "/home/eirik/.cache/pypoetry/virtualenvs/xai-is73Zs3s-py3.11/lib/python3.11/site-packages/wandb/sdk/interface/interface_sock.py", line 51, in _publish
    self._sock_client.send_record_publish(record)
  File "/home/eirik/.cache/pypoetry/virtualenvs/xai-is73Zs3s-py3.11/lib/python3.11/site-packages/wandb/sdk/lib/sock_client.py", line 225, in send_record_publish
    self.send_server_request(server_req)
  File "/home/eirik/.cache/pypoetry/virtualenvs/xai-is73Zs3s-py3.11/lib/python3.11/site-packages/wandb/sdk/lib/sock_client.py", line 157, in send_server_request
    self._send_message(msg)
  File "/home/eirik/.cache/pypoetry/virtualenvs/xai-is73Zs3s-py3.11/lib/python3.11/site-packages/wandb/sdk/lib/sock_client.py", line 154, in _send_message
    self._sendall_with_error_handle(header + data)
  File "/home/eirik/.cache/pypoetry/virtualenvs/xai-is73Zs3s-py3.11/lib/python3.11/site-packages/wandb/sdk/lib/sock_client.py", line 132, in _sendall_with_error_handle
    sent = self._sock.send(data)
           ^^^^^^^^^^^^^^^^^^^^^
BrokenPipeError: [Errno 32] Broken pipe

INFO: Hyperparameters: lr=0.0001, gamma=0.99, eps_start=0.9, eps_end=0.05, eps_decay=50000, batch_size=32, tau=0.005,hidden_layers=[128, 128], conv_layers=[]
INFO: Number of parameters: 30085
INFO: QNetwork(
  (conv_feature): Sequential()
  (fc_feature): Sequential(
    (0): Linear(in_features=100, out_features=128, bias=True)
    (1): ReLU()
    (2): Linear(in_features=128, out_features=128, bias=True)
    (3): ReLU()
    (4): Linear(in_features=128, out_features=5, bias=True)
  )
)
INFO: Hyperparameters: lr=0.0001, gamma=0.99, eps_start=0.9, eps_end=0.05, eps_decay=50000, batch_size=32, tau=0.005,hidden_layers=[128, 128], conv_layers=[]
INFO: Learning...
ERROR: [Errno 32] Broken pipe
ERROR: Traceback (most recent call last):
  File "/home/eirik/Projects/XAI/rl/src/dqn/wrapper/multi_agent_dqn.py", line 108, in learn
    self.wandb_manager.log(log)
  File "/home/eirik/Projects/XAI/rl/src/managers/wandb_manager.py", line 91, in log
    wandb.log(data, commit=False)
  File "/home/eirik/.cache/pypoetry/virtualenvs/xai-is73Zs3s-py3.11/lib/python3.11/site-packages/wandb/sdk/wandb_run.py", line 452, in wrapper
    return func(self, *args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/eirik/.cache/pypoetry/virtualenvs/xai-is73Zs3s-py3.11/lib/python3.11/site-packages/wandb/sdk/wandb_run.py", line 403, in wrapper_fn
    return func(self, *args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/eirik/.cache/pypoetry/virtualenvs/xai-is73Zs3s-py3.11/lib/python3.11/site-packages/wandb/sdk/wandb_run.py", line 393, in wrapper
    return func(self, *args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/eirik/.cache/pypoetry/virtualenvs/xai-is73Zs3s-py3.11/lib/python3.11/site-packages/wandb/sdk/wandb_run.py", line 1933, in log
    self._log(data=data, step=step, commit=commit)
  File "/home/eirik/.cache/pypoetry/virtualenvs/xai-is73Zs3s-py3.11/lib/python3.11/site-packages/wandb/sdk/wandb_run.py", line 1652, in _log
    self._partial_history_callback(data, step, commit)
  File "/home/eirik/.cache/pypoetry/virtualenvs/xai-is73Zs3s-py3.11/lib/python3.11/site-packages/wandb/sdk/wandb_run.py", line 1524, in _partial_history_callback
    self._backend.interface.publish_partial_history(
  File "/home/eirik/.cache/pypoetry/virtualenvs/xai-is73Zs3s-py3.11/lib/python3.11/site-packages/wandb/sdk/interface/interface.py", line 647, in publish_partial_history
    self._publish_partial_history(partial_history)
  File "/home/eirik/.cache/pypoetry/virtualenvs/xai-is73Zs3s-py3.11/lib/python3.11/site-packages/wandb/sdk/interface/interface_shared.py", line 89, in _publish_partial_history
    self._publish(rec)
  File "/home/eirik/.cache/pypoetry/virtualenvs/xai-is73Zs3s-py3.11/lib/python3.11/site-packages/wandb/sdk/interface/interface_sock.py", line 51, in _publish
    self._sock_client.send_record_publish(record)
  File "/home/eirik/.cache/pypoetry/virtualenvs/xai-is73Zs3s-py3.11/lib/python3.11/site-packages/wandb/sdk/lib/sock_client.py", line 225, in send_record_publish
    self.send_server_request(server_req)
  File "/home/eirik/.cache/pypoetry/virtualenvs/xai-is73Zs3s-py3.11/lib/python3.11/site-packages/wandb/sdk/lib/sock_client.py", line 157, in send_server_request
    self._send_message(msg)
  File "/home/eirik/.cache/pypoetry/virtualenvs/xai-is73Zs3s-py3.11/lib/python3.11/site-packages/wandb/sdk/lib/sock_client.py", line 154, in _send_message
    self._sendall_with_error_handle(header + data)
  File "/home/eirik/.cache/pypoetry/virtualenvs/xai-is73Zs3s-py3.11/lib/python3.11/site-packages/wandb/sdk/lib/sock_client.py", line 132, in _sendall_with_error_handle
    sent = self._sock.send(data)
           ^^^^^^^^^^^^^^^^^^^^^
BrokenPipeError: [Errno 32] Broken pipe

INFO: Hyperparameters: lr=0.0001, gamma=0.99, eps_start=0.9, eps_end=0.05, eps_decay=50000, batch_size=32, tau=0.005,hidden_layers=[128, 128], conv_layers=[]
INFO: Number of parameters: 30085
INFO: QNetwork(
  (conv_feature): Sequential()
  (fc_feature): Sequential(
    (0): Linear(in_features=100, out_features=128, bias=True)
    (1): ReLU()
    (2): Linear(in_features=128, out_features=128, bias=True)
    (3): ReLU()
    (4): Linear(in_features=128, out_features=5, bias=True)
  )
)
INFO: Hyperparameters: lr=0.0001, gamma=0.99, eps_start=0.9, eps_end=0.05, eps_decay=50000, batch_size=32, tau=0.005,hidden_layers=[128, 128], conv_layers=[]
INFO: Learning...
ERROR: [Errno 32] Broken pipe
ERROR: Traceback (most recent call last):
  File "/home/eirik/Projects/XAI/rl/src/dqn/wrapper/multi_agent_dqn.py", line 108, in learn
    self.wandb_manager.log(log)
  File "/home/eirik/Projects/XAI/rl/src/managers/wandb_manager.py", line 91, in log
    wandb.log(data, commit=False)
  File "/home/eirik/.cache/pypoetry/virtualenvs/xai-is73Zs3s-py3.11/lib/python3.11/site-packages/wandb/sdk/wandb_run.py", line 452, in wrapper
    return func(self, *args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/eirik/.cache/pypoetry/virtualenvs/xai-is73Zs3s-py3.11/lib/python3.11/site-packages/wandb/sdk/wandb_run.py", line 403, in wrapper_fn
    return func(self, *args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/eirik/.cache/pypoetry/virtualenvs/xai-is73Zs3s-py3.11/lib/python3.11/site-packages/wandb/sdk/wandb_run.py", line 393, in wrapper
    return func(self, *args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/eirik/.cache/pypoetry/virtualenvs/xai-is73Zs3s-py3.11/lib/python3.11/site-packages/wandb/sdk/wandb_run.py", line 1933, in log
    self._log(data=data, step=step, commit=commit)
  File "/home/eirik/.cache/pypoetry/virtualenvs/xai-is73Zs3s-py3.11/lib/python3.11/site-packages/wandb/sdk/wandb_run.py", line 1652, in _log
    self._partial_history_callback(data, step, commit)
  File "/home/eirik/.cache/pypoetry/virtualenvs/xai-is73Zs3s-py3.11/lib/python3.11/site-packages/wandb/sdk/wandb_run.py", line 1524, in _partial_history_callback
    self._backend.interface.publish_partial_history(
  File "/home/eirik/.cache/pypoetry/virtualenvs/xai-is73Zs3s-py3.11/lib/python3.11/site-packages/wandb/sdk/interface/interface.py", line 647, in publish_partial_history
    self._publish_partial_history(partial_history)
  File "/home/eirik/.cache/pypoetry/virtualenvs/xai-is73Zs3s-py3.11/lib/python3.11/site-packages/wandb/sdk/interface/interface_shared.py", line 89, in _publish_partial_history
    self._publish(rec)
  File "/home/eirik/.cache/pypoetry/virtualenvs/xai-is73Zs3s-py3.11/lib/python3.11/site-packages/wandb/sdk/interface/interface_sock.py", line 51, in _publish
    self._sock_client.send_record_publish(record)
  File "/home/eirik/.cache/pypoetry/virtualenvs/xai-is73Zs3s-py3.11/lib/python3.11/site-packages/wandb/sdk/lib/sock_client.py", line 225, in send_record_publish
    self.send_server_request(server_req)
  File "/home/eirik/.cache/pypoetry/virtualenvs/xai-is73Zs3s-py3.11/lib/python3.11/site-packages/wandb/sdk/lib/sock_client.py", line 157, in send_server_request
    self._send_message(msg)
  File "/home/eirik/.cache/pypoetry/virtualenvs/xai-is73Zs3s-py3.11/lib/python3.11/site-packages/wandb/sdk/lib/sock_client.py", line 154, in _send_message
    self._sendall_with_error_handle(header + data)
  File "/home/eirik/.cache/pypoetry/virtualenvs/xai-is73Zs3s-py3.11/lib/python3.11/site-packages/wandb/sdk/lib/sock_client.py", line 132, in _sendall_with_error_handle
    sent = self._sock.send(data)
           ^^^^^^^^^^^^^^^^^^^^^
BrokenPipeError: [Errno 32] Broken pipe

INFO: Hyperparameters: lr=0.0001, gamma=0.99, eps_start=0.9, eps_end=0.05, eps_decay=50000, batch_size=32, tau=0.005,hidden_layers=[128, 128], conv_layers=[]
INFO: Number of parameters: 30085
INFO: QNetwork(
  (conv_feature): Sequential()
  (fc_feature): Sequential(
    (0): Linear(in_features=100, out_features=128, bias=True)
    (1): ReLU()
    (2): Linear(in_features=128, out_features=128, bias=True)
    (3): ReLU()
    (4): Linear(in_features=128, out_features=5, bias=True)
  )
)
INFO: Hyperparameters: lr=0.0001, gamma=0.99, eps_start=0.9, eps_end=0.05, eps_decay=50000, batch_size=32, tau=0.005,hidden_layers=[128, 128], conv_layers=[]
INFO: Learning...
ERROR: [Errno 32] Broken pipe
ERROR: Traceback (most recent call last):
  File "/home/eirik/Projects/XAI/rl/src/dqn/wrapper/multi_agent_dqn.py", line 108, in learn
    self.wandb_manager.log(log)
  File "/home/eirik/Projects/XAI/rl/src/managers/wandb_manager.py", line 91, in log
    wandb.log(data, commit=False)
  File "/home/eirik/.cache/pypoetry/virtualenvs/xai-is73Zs3s-py3.11/lib/python3.11/site-packages/wandb/sdk/wandb_run.py", line 452, in wrapper
    return func(self, *args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/eirik/.cache/pypoetry/virtualenvs/xai-is73Zs3s-py3.11/lib/python3.11/site-packages/wandb/sdk/wandb_run.py", line 403, in wrapper_fn
    return func(self, *args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/eirik/.cache/pypoetry/virtualenvs/xai-is73Zs3s-py3.11/lib/python3.11/site-packages/wandb/sdk/wandb_run.py", line 393, in wrapper
    return func(self, *args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/eirik/.cache/pypoetry/virtualenvs/xai-is73Zs3s-py3.11/lib/python3.11/site-packages/wandb/sdk/wandb_run.py", line 1933, in log
    self._log(data=data, step=step, commit=commit)
  File "/home/eirik/.cache/pypoetry/virtualenvs/xai-is73Zs3s-py3.11/lib/python3.11/site-packages/wandb/sdk/wandb_run.py", line 1652, in _log
    self._partial_history_callback(data, step, commit)
  File "/home/eirik/.cache/pypoetry/virtualenvs/xai-is73Zs3s-py3.11/lib/python3.11/site-packages/wandb/sdk/wandb_run.py", line 1524, in _partial_history_callback
    self._backend.interface.publish_partial_history(
  File "/home/eirik/.cache/pypoetry/virtualenvs/xai-is73Zs3s-py3.11/lib/python3.11/site-packages/wandb/sdk/interface/interface.py", line 647, in publish_partial_history
    self._publish_partial_history(partial_history)
  File "/home/eirik/.cache/pypoetry/virtualenvs/xai-is73Zs3s-py3.11/lib/python3.11/site-packages/wandb/sdk/interface/interface_shared.py", line 89, in _publish_partial_history
    self._publish(rec)
  File "/home/eirik/.cache/pypoetry/virtualenvs/xai-is73Zs3s-py3.11/lib/python3.11/site-packages/wandb/sdk/interface/interface_sock.py", line 51, in _publish
    self._sock_client.send_record_publish(record)
  File "/home/eirik/.cache/pypoetry/virtualenvs/xai-is73Zs3s-py3.11/lib/python3.11/site-packages/wandb/sdk/lib/sock_client.py", line 225, in send_record_publish
    self.send_server_request(server_req)
  File "/home/eirik/.cache/pypoetry/virtualenvs/xai-is73Zs3s-py3.11/lib/python3.11/site-packages/wandb/sdk/lib/sock_client.py", line 157, in send_server_request
    self._send_message(msg)
  File "/home/eirik/.cache/pypoetry/virtualenvs/xai-is73Zs3s-py3.11/lib/python3.11/site-packages/wandb/sdk/lib/sock_client.py", line 154, in _send_message
    self._sendall_with_error_handle(header + data)
  File "/home/eirik/.cache/pypoetry/virtualenvs/xai-is73Zs3s-py3.11/lib/python3.11/site-packages/wandb/sdk/lib/sock_client.py", line 132, in _sendall_with_error_handle
    sent = self._sock.send(data)
           ^^^^^^^^^^^^^^^^^^^^^
BrokenPipeError: [Errno 32] Broken pipe

INFO: Hyperparameters: lr=0.0001, gamma=0.99, eps_start=0.9, eps_end=0.05, eps_decay=50000, batch_size=32, tau=0.005,hidden_layers=[128, 128], conv_layers=[]
INFO: Number of parameters: 30085
INFO: QNetwork(
  (conv_feature): Sequential()
  (fc_feature): Sequential(
    (0): Linear(in_features=100, out_features=128, bias=True)
    (1): ReLU()
    (2): Linear(in_features=128, out_features=128, bias=True)
    (3): ReLU()
    (4): Linear(in_features=128, out_features=5, bias=True)
  )
)
INFO: Hyperparameters: lr=0.0001, gamma=0.99, eps_start=0.9, eps_end=0.05, eps_decay=50000, batch_size=32, tau=0.005,hidden_layers=[128, 128], conv_layers=[]
INFO: Hyperparameters: lr=0.0001, gamma=0.99, eps_start=0.9, eps_end=0.05, eps_decay=50000, batch_size=32, tau=0.005,hidden_layers=[128, 128], conv_layers=[]
INFO: Number of parameters: 30085
INFO: QNetwork(
  (conv_feature): Sequential()
  (fc_feature): Sequential(
    (0): Linear(in_features=100, out_features=128, bias=True)
    (1): ReLU()
    (2): Linear(in_features=128, out_features=128, bias=True)
    (3): ReLU()
    (4): Linear(in_features=128, out_features=5, bias=True)
  )
)
INFO: Hyperparameters: lr=0.0001, gamma=0.99, eps_start=0.9, eps_end=0.05, eps_decay=50000, batch_size=32, tau=0.005,hidden_layers=[128, 128], conv_layers=[]
INFO: Hyperparameters: lr=0.0001, gamma=0.99, eps_start=0.9, eps_end=0.05, eps_decay=50000, batch_size=32, tau=0.005,hidden_layers=[128, 128], conv_layers=[]
INFO: Number of parameters: 30085
INFO: QNetwork(
  (conv_feature): Sequential()
  (fc_feature): Sequential(
    (0): Linear(in_features=100, out_features=128, bias=True)
    (1): ReLU()
    (2): Linear(in_features=128, out_features=128, bias=True)
    (3): ReLU()
    (4): Linear(in_features=128, out_features=5, bias=True)
  )
)
INFO: Hyperparameters: lr=0.0001, gamma=0.99, eps_start=0.9, eps_end=0.05, eps_decay=50000, batch_size=32, tau=0.005,hidden_layers=[128, 128], conv_layers=[]
INFO: Learning...
INFO: Hyperparameters: lr=0.0001, gamma=0.99, eps_start=0.9, eps_end=0.05, eps_decay=50000, batch_size=32, tau=0.005,hidden_layers=[128, 128], conv_layers=[]
INFO: Number of parameters: 30085
INFO: QNetwork(
  (conv_feature): Sequential()
  (fc_feature): Sequential(
    (0): Linear(in_features=100, out_features=128, bias=True)
    (1): ReLU()
    (2): Linear(in_features=128, out_features=128, bias=True)
    (3): ReLU()
    (4): Linear(in_features=128, out_features=5, bias=True)
  )
)
INFO: Hyperparameters: lr=0.0001, gamma=0.99, eps_start=0.9, eps_end=0.05, eps_decay=50000, batch_size=32, tau=0.005,hidden_layers=[128, 128], conv_layers=[]
ERROR: [Errno 32] Broken pipe
ERROR: Traceback (most recent call last):
  File "/home/eirik/Projects/XAI/rl/src/dqn/wrapper/multi_agent_dqn.py", line 110, in learn
    self.wandb_manager.log(log)
  File "/home/eirik/Projects/XAI/rl/src/managers/wandb_manager.py", line 91, in log
    wandb.log(data, commit=False)
  File "/home/eirik/.cache/pypoetry/virtualenvs/xai-is73Zs3s-py3.11/lib/python3.11/site-packages/wandb/sdk/wandb_run.py", line 452, in wrapper
    return func(self, *args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/eirik/.cache/pypoetry/virtualenvs/xai-is73Zs3s-py3.11/lib/python3.11/site-packages/wandb/sdk/wandb_run.py", line 403, in wrapper_fn
    return func(self, *args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/eirik/.cache/pypoetry/virtualenvs/xai-is73Zs3s-py3.11/lib/python3.11/site-packages/wandb/sdk/wandb_run.py", line 393, in wrapper
    return func(self, *args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/eirik/.cache/pypoetry/virtualenvs/xai-is73Zs3s-py3.11/lib/python3.11/site-packages/wandb/sdk/wandb_run.py", line 1933, in log
    self._log(data=data, step=step, commit=commit)
  File "/home/eirik/.cache/pypoetry/virtualenvs/xai-is73Zs3s-py3.11/lib/python3.11/site-packages/wandb/sdk/wandb_run.py", line 1652, in _log
    self._partial_history_callback(data, step, commit)
  File "/home/eirik/.cache/pypoetry/virtualenvs/xai-is73Zs3s-py3.11/lib/python3.11/site-packages/wandb/sdk/wandb_run.py", line 1524, in _partial_history_callback
    self._backend.interface.publish_partial_history(
  File "/home/eirik/.cache/pypoetry/virtualenvs/xai-is73Zs3s-py3.11/lib/python3.11/site-packages/wandb/sdk/interface/interface.py", line 647, in publish_partial_history
    self._publish_partial_history(partial_history)
  File "/home/eirik/.cache/pypoetry/virtualenvs/xai-is73Zs3s-py3.11/lib/python3.11/site-packages/wandb/sdk/interface/interface_shared.py", line 89, in _publish_partial_history
    self._publish(rec)
  File "/home/eirik/.cache/pypoetry/virtualenvs/xai-is73Zs3s-py3.11/lib/python3.11/site-packages/wandb/sdk/interface/interface_sock.py", line 51, in _publish
    self._sock_client.send_record_publish(record)
  File "/home/eirik/.cache/pypoetry/virtualenvs/xai-is73Zs3s-py3.11/lib/python3.11/site-packages/wandb/sdk/lib/sock_client.py", line 225, in send_record_publish
    self.send_server_request(server_req)
  File "/home/eirik/.cache/pypoetry/virtualenvs/xai-is73Zs3s-py3.11/lib/python3.11/site-packages/wandb/sdk/lib/sock_client.py", line 157, in send_server_request
    self._send_message(msg)
  File "/home/eirik/.cache/pypoetry/virtualenvs/xai-is73Zs3s-py3.11/lib/python3.11/site-packages/wandb/sdk/lib/sock_client.py", line 154, in _send_message
    self._sendall_with_error_handle(header + data)
  File "/home/eirik/.cache/pypoetry/virtualenvs/xai-is73Zs3s-py3.11/lib/python3.11/site-packages/wandb/sdk/lib/sock_client.py", line 132, in _sendall_with_error_handle
    sent = self._sock.send(data)
           ^^^^^^^^^^^^^^^^^^^^^
BrokenPipeError: [Errno 32] Broken pipe

INFO: Learning...
INFO: Hyperparameters: lr=0.0001, gamma=0.99, eps_start=0.9, eps_end=0.05, eps_decay=50000, batch_size=32, tau=0.005,hidden_layers=[128, 128], conv_layers=[]
INFO: Number of parameters: 30085
INFO: QNetwork(
  (conv_feature): Sequential()
  (fc_feature): Sequential(
    (0): Linear(in_features=100, out_features=128, bias=True)
    (1): ReLU()
    (2): Linear(in_features=128, out_features=128, bias=True)
    (3): ReLU()
    (4): Linear(in_features=128, out_features=5, bias=True)
  )
)
INFO: Hyperparameters: lr=0.0001, gamma=0.99, eps_start=0.9, eps_end=0.05, eps_decay=50000, batch_size=32, tau=0.005,hidden_layers=[128, 128], conv_layers=[]
ERROR: [Errno 32] Broken pipe
ERROR: Traceback (most recent call last):
  File "/home/eirik/Projects/XAI/rl/src/dqn/wrapper/multi_agent_dqn.py", line 110, in learn
    self.wandb_manager.log(log)
  File "/home/eirik/Projects/XAI/rl/src/managers/wandb_manager.py", line 92, in log
    wandb.log(data, commit=False)
  File "/home/eirik/.cache/pypoetry/virtualenvs/xai-is73Zs3s-py3.11/lib/python3.11/site-packages/wandb/sdk/wandb_run.py", line 452, in wrapper
    return func(self, *args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/eirik/.cache/pypoetry/virtualenvs/xai-is73Zs3s-py3.11/lib/python3.11/site-packages/wandb/sdk/wandb_run.py", line 403, in wrapper_fn
    return func(self, *args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/eirik/.cache/pypoetry/virtualenvs/xai-is73Zs3s-py3.11/lib/python3.11/site-packages/wandb/sdk/wandb_run.py", line 393, in wrapper
    return func(self, *args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/eirik/.cache/pypoetry/virtualenvs/xai-is73Zs3s-py3.11/lib/python3.11/site-packages/wandb/sdk/wandb_run.py", line 1933, in log
    self._log(data=data, step=step, commit=commit)
  File "/home/eirik/.cache/pypoetry/virtualenvs/xai-is73Zs3s-py3.11/lib/python3.11/site-packages/wandb/sdk/wandb_run.py", line 1652, in _log
    self._partial_history_callback(data, step, commit)
  File "/home/eirik/.cache/pypoetry/virtualenvs/xai-is73Zs3s-py3.11/lib/python3.11/site-packages/wandb/sdk/wandb_run.py", line 1524, in _partial_history_callback
    self._backend.interface.publish_partial_history(
  File "/home/eirik/.cache/pypoetry/virtualenvs/xai-is73Zs3s-py3.11/lib/python3.11/site-packages/wandb/sdk/interface/interface.py", line 647, in publish_partial_history
    self._publish_partial_history(partial_history)
  File "/home/eirik/.cache/pypoetry/virtualenvs/xai-is73Zs3s-py3.11/lib/python3.11/site-packages/wandb/sdk/interface/interface_shared.py", line 89, in _publish_partial_history
    self._publish(rec)
  File "/home/eirik/.cache/pypoetry/virtualenvs/xai-is73Zs3s-py3.11/lib/python3.11/site-packages/wandb/sdk/interface/interface_sock.py", line 51, in _publish
    self._sock_client.send_record_publish(record)
  File "/home/eirik/.cache/pypoetry/virtualenvs/xai-is73Zs3s-py3.11/lib/python3.11/site-packages/wandb/sdk/lib/sock_client.py", line 225, in send_record_publish
    self.send_server_request(server_req)
  File "/home/eirik/.cache/pypoetry/virtualenvs/xai-is73Zs3s-py3.11/lib/python3.11/site-packages/wandb/sdk/lib/sock_client.py", line 157, in send_server_request
    self._send_message(msg)
  File "/home/eirik/.cache/pypoetry/virtualenvs/xai-is73Zs3s-py3.11/lib/python3.11/site-packages/wandb/sdk/lib/sock_client.py", line 154, in _send_message
    self._sendall_with_error_handle(header + data)
  File "/home/eirik/.cache/pypoetry/virtualenvs/xai-is73Zs3s-py3.11/lib/python3.11/site-packages/wandb/sdk/lib/sock_client.py", line 132, in _sendall_with_error_handle
    sent = self._sock.send(data)
           ^^^^^^^^^^^^^^^^^^^^^
BrokenPipeError: [Errno 32] Broken pipe

INFO: Learning...
INFO: Hyperparameters: lr=0.0001, gamma=0.99, eps_start=0.9, eps_end=0.05, eps_decay=50000, batch_size=32, tau=0.005,hidden_layers=[128, 128], conv_layers=[]
INFO: Number of parameters: 30085
INFO: QNetwork(
  (conv_feature): Sequential()
  (fc_feature): Sequential(
    (0): Linear(in_features=100, out_features=128, bias=True)
    (1): ReLU()
    (2): Linear(in_features=128, out_features=128, bias=True)
    (3): ReLU()
    (4): Linear(in_features=128, out_features=5, bias=True)
  )
)
INFO: Hyperparameters: lr=0.0001, gamma=0.99, eps_start=0.9, eps_end=0.05, eps_decay=50000, batch_size=32, tau=0.005,hidden_layers=[128, 128], conv_layers=[]
ERROR: [Errno 32] Broken pipe
ERROR: Traceback (most recent call last):
  File "/home/eirik/Projects/XAI/rl/src/dqn/wrapper/multi_agent_dqn.py", line 110, in learn
    self.wandb_manager.log(log)
  File "/home/eirik/Projects/XAI/rl/src/managers/wandb_manager.py", line 90, in log
    wandb.log(data, commit=False)
  File "/home/eirik/.cache/pypoetry/virtualenvs/xai-is73Zs3s-py3.11/lib/python3.11/site-packages/wandb/sdk/wandb_run.py", line 452, in wrapper
    return func(self, *args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/eirik/.cache/pypoetry/virtualenvs/xai-is73Zs3s-py3.11/lib/python3.11/site-packages/wandb/sdk/wandb_run.py", line 403, in wrapper_fn
    return func(self, *args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/eirik/.cache/pypoetry/virtualenvs/xai-is73Zs3s-py3.11/lib/python3.11/site-packages/wandb/sdk/wandb_run.py", line 393, in wrapper
    return func(self, *args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/eirik/.cache/pypoetry/virtualenvs/xai-is73Zs3s-py3.11/lib/python3.11/site-packages/wandb/sdk/wandb_run.py", line 1933, in log
    self._log(data=data, step=step, commit=commit)
  File "/home/eirik/.cache/pypoetry/virtualenvs/xai-is73Zs3s-py3.11/lib/python3.11/site-packages/wandb/sdk/wandb_run.py", line 1652, in _log
    self._partial_history_callback(data, step, commit)
  File "/home/eirik/.cache/pypoetry/virtualenvs/xai-is73Zs3s-py3.11/lib/python3.11/site-packages/wandb/sdk/wandb_run.py", line 1524, in _partial_history_callback
    self._backend.interface.publish_partial_history(
  File "/home/eirik/.cache/pypoetry/virtualenvs/xai-is73Zs3s-py3.11/lib/python3.11/site-packages/wandb/sdk/interface/interface.py", line 647, in publish_partial_history
    self._publish_partial_history(partial_history)
  File "/home/eirik/.cache/pypoetry/virtualenvs/xai-is73Zs3s-py3.11/lib/python3.11/site-packages/wandb/sdk/interface/interface_shared.py", line 89, in _publish_partial_history
    self._publish(rec)
  File "/home/eirik/.cache/pypoetry/virtualenvs/xai-is73Zs3s-py3.11/lib/python3.11/site-packages/wandb/sdk/interface/interface_sock.py", line 51, in _publish
    self._sock_client.send_record_publish(record)
  File "/home/eirik/.cache/pypoetry/virtualenvs/xai-is73Zs3s-py3.11/lib/python3.11/site-packages/wandb/sdk/lib/sock_client.py", line 225, in send_record_publish
    self.send_server_request(server_req)
  File "/home/eirik/.cache/pypoetry/virtualenvs/xai-is73Zs3s-py3.11/lib/python3.11/site-packages/wandb/sdk/lib/sock_client.py", line 157, in send_server_request
    self._send_message(msg)
  File "/home/eirik/.cache/pypoetry/virtualenvs/xai-is73Zs3s-py3.11/lib/python3.11/site-packages/wandb/sdk/lib/sock_client.py", line 154, in _send_message
    self._sendall_with_error_handle(header + data)
  File "/home/eirik/.cache/pypoetry/virtualenvs/xai-is73Zs3s-py3.11/lib/python3.11/site-packages/wandb/sdk/lib/sock_client.py", line 132, in _sendall_with_error_handle
    sent = self._sock.send(data)
           ^^^^^^^^^^^^^^^^^^^^^
BrokenPipeError: [Errno 32] Broken pipe

INFO: Learning...
INFO: Hyperparameters: lr=0.0001, gamma=0.99, eps_start=0.9, eps_end=0.05, eps_decay=50000, batch_size=32, tau=0.005,hidden_layers=[128, 128], conv_layers=[]
INFO: Number of parameters: 30085
INFO: QNetwork(
  (conv_feature): Sequential()
  (fc_feature): Sequential(
    (0): Linear(in_features=100, out_features=128, bias=True)
    (1): ReLU()
    (2): Linear(in_features=128, out_features=128, bias=True)
    (3): ReLU()
    (4): Linear(in_features=128, out_features=5, bias=True)
  )
)
INFO: Hyperparameters: lr=0.0001, gamma=0.99, eps_start=0.9, eps_end=0.05, eps_decay=50000, batch_size=32, tau=0.005,hidden_layers=[128, 128], conv_layers=[]
INFO: Hyperparameters: lr=0.0001, gamma=0.99, eps_start=0.9, eps_end=0.05, eps_decay=50000, batch_size=32, tau=0.005,hidden_layers=[128, 128], conv_layers=[]
INFO: Number of parameters: 30085
INFO: QNetwork(
  (conv_feature): Sequential()
  (fc_feature): Sequential(
    (0): Linear(in_features=100, out_features=128, bias=True)
    (1): ReLU()
    (2): Linear(in_features=128, out_features=128, bias=True)
    (3): ReLU()
    (4): Linear(in_features=128, out_features=5, bias=True)
  )
)
INFO: Hyperparameters: lr=0.0001, gamma=0.99, eps_start=0.9, eps_end=0.05, eps_decay=50000, batch_size=32, tau=0.005,hidden_layers=[128, 128], conv_layers=[]
INFO: Hyperparameters: lr=0.0001, gamma=0.99, eps_start=0.9, eps_end=0.05, eps_decay=50000, batch_size=32, tau=0.005,hidden_layers=[128, 128], conv_layers=[]
INFO: Number of parameters: 30085
INFO: QNetwork(
  (conv_feature): Sequential()
  (fc_feature): Sequential(
    (0): Linear(in_features=100, out_features=128, bias=True)
    (1): ReLU()
    (2): Linear(in_features=128, out_features=128, bias=True)
    (3): ReLU()
    (4): Linear(in_features=128, out_features=5, bias=True)
  )
)
INFO: Hyperparameters: lr=0.0001, gamma=0.99, eps_start=0.9, eps_end=0.05, eps_decay=50000, batch_size=32, tau=0.005,hidden_layers=[128, 128], conv_layers=[]
INFO: Hyperparameters: lr=0.0001, gamma=0.99, eps_start=0.9, eps_end=0.05, eps_decay=50000, batch_size=32, tau=0.005,hidden_layers=[128, 128], conv_layers=[]
INFO: Number of parameters: 30085
INFO: QNetwork(
  (conv_feature): Sequential()
  (fc_feature): Sequential(
    (0): Linear(in_features=100, out_features=128, bias=True)
    (1): ReLU()
    (2): Linear(in_features=128, out_features=128, bias=True)
    (3): ReLU()
    (4): Linear(in_features=128, out_features=5, bias=True)
  )
)
INFO: Hyperparameters: lr=0.0001, gamma=0.99, eps_start=0.9, eps_end=0.05, eps_decay=50000, batch_size=32, tau=0.005,hidden_layers=[128, 128], conv_layers=[]
INFO: Learning...
INFO: Hyperparameters: lr=0.0001, gamma=0.99, eps_start=0.9, eps_end=0.05, eps_decay=50000, batch_size=32, tau=0.005,hidden_layers=[128, 128], conv_layers=[]
INFO: Number of parameters: 30085
INFO: QNetwork(
  (conv_feature): Sequential()
  (fc_feature): Sequential(
    (0): Linear(in_features=100, out_features=128, bias=True)
    (1): ReLU()
    (2): Linear(in_features=128, out_features=128, bias=True)
    (3): ReLU()
    (4): Linear(in_features=128, out_features=5, bias=True)
  )
)
INFO: Hyperparameters: lr=0.0001, gamma=0.99, eps_start=0.9, eps_end=0.05, eps_decay=50000, batch_size=32, tau=0.005,hidden_layers=[128, 128], conv_layers=[]
ERROR: [Errno 32] Broken pipe
ERROR: Traceback (most recent call last):
  File "/home/eirik/Projects/XAI/rl/src/dqn/wrapper/multi_agent_dqn.py", line 110, in learn
    self.wandb_manager.log(log)
  File "/home/eirik/Projects/XAI/rl/src/managers/wandb_manager.py", line 89, in log
    wandb.log(data, commit=False)
  File "/home/eirik/.cache/pypoetry/virtualenvs/xai-is73Zs3s-py3.11/lib/python3.11/site-packages/wandb/sdk/wandb_run.py", line 452, in wrapper
    return func(self, *args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/eirik/.cache/pypoetry/virtualenvs/xai-is73Zs3s-py3.11/lib/python3.11/site-packages/wandb/sdk/wandb_run.py", line 403, in wrapper_fn
    return func(self, *args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/eirik/.cache/pypoetry/virtualenvs/xai-is73Zs3s-py3.11/lib/python3.11/site-packages/wandb/sdk/wandb_run.py", line 393, in wrapper
    return func(self, *args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/eirik/.cache/pypoetry/virtualenvs/xai-is73Zs3s-py3.11/lib/python3.11/site-packages/wandb/sdk/wandb_run.py", line 1933, in log
    self._log(data=data, step=step, commit=commit)
  File "/home/eirik/.cache/pypoetry/virtualenvs/xai-is73Zs3s-py3.11/lib/python3.11/site-packages/wandb/sdk/wandb_run.py", line 1652, in _log
    self._partial_history_callback(data, step, commit)
  File "/home/eirik/.cache/pypoetry/virtualenvs/xai-is73Zs3s-py3.11/lib/python3.11/site-packages/wandb/sdk/wandb_run.py", line 1524, in _partial_history_callback
    self._backend.interface.publish_partial_history(
  File "/home/eirik/.cache/pypoetry/virtualenvs/xai-is73Zs3s-py3.11/lib/python3.11/site-packages/wandb/sdk/interface/interface.py", line 647, in publish_partial_history
    self._publish_partial_history(partial_history)
  File "/home/eirik/.cache/pypoetry/virtualenvs/xai-is73Zs3s-py3.11/lib/python3.11/site-packages/wandb/sdk/interface/interface_shared.py", line 89, in _publish_partial_history
    self._publish(rec)
  File "/home/eirik/.cache/pypoetry/virtualenvs/xai-is73Zs3s-py3.11/lib/python3.11/site-packages/wandb/sdk/interface/interface_sock.py", line 51, in _publish
    self._sock_client.send_record_publish(record)
  File "/home/eirik/.cache/pypoetry/virtualenvs/xai-is73Zs3s-py3.11/lib/python3.11/site-packages/wandb/sdk/lib/sock_client.py", line 225, in send_record_publish
    self.send_server_request(server_req)
  File "/home/eirik/.cache/pypoetry/virtualenvs/xai-is73Zs3s-py3.11/lib/python3.11/site-packages/wandb/sdk/lib/sock_client.py", line 157, in send_server_request
    self._send_message(msg)
  File "/home/eirik/.cache/pypoetry/virtualenvs/xai-is73Zs3s-py3.11/lib/python3.11/site-packages/wandb/sdk/lib/sock_client.py", line 154, in _send_message
    self._sendall_with_error_handle(header + data)
  File "/home/eirik/.cache/pypoetry/virtualenvs/xai-is73Zs3s-py3.11/lib/python3.11/site-packages/wandb/sdk/lib/sock_client.py", line 132, in _sendall_with_error_handle
    sent = self._sock.send(data)
           ^^^^^^^^^^^^^^^^^^^^^
BrokenPipeError: [Errno 32] Broken pipe

INFO: Learning...
INFO: Hyperparameters: lr=0.0001, gamma=0.99, eps_start=0.9, eps_end=0.05, eps_decay=50000, batch_size=32, tau=0.005,hidden_layers=[128, 128], conv_layers=[]
INFO: Number of parameters: 18052
INFO: QNetwork(
  (conv_feature): Sequential()
  (fc_feature): Sequential(
    (0): Linear(in_features=7, out_features=128, bias=True)
    (1): ReLU()
    (2): Linear(in_features=128, out_features=128, bias=True)
    (3): ReLU()
    (4): Linear(in_features=128, out_features=4, bias=True)
  )
)
ERROR: Error: Could not load model with artifact: eirikreiestad-ntnu/maze-v0-local/model_200:latest
ERROR: Error: artifact 'model_200:latest' not found in 'eirikreiestad-ntnu/maze-v0-local'
INFO: Hyperparameters: lr=0.0001, gamma=0.99, eps_start=0.9, eps_end=0.05, eps_decay=50000, batch_size=32, tau=0.005,hidden_layers=[128, 128], conv_layers=[]
INFO: Number of parameters: 18052
INFO: QNetwork(
  (conv_feature): Sequential()
  (fc_feature): Sequential(
    (0): Linear(in_features=7, out_features=128, bias=True)
    (1): ReLU()
    (2): Linear(in_features=128, out_features=128, bias=True)
    (3): ReLU()
    (4): Linear(in_features=128, out_features=4, bias=True)
  )
)
WARNING: No frames in gif to save.
WARNING: Error: The file assets/gifs/dqn.gif does not exist or is empty.
INFO: Hyperparameters: lr=0.0001, gamma=0.99, eps_start=0.9, eps_end=0.05, eps_decay=50000, batch_size=32, tau=0.005,hidden_layers=[128, 128], conv_layers=[]
INFO: Number of parameters: 18052
INFO: QNetwork(
  (conv_feature): Sequential()
  (fc_feature): Sequential(
    (0): Linear(in_features=7, out_features=128, bias=True)
    (1): ReLU()
    (2): Linear(in_features=128, out_features=128, bias=True)
    (3): ReLU()
    (4): Linear(in_features=128, out_features=4, bias=True)
  )
)
WARNING: No frames in gif to save.
WARNING: Error: The file assets/gifs/dqn.gif does not exist or is empty.
INFO: Hyperparameters: lr=0.0001, gamma=0.99, eps_start=0.9, eps_end=0.05, eps_decay=50000, batch_size=32, tau=0.005,hidden_layers=[128, 128], conv_layers=[]
INFO: Number of parameters: 18052
INFO: QNetwork(
  (conv_feature): Sequential()
  (fc_feature): Sequential(
    (0): Linear(in_features=7, out_features=128, bias=True)
    (1): ReLU()
    (2): Linear(in_features=128, out_features=128, bias=True)
    (3): ReLU()
    (4): Linear(in_features=128, out_features=4, bias=True)
  )
)
INFO: Hyperparameters: lr=0.0001, gamma=0.99, eps_start=0.9, eps_end=0.05, eps_decay=50000, batch_size=32, tau=0.005,hidden_layers=[128, 128], conv_layers=[]
INFO: Number of parameters: 18052
INFO: QNetwork(
  (conv_feature): Sequential()
  (fc_feature): Sequential(
    (0): Linear(in_features=7, out_features=128, bias=True)
    (1): ReLU()
    (2): Linear(in_features=128, out_features=128, bias=True)
    (3): ReLU()
    (4): Linear(in_features=128, out_features=4, bias=True)
  )
)
WARNING: No frames in gif to save.
WARNING: Error: The file assets/gifs/dqn.gif does not exist or is empty.
WARNING: No frames in gif to save.
WARNING: Error: The file assets/gifs/dqn.gif does not exist or is empty.
WARNING: No frames in gif to save.
WARNING: Error: The file assets/gifs/dqn.gif does not exist or is empty.
INFO: Hyperparameters: lr=0.0001, gamma=0.99, eps_start=0.9, eps_end=0.05, eps_decay=50000, batch_size=32, tau=0.005,hidden_layers=[128, 128], conv_layers=[]
INFO: Number of parameters: 30085
INFO: QNetwork(
  (conv_feature): Sequential()
  (fc_feature): Sequential(
    (0): Linear(in_features=100, out_features=128, bias=True)
    (1): ReLU()
    (2): Linear(in_features=128, out_features=128, bias=True)
    (3): ReLU()
    (4): Linear(in_features=128, out_features=5, bias=True)
  )
)
INFO: Hyperparameters: lr=0.0001, gamma=0.99, eps_start=0.9, eps_end=0.05, eps_decay=50000, batch_size=32, tau=0.005,hidden_layers=[128, 128], conv_layers=[]
INFO: Learning...
INFO: Hyperparameters: lr=0.0001, gamma=0.99, eps_start=0.9, eps_end=0.05, eps_decay=50000, batch_size=32, tau=0.005,hidden_layers=[128, 128], conv_layers=[]
INFO: Number of parameters: 30085
INFO: QNetwork(
  (conv_feature): Sequential()
  (fc_feature): Sequential(
    (0): Linear(in_features=100, out_features=128, bias=True)
    (1): ReLU()
    (2): Linear(in_features=128, out_features=128, bias=True)
    (3): ReLU()
    (4): Linear(in_features=128, out_features=5, bias=True)
  )
)
INFO: Hyperparameters: lr=0.0001, gamma=0.99, eps_start=0.9, eps_end=0.05, eps_decay=50000, batch_size=32, tau=0.005,hidden_layers=[128, 128], conv_layers=[]
INFO: Learning...
ERROR: [Errno 32] Broken pipe
ERROR: Traceback (most recent call last):
  File "/home/eirik/Projects/XAI/rl/src/dqn/wrapper/multi_agent_dqn.py", line 109, in learn
    self.wandb_manager.log(log)
  File "/home/eirik/Projects/XAI/rl/src/managers/wandb_manager.py", line 89, in log
    wandb.log(data, commit=False)
  File "/home/eirik/.cache/pypoetry/virtualenvs/xai-is73Zs3s-py3.11/lib/python3.11/site-packages/wandb/sdk/wandb_run.py", line 452, in wrapper
    return func(self, *args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/eirik/.cache/pypoetry/virtualenvs/xai-is73Zs3s-py3.11/lib/python3.11/site-packages/wandb/sdk/wandb_run.py", line 403, in wrapper_fn
    return func(self, *args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/eirik/.cache/pypoetry/virtualenvs/xai-is73Zs3s-py3.11/lib/python3.11/site-packages/wandb/sdk/wandb_run.py", line 393, in wrapper
    return func(self, *args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/eirik/.cache/pypoetry/virtualenvs/xai-is73Zs3s-py3.11/lib/python3.11/site-packages/wandb/sdk/wandb_run.py", line 1933, in log
    self._log(data=data, step=step, commit=commit)
  File "/home/eirik/.cache/pypoetry/virtualenvs/xai-is73Zs3s-py3.11/lib/python3.11/site-packages/wandb/sdk/wandb_run.py", line 1652, in _log
    self._partial_history_callback(data, step, commit)
  File "/home/eirik/.cache/pypoetry/virtualenvs/xai-is73Zs3s-py3.11/lib/python3.11/site-packages/wandb/sdk/wandb_run.py", line 1524, in _partial_history_callback
    self._backend.interface.publish_partial_history(
  File "/home/eirik/.cache/pypoetry/virtualenvs/xai-is73Zs3s-py3.11/lib/python3.11/site-packages/wandb/sdk/interface/interface.py", line 647, in publish_partial_history
    self._publish_partial_history(partial_history)
  File "/home/eirik/.cache/pypoetry/virtualenvs/xai-is73Zs3s-py3.11/lib/python3.11/site-packages/wandb/sdk/interface/interface_shared.py", line 89, in _publish_partial_history
    self._publish(rec)
  File "/home/eirik/.cache/pypoetry/virtualenvs/xai-is73Zs3s-py3.11/lib/python3.11/site-packages/wandb/sdk/interface/interface_sock.py", line 51, in _publish
    self._sock_client.send_record_publish(record)
  File "/home/eirik/.cache/pypoetry/virtualenvs/xai-is73Zs3s-py3.11/lib/python3.11/site-packages/wandb/sdk/lib/sock_client.py", line 225, in send_record_publish
    self.send_server_request(server_req)
  File "/home/eirik/.cache/pypoetry/virtualenvs/xai-is73Zs3s-py3.11/lib/python3.11/site-packages/wandb/sdk/lib/sock_client.py", line 157, in send_server_request
    self._send_message(msg)
  File "/home/eirik/.cache/pypoetry/virtualenvs/xai-is73Zs3s-py3.11/lib/python3.11/site-packages/wandb/sdk/lib/sock_client.py", line 154, in _send_message
    self._sendall_with_error_handle(header + data)
  File "/home/eirik/.cache/pypoetry/virtualenvs/xai-is73Zs3s-py3.11/lib/python3.11/site-packages/wandb/sdk/lib/sock_client.py", line 132, in _sendall_with_error_handle
    sent = self._sock.send(data)
           ^^^^^^^^^^^^^^^^^^^^^
BrokenPipeError: [Errno 32] Broken pipe

INFO: Hyperparameters: lr=0.0001, gamma=0.99, eps_start=0.9, eps_end=0.05, eps_decay=50000, batch_size=32, tau=0.005,hidden_layers=[128, 128], conv_layers=[]
INFO: Number of parameters: 30085
INFO: QNetwork(
  (conv_feature): Sequential()
  (fc_feature): Sequential(
    (0): Linear(in_features=100, out_features=128, bias=True)
    (1): ReLU()
    (2): Linear(in_features=128, out_features=128, bias=True)
    (3): ReLU()
    (4): Linear(in_features=128, out_features=5, bias=True)
  )
)
INFO: Hyperparameters: lr=0.0001, gamma=0.99, eps_start=0.9, eps_end=0.05, eps_decay=50000, batch_size=32, tau=0.005,hidden_layers=[128, 128], conv_layers=[]
INFO: Learning...
ERROR: [Errno 32] Broken pipe
ERROR: Traceback (most recent call last):
  File "/home/eirik/Projects/XAI/rl/src/dqn/wrapper/multi_agent_dqn.py", line 109, in learn
    self.wandb_manager.log(log)
  File "/home/eirik/Projects/XAI/rl/src/managers/wandb_manager.py", line 89, in log
    wandb.log(data, commit=False)
  File "/home/eirik/.cache/pypoetry/virtualenvs/xai-is73Zs3s-py3.11/lib/python3.11/site-packages/wandb/sdk/wandb_run.py", line 452, in wrapper
    return func(self, *args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/eirik/.cache/pypoetry/virtualenvs/xai-is73Zs3s-py3.11/lib/python3.11/site-packages/wandb/sdk/wandb_run.py", line 403, in wrapper_fn
    return func(self, *args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/eirik/.cache/pypoetry/virtualenvs/xai-is73Zs3s-py3.11/lib/python3.11/site-packages/wandb/sdk/wandb_run.py", line 393, in wrapper
    return func(self, *args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/eirik/.cache/pypoetry/virtualenvs/xai-is73Zs3s-py3.11/lib/python3.11/site-packages/wandb/sdk/wandb_run.py", line 1933, in log
    self._log(data=data, step=step, commit=commit)
  File "/home/eirik/.cache/pypoetry/virtualenvs/xai-is73Zs3s-py3.11/lib/python3.11/site-packages/wandb/sdk/wandb_run.py", line 1652, in _log
    self._partial_history_callback(data, step, commit)
  File "/home/eirik/.cache/pypoetry/virtualenvs/xai-is73Zs3s-py3.11/lib/python3.11/site-packages/wandb/sdk/wandb_run.py", line 1524, in _partial_history_callback
    self._backend.interface.publish_partial_history(
  File "/home/eirik/.cache/pypoetry/virtualenvs/xai-is73Zs3s-py3.11/lib/python3.11/site-packages/wandb/sdk/interface/interface.py", line 647, in publish_partial_history
    self._publish_partial_history(partial_history)
  File "/home/eirik/.cache/pypoetry/virtualenvs/xai-is73Zs3s-py3.11/lib/python3.11/site-packages/wandb/sdk/interface/interface_shared.py", line 89, in _publish_partial_history
    self._publish(rec)
  File "/home/eirik/.cache/pypoetry/virtualenvs/xai-is73Zs3s-py3.11/lib/python3.11/site-packages/wandb/sdk/interface/interface_sock.py", line 51, in _publish
    self._sock_client.send_record_publish(record)
  File "/home/eirik/.cache/pypoetry/virtualenvs/xai-is73Zs3s-py3.11/lib/python3.11/site-packages/wandb/sdk/lib/sock_client.py", line 225, in send_record_publish
    self.send_server_request(server_req)
  File "/home/eirik/.cache/pypoetry/virtualenvs/xai-is73Zs3s-py3.11/lib/python3.11/site-packages/wandb/sdk/lib/sock_client.py", line 157, in send_server_request
    self._send_message(msg)
  File "/home/eirik/.cache/pypoetry/virtualenvs/xai-is73Zs3s-py3.11/lib/python3.11/site-packages/wandb/sdk/lib/sock_client.py", line 154, in _send_message
    self._sendall_with_error_handle(header + data)
  File "/home/eirik/.cache/pypoetry/virtualenvs/xai-is73Zs3s-py3.11/lib/python3.11/site-packages/wandb/sdk/lib/sock_client.py", line 132, in _sendall_with_error_handle
    sent = self._sock.send(data)
           ^^^^^^^^^^^^^^^^^^^^^
BrokenPipeError: [Errno 32] Broken pipe

INFO: Hyperparameters: lr=0.0001, gamma=0.99, eps_start=0.9, eps_end=0.05, eps_decay=50000, batch_size=32, tau=0.005,hidden_layers=[128, 128], conv_layers=[]
INFO: Number of parameters: 30085
INFO: QNetwork(
  (conv_feature): Sequential()
  (fc_feature): Sequential(
    (0): Linear(in_features=100, out_features=128, bias=True)
    (1): ReLU()
    (2): Linear(in_features=128, out_features=128, bias=True)
    (3): ReLU()
    (4): Linear(in_features=128, out_features=5, bias=True)
  )
)
INFO: Hyperparameters: lr=0.0001, gamma=0.99, eps_start=0.9, eps_end=0.05, eps_decay=50000, batch_size=32, tau=0.005,hidden_layers=[128, 128], conv_layers=[]
INFO: Learning...
INFO: Hyperparameters: lr=0.0001, gamma=0.99, eps_start=0.9, eps_end=0.05, eps_decay=50000, batch_size=32, tau=0.005,hidden_layers=[128, 128], conv_layers=[]
INFO: Number of parameters: 30085
INFO: QNetwork(
  (conv_feature): Sequential()
  (fc_feature): Sequential(
    (0): Linear(in_features=100, out_features=128, bias=True)
    (1): ReLU()
    (2): Linear(in_features=128, out_features=128, bias=True)
    (3): ReLU()
    (4): Linear(in_features=128, out_features=5, bias=True)
  )
)
INFO: Hyperparameters: lr=0.0001, gamma=0.99, eps_start=0.9, eps_end=0.05, eps_decay=50000, batch_size=32, tau=0.005,hidden_layers=[128, 128], conv_layers=[]
INFO: Learning...
INFO: Hyperparameters: lr=0.0001, gamma=0.99, eps_start=0.9, eps_end=0.05, eps_decay=50000, batch_size=32, tau=0.005,hidden_layers=[128, 128], conv_layers=[]
INFO: Number of parameters: 30085
INFO: QNetwork(
  (conv_feature): Sequential()
  (fc_feature): Sequential(
    (0): Linear(in_features=100, out_features=128, bias=True)
    (1): ReLU()
    (2): Linear(in_features=128, out_features=128, bias=True)
    (3): ReLU()
    (4): Linear(in_features=128, out_features=5, bias=True)
  )
)
INFO: Hyperparameters: lr=0.0001, gamma=0.99, eps_start=0.9, eps_end=0.05, eps_decay=50000, batch_size=32, tau=0.005,hidden_layers=[128, 128], conv_layers=[]
INFO: Learning...
INFO: Hyperparameters: lr=0.0001, gamma=0.99, eps_start=0.9, eps_end=0.05, eps_decay=50000, batch_size=32, tau=0.005,hidden_layers=[128, 128], conv_layers=[]
INFO: Number of parameters: 30085
INFO: QNetwork(
  (conv_feature): Sequential()
  (fc_feature): Sequential(
    (0): Linear(in_features=100, out_features=128, bias=True)
    (1): ReLU()
    (2): Linear(in_features=128, out_features=128, bias=True)
    (3): ReLU()
    (4): Linear(in_features=128, out_features=5, bias=True)
  )
)
INFO: Hyperparameters: lr=0.0001, gamma=0.99, eps_start=0.9, eps_end=0.05, eps_decay=50000, batch_size=32, tau=0.005,hidden_layers=[128, 128], conv_layers=[]
INFO: Learning...
INFO: Hyperparameters: lr=0.0001, gamma=0.99, eps_start=0.9, eps_end=0.05, eps_decay=50000, batch_size=32, tau=0.005,hidden_layers=[128, 128], conv_layers=[]
INFO: Number of parameters: 30085
INFO: QNetwork(
  (conv_feature): Sequential()
  (fc_feature): Sequential(
    (0): Linear(in_features=100, out_features=128, bias=True)
    (1): ReLU()
    (2): Linear(in_features=128, out_features=128, bias=True)
    (3): ReLU()
    (4): Linear(in_features=128, out_features=5, bias=True)
  )
)
INFO: Hyperparameters: lr=0.0001, gamma=0.99, eps_start=0.9, eps_end=0.05, eps_decay=50000, batch_size=32, tau=0.005,hidden_layers=[128, 128], conv_layers=[]
INFO: Learning...
INFO: Hyperparameters: lr=0.0001, gamma=0.99, eps_start=0.9, eps_end=0.05, eps_decay=50000, batch_size=32, tau=0.005,hidden_layers=[128, 128], conv_layers=[]
INFO: Number of parameters: 30085
INFO: QNetwork(
  (conv_feature): Sequential()
  (fc_feature): Sequential(
    (0): Linear(in_features=100, out_features=128, bias=True)
    (1): ReLU()
    (2): Linear(in_features=128, out_features=128, bias=True)
    (3): ReLU()
    (4): Linear(in_features=128, out_features=5, bias=True)
  )
)
INFO: Hyperparameters: lr=0.0001, gamma=0.99, eps_start=0.9, eps_end=0.05, eps_decay=50000, batch_size=32, tau=0.005,hidden_layers=[128, 128], conv_layers=[]
INFO: Learning...
INFO: Hyperparameters: lr=0.0001, gamma=0.99, eps_start=0.9, eps_end=0.05, eps_decay=50000, batch_size=32, tau=0.005,hidden_layers=[128, 128], conv_layers=[]
INFO: Number of parameters: 30085
INFO: QNetwork(
  (conv_feature): Sequential()
  (fc_feature): Sequential(
    (0): Linear(in_features=100, out_features=128, bias=True)
    (1): ReLU()
    (2): Linear(in_features=128, out_features=128, bias=True)
    (3): ReLU()
    (4): Linear(in_features=128, out_features=5, bias=True)
  )
)
INFO: Hyperparameters: lr=0.0001, gamma=0.99, eps_start=0.9, eps_end=0.05, eps_decay=50000, batch_size=32, tau=0.005,hidden_layers=[128, 128], conv_layers=[]
INFO: Learning...
INFO: BootcampName.HIDER Bootcamp completed, starting BootcampName.SEEKER Bootcamp #0 for 500 days
INFO: BootcampName.SEEKER Bootcamp completed, starting BootcampName.SLOW_AGENT Bootcamp #0 for 1000 days
INFO: Continuing with Bootcamp #0 BootcampName.SLOW_AGENT with slow factor: 9 for agent 1
INFO: Continuing with Bootcamp #0 BootcampName.SLOW_AGENT with slow factor: 9 for agent 0
INFO: Continuing with Bootcamp #0 BootcampName.SLOW_AGENT with slow factor: 8 for agent 1
INFO: Hyperparameters: lr=0.0001, gamma=0.99, eps_start=0.9, eps_end=0.05, eps_decay=50000, batch_size=32, tau=0.005,hidden_layers=[128, 128], conv_layers=[]
INFO: Number of parameters: 30085
INFO: QNetwork(
  (conv_feature): Sequential()
  (fc_feature): Sequential(
    (0): Linear(in_features=100, out_features=128, bias=True)
    (1): ReLU()
    (2): Linear(in_features=128, out_features=128, bias=True)
    (3): ReLU()
    (4): Linear(in_features=128, out_features=5, bias=True)
  )
)
INFO: Hyperparameters: lr=0.0001, gamma=0.99, eps_start=0.9, eps_end=0.05, eps_decay=50000, batch_size=32, tau=0.005,hidden_layers=[128, 128], conv_layers=[]
INFO: Learning...
INFO: BootcampName.HIDER Bootcamp completed, starting BootcampName.SEEKER Bootcamp #0 for 500 days
INFO: BootcampName.SEEKER Bootcamp completed, starting BootcampName.SLOW_AGENT Bootcamp #0 for 1000 days
INFO: Continuing with Bootcamp #0 BootcampName.SLOW_AGENT with slow factor: 9 for agent 1
INFO: Continuing with Bootcamp #0 BootcampName.SLOW_AGENT with slow factor: 9 for agent 0
INFO: Continuing with Bootcamp #0 BootcampName.SLOW_AGENT with slow factor: 8 for agent 1
INFO: Hyperparameters: lr=0.0001, gamma=0.99, eps_start=0.9, eps_end=0.05, eps_decay=50000, batch_size=32, tau=0.005,hidden_layers=[128, 128], conv_layers=[]
INFO: Number of parameters: 30085
INFO: QNetwork(
  (conv_feature): Sequential()
  (fc_feature): Sequential(
    (0): Linear(in_features=100, out_features=128, bias=True)
    (1): ReLU()
    (2): Linear(in_features=128, out_features=128, bias=True)
    (3): ReLU()
    (4): Linear(in_features=128, out_features=5, bias=True)
  )
)
INFO: Hyperparameters: lr=0.0001, gamma=0.99, eps_start=0.9, eps_end=0.05, eps_decay=50000, batch_size=32, tau=0.005,hidden_layers=[128, 128], conv_layers=[]
INFO: Learning...
INFO: Hyperparameters: lr=0.0001, gamma=0.99, eps_start=0.9, eps_end=0.05, eps_decay=50000, batch_size=32, tau=0.005,hidden_layers=[128, 128], conv_layers=[]
INFO: Number of parameters: 30085
INFO: QNetwork(
  (conv_feature): Sequential()
  (fc_feature): Sequential(
    (0): Linear(in_features=100, out_features=128, bias=True)
    (1): ReLU()
    (2): Linear(in_features=128, out_features=128, bias=True)
    (3): ReLU()
    (4): Linear(in_features=128, out_features=5, bias=True)
  )
)
INFO: Hyperparameters: lr=0.0001, gamma=0.99, eps_start=0.9, eps_end=0.05, eps_decay=50000, batch_size=32, tau=0.005,hidden_layers=[128, 128], conv_layers=[]
INFO: Learning...
INFO: BootcampName.HIDER Bootcamp completed, starting BootcampName.SEEKER Bootcamp #0 for 500 days
INFO: BootcampName.SEEKER Bootcamp completed, starting BootcampName.SLOW_AGENT Bootcamp #0 for 1000 days
INFO: Continuing with Bootcamp #0 BootcampName.SLOW_AGENT with slow factor: 9 for agent 1
INFO: Continuing with Bootcamp #0 BootcampName.SLOW_AGENT with slow factor: 9 for agent 0
INFO: Continuing with Bootcamp #0 BootcampName.SLOW_AGENT with slow factor: 8 for agent 1
INFO: Continuing with Bootcamp #0 BootcampName.SLOW_AGENT with slow factor: 8 for agent 0
INFO: Continuing with Bootcamp #0 BootcampName.SLOW_AGENT with slow factor: 7 for agent 1
INFO: Continuing with Bootcamp #0 BootcampName.SLOW_AGENT with slow factor: 7 for agent 0
INFO: Continuing with Bootcamp #0 BootcampName.SLOW_AGENT with slow factor: 6 for agent 1
INFO: Continuing with Bootcamp #0 BootcampName.SLOW_AGENT with slow factor: 6 for agent 0
INFO: Continuing with Bootcamp #0 BootcampName.SLOW_AGENT with slow factor: 5 for agent 1
INFO: Continuing with Bootcamp #0 BootcampName.SLOW_AGENT with slow factor: 5 for agent 0
INFO: Hyperparameters: lr=0.0001, gamma=0.99, eps_start=0.9, eps_end=0.05, eps_decay=50000, batch_size=32, tau=0.005,hidden_layers=[128, 128], conv_layers=[]
INFO: Number of parameters: 30085
INFO: QNetwork(
  (conv_feature): Sequential()
  (fc_feature): Sequential(
    (0): Linear(in_features=100, out_features=128, bias=True)
    (1): ReLU()
    (2): Linear(in_features=128, out_features=128, bias=True)
    (3): ReLU()
    (4): Linear(in_features=128, out_features=5, bias=True)
  )
)
INFO: Hyperparameters: lr=0.0001, gamma=0.99, eps_start=0.9, eps_end=0.05, eps_decay=50000, batch_size=32, tau=0.005,hidden_layers=[128, 128], conv_layers=[]
INFO: Learning...
INFO: BootcampName.HIDER Bootcamp completed, starting BootcampName.SEEKER Bootcamp #0 for 500 days
INFO: BootcampName.SEEKER Bootcamp completed, starting BootcampName.SLOW_AGENT Bootcamp #0 for 1000 days
INFO: Continuing with Bootcamp #0 BootcampName.SLOW_AGENT with slow factor: 9 for agent 1
INFO: Continuing with Bootcamp #0 BootcampName.SLOW_AGENT with slow factor: 9 for agent 0
INFO: Continuing with Bootcamp #0 BootcampName.SLOW_AGENT with slow factor: 8 for agent 1
INFO: Continuing with Bootcamp #0 BootcampName.SLOW_AGENT with slow factor: 8 for agent 0
INFO: Continuing with Bootcamp #0 BootcampName.SLOW_AGENT with slow factor: 7 for agent 1
INFO: Continuing with Bootcamp #0 BootcampName.SLOW_AGENT with slow factor: 7 for agent 0
INFO: Continuing with Bootcamp #0 BootcampName.SLOW_AGENT with slow factor: 6 for agent 1
INFO: Continuing with Bootcamp #0 BootcampName.SLOW_AGENT with slow factor: 6 for agent 0
INFO: Continuing with Bootcamp #0 BootcampName.SLOW_AGENT with slow factor: 5 for agent 1
INFO: Continuing with Bootcamp #0 BootcampName.SLOW_AGENT with slow factor: 5 for agent 0
INFO: Continuing with Bootcamp #0 BootcampName.SLOW_AGENT with slow factor: 4 for agent 1
INFO: Continuing with Bootcamp #0 BootcampName.SLOW_AGENT with slow factor: 4 for agent 0
INFO: Continuing with Bootcamp #0 BootcampName.SLOW_AGENT with slow factor: 3 for agent 1
INFO: Continuing with Bootcamp #0 BootcampName.SLOW_AGENT with slow factor: 3 for agent 0
INFO: Continuing with Bootcamp #0 BootcampName.SLOW_AGENT with slow factor: 2 for agent 1
INFO: Continuing with Bootcamp #0 BootcampName.SLOW_AGENT with slow factor: 2 for agent 0
INFO: BootcampName.SLOW_AGENT Bootcamp completed, starting BootcampName.COMBINED Bootcamp #0 for 1000 days
INFO: BootcampName.COMBINED Bootcamp completed, starting BootcampName.FINISHED Bootcamp #0 for 0 days
INFO: Hyperparameters: lr=0.0001, gamma=0.99, eps_start=0.9, eps_end=0.05, eps_decay=50000, batch_size=32, tau=0.005,hidden_layers=[128, 128], conv_layers=[]
INFO: Number of parameters: 30085
INFO: QNetwork(
  (conv_feature): Sequential()
  (fc_feature): Sequential(
    (0): Linear(in_features=100, out_features=128, bias=True)
    (1): ReLU()
    (2): Linear(in_features=128, out_features=128, bias=True)
    (3): ReLU()
    (4): Linear(in_features=128, out_features=5, bias=True)
  )
)
INFO: Hyperparameters: lr=0.0001, gamma=0.99, eps_start=0.9, eps_end=0.05, eps_decay=50000, batch_size=32, tau=0.005,hidden_layers=[128, 128], conv_layers=[]
INFO: Learning...
INFO: BootcampName.HIDER Bootcamp completed, starting BootcampName.SEEKER Bootcamp #0 for 100 days
INFO: BootcampName.SEEKER Bootcamp completed, starting BootcampName.SLOW_AGENT Bootcamp #0 for 100 days
INFO: Continuing with Bootcamp #0 BootcampName.SLOW_AGENT with slow factor: 9 for agent 1
INFO: Continuing with Bootcamp #0 BootcampName.SLOW_AGENT with slow factor: 9 for agent 0
INFO: Continuing with Bootcamp #0 BootcampName.SLOW_AGENT with slow factor: 8 for agent 1
INFO: Continuing with Bootcamp #0 BootcampName.SLOW_AGENT with slow factor: 8 for agent 0
INFO: Continuing with Bootcamp #0 BootcampName.SLOW_AGENT with slow factor: 7 for agent 1
INFO: Continuing with Bootcamp #0 BootcampName.SLOW_AGENT with slow factor: 7 for agent 0
INFO: Continuing with Bootcamp #0 BootcampName.SLOW_AGENT with slow factor: 6 for agent 1
INFO: Continuing with Bootcamp #0 BootcampName.SLOW_AGENT with slow factor: 6 for agent 0
INFO: Continuing with Bootcamp #0 BootcampName.SLOW_AGENT with slow factor: 5 for agent 1
INFO: Continuing with Bootcamp #0 BootcampName.SLOW_AGENT with slow factor: 5 for agent 0
INFO: Continuing with Bootcamp #0 BootcampName.SLOW_AGENT with slow factor: 4 for agent 1
INFO: Continuing with Bootcamp #0 BootcampName.SLOW_AGENT with slow factor: 4 for agent 0
INFO: Continuing with Bootcamp #0 BootcampName.SLOW_AGENT with slow factor: 3 for agent 1
INFO: Continuing with Bootcamp #0 BootcampName.SLOW_AGENT with slow factor: 3 for agent 0
INFO: Continuing with Bootcamp #0 BootcampName.SLOW_AGENT with slow factor: 2 for agent 1
INFO: Continuing with Bootcamp #0 BootcampName.SLOW_AGENT with slow factor: 2 for agent 0
INFO: BootcampName.SLOW_AGENT Bootcamp completed, starting BootcampName.COMBINED Bootcamp #0 for 100 days
INFO: BootcampName.COMBINED Bootcamp completed, starting BootcampName.FINISHED Bootcamp #0 for 0 days
INFO: Hyperparameters: lr=0.0001, gamma=0.99, eps_start=0.9, eps_end=0.05, eps_decay=50000, batch_size=32, tau=0.005,hidden_layers=[128, 128], conv_layers=[]
INFO: Number of parameters: 30085
INFO: QNetwork(
  (conv_feature): Sequential()
  (fc_feature): Sequential(
    (0): Linear(in_features=100, out_features=128, bias=True)
    (1): ReLU()
    (2): Linear(in_features=128, out_features=128, bias=True)
    (3): ReLU()
    (4): Linear(in_features=128, out_features=5, bias=True)
  )
)
INFO: Hyperparameters: lr=0.0001, gamma=0.99, eps_start=0.9, eps_end=0.05, eps_decay=50000, batch_size=32, tau=0.005,hidden_layers=[128, 128], conv_layers=[]
INFO: Learning...
INFO: BootcampName.HIDER Bootcamp completed, starting BootcampName.SEEKER Bootcamp #0 for 100 days
INFO: BootcampName.SEEKER Bootcamp completed, starting BootcampName.SLOW_AGENT Bootcamp #0 for 100 days
INFO: Continuing with Bootcamp #0 BootcampName.SLOW_AGENT with slow factor: 9 for agent 1
INFO: Continuing with Bootcamp #0 BootcampName.SLOW_AGENT with slow factor: 9 for agent 0
INFO: Continuing with Bootcamp #0 BootcampName.SLOW_AGENT with slow factor: 8 for agent 1
INFO: Continuing with Bootcamp #0 BootcampName.SLOW_AGENT with slow factor: 8 for agent 0
INFO: Continuing with Bootcamp #0 BootcampName.SLOW_AGENT with slow factor: 7 for agent 1
INFO: Continuing with Bootcamp #0 BootcampName.SLOW_AGENT with slow factor: 7 for agent 0
INFO: Continuing with Bootcamp #0 BootcampName.SLOW_AGENT with slow factor: 6 for agent 1
INFO: Continuing with Bootcamp #0 BootcampName.SLOW_AGENT with slow factor: 6 for agent 0
INFO: Continuing with Bootcamp #0 BootcampName.SLOW_AGENT with slow factor: 5 for agent 1
INFO: Continuing with Bootcamp #0 BootcampName.SLOW_AGENT with slow factor: 5 for agent 0
INFO: Continuing with Bootcamp #0 BootcampName.SLOW_AGENT with slow factor: 4 for agent 1
INFO: Continuing with Bootcamp #0 BootcampName.SLOW_AGENT with slow factor: 4 for agent 0
INFO: Continuing with Bootcamp #0 BootcampName.SLOW_AGENT with slow factor: 3 for agent 1
INFO: Continuing with Bootcamp #0 BootcampName.SLOW_AGENT with slow factor: 3 for agent 0
INFO: Continuing with Bootcamp #0 BootcampName.SLOW_AGENT with slow factor: 2 for agent 1
INFO: Continuing with Bootcamp #0 BootcampName.SLOW_AGENT with slow factor: 2 for agent 0
INFO: BootcampName.SLOW_AGENT Bootcamp completed, starting BootcampName.COMBINED Bootcamp #0 for 100 days
INFO: BootcampName.COMBINED Bootcamp completed, starting BootcampName.FINISHED Bootcamp #0 for 0 days
INFO: Hyperparameters: lr=0.0001, gamma=0.99, eps_start=0.9, eps_end=0.05, eps_decay=50000, batch_size=32, tau=0.005,hidden_layers=[128, 128], conv_layers=[]
INFO: Number of parameters: 30085
INFO: QNetwork(
  (conv_feature): Sequential()
  (fc_feature): Sequential(
    (0): Linear(in_features=100, out_features=128, bias=True)
    (1): ReLU()
    (2): Linear(in_features=128, out_features=128, bias=True)
    (3): ReLU()
    (4): Linear(in_features=128, out_features=5, bias=True)
  )
)
INFO: Hyperparameters: lr=0.0001, gamma=0.99, eps_start=0.9, eps_end=0.05, eps_decay=50000, batch_size=32, tau=0.005,hidden_layers=[128, 128], conv_layers=[]
INFO: Learning...
INFO: BootcampName.HIDER Bootcamp completed, starting BootcampName.SEEKER Bootcamp #0 for 100 days
INFO: BootcampName.SEEKER Bootcamp completed, starting BootcampName.SLOW_AGENT Bootcamp #0 for 100 days
INFO: Continuing with Bootcamp #0 BootcampName.SLOW_AGENT with slow factor: 9 for agent 1
INFO: Continuing with Bootcamp #0 BootcampName.SLOW_AGENT with slow factor: 9 for agent 0
INFO: Continuing with Bootcamp #0 BootcampName.SLOW_AGENT with slow factor: 8 for agent 1
INFO: Continuing with Bootcamp #0 BootcampName.SLOW_AGENT with slow factor: 8 for agent 0
INFO: Continuing with Bootcamp #0 BootcampName.SLOW_AGENT with slow factor: 7 for agent 1
INFO: Continuing with Bootcamp #0 BootcampName.SLOW_AGENT with slow factor: 7 for agent 0
INFO: Continuing with Bootcamp #0 BootcampName.SLOW_AGENT with slow factor: 6 for agent 1
INFO: Continuing with Bootcamp #0 BootcampName.SLOW_AGENT with slow factor: 6 for agent 0
INFO: Continuing with Bootcamp #0 BootcampName.SLOW_AGENT with slow factor: 5 for agent 1
INFO: BootcampName.HIDER Bootcamp completed, starting BootcampName.SEEKER Bootcamp #0 for 100 days
INFO: BootcampName.SEEKER Bootcamp completed, starting BootcampName.SLOW_AGENT Bootcamp #0 for 100 days
INFO: Continuing with Bootcamp #0 BootcampName.SLOW_AGENT with slow factor: 9 for agent 1
INFO: Continuing with Bootcamp #0 BootcampName.SLOW_AGENT with slow factor: 9 for agent 0
INFO: Continuing with Bootcamp #0 BootcampName.SLOW_AGENT with slow factor: 8 for agent 1
INFO: Continuing with Bootcamp #0 BootcampName.SLOW_AGENT with slow factor: 8 for agent 0
INFO: Continuing with Bootcamp #0 BootcampName.SLOW_AGENT with slow factor: 7 for agent 1
INFO: Continuing with Bootcamp #0 BootcampName.SLOW_AGENT with slow factor: 7 for agent 0
INFO: Continuing with Bootcamp #0 BootcampName.SLOW_AGENT with slow factor: 6 for agent 1
INFO: Continuing with Bootcamp #0 BootcampName.SLOW_AGENT with slow factor: 6 for agent 0
INFO: BootcampName.HIDER Bootcamp completed, starting BootcampName.SEEKER Bootcamp #0 for 100 days
INFO: BootcampName.SEEKER Bootcamp completed, starting BootcampName.SLOW_AGENT Bootcamp #0 for 100 days
INFO: Continuing with Bootcamp #0 BootcampName.SLOW_AGENT with slow factor: 9 for agent 1
INFO: Continuing with Bootcamp #0 BootcampName.SLOW_AGENT with slow factor: 9 for agent 0
INFO: Continuing with Bootcamp #0 BootcampName.SLOW_AGENT with slow factor: 8 for agent 1
INFO: Continuing with Bootcamp #0 BootcampName.SLOW_AGENT with slow factor: 8 for agent 0
INFO: Continuing with Bootcamp #0 BootcampName.SLOW_AGENT with slow factor: 7 for agent 1
INFO: Continuing with Bootcamp #0 BootcampName.SLOW_AGENT with slow factor: 7 for agent 0
INFO: Continuing with Bootcamp #0 BootcampName.SLOW_AGENT with slow factor: 6 for agent 1
INFO: Continuing with Bootcamp #0 BootcampName.SLOW_AGENT with slow factor: 6 for agent 0
INFO: Continuing with Bootcamp #0 BootcampName.SLOW_AGENT with slow factor: 5 for agent 1
INFO: BootcampName.HIDER Bootcamp completed, starting BootcampName.SEEKER Bootcamp #0 for 100 days
INFO: BootcampName.SEEKER Bootcamp completed, starting BootcampName.SLOW_AGENT Bootcamp #0 for 100 days
INFO: Continuing with Bootcamp #0 BootcampName.SLOW_AGENT with slow factor: 9 for agent 1
INFO: Continuing with Bootcamp #0 BootcampName.SLOW_AGENT with slow factor: 9 for agent 0
INFO: Continuing with Bootcamp #0 BootcampName.SLOW_AGENT with slow factor: 8 for agent 1
INFO: Continuing with Bootcamp #0 BootcampName.SLOW_AGENT with slow factor: 8 for agent 0
INFO: Continuing with Bootcamp #0 BootcampName.SLOW_AGENT with slow factor: 7 for agent 1
INFO: Continuing with Bootcamp #0 BootcampName.SLOW_AGENT with slow factor: 7 for agent 0
INFO: Continuing with Bootcamp #0 BootcampName.SLOW_AGENT with slow factor: 6 for agent 1
INFO: Continuing with Bootcamp #0 BootcampName.SLOW_AGENT with slow factor: 6 for agent 0
INFO: BootcampName.HIDER Bootcamp completed, starting BootcampName.SEEKER Bootcamp #0 for 100 days
INFO: BootcampName.SEEKER Bootcamp completed, starting BootcampName.SLOW_AGENT Bootcamp #0 for 100 days
INFO: Continuing with Bootcamp #0 BootcampName.SLOW_AGENT with slow factor: 9 for agent 1
INFO: Continuing with Bootcamp #0 BootcampName.SLOW_AGENT with slow factor: 9 for agent 0
INFO: Continuing with Bootcamp #0 BootcampName.SLOW_AGENT with slow factor: 8 for agent 1
INFO: Continuing with Bootcamp #0 BootcampName.SLOW_AGENT with slow factor: 8 for agent 0
INFO: Continuing with Bootcamp #0 BootcampName.SLOW_AGENT with slow factor: 7 for agent 1
INFO: Continuing with Bootcamp #0 BootcampName.SLOW_AGENT with slow factor: 7 for agent 0
INFO: Continuing with Bootcamp #0 BootcampName.SLOW_AGENT with slow factor: 6 for agent 1
INFO: Continuing with Bootcamp #0 BootcampName.SLOW_AGENT with slow factor: 6 for agent 0
INFO: Continuing with Bootcamp #0 BootcampName.SLOW_AGENT with slow factor: 5 for agent 1
INFO: BootcampName.HIDER Bootcamp completed, starting BootcampName.SEEKER Bootcamp #0 for 100 days
INFO: BootcampName.SEEKER Bootcamp completed, starting BootcampName.SLOW_AGENT Bootcamp #0 for 100 days
INFO: Continuing with Bootcamp #0 BootcampName.SLOW_AGENT with slow factor: 9 for agent 1
INFO: Continuing with Bootcamp #0 BootcampName.SLOW_AGENT with slow factor: 9 for agent 0
INFO: Continuing with Bootcamp #0 BootcampName.SLOW_AGENT with slow factor: 8 for agent 1
INFO: Continuing with Bootcamp #0 BootcampName.SLOW_AGENT with slow factor: 8 for agent 0
INFO: Continuing with Bootcamp #0 BootcampName.SLOW_AGENT with slow factor: 7 for agent 1
INFO: Continuing with Bootcamp #0 BootcampName.SLOW_AGENT with slow factor: 7 for agent 0
INFO: Continuing with Bootcamp #0 BootcampName.SLOW_AGENT with slow factor: 6 for agent 1
INFO: Continuing with Bootcamp #0 BootcampName.SLOW_AGENT with slow factor: 6 for agent 0
INFO: Continuing with Bootcamp #0 BootcampName.SLOW_AGENT with slow factor: 5 for agent 1
INFO: BootcampName.HIDER Bootcamp completed, starting BootcampName.SEEKER Bootcamp #0 for 100 days
INFO: BootcampName.SEEKER Bootcamp completed, starting BootcampName.SLOW_AGENT Bootcamp #0 for 100 days
INFO: Continuing with Bootcamp #0 BootcampName.SLOW_AGENT with slow factor: 9 for agent 1
INFO: Continuing with Bootcamp #0 BootcampName.SLOW_AGENT with slow factor: 9 for agent 0
INFO: Continuing with Bootcamp #0 BootcampName.SLOW_AGENT with slow factor: 8 for agent 1
INFO: Continuing with Bootcamp #0 BootcampName.SLOW_AGENT with slow factor: 8 for agent 0
INFO: Continuing with Bootcamp #0 BootcampName.SLOW_AGENT with slow factor: 7 for agent 1
INFO: Continuing with Bootcamp #0 BootcampName.SLOW_AGENT with slow factor: 7 for agent 0
INFO: Continuing with Bootcamp #0 BootcampName.SLOW_AGENT with slow factor: 6 for agent 1
INFO: Continuing with Bootcamp #0 BootcampName.SLOW_AGENT with slow factor: 6 for agent 0
INFO: Continuing with Bootcamp #0 BootcampName.SLOW_AGENT with slow factor: 5 for agent 1
INFO: BootcampName.HIDER Bootcamp completed, starting BootcampName.SEEKER Bootcamp #0 for 100 days
INFO: BootcampName.SEEKER Bootcamp completed, starting BootcampName.SLOW_AGENT Bootcamp #0 for 100 days
INFO: Continuing with Bootcamp #0 BootcampName.SLOW_AGENT with slow factor: 9 for agent 1
INFO: Continuing with Bootcamp #0 BootcampName.SLOW_AGENT with slow factor: 9 for agent 0
INFO: Continuing with Bootcamp #0 BootcampName.SLOW_AGENT with slow factor: 8 for agent 1
INFO: Continuing with Bootcamp #0 BootcampName.SLOW_AGENT with slow factor: 8 for agent 0
INFO: Continuing with Bootcamp #0 BootcampName.SLOW_AGENT with slow factor: 7 for agent 1
INFO: Continuing with Bootcamp #0 BootcampName.SLOW_AGENT with slow factor: 7 for agent 0
INFO: Continuing with Bootcamp #0 BootcampName.SLOW_AGENT with slow factor: 6 for agent 1
INFO: Continuing with Bootcamp #0 BootcampName.SLOW_AGENT with slow factor: 6 for agent 0
INFO: Continuing with Bootcamp #0 BootcampName.SLOW_AGENT with slow factor: 5 for agent 1
INFO: BootcampName.HIDER Bootcamp completed, starting BootcampName.SEEKER Bootcamp #0 for 100 days
INFO: BootcampName.SEEKER Bootcamp completed, starting BootcampName.SLOW_AGENT Bootcamp #0 for 100 days
INFO: Continuing with Bootcamp #0 BootcampName.SLOW_AGENT with slow factor: 9 for agent 1
INFO: Continuing with Bootcamp #0 BootcampName.SLOW_AGENT with slow factor: 9 for agent 0
INFO: Continuing with Bootcamp #0 BootcampName.SLOW_AGENT with slow factor: 8 for agent 1
INFO: Continuing with Bootcamp #0 BootcampName.SLOW_AGENT with slow factor: 8 for agent 0
INFO: Continuing with Bootcamp #0 BootcampName.SLOW_AGENT with slow factor: 7 for agent 1
INFO: Continuing with Bootcamp #0 BootcampName.SLOW_AGENT with slow factor: 7 for agent 0
INFO: Continuing with Bootcamp #0 BootcampName.SLOW_AGENT with slow factor: 6 for agent 1
INFO: Continuing with Bootcamp #0 BootcampName.SLOW_AGENT with slow factor: 6 for agent 0
INFO: Continuing with Bootcamp #0 BootcampName.SLOW_AGENT with slow factor: 5 for agent 1
INFO: BootcampName.HIDER Bootcamp completed, starting BootcampName.SEEKER Bootcamp #0 for 100 days
INFO: BootcampName.SEEKER Bootcamp completed, starting BootcampName.SLOW_AGENT Bootcamp #0 for 100 days
INFO: Continuing with Bootcamp #0 BootcampName.SLOW_AGENT with slow factor: 9 for agent 1
INFO: Continuing with Bootcamp #0 BootcampName.SLOW_AGENT with slow factor: 9 for agent 0
INFO: Continuing with Bootcamp #0 BootcampName.SLOW_AGENT with slow factor: 8 for agent 1
INFO: Continuing with Bootcamp #0 BootcampName.SLOW_AGENT with slow factor: 8 for agent 0
INFO: Continuing with Bootcamp #0 BootcampName.SLOW_AGENT with slow factor: 7 for agent 1
INFO: Continuing with Bootcamp #0 BootcampName.SLOW_AGENT with slow factor: 7 for agent 0
INFO: Continuing with Bootcamp #0 BootcampName.SLOW_AGENT with slow factor: 6 for agent 1
INFO: Continuing with Bootcamp #0 BootcampName.SLOW_AGENT with slow factor: 6 for agent 0
INFO: Continuing with Bootcamp #0 BootcampName.SLOW_AGENT with slow factor: 5 for agent 1
INFO: Hyperparameters: lr=0.0001, gamma=0.99, eps_start=0.9, eps_end=0.05, eps_decay=50000, batch_size=32, tau=0.005,hidden_layers=[128, 128], conv_layers=[]
INFO: Number of parameters: 30085
INFO: QNetwork(
  (conv_feature): Sequential()
  (fc_feature): Sequential(
    (0): Linear(in_features=100, out_features=128, bias=True)
    (1): ReLU()
    (2): Linear(in_features=128, out_features=128, bias=True)
    (3): ReLU()
    (4): Linear(in_features=128, out_features=5, bias=True)
  )
)
INFO: Hyperparameters: lr=0.0001, gamma=0.99, eps_start=0.9, eps_end=0.05, eps_decay=50000, batch_size=32, tau=0.005,hidden_layers=[128, 128], conv_layers=[]
INFO: Number of parameters: 30085
INFO: QNetwork(
  (conv_feature): Sequential()
  (fc_feature): Sequential(
    (0): Linear(in_features=100, out_features=128, bias=True)
    (1): ReLU()
    (2): Linear(in_features=128, out_features=128, bias=True)
    (3): ReLU()
    (4): Linear(in_features=128, out_features=5, bias=True)
  )
)
INFO: Hyperparameters: lr=0.0001, gamma=0.99, eps_start=0.9, eps_end=0.05, eps_decay=50000, batch_size=32, tau=0.005,hidden_layers=[128, 128], conv_layers=[]
INFO: Learning...
INFO: Hyperparameters: lr=0.0001, gamma=0.99, eps_start=0.9, eps_end=0.05, eps_decay=50000, batch_size=32, tau=0.005,hidden_layers=[128, 128], conv_layers=[]
INFO: Number of parameters: 30085
INFO: QNetwork(
  (conv_feature): Sequential()
  (fc_feature): Sequential(
    (0): Linear(in_features=100, out_features=128, bias=True)
    (1): ReLU()
    (2): Linear(in_features=128, out_features=128, bias=True)
    (3): ReLU()
    (4): Linear(in_features=128, out_features=5, bias=True)
  )
)
INFO: Hyperparameters: lr=0.0001, gamma=0.99, eps_start=0.9, eps_end=0.05, eps_decay=50000, batch_size=32, tau=0.005,hidden_layers=[128, 128], conv_layers=[]
INFO: Learning...
ERROR: Wandb must be active to run a sweep.
INFO: Hyperparameters: lr=0.0001, gamma=0.99, eps_start=0.9, eps_end=0.05, eps_decay=50000, batch_size=32, tau=0.005,hidden_layers=[128, 128], conv_layers=[]
INFO: Number of parameters: 30085
INFO: QNetwork(
  (conv_feature): Sequential()
  (fc_feature): Sequential(
    (0): Linear(in_features=100, out_features=128, bias=True)
    (1): ReLU()
    (2): Linear(in_features=128, out_features=128, bias=True)
    (3): ReLU()
    (4): Linear(in_features=128, out_features=5, bias=True)
  )
)
INFO: Hyperparameters: lr=0.0001, gamma=0.99, eps_start=0.9, eps_end=0.05, eps_decay=50000, batch_size=32, tau=0.005,hidden_layers=[128, 128], conv_layers=[]
INFO: Number of parameters: 30085
INFO: QNetwork(
  (conv_feature): Sequential()
  (fc_feature): Sequential(
    (0): Linear(in_features=100, out_features=128, bias=True)
    (1): ReLU()
    (2): Linear(in_features=128, out_features=128, bias=True)
    (3): ReLU()
    (4): Linear(in_features=128, out_features=5, bias=True)
  )
)
INFO: Hyperparameters: lr=0.0001, gamma=0.99, eps_start=0.9, eps_end=0.05, eps_decay=50000, batch_size=32, tau=0.005,hidden_layers=[128, 128], conv_layers=[]
INFO: Learning...
INFO: Hyperparameters: lr=0.0001, gamma=0.99, eps_start=0.9, eps_end=0.05, eps_decay=50000, batch_size=32, tau=0.005,hidden_layers=[128, 128], conv_layers=[]
INFO: Number of parameters: 30085
INFO: QNetwork(
  (conv_feature): Sequential()
  (fc_feature): Sequential(
    (0): Linear(in_features=100, out_features=128, bias=True)
    (1): ReLU()
    (2): Linear(in_features=128, out_features=128, bias=True)
    (3): ReLU()
    (4): Linear(in_features=128, out_features=5, bias=True)
  )
)
INFO: Hyperparameters: lr=0.0001, gamma=0.99, eps_start=0.9, eps_end=0.05, eps_decay=50000, batch_size=32, tau=0.005,hidden_layers=[128, 128], conv_layers=[]
INFO: Learning...
ERROR: Wandb must be active to run a sweep.
INFO: Hyperparameters: lr=0.0001, gamma=0.99, eps_start=0.9, eps_end=0.05, eps_decay=50000, batch_size=32, tau=0.005,hidden_layers=[128, 128], conv_layers=[]
INFO: Number of parameters: 30085
INFO: QNetwork(
  (conv_feature): Sequential()
  (fc_feature): Sequential(
    (0): Linear(in_features=100, out_features=128, bias=True)
    (1): ReLU()
    (2): Linear(in_features=128, out_features=128, bias=True)
    (3): ReLU()
    (4): Linear(in_features=128, out_features=5, bias=True)
  )
)
INFO: Hyperparameters: lr=0.0001, gamma=0.99, eps_start=0.9, eps_end=0.05, eps_decay=50000, batch_size=32, tau=0.005,hidden_layers=[128, 128], conv_layers=[]
INFO: Learning...
INFO: BootcampName.HIDER Bootcamp completed, starting BootcampName.SEEKER Bootcamp #0 for 500 days
INFO: BootcampName.SEEKER Bootcamp completed, starting BootcampName.SLOW_AGENT Bootcamp #0 for 1000 days
ERROR: [Errno 32] Broken pipe
ERROR: Traceback (most recent call last):
  File "/home/eirik/Projects/XAI/rl/src/dqn/wrapper/multi_agent_dqn.py", line 117, in learn
    self.wandb_manager.log(log)
  File "/home/eirik/Projects/XAI/rl/src/managers/wandb_manager.py", line 92, in log
    wandb.log(data)
  File "/home/eirik/.cache/pypoetry/virtualenvs/xai-is73Zs3s-py3.11/lib/python3.11/site-packages/wandb/sdk/wandb_run.py", line 452, in wrapper
    return func(self, *args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/eirik/.cache/pypoetry/virtualenvs/xai-is73Zs3s-py3.11/lib/python3.11/site-packages/wandb/sdk/wandb_run.py", line 403, in wrapper_fn
    return func(self, *args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/eirik/.cache/pypoetry/virtualenvs/xai-is73Zs3s-py3.11/lib/python3.11/site-packages/wandb/sdk/wandb_run.py", line 393, in wrapper
    return func(self, *args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/eirik/.cache/pypoetry/virtualenvs/xai-is73Zs3s-py3.11/lib/python3.11/site-packages/wandb/sdk/wandb_run.py", line 1933, in log
    self._log(data=data, step=step, commit=commit)
  File "/home/eirik/.cache/pypoetry/virtualenvs/xai-is73Zs3s-py3.11/lib/python3.11/site-packages/wandb/sdk/wandb_run.py", line 1652, in _log
    self._partial_history_callback(data, step, commit)
  File "/home/eirik/.cache/pypoetry/virtualenvs/xai-is73Zs3s-py3.11/lib/python3.11/site-packages/wandb/sdk/wandb_run.py", line 1524, in _partial_history_callback
    self._backend.interface.publish_partial_history(
  File "/home/eirik/.cache/pypoetry/virtualenvs/xai-is73Zs3s-py3.11/lib/python3.11/site-packages/wandb/sdk/interface/interface.py", line 647, in publish_partial_history
    self._publish_partial_history(partial_history)
  File "/home/eirik/.cache/pypoetry/virtualenvs/xai-is73Zs3s-py3.11/lib/python3.11/site-packages/wandb/sdk/interface/interface_shared.py", line 89, in _publish_partial_history
    self._publish(rec)
  File "/home/eirik/.cache/pypoetry/virtualenvs/xai-is73Zs3s-py3.11/lib/python3.11/site-packages/wandb/sdk/interface/interface_sock.py", line 51, in _publish
    self._sock_client.send_record_publish(record)
  File "/home/eirik/.cache/pypoetry/virtualenvs/xai-is73Zs3s-py3.11/lib/python3.11/site-packages/wandb/sdk/lib/sock_client.py", line 225, in send_record_publish
    self.send_server_request(server_req)
  File "/home/eirik/.cache/pypoetry/virtualenvs/xai-is73Zs3s-py3.11/lib/python3.11/site-packages/wandb/sdk/lib/sock_client.py", line 157, in send_server_request
    self._send_message(msg)
  File "/home/eirik/.cache/pypoetry/virtualenvs/xai-is73Zs3s-py3.11/lib/python3.11/site-packages/wandb/sdk/lib/sock_client.py", line 154, in _send_message
    self._sendall_with_error_handle(header + data)
  File "/home/eirik/.cache/pypoetry/virtualenvs/xai-is73Zs3s-py3.11/lib/python3.11/site-packages/wandb/sdk/lib/sock_client.py", line 132, in _sendall_with_error_handle
    sent = self._sock.send(data)
           ^^^^^^^^^^^^^^^^^^^^^
BrokenPipeError: [Errno 32] Broken pipe

INFO: Hyperparameters: lr=0.0001, gamma=0.99, eps_start=0.9, eps_end=0.05, eps_decay=50000, batch_size=32, tau=0.005,hidden_layers=[128, 128], conv_layers=[]
INFO: Number of parameters: 30085
INFO: QNetwork(
  (conv_feature): Sequential()
  (fc_feature): Sequential(
    (0): Linear(in_features=100, out_features=128, bias=True)
    (1): ReLU()
    (2): Linear(in_features=128, out_features=128, bias=True)
    (3): ReLU()
    (4): Linear(in_features=128, out_features=5, bias=True)
  )
)
INFO: Hyperparameters: lr=0.0001, gamma=0.99, eps_start=0.9, eps_end=0.05, eps_decay=50000, batch_size=32, tau=0.005,hidden_layers=[128, 128], conv_layers=[]
INFO: Learning...
INFO: BootcampName.HIDER Bootcamp completed, starting BootcampName.SEEKER Bootcamp #0 for 500 days
INFO: BootcampName.SEEKER Bootcamp completed, starting BootcampName.SLOW_AGENT Bootcamp #0 for 1000 days
INFO: Continuing with Bootcamp #0 BootcampName.SLOW_AGENT with slow factor: 9 for agent 1
INFO: Hyperparameters: lr=0.0001, gamma=0.99, eps_start=0.9, eps_end=0.05, eps_decay=50000, batch_size=32, tau=0.005,hidden_layers=[128, 128], conv_layers=[]
INFO: Number of parameters: 30085
INFO: QNetwork(
  (conv_feature): Sequential()
  (fc_feature): Sequential(
    (0): Linear(in_features=100, out_features=128, bias=True)
    (1): ReLU()
    (2): Linear(in_features=128, out_features=128, bias=True)
    (3): ReLU()
    (4): Linear(in_features=128, out_features=5, bias=True)
  )
)
INFO: Hyperparameters: lr=0.0001, gamma=0.99, eps_start=0.9, eps_end=0.05, eps_decay=50000, batch_size=32, tau=0.005,hidden_layers=[128, 128], conv_layers=[]
INFO: Learning...
INFO: BootcampName.HIDER Bootcamp completed, starting BootcampName.SEEKER Bootcamp #0 for 500 days
INFO: Hyperparameters: lr=0.0001, gamma=0.99, eps_start=0.9, eps_end=0.05, eps_decay=50000, batch_size=32, tau=0.005,hidden_layers=[128, 128], conv_layers=[]
INFO: Number of parameters: 30085
INFO: QNetwork(
  (conv_feature): Sequential()
  (fc_feature): Sequential(
    (0): Linear(in_features=100, out_features=128, bias=True)
    (1): ReLU()
    (2): Linear(in_features=128, out_features=128, bias=True)
    (3): ReLU()
    (4): Linear(in_features=128, out_features=5, bias=True)
  )
)
INFO: Hyperparameters: lr=0.0001, gamma=0.99, eps_start=0.9, eps_end=0.05, eps_decay=50000, batch_size=32, tau=0.005,hidden_layers=[128, 128], conv_layers=[]
INFO: Learning...
INFO: BootcampName.HIDER Bootcamp completed, starting BootcampName.SEEKER Bootcamp #0 for 500 days
INFO: BootcampName.SEEKER Bootcamp completed, starting BootcampName.SLOW_AGENT Bootcamp #0 for 1000 days
INFO: Hyperparameters: lr=0.0001, gamma=0.99, eps_start=0.9, eps_end=0.05, eps_decay=50000, batch_size=32, tau=0.005,hidden_layers=[128, 128], conv_layers=[]
INFO: Number of parameters: 30085
INFO: QNetwork(
  (conv_feature): Sequential()
  (fc_feature): Sequential(
    (0): Linear(in_features=100, out_features=128, bias=True)
    (1): ReLU()
    (2): Linear(in_features=128, out_features=128, bias=True)
    (3): ReLU()
    (4): Linear(in_features=128, out_features=5, bias=True)
  )
)
INFO: Hyperparameters: lr=0.0001, gamma=0.99, eps_start=0.9, eps_end=0.05, eps_decay=50000, batch_size=32, tau=0.005,hidden_layers=[128, 128], conv_layers=[]
INFO: Learning...
WARNING: Seeker won not found in info.
WARNING: Seeker won not found in info.
WARNING: Seeker won not found in info.
WARNING: Seeker won not found in info.
WARNING: Seeker won not found in info.
INFO: BootcampName.HIDER Bootcamp completed, starting BootcampName.SEEKER Bootcamp #0 for 500 days
WARNING: Seeker won not found in info.
WARNING: Seeker won not found in info.
WARNING: Seeker won not found in info.
WARNING: Seeker won not found in info.
WARNING: Seeker won not found in info.
INFO: BootcampName.SEEKER Bootcamp completed, starting BootcampName.SLOW_AGENT Bootcamp #0 for 1000 days
WARNING: Seeker won not found in info.
WARNING: Seeker won not found in info.
WARNING: Seeker won not found in info.
WARNING: Seeker won not found in info.
WARNING: Seeker won not found in info.
WARNING: Seeker won not found in info.
WARNING: Seeker won not found in info.
WARNING: Seeker won not found in info.
INFO: Continuing with Bootcamp #0 BootcampName.SLOW_AGENT with slow factor: 9 for agent 1
WARNING: Seeker won not found in info.
WARNING: Seeker won not found in info.
WARNING: Seeker won not found in info.
WARNING: Seeker won not found in info.
WARNING: Seeker won not found in info.
WARNING: Seeker won not found in info.
WARNING: Seeker won not found in info.
WARNING: Seeker won not found in info.
WARNING: Seeker won not found in info.
INFO: Continuing with Bootcamp #0 BootcampName.SLOW_AGENT with slow factor: 9 for agent 0
WARNING: Seeker won not found in info.
WARNING: Seeker won not found in info.
WARNING: Seeker won not found in info.
WARNING: Seeker won not found in info.
WARNING: Seeker won not found in info.
WARNING: Seeker won not found in info.
WARNING: Seeker won not found in info.
WARNING: Seeker won not found in info.
WARNING: Seeker won not found in info.
INFO: Continuing with Bootcamp #0 BootcampName.SLOW_AGENT with slow factor: 8 for agent 1
WARNING: Seeker won not found in info.
WARNING: Seeker won not found in info.
WARNING: Seeker won not found in info.
WARNING: Seeker won not found in info.
WARNING: Seeker won not found in info.
WARNING: Seeker won not found in info.
WARNING: Seeker won not found in info.
WARNING: Seeker won not found in info.
WARNING: Seeker won not found in info.
WARNING: Seeker won not found in info.
INFO: Continuing with Bootcamp #0 BootcampName.SLOW_AGENT with slow factor: 8 for agent 0
WARNING: Seeker won not found in info.
WARNING: Seeker won not found in info.
WARNING: Seeker won not found in info.
WARNING: Seeker won not found in info.
WARNING: Seeker won not found in info.
WARNING: Seeker won not found in info.
WARNING: Seeker won not found in info.
WARNING: Seeker won not found in info.
INFO: Continuing with Bootcamp #0 BootcampName.SLOW_AGENT with slow factor: 7 for agent 1
WARNING: Seeker won not found in info.
WARNING: Seeker won not found in info.
WARNING: Seeker won not found in info.
WARNING: Seeker won not found in info.
WARNING: Seeker won not found in info.
WARNING: Seeker won not found in info.
WARNING: Seeker won not found in info.
WARNING: Seeker won not found in info.
WARNING: Seeker won not found in info.
INFO: Continuing with Bootcamp #0 BootcampName.SLOW_AGENT with slow factor: 7 for agent 0
WARNING: Seeker won not found in info.
WARNING: Seeker won not found in info.
WARNING: Seeker won not found in info.
WARNING: Seeker won not found in info.
WARNING: Seeker won not found in info.
WARNING: Seeker won not found in info.
WARNING: Seeker won not found in info.
WARNING: Seeker won not found in info.
WARNING: Seeker won not found in info.
INFO: Continuing with Bootcamp #0 BootcampName.SLOW_AGENT with slow factor: 6 for agent 1
WARNING: Seeker won not found in info.
WARNING: Seeker won not found in info.
WARNING: Seeker won not found in info.
WARNING: Seeker won not found in info.
WARNING: Seeker won not found in info.
WARNING: Seeker won not found in info.
WARNING: Seeker won not found in info.
WARNING: Seeker won not found in info.
WARNING: Seeker won not found in info.
WARNING: Seeker won not found in info.
INFO: Continuing with Bootcamp #0 BootcampName.SLOW_AGENT with slow factor: 6 for agent 0
WARNING: Seeker won not found in info.
WARNING: Seeker won not found in info.
WARNING: Seeker won not found in info.
WARNING: Seeker won not found in info.
WARNING: Seeker won not found in info.
WARNING: Seeker won not found in info.
WARNING: Seeker won not found in info.
INFO: Continuing with Bootcamp #0 BootcampName.SLOW_AGENT with slow factor: 5 for agent 1
WARNING: Seeker won not found in info.
WARNING: Seeker won not found in info.
WARNING: Seeker won not found in info.
WARNING: Seeker won not found in info.
WARNING: Seeker won not found in info.
WARNING: Seeker won not found in info.
WARNING: Seeker won not found in info.
WARNING: Seeker won not found in info.
WARNING: Seeker won not found in info.
INFO: Continuing with Bootcamp #0 BootcampName.SLOW_AGENT with slow factor: 5 for agent 0
WARNING: Seeker won not found in info.
WARNING: Seeker won not found in info.
WARNING: Seeker won not found in info.
WARNING: Seeker won not found in info.
WARNING: Seeker won not found in info.
WARNING: Seeker won not found in info.
WARNING: Seeker won not found in info.
WARNING: Seeker won not found in info.
INFO: Continuing with Bootcamp #0 BootcampName.SLOW_AGENT with slow factor: 4 for agent 1
WARNING: Seeker won not found in info.
WARNING: Seeker won not found in info.
WARNING: Seeker won not found in info.
WARNING: Seeker won not found in info.
WARNING: Seeker won not found in info.
WARNING: Seeker won not found in info.
WARNING: Seeker won not found in info.
WARNING: Seeker won not found in info.
WARNING: Seeker won not found in info.
WARNING: Seeker won not found in info.
INFO: Continuing with Bootcamp #0 BootcampName.SLOW_AGENT with slow factor: 4 for agent 0
WARNING: Seeker won not found in info.
WARNING: Seeker won not found in info.
WARNING: Seeker won not found in info.
WARNING: Seeker won not found in info.
WARNING: Seeker won not found in info.
WARNING: Seeker won not found in info.
WARNING: Seeker won not found in info.
INFO: Continuing with Bootcamp #0 BootcampName.SLOW_AGENT with slow factor: 3 for agent 1
WARNING: Seeker won not found in info.
WARNING: Seeker won not found in info.
WARNING: Seeker won not found in info.
WARNING: Seeker won not found in info.
WARNING: Seeker won not found in info.
WARNING: Seeker won not found in info.
WARNING: Seeker won not found in info.
WARNING: Seeker won not found in info.
INFO: Continuing with Bootcamp #0 BootcampName.SLOW_AGENT with slow factor: 3 for agent 0
WARNING: Seeker won not found in info.
WARNING: Seeker won not found in info.
WARNING: Seeker won not found in info.
WARNING: Seeker won not found in info.
WARNING: Seeker won not found in info.
WARNING: Seeker won not found in info.
WARNING: Seeker won not found in info.
INFO: Continuing with Bootcamp #0 BootcampName.SLOW_AGENT with slow factor: 2 for agent 1
WARNING: Seeker won not found in info.
WARNING: Seeker won not found in info.
WARNING: Seeker won not found in info.
WARNING: Seeker won not found in info.
WARNING: Seeker won not found in info.
WARNING: Seeker won not found in info.
WARNING: Seeker won not found in info.
WARNING: Seeker won not found in info.
WARNING: Seeker won not found in info.
WARNING: Seeker won not found in info.
INFO: Continuing with Bootcamp #0 BootcampName.SLOW_AGENT with slow factor: 2 for agent 0
WARNING: Seeker won not found in info.
WARNING: Seeker won not found in info.
WARNING: Seeker won not found in info.
WARNING: Seeker won not found in info.
WARNING: Seeker won not found in info.
INFO: BootcampName.SLOW_AGENT Bootcamp completed, starting BootcampName.COMBINED Bootcamp #0 for 1000 days
WARNING: Seeker won not found in info.
WARNING: Seeker won not found in info.
WARNING: Seeker won not found in info.
WARNING: Seeker won not found in info.
WARNING: Seeker won not found in info.
INFO: BootcampName.COMBINED Bootcamp completed, starting BootcampName.FINISHED Bootcamp #0 for 0 days
WARNING: Seeker won not found in info.
WARNING: Seeker won not found in info.
WARNING: Seeker won not found in info.
WARNING: Seeker won not found in info.
WARNING: Seeker won not found in info.
WARNING: Seeker won not found in info.
WARNING: Seeker won not found in info.
WARNING: Seeker won not found in info.
WARNING: Seeker won not found in info.
WARNING: Seeker won not found in info.
WARNING: Seeker won not found in info.
WARNING: Seeker won not found in info.
WARNING: Seeker won not found in info.
WARNING: Seeker won not found in info.
WARNING: Seeker won not found in info.
WARNING: Seeker won not found in info.
WARNING: Seeker won not found in info.
WARNING: Seeker won not found in info.
WARNING: Seeker won not found in info.
WARNING: Seeker won not found in info.
WARNING: Seeker won not found in info.
WARNING: Seeker won not found in info.
WARNING: Seeker won not found in info.
WARNING: Seeker won not found in info.
WARNING: Seeker won not found in info.
WARNING: Seeker won not found in info.
WARNING: Seeker won not found in info.
WARNING: Seeker won not found in info.
WARNING: Seeker won not found in info.
WARNING: Seeker won not found in info.
WARNING: Seeker won not found in info.
WARNING: Seeker won not found in info.
WARNING: Seeker won not found in info.
WARNING: Seeker won not found in info.
WARNING: Seeker won not found in info.
WARNING: Seeker won not found in info.
WARNING: Seeker won not found in info.
WARNING: Seeker won not found in info.
WARNING: Seeker won not found in info.
WARNING: Seeker won not found in info.
WARNING: Seeker won not found in info.
WARNING: Seeker won not found in info.
WARNING: Seeker won not found in info.
WARNING: Seeker won not found in info.
WARNING: Seeker won not found in info.
WARNING: Seeker won not found in info.
WARNING: Seeker won not found in info.
WARNING: Seeker won not found in info.
WARNING: Seeker won not found in info.
WARNING: Seeker won not found in info.
WARNING: Seeker won not found in info.
WARNING: Seeker won not found in info.
WARNING: Seeker won not found in info.
WARNING: Seeker won not found in info.
WARNING: Seeker won not found in info.
WARNING: Seeker won not found in info.
WARNING: Seeker won not found in info.
WARNING: Seeker won not found in info.
WARNING: Seeker won not found in info.
WARNING: Seeker won not found in info.
WARNING: Seeker won not found in info.
WARNING: Seeker won not found in info.
INFO: Hyperparameters: lr=0.0001, gamma=0.99, eps_start=0.9, eps_end=0.05, eps_decay=50000, batch_size=32, tau=0.005,hidden_layers=[128, 128], conv_layers=[]
INFO: Number of parameters: 30085
INFO: QNetwork(
  (conv_feature): Sequential()
  (fc_feature): Sequential(
    (0): Linear(in_features=100, out_features=128, bias=True)
    (1): ReLU()
    (2): Linear(in_features=128, out_features=128, bias=True)
    (3): ReLU()
    (4): Linear(in_features=128, out_features=5, bias=True)
  )
)
INFO: Hyperparameters: lr=0.0001, gamma=0.99, eps_start=0.9, eps_end=0.05, eps_decay=50000, batch_size=32, tau=0.005,hidden_layers=[128, 128], conv_layers=[]
INFO: Learning...
WARNING: Seeker won not found in info.
WARNING: Seeker won not found in info.
WARNING: Seeker won not found in info.
WARNING: Seeker won not found in info.
WARNING: Seeker won not found in info.
INFO: BootcampName.HIDER Bootcamp completed, starting BootcampName.SEEKER Bootcamp #0 for 500 days
WARNING: Seeker won not found in info.
WARNING: Seeker won not found in info.
WARNING: Seeker won not found in info.
WARNING: Seeker won not found in info.
WARNING: Seeker won not found in info.
INFO: BootcampName.SEEKER Bootcamp completed, starting BootcampName.SLOW_AGENT Bootcamp #0 for 1000 days
WARNING: Seeker won not found in info.
WARNING: Seeker won not found in info.
WARNING: Seeker won not found in info.
INFO: Hyperparameters: lr=0.0001, gamma=0.99, eps_start=0.9, eps_end=0.05, eps_decay=50000, batch_size=32, tau=0.005,hidden_layers=[128, 128], conv_layers=[]
INFO: Number of parameters: 30085
INFO: QNetwork(
  (conv_feature): Sequential()
  (fc_feature): Sequential(
    (0): Linear(in_features=100, out_features=128, bias=True)
    (1): ReLU()
    (2): Linear(in_features=128, out_features=128, bias=True)
    (3): ReLU()
    (4): Linear(in_features=128, out_features=5, bias=True)
  )
)
INFO: Hyperparameters: lr=0.0001, gamma=0.99, eps_start=0.9, eps_end=0.05, eps_decay=50000, batch_size=32, tau=0.005,hidden_layers=[128, 128], conv_layers=[]
INFO: Learning...
INFO: BootcampName.HIDER Bootcamp completed, starting BootcampName.SEEKER Bootcamp #0 for 500 days
INFO: BootcampName.SEEKER Bootcamp completed, starting BootcampName.SLOW_AGENT Bootcamp #0 for 1000 days
INFO: Hyperparameters: lr=0.0001, gamma=0.99, eps_start=0.9, eps_end=0.05, eps_decay=50000, batch_size=32, tau=0.005,hidden_layers=[128, 128], conv_layers=[]
INFO: Number of parameters: 30085
INFO: QNetwork(
  (conv_feature): Sequential()
  (fc_feature): Sequential(
    (0): Linear(in_features=100, out_features=128, bias=True)
    (1): ReLU()
    (2): Linear(in_features=128, out_features=128, bias=True)
    (3): ReLU()
    (4): Linear(in_features=128, out_features=5, bias=True)
  )
)
INFO: Hyperparameters: lr=0.0001, gamma=0.99, eps_start=0.9, eps_end=0.05, eps_decay=50000, batch_size=32, tau=0.005,hidden_layers=[128, 128], conv_layers=[]
INFO: Learning...
INFO: BootcampName.HIDER Bootcamp completed, starting BootcampName.SEEKER Bootcamp #0 for 500 days
INFO: BootcampName.SEEKER Bootcamp completed, starting BootcampName.SLOW_AGENT Bootcamp #0 for 1000 days
INFO: Continuing with Bootcamp #0 BootcampName.SLOW_AGENT with slow factor: 9 for agent 1
INFO: Continuing with Bootcamp #0 BootcampName.SLOW_AGENT with slow factor: 9 for agent 0
INFO: Continuing with Bootcamp #0 BootcampName.SLOW_AGENT with slow factor: 8 for agent 1
INFO: Continuing with Bootcamp #0 BootcampName.SLOW_AGENT with slow factor: 8 for agent 0
INFO: Hyperparameters: lr=0.0001, gamma=0.99, eps_start=0.9, eps_end=0.05, eps_decay=50000, batch_size=32, tau=0.005,hidden_layers=[128, 128], conv_layers=[]
INFO: Number of parameters: 30085
INFO: QNetwork(
  (conv_feature): Sequential()
  (fc_feature): Sequential(
    (0): Linear(in_features=100, out_features=128, bias=True)
    (1): ReLU()
    (2): Linear(in_features=128, out_features=128, bias=True)
    (3): ReLU()
    (4): Linear(in_features=128, out_features=5, bias=True)
  )
)
INFO: Hyperparameters: lr=0.0001, gamma=0.99, eps_start=0.9, eps_end=0.05, eps_decay=50000, batch_size=32, tau=0.005,hidden_layers=[128, 128], conv_layers=[]
INFO: Learning...
INFO: BootcampName.HIDER Bootcamp completed, starting BootcampName.SEEKER Bootcamp #0 for 500 days
INFO: BootcampName.SEEKER Bootcamp completed, starting BootcampName.SLOW_AGENT Bootcamp #0 for 1000 days
INFO: Hyperparameters: lr=0.0001, gamma=0.99, eps_start=0.9, eps_end=0.05, eps_decay=50000, batch_size=32, tau=0.005,hidden_layers=[128, 128], conv_layers=[]
INFO: Number of parameters: 30085
INFO: QNetwork(
  (conv_feature): Sequential()
  (fc_feature): Sequential(
    (0): Linear(in_features=100, out_features=128, bias=True)
    (1): ReLU()
    (2): Linear(in_features=128, out_features=128, bias=True)
    (3): ReLU()
    (4): Linear(in_features=128, out_features=5, bias=True)
  )
)
INFO: Hyperparameters: lr=0.0001, gamma=0.99, eps_start=0.9, eps_end=0.05, eps_decay=50000, batch_size=32, tau=0.005,hidden_layers=[128, 128], conv_layers=[]
INFO: Learning...
INFO: BootcampName.HIDER Bootcamp completed, starting BootcampName.SEEKER Bootcamp #0 for 500 days
INFO: BootcampName.SEEKER Bootcamp completed, starting BootcampName.SLOW_AGENT Bootcamp #0 for 1000 days
INFO: Hyperparameters: lr=0.0001, gamma=0.99, eps_start=0.9, eps_end=0.05, eps_decay=50000, batch_size=32, tau=0.005,hidden_layers=[128, 128], conv_layers=[]
INFO: Number of parameters: 30085
INFO: QNetwork(
  (conv_feature): Sequential()
  (fc_feature): Sequential(
    (0): Linear(in_features=100, out_features=128, bias=True)
    (1): ReLU()
    (2): Linear(in_features=128, out_features=128, bias=True)
    (3): ReLU()
    (4): Linear(in_features=128, out_features=5, bias=True)
  )
)
INFO: Hyperparameters: lr=0.0001, gamma=0.99, eps_start=0.9, eps_end=0.05, eps_decay=50000, batch_size=32, tau=0.005,hidden_layers=[128, 128], conv_layers=[]
INFO: Learning...
INFO: BootcampName.HIDER Bootcamp completed, starting BootcampName.SEEKER Bootcamp #0 for 500 days
INFO: Early stopping at episode 10
INFO: Hyperparameters: lr=0.0001, gamma=0.99, eps_start=0.9, eps_end=0.05, eps_decay=50000, batch_size=32, tau=0.005,hidden_layers=[128, 128], conv_layers=[]
INFO: Number of parameters: 30085
INFO: QNetwork(
  (conv_feature): Sequential()
  (fc_feature): Sequential(
    (0): Linear(in_features=100, out_features=128, bias=True)
    (1): ReLU()
    (2): Linear(in_features=128, out_features=128, bias=True)
    (3): ReLU()
    (4): Linear(in_features=128, out_features=5, bias=True)
  )
)
INFO: Hyperparameters: lr=0.0001, gamma=0.99, eps_start=0.9, eps_end=0.05, eps_decay=50000, batch_size=32, tau=0.005,hidden_layers=[128, 128], conv_layers=[]
INFO: Learning...
INFO: BootcampName.HIDER Bootcamp completed, starting BootcampName.SEEKER Bootcamp #0 for 500 days
INFO: Hyperparameters: lr=0.0001, gamma=0.99, eps_start=0.9, eps_end=0.05, eps_decay=50000, batch_size=32, tau=0.005,hidden_layers=[128, 128], conv_layers=[]
INFO: Number of parameters: 30085
INFO: QNetwork(
  (conv_feature): Sequential()
  (fc_feature): Sequential(
    (0): Linear(in_features=100, out_features=128, bias=True)
    (1): ReLU()
    (2): Linear(in_features=128, out_features=128, bias=True)
    (3): ReLU()
    (4): Linear(in_features=128, out_features=5, bias=True)
  )
)
INFO: Hyperparameters: lr=0.0001, gamma=0.99, eps_start=0.9, eps_end=0.05, eps_decay=50000, batch_size=32, tau=0.005,hidden_layers=[128, 128], conv_layers=[]
INFO: Learning...
INFO: BootcampName.HIDER Bootcamp completed, starting BootcampName.SEEKER Bootcamp #0 for 500 days
INFO: BootcampName.SEEKER Bootcamp completed, starting BootcampName.SLOW_AGENT Bootcamp #0 for 1000 days
INFO: Continuing with Bootcamp #0 BootcampName.SLOW_AGENT with slow factor: 9 for agent 1
INFO: Continuing with Bootcamp #0 BootcampName.SLOW_AGENT with slow factor: 9 for agent 0
INFO: Continuing with Bootcamp #0 BootcampName.SLOW_AGENT with slow factor: 8 for agent 1
INFO: Continuing with Bootcamp #0 BootcampName.SLOW_AGENT with slow factor: 8 for agent 0
INFO: Continuing with Bootcamp #0 BootcampName.SLOW_AGENT with slow factor: 7 for agent 1
INFO: Continuing with Bootcamp #0 BootcampName.SLOW_AGENT with slow factor: 7 for agent 0
INFO: Continuing with Bootcamp #0 BootcampName.SLOW_AGENT with slow factor: 6 for agent 1
INFO: Continuing with Bootcamp #0 BootcampName.SLOW_AGENT with slow factor: 6 for agent 0
INFO: Continuing with Bootcamp #0 BootcampName.SLOW_AGENT with slow factor: 5 for agent 1
INFO: Continuing with Bootcamp #0 BootcampName.SLOW_AGENT with slow factor: 5 for agent 0
INFO: Continuing with Bootcamp #0 BootcampName.SLOW_AGENT with slow factor: 4 for agent 1
INFO: Continuing with Bootcamp #0 BootcampName.SLOW_AGENT with slow factor: 4 for agent 0
INFO: Continuing with Bootcamp #0 BootcampName.SLOW_AGENT with slow factor: 3 for agent 1
INFO: Continuing with Bootcamp #0 BootcampName.SLOW_AGENT with slow factor: 3 for agent 0
INFO: Continuing with Bootcamp #0 BootcampName.SLOW_AGENT with slow factor: 2 for agent 1
INFO: Hyperparameters: lr=0.0001, gamma=0.99, eps_start=0.9, eps_end=0.05, eps_decay=50000, batch_size=32, tau=0.005,hidden_layers=[128, 128], conv_layers=[]
INFO: Number of parameters: 30085
INFO: QNetwork(
  (conv_feature): Sequential()
  (fc_feature): Sequential(
    (0): Linear(in_features=100, out_features=128, bias=True)
    (1): ReLU()
    (2): Linear(in_features=128, out_features=128, bias=True)
    (3): ReLU()
    (4): Linear(in_features=128, out_features=5, bias=True)
  )
)
INFO: Hyperparameters: lr=0.0001, gamma=0.99, eps_start=0.9, eps_end=0.05, eps_decay=50000, batch_size=32, tau=0.005,hidden_layers=[128, 128], conv_layers=[]
INFO: Learning...
INFO: Hyperparameters: lr=0.0001, gamma=0.99, eps_start=0.9, eps_end=0.05, eps_decay=50000, batch_size=32, tau=0.005,hidden_layers=[128, 128], conv_layers=[]
INFO: Number of parameters: 30085
INFO: QNetwork(
  (conv_feature): Sequential()
  (fc_feature): Sequential(
    (0): Linear(in_features=100, out_features=128, bias=True)
    (1): ReLU()
    (2): Linear(in_features=128, out_features=128, bias=True)
    (3): ReLU()
    (4): Linear(in_features=128, out_features=5, bias=True)
  )
)
INFO: Hyperparameters: lr=0.0001, gamma=0.99, eps_start=0.9, eps_end=0.05, eps_decay=50000, batch_size=32, tau=0.005,hidden_layers=[128, 128], conv_layers=[]
INFO: Learning...
INFO: BootcampName.HIDER Bootcamp completed, starting BootcampName.SEEKER Bootcamp #0 for 500 days
INFO: Hyperparameters: lr=0.0001, gamma=0.99, eps_start=0.9, eps_end=0.05, eps_decay=50000, batch_size=32, tau=0.005,hidden_layers=[128, 128], conv_layers=[]
INFO: Number of parameters: 30085
INFO: QNetwork(
  (conv_feature): Sequential()
  (fc_feature): Sequential(
    (0): Linear(in_features=100, out_features=128, bias=True)
    (1): ReLU()
    (2): Linear(in_features=128, out_features=128, bias=True)
    (3): ReLU()
    (4): Linear(in_features=128, out_features=5, bias=True)
  )
)
INFO: Hyperparameters: lr=0.0001, gamma=0.99, eps_start=0.9, eps_end=0.05, eps_decay=50000, batch_size=32, tau=0.005,hidden_layers=[128, 128], conv_layers=[]
INFO: Learning...
INFO: Hyperparameters: lr=0.0001, gamma=0.99, eps_start=0.9, eps_end=0.05, eps_decay=50000, batch_size=32, tau=0.005,hidden_layers=[128, 128], conv_layers=[]
INFO: Number of parameters: 30085
INFO: QNetwork(
  (conv_feature): Sequential()
  (fc_feature): Sequential(
    (0): Linear(in_features=100, out_features=128, bias=True)
    (1): ReLU()
    (2): Linear(in_features=128, out_features=128, bias=True)
    (3): ReLU()
    (4): Linear(in_features=128, out_features=5, bias=True)
  )
)
INFO: Hyperparameters: lr=0.0001, gamma=0.99, eps_start=0.9, eps_end=0.05, eps_decay=50000, batch_size=32, tau=0.005,hidden_layers=[128, 128], conv_layers=[]
INFO: Learning...
INFO: Hyperparameters: lr=0.0001, gamma=0.99, eps_start=0.9, eps_end=0.05, eps_decay=50000, batch_size=32, tau=0.005,hidden_layers=[128, 128], conv_layers=[]
INFO: Number of parameters: 30085
INFO: QNetwork(
  (conv_feature): Sequential()
  (fc_feature): Sequential(
    (0): Linear(in_features=100, out_features=128, bias=True)
    (1): ReLU()
    (2): Linear(in_features=128, out_features=128, bias=True)
    (3): ReLU()
    (4): Linear(in_features=128, out_features=5, bias=True)
  )
)
INFO: Hyperparameters: lr=0.0001, gamma=0.99, eps_start=0.9, eps_end=0.05, eps_decay=50000, batch_size=32, tau=0.005,hidden_layers=[128, 128], conv_layers=[]
INFO: Learning...
INFO: Hyperparameters: lr=0.0001, gamma=0.99, eps_start=0.9, eps_end=0.05, eps_decay=50000, batch_size=32, tau=0.005,hidden_layers=[128, 128], conv_layers=[]
INFO: Number of parameters: 30085
INFO: QNetwork(
  (conv_feature): Sequential()
  (fc_feature): Sequential(
    (0): Linear(in_features=100, out_features=128, bias=True)
    (1): ReLU()
    (2): Linear(in_features=128, out_features=128, bias=True)
    (3): ReLU()
    (4): Linear(in_features=128, out_features=5, bias=True)
  )
)
INFO: Hyperparameters: lr=0.0001, gamma=0.99, eps_start=0.9, eps_end=0.05, eps_decay=50000, batch_size=32, tau=0.005,hidden_layers=[128, 128], conv_layers=[]
INFO: Learning...
INFO: Hyperparameters: lr=0.0001, gamma=0.99, eps_start=0.9, eps_end=0.05, eps_decay=50000, batch_size=32, tau=0.005,hidden_layers=[128, 128], conv_layers=[]
INFO: Number of parameters: 30085
INFO: QNetwork(
  (conv_feature): Sequential()
  (fc_feature): Sequential(
    (0): Linear(in_features=100, out_features=128, bias=True)
    (1): ReLU()
    (2): Linear(in_features=128, out_features=128, bias=True)
    (3): ReLU()
    (4): Linear(in_features=128, out_features=5, bias=True)
  )
)
INFO: Hyperparameters: lr=0.0001, gamma=0.99, eps_start=0.9, eps_end=0.05, eps_decay=50000, batch_size=32, tau=0.005,hidden_layers=[128, 128], conv_layers=[]
INFO: Learning...
INFO: Hyperparameters: lr=0.0001, gamma=0.99, eps_start=0.9, eps_end=0.05, eps_decay=50000, batch_size=32, tau=0.005,hidden_layers=[128, 128], conv_layers=[]
INFO: Number of parameters: 30085
INFO: QNetwork(
  (conv_feature): Sequential()
  (fc_feature): Sequential(
    (0): Linear(in_features=100, out_features=128, bias=True)
    (1): ReLU()
    (2): Linear(in_features=128, out_features=128, bias=True)
    (3): ReLU()
    (4): Linear(in_features=128, out_features=5, bias=True)
  )
)
INFO: Hyperparameters: lr=0.0001, gamma=0.99, eps_start=0.9, eps_end=0.05, eps_decay=50000, batch_size=32, tau=0.005,hidden_layers=[128, 128], conv_layers=[]
INFO: Learning...
INFO: Hyperparameters: lr=0.0001, gamma=0.99, eps_start=0.9, eps_end=0.05, eps_decay=50000, batch_size=32, tau=0.005,hidden_layers=[128, 128], conv_layers=[]
INFO: Number of parameters: 30085
INFO: QNetwork(
  (conv_feature): Sequential()
  (fc_feature): Sequential(
    (0): Linear(in_features=100, out_features=128, bias=True)
    (1): ReLU()
    (2): Linear(in_features=128, out_features=128, bias=True)
    (3): ReLU()
    (4): Linear(in_features=128, out_features=5, bias=True)
  )
)
INFO: Hyperparameters: lr=0.0001, gamma=0.99, eps_start=0.9, eps_end=0.05, eps_decay=50000, batch_size=32, tau=0.005,hidden_layers=[128, 128], conv_layers=[]
INFO: Learning...
INFO: Hyperparameters: lr=0.0001, gamma=0.99, eps_start=0.9, eps_end=0.05, eps_decay=50000, batch_size=32, tau=0.005,hidden_layers=[128, 128], conv_layers=[]
INFO: Number of parameters: 30085
INFO: QNetwork(
  (conv_feature): Sequential()
  (fc_feature): Sequential(
    (0): Linear(in_features=100, out_features=128, bias=True)
    (1): ReLU()
    (2): Linear(in_features=128, out_features=128, bias=True)
    (3): ReLU()
    (4): Linear(in_features=128, out_features=5, bias=True)
  )
)
INFO: Hyperparameters: lr=0.0001, gamma=0.99, eps_start=0.9, eps_end=0.05, eps_decay=50000, batch_size=32, tau=0.005,hidden_layers=[128, 128], conv_layers=[]
INFO: Learning...
INFO: Hyperparameters: lr=0.0001, gamma=0.99, eps_start=0.9, eps_end=0.05, eps_decay=50000, batch_size=32, tau=0.005,hidden_layers=[128, 128], conv_layers=[]
INFO: Number of parameters: 30085
INFO: QNetwork(
  (conv_feature): Sequential()
  (fc_feature): Sequential(
    (0): Linear(in_features=100, out_features=128, bias=True)
    (1): ReLU()
    (2): Linear(in_features=128, out_features=128, bias=True)
    (3): ReLU()
    (4): Linear(in_features=128, out_features=5, bias=True)
  )
)
INFO: Hyperparameters: lr=0.0001, gamma=0.99, eps_start=0.9, eps_end=0.05, eps_decay=50000, batch_size=32, tau=0.005,hidden_layers=[128, 128], conv_layers=[]
INFO: Learning...
INFO: BootcampName.HIDER Bootcamp completed, starting BootcampName.SEEKER Bootcamp #0 for 500 days
INFO: Number of parameters: 30085
INFO: QNetwork(
  (conv_feature): Sequential()
  (fc_feature): Sequential(
    (0): Linear(in_features=100, out_features=128, bias=True)
    (1): ReLU()
    (2): Linear(in_features=128, out_features=128, bias=True)
    (3): ReLU()
    (4): Linear(in_features=128, out_features=5, bias=True)
  )
)
INFO: Learning...
INFO: BootcampName.HIDER Bootcamp completed, starting BootcampName.SEEKER Bootcamp #0 for 500 days
INFO: BootcampName.SEEKER Bootcamp completed, starting BootcampName.SLOW_AGENT Bootcamp #0 for 1000 days
INFO: Continuing with Bootcamp #0 BootcampName.SLOW_AGENT with slow factor: 9 for agent 1
INFO: Continuing with Bootcamp #0 BootcampName.SLOW_AGENT with slow factor: 9 for agent 0
INFO: Continuing with Bootcamp #0 BootcampName.SLOW_AGENT with slow factor: 8 for agent 1
INFO: Continuing with Bootcamp #0 BootcampName.SLOW_AGENT with slow factor: 8 for agent 0
INFO: Number of parameters: 30085
INFO: QNetwork(
  (conv_feature): Sequential()
  (fc_feature): Sequential(
    (0): Linear(in_features=100, out_features=128, bias=True)
    (1): ReLU()
    (2): Linear(in_features=128, out_features=128, bias=True)
    (3): ReLU()
    (4): Linear(in_features=128, out_features=5, bias=True)
  )
)
INFO: Learning...
INFO: BootcampName.HIDER Bootcamp completed, starting BootcampName.SEEKER Bootcamp #0 for 500 days
INFO: Number of parameters: 30085
INFO: QNetwork(
  (conv_feature): Sequential()
  (fc_feature): Sequential(
    (0): Linear(in_features=100, out_features=128, bias=True)
    (1): ReLU()
    (2): Linear(in_features=128, out_features=128, bias=True)
    (3): ReLU()
    (4): Linear(in_features=128, out_features=5, bias=True)
  )
)
INFO: Learning...
INFO: Number of parameters: 30085
INFO: QNetwork(
  (conv_feature): Sequential()
  (fc_feature): Sequential(
    (0): Linear(in_features=100, out_features=128, bias=True)
    (1): ReLU()
    (2): Linear(in_features=128, out_features=128, bias=True)
    (3): ReLU()
    (4): Linear(in_features=128, out_features=5, bias=True)
  )
)
INFO: Learning...
INFO: BootcampName.HIDER Bootcamp completed, starting BootcampName.SEEKER Bootcamp #0 for 500 days
INFO: BootcampName.SEEKER Bootcamp completed, starting BootcampName.SLOW_AGENT Bootcamp #0 for 1000 days
INFO: Continuing with Bootcamp #0 BootcampName.SLOW_AGENT with slow factor: 9 for agent 1
INFO: Continuing with Bootcamp #0 BootcampName.SLOW_AGENT with slow factor: 9 for agent 0
INFO: Continuing with Bootcamp #0 BootcampName.SLOW_AGENT with slow factor: 8 for agent 1
INFO: Continuing with Bootcamp #0 BootcampName.SLOW_AGENT with slow factor: 8 for agent 0
INFO: Continuing with Bootcamp #0 BootcampName.SLOW_AGENT with slow factor: 7 for agent 1
INFO: Continuing with Bootcamp #0 BootcampName.SLOW_AGENT with slow factor: 7 for agent 0
INFO: Continuing with Bootcamp #0 BootcampName.SLOW_AGENT with slow factor: 6 for agent 1
INFO: Continuing with Bootcamp #0 BootcampName.SLOW_AGENT with slow factor: 6 for agent 0
INFO: Continuing with Bootcamp #0 BootcampName.SLOW_AGENT with slow factor: 5 for agent 1
INFO: Continuing with Bootcamp #0 BootcampName.SLOW_AGENT with slow factor: 5 for agent 0
INFO: Continuing with Bootcamp #0 BootcampName.SLOW_AGENT with slow factor: 4 for agent 1
INFO: Continuing with Bootcamp #0 BootcampName.SLOW_AGENT with slow factor: 4 for agent 0
INFO: Continuing with Bootcamp #0 BootcampName.SLOW_AGENT with slow factor: 3 for agent 1
INFO: Continuing with Bootcamp #0 BootcampName.SLOW_AGENT with slow factor: 3 for agent 0
INFO: Continuing with Bootcamp #0 BootcampName.SLOW_AGENT with slow factor: 2 for agent 1
INFO: Continuing with Bootcamp #0 BootcampName.SLOW_AGENT with slow factor: 2 for agent 0
INFO: BootcampName.SLOW_AGENT Bootcamp completed, starting BootcampName.COMBINED Bootcamp #0 for 1000 days
INFO: BootcampName.COMBINED Bootcamp completed, starting BootcampName.FINISHED Bootcamp #0 for 0 days
INFO: Early stopping at episode 500
INFO: BootcampName.HIDER Bootcamp completed, starting BootcampName.SEEKER Bootcamp #0 for 500 days
INFO: BootcampName.SEEKER Bootcamp completed, starting BootcampName.SLOW_AGENT Bootcamp #0 for 1000 days
INFO: Number of parameters: 30085
INFO: QNetwork(
  (conv_feature): Sequential()
  (fc_feature): Sequential(
    (0): Linear(in_features=100, out_features=128, bias=True)
    (1): ReLU()
    (2): Linear(in_features=128, out_features=128, bias=True)
    (3): ReLU()
    (4): Linear(in_features=128, out_features=5, bias=True)
  )
)
INFO: Learning...
INFO: BootcampName.HIDER Bootcamp completed, starting BootcampName.SEEKER Bootcamp #0 for 500 days
INFO: BootcampName.SEEKER Bootcamp completed, starting BootcampName.SLOW_AGENT Bootcamp #0 for 1000 days
INFO: Continuing with Bootcamp #0 BootcampName.SLOW_AGENT with slow factor: 9 for agent 1
INFO: Continuing with Bootcamp #0 BootcampName.SLOW_AGENT with slow factor: 9 for agent 0
INFO: Continuing with Bootcamp #0 BootcampName.SLOW_AGENT with slow factor: 8 for agent 1
INFO: Continuing with Bootcamp #0 BootcampName.SLOW_AGENT with slow factor: 8 for agent 0
INFO: Continuing with Bootcamp #0 BootcampName.SLOW_AGENT with slow factor: 7 for agent 1
INFO: Number of parameters: 30085
INFO: QNetwork(
  (conv_feature): Sequential()
  (fc_feature): Sequential(
    (0): Linear(in_features=100, out_features=128, bias=True)
    (1): ReLU()
    (2): Linear(in_features=128, out_features=128, bias=True)
    (3): ReLU()
    (4): Linear(in_features=128, out_features=5, bias=True)
  )
)
INFO: Learning...
INFO: BootcampName.HIDER Bootcamp completed, starting BootcampName.SEEKER Bootcamp #0 for 500 days
INFO: BootcampName.SEEKER Bootcamp completed, starting BootcampName.SLOW_AGENT Bootcamp #0 for 1000 days
INFO: Continuing with Bootcamp #0 BootcampName.SLOW_AGENT with slow factor: 9 for agent 1
INFO: Continuing with Bootcamp #0 BootcampName.SLOW_AGENT with slow factor: 9 for agent 0
INFO: Continuing with Bootcamp #0 BootcampName.SLOW_AGENT with slow factor: 8 for agent 1
INFO: Continuing with Bootcamp #0 BootcampName.SLOW_AGENT with slow factor: 8 for agent 0
INFO: Continuing with Bootcamp #0 BootcampName.SLOW_AGENT with slow factor: 7 for agent 1
INFO: Continuing with Bootcamp #0 BootcampName.SLOW_AGENT with slow factor: 7 for agent 0
INFO: Continuing with Bootcamp #0 BootcampName.SLOW_AGENT with slow factor: 6 for agent 1
INFO: Continuing with Bootcamp #0 BootcampName.SLOW_AGENT with slow factor: 6 for agent 0
INFO: Continuing with Bootcamp #0 BootcampName.SLOW_AGENT with slow factor: 5 for agent 1
INFO: Continuing with Bootcamp #0 BootcampName.SLOW_AGENT with slow factor: 5 for agent 0
INFO: Continuing with Bootcamp #0 BootcampName.SLOW_AGENT with slow factor: 4 for agent 1
INFO: Number of parameters: 30085
INFO: QNetwork(
  (conv_feature): Sequential()
  (fc_feature): Sequential(
    (0): Linear(in_features=100, out_features=128, bias=True)
    (1): ReLU()
    (2): Linear(in_features=128, out_features=128, bias=True)
    (3): ReLU()
    (4): Linear(in_features=128, out_features=5, bias=True)
  )
)
INFO: Learning...
INFO: BootcampName.HIDER Bootcamp completed, starting BootcampName.SEEKER Bootcamp #0 for 500 days
INFO: Early stopping at episode 10
INFO: BootcampName.HIDER Bootcamp completed, starting BootcampName.SEEKER Bootcamp #0 for 500 days
INFO: Early stopping at episode 10
INFO: Number of parameters: 30085
INFO: QNetwork(
  (conv_feature): Sequential()
  (fc_feature): Sequential(
    (0): Linear(in_features=100, out_features=128, bias=True)
    (1): ReLU()
    (2): Linear(in_features=128, out_features=128, bias=True)
    (3): ReLU()
    (4): Linear(in_features=128, out_features=5, bias=True)
  )
)
INFO: Learning...
INFO: BootcampName.HIDER Bootcamp completed, starting BootcampName.SEEKER Bootcamp #0 for 500 days
INFO: Early stopping at episode 10
INFO: BootcampName.HIDER Bootcamp completed, starting BootcampName.SEEKER Bootcamp #0 for 500 days
ERROR: [Errno 32] Broken pipe
ERROR: Traceback (most recent call last):
  File "/home/eirik/Projects/XAI/rl/src/dqn/wrapper/multi_agent_dqn.py", line 134, in learn
    self.wandb_manager.log(log)
  File "/home/eirik/Projects/XAI/rl/src/managers/wandb_manager.py", line 102, in log
    wandb.log(data)
  File "/home/eirik/.cache/pypoetry/virtualenvs/xai-is73Zs3s-py3.11/lib/python3.11/site-packages/wandb/sdk/wandb_run.py", line 452, in wrapper
    return func(self, *args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/eirik/.cache/pypoetry/virtualenvs/xai-is73Zs3s-py3.11/lib/python3.11/site-packages/wandb/sdk/wandb_run.py", line 403, in wrapper_fn
    return func(self, *args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/eirik/.cache/pypoetry/virtualenvs/xai-is73Zs3s-py3.11/lib/python3.11/site-packages/wandb/sdk/wandb_run.py", line 393, in wrapper
    return func(self, *args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/eirik/.cache/pypoetry/virtualenvs/xai-is73Zs3s-py3.11/lib/python3.11/site-packages/wandb/sdk/wandb_run.py", line 1933, in log
    self._log(data=data, step=step, commit=commit)
  File "/home/eirik/.cache/pypoetry/virtualenvs/xai-is73Zs3s-py3.11/lib/python3.11/site-packages/wandb/sdk/wandb_run.py", line 1652, in _log
    self._partial_history_callback(data, step, commit)
  File "/home/eirik/.cache/pypoetry/virtualenvs/xai-is73Zs3s-py3.11/lib/python3.11/site-packages/wandb/sdk/wandb_run.py", line 1524, in _partial_history_callback
    self._backend.interface.publish_partial_history(
  File "/home/eirik/.cache/pypoetry/virtualenvs/xai-is73Zs3s-py3.11/lib/python3.11/site-packages/wandb/sdk/interface/interface.py", line 647, in publish_partial_history
    self._publish_partial_history(partial_history)
  File "/home/eirik/.cache/pypoetry/virtualenvs/xai-is73Zs3s-py3.11/lib/python3.11/site-packages/wandb/sdk/interface/interface_shared.py", line 89, in _publish_partial_history
    self._publish(rec)
  File "/home/eirik/.cache/pypoetry/virtualenvs/xai-is73Zs3s-py3.11/lib/python3.11/site-packages/wandb/sdk/interface/interface_sock.py", line 51, in _publish
    self._sock_client.send_record_publish(record)
  File "/home/eirik/.cache/pypoetry/virtualenvs/xai-is73Zs3s-py3.11/lib/python3.11/site-packages/wandb/sdk/lib/sock_client.py", line 225, in send_record_publish
    self.send_server_request(server_req)
  File "/home/eirik/.cache/pypoetry/virtualenvs/xai-is73Zs3s-py3.11/lib/python3.11/site-packages/wandb/sdk/lib/sock_client.py", line 157, in send_server_request
    self._send_message(msg)
  File "/home/eirik/.cache/pypoetry/virtualenvs/xai-is73Zs3s-py3.11/lib/python3.11/site-packages/wandb/sdk/lib/sock_client.py", line 154, in _send_message
    self._sendall_with_error_handle(header + data)
  File "/home/eirik/.cache/pypoetry/virtualenvs/xai-is73Zs3s-py3.11/lib/python3.11/site-packages/wandb/sdk/lib/sock_client.py", line 132, in _sendall_with_error_handle
    sent = self._sock.send(data)
           ^^^^^^^^^^^^^^^^^^^^^
BrokenPipeError: [Errno 32] Broken pipe

INFO: Number of parameters: 30085
INFO: QNetwork(
  (conv_feature): Sequential()
  (fc_feature): Sequential(
    (0): Linear(in_features=100, out_features=128, bias=True)
    (1): ReLU()
    (2): Linear(in_features=128, out_features=128, bias=True)
    (3): ReLU()
    (4): Linear(in_features=128, out_features=5, bias=True)
  )
)
INFO: Learning...
INFO: BootcampName.HIDER Bootcamp completed, starting BootcampName.SEEKER Bootcamp #0 for 500 days
INFO: BootcampName.SEEKER Bootcamp completed, starting BootcampName.SLOW_AGENT Bootcamp #0 for 1000 days
INFO: Continuing with Bootcamp #0 BootcampName.SLOW_AGENT with slow factor: 9 for agent 1
INFO: Continuing with Bootcamp #0 BootcampName.SLOW_AGENT with slow factor: 9 for agent 0
INFO: Continuing with Bootcamp #0 BootcampName.SLOW_AGENT with slow factor: 8 for agent 1
INFO: Continuing with Bootcamp #0 BootcampName.SLOW_AGENT with slow factor: 8 for agent 0
INFO: Continuing with Bootcamp #0 BootcampName.SLOW_AGENT with slow factor: 7 for agent 1
INFO: Continuing with Bootcamp #0 BootcampName.SLOW_AGENT with slow factor: 7 for agent 0
INFO: Continuing with Bootcamp #0 BootcampName.SLOW_AGENT with slow factor: 6 for agent 1
INFO: Continuing with Bootcamp #0 BootcampName.SLOW_AGENT with slow factor: 6 for agent 0
INFO: Continuing with Bootcamp #0 BootcampName.SLOW_AGENT with slow factor: 5 for agent 1
INFO: Continuing with Bootcamp #0 BootcampName.SLOW_AGENT with slow factor: 5 for agent 0
INFO: Continuing with Bootcamp #0 BootcampName.SLOW_AGENT with slow factor: 4 for agent 1
INFO: Continuing with Bootcamp #0 BootcampName.SLOW_AGENT with slow factor: 4 for agent 0
INFO: Continuing with Bootcamp #0 BootcampName.SLOW_AGENT with slow factor: 3 for agent 1
INFO: Continuing with Bootcamp #0 BootcampName.SLOW_AGENT with slow factor: 3 for agent 0
INFO: Continuing with Bootcamp #0 BootcampName.SLOW_AGENT with slow factor: 2 for agent 1
INFO: Continuing with Bootcamp #0 BootcampName.SLOW_AGENT with slow factor: 2 for agent 0
INFO: BootcampName.SLOW_AGENT Bootcamp completed, starting BootcampName.COMBINED Bootcamp #0 for 1000 days
INFO: BootcampName.COMBINED Bootcamp completed, starting BootcampName.FINISHED Bootcamp #0 for 0 days
ERROR: [Errno 32] Broken pipe
ERROR: Traceback (most recent call last):
  File "/home/eirik/Projects/XAI/rl/src/dqn/wrapper/multi_agent_dqn.py", line 138, in learn
    self.wandb_manager.log(log)
  File "/home/eirik/Projects/XAI/rl/src/managers/wandb_manager.py", line 102, in log
    wandb.log(data)
  File "/home/eirik/.cache/pypoetry/virtualenvs/xai-is73Zs3s-py3.11/lib/python3.11/site-packages/wandb/sdk/wandb_run.py", line 452, in wrapper
    return func(self, *args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/eirik/.cache/pypoetry/virtualenvs/xai-is73Zs3s-py3.11/lib/python3.11/site-packages/wandb/sdk/wandb_run.py", line 403, in wrapper_fn
    return func(self, *args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/eirik/.cache/pypoetry/virtualenvs/xai-is73Zs3s-py3.11/lib/python3.11/site-packages/wandb/sdk/wandb_run.py", line 393, in wrapper
    return func(self, *args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/eirik/.cache/pypoetry/virtualenvs/xai-is73Zs3s-py3.11/lib/python3.11/site-packages/wandb/sdk/wandb_run.py", line 1933, in log
    self._log(data=data, step=step, commit=commit)
  File "/home/eirik/.cache/pypoetry/virtualenvs/xai-is73Zs3s-py3.11/lib/python3.11/site-packages/wandb/sdk/wandb_run.py", line 1652, in _log
    self._partial_history_callback(data, step, commit)
  File "/home/eirik/.cache/pypoetry/virtualenvs/xai-is73Zs3s-py3.11/lib/python3.11/site-packages/wandb/sdk/wandb_run.py", line 1524, in _partial_history_callback
    self._backend.interface.publish_partial_history(
  File "/home/eirik/.cache/pypoetry/virtualenvs/xai-is73Zs3s-py3.11/lib/python3.11/site-packages/wandb/sdk/interface/interface.py", line 647, in publish_partial_history
    self._publish_partial_history(partial_history)
  File "/home/eirik/.cache/pypoetry/virtualenvs/xai-is73Zs3s-py3.11/lib/python3.11/site-packages/wandb/sdk/interface/interface_shared.py", line 89, in _publish_partial_history
    self._publish(rec)
  File "/home/eirik/.cache/pypoetry/virtualenvs/xai-is73Zs3s-py3.11/lib/python3.11/site-packages/wandb/sdk/interface/interface_sock.py", line 51, in _publish
    self._sock_client.send_record_publish(record)
  File "/home/eirik/.cache/pypoetry/virtualenvs/xai-is73Zs3s-py3.11/lib/python3.11/site-packages/wandb/sdk/lib/sock_client.py", line 225, in send_record_publish
    self.send_server_request(server_req)
  File "/home/eirik/.cache/pypoetry/virtualenvs/xai-is73Zs3s-py3.11/lib/python3.11/site-packages/wandb/sdk/lib/sock_client.py", line 157, in send_server_request
    self._send_message(msg)
  File "/home/eirik/.cache/pypoetry/virtualenvs/xai-is73Zs3s-py3.11/lib/python3.11/site-packages/wandb/sdk/lib/sock_client.py", line 154, in _send_message
    self._sendall_with_error_handle(header + data)
  File "/home/eirik/.cache/pypoetry/virtualenvs/xai-is73Zs3s-py3.11/lib/python3.11/site-packages/wandb/sdk/lib/sock_client.py", line 132, in _sendall_with_error_handle
    sent = self._sock.send(data)
           ^^^^^^^^^^^^^^^^^^^^^
BrokenPipeError: [Errno 32] Broken pipe

INFO: Number of parameters: 30085
INFO: QNetwork(
  (conv_feature): Sequential()
  (fc_feature): Sequential(
    (0): Linear(in_features=100, out_features=128, bias=True)
    (1): ReLU()
    (2): Linear(in_features=128, out_features=128, bias=True)
    (3): ReLU()
    (4): Linear(in_features=128, out_features=5, bias=True)
  )
)
INFO: Learning...
INFO: BootcampName.HIDER Bootcamp completed, starting BootcampName.SEEKER Bootcamp #0 for 500 days
INFO: BootcampName.SEEKER Bootcamp completed, starting BootcampName.SLOW_AGENT Bootcamp #0 for 1000 days
INFO: Continuing with Bootcamp #0 BootcampName.SLOW_AGENT with slow factor: 9 for agent 1
INFO: Continuing with Bootcamp #0 BootcampName.SLOW_AGENT with slow factor: 9 for agent 0
INFO: Continuing with Bootcamp #0 BootcampName.SLOW_AGENT with slow factor: 8 for agent 1
INFO: Continuing with Bootcamp #0 BootcampName.SLOW_AGENT with slow factor: 8 for agent 0
INFO: Continuing with Bootcamp #0 BootcampName.SLOW_AGENT with slow factor: 7 for agent 1
INFO: Continuing with Bootcamp #0 BootcampName.SLOW_AGENT with slow factor: 7 for agent 0
INFO: Continuing with Bootcamp #0 BootcampName.SLOW_AGENT with slow factor: 6 for agent 1
INFO: Continuing with Bootcamp #0 BootcampName.SLOW_AGENT with slow factor: 6 for agent 0
INFO: Number of parameters: 30085
INFO: QNetwork(
  (conv_feature): Sequential()
  (fc_feature): Sequential(
    (0): Linear(in_features=100, out_features=128, bias=True)
    (1): ReLU()
    (2): Linear(in_features=128, out_features=128, bias=True)
    (3): ReLU()
    (4): Linear(in_features=128, out_features=5, bias=True)
  )
)
INFO: Learning...
INFO: BootcampName.HIDER Bootcamp completed, starting BootcampName.SEEKER Bootcamp #0 for 500 days
INFO: BootcampName.SEEKER Bootcamp completed, starting BootcampName.SLOW_AGENT Bootcamp #0 for 1000 days
INFO: Continuing with Bootcamp #0 BootcampName.SLOW_AGENT with slow factor: 9 for agent 1
INFO: Continuing with Bootcamp #0 BootcampName.SLOW_AGENT with slow factor: 9 for agent 0
INFO: Continuing with Bootcamp #0 BootcampName.SLOW_AGENT with slow factor: 8 for agent 1
INFO: Number of parameters: 30085
INFO: QNetwork(
  (conv_feature): Sequential()
  (fc_feature): Sequential(
    (0): Linear(in_features=100, out_features=128, bias=True)
    (1): ReLU()
    (2): Linear(in_features=128, out_features=128, bias=True)
    (3): ReLU()
    (4): Linear(in_features=128, out_features=5, bias=True)
  )
)
INFO: Learning...
INFO: BootcampName.HIDER Bootcamp completed, starting BootcampName.SEEKER Bootcamp #0 for 500 days
INFO: BootcampName.SEEKER Bootcamp completed, starting BootcampName.SLOW_AGENT Bootcamp #0 for 1000 days
INFO: Continuing with Bootcamp #0 BootcampName.SLOW_AGENT with slow factor: 9 for agent 1
INFO: Continuing with Bootcamp #0 BootcampName.SLOW_AGENT with slow factor: 9 for agent 0
INFO: Continuing with Bootcamp #0 BootcampName.SLOW_AGENT with slow factor: 8 for agent 1
INFO: Number of parameters: 30085
INFO: QNetwork(
  (conv_feature): Sequential()
  (fc_feature): Sequential(
    (0): Linear(in_features=100, out_features=128, bias=True)
    (1): ReLU()
    (2): Linear(in_features=128, out_features=128, bias=True)
    (3): ReLU()
    (4): Linear(in_features=128, out_features=5, bias=True)
  )
)
INFO: Learning...
INFO: Number of parameters: 30085
INFO: QNetwork(
  (conv_feature): Sequential()
  (fc_feature): Sequential(
    (0): Linear(in_features=100, out_features=128, bias=True)
    (1): ReLU()
    (2): Linear(in_features=128, out_features=128, bias=True)
    (3): ReLU()
    (4): Linear(in_features=128, out_features=5, bias=True)
  )
)
INFO: Learning...
INFO: BootcampName.HIDER Bootcamp completed, starting BootcampName.SEEKER Bootcamp #0 for 500 days
INFO: BootcampName.SEEKER Bootcamp completed, starting BootcampName.SLOW_AGENT Bootcamp #0 for 1000 days
INFO: Continuing with Bootcamp #0 BootcampName.SLOW_AGENT with slow factor: 9 for agent 1
INFO: Continuing with Bootcamp #0 BootcampName.SLOW_AGENT with slow factor: 9 for agent 0
INFO: Continuing with Bootcamp #0 BootcampName.SLOW_AGENT with slow factor: 8 for agent 1
INFO: Continuing with Bootcamp #0 BootcampName.SLOW_AGENT with slow factor: 8 for agent 0
INFO: Number of parameters: 30085
INFO: QNetwork(
  (conv_feature): Sequential()
  (fc_feature): Sequential(
    (0): Linear(in_features=100, out_features=128, bias=True)
    (1): ReLU()
    (2): Linear(in_features=128, out_features=128, bias=True)
    (3): ReLU()
    (4): Linear(in_features=128, out_features=5, bias=True)
  )
)
INFO: Learning...
INFO: BootcampName.HIDER Bootcamp completed, starting BootcampName.SEEKER Bootcamp #0 for 500 days
INFO: BootcampName.SEEKER Bootcamp completed, starting BootcampName.SLOW_AGENT Bootcamp #0 for 1000 days
INFO: Number of parameters: 30085
INFO: QNetwork(
  (conv_feature): Sequential()
  (fc_feature): Sequential(
    (0): Linear(in_features=100, out_features=128, bias=True)
    (1): ReLU()
    (2): Linear(in_features=128, out_features=128, bias=True)
    (3): ReLU()
    (4): Linear(in_features=128, out_features=5, bias=True)
  )
)
INFO: Learning...
INFO: BootcampName.HIDER Bootcamp completed, starting BootcampName.SEEKER Bootcamp #0 for 500 days
INFO: BootcampName.SEEKER Bootcamp completed, starting BootcampName.SLOW_AGENT Bootcamp #0 for 1000 days
INFO: Continuing with Bootcamp #0 BootcampName.SLOW_AGENT with slow factor: 9 for agent 1
INFO: Continuing with Bootcamp #0 BootcampName.SLOW_AGENT with slow factor: 9 for agent 0
INFO: Number of parameters: 30085
INFO: QNetwork(
  (conv_feature): Sequential()
  (fc_feature): Sequential(
    (0): Linear(in_features=100, out_features=128, bias=True)
    (1): ReLU()
    (2): Linear(in_features=128, out_features=128, bias=True)
    (3): ReLU()
    (4): Linear(in_features=128, out_features=5, bias=True)
  )
)
INFO: Learning...
INFO: Number of parameters: 30085
INFO: QNetwork(
  (conv_feature): Sequential()
  (fc_feature): Sequential(
    (0): Linear(in_features=100, out_features=128, bias=True)
    (1): ReLU()
    (2): Linear(in_features=128, out_features=128, bias=True)
    (3): ReLU()
    (4): Linear(in_features=128, out_features=5, bias=True)
  )
)
WARNING: GIF is enabled but the environment does not support RGB array rendering.
INFO: Learning...
INFO: Number of parameters: 30085
INFO: QNetwork(
  (conv_feature): Sequential()
  (fc_feature): Sequential(
    (0): Linear(in_features=100, out_features=128, bias=True)
    (1): ReLU()
    (2): Linear(in_features=128, out_features=128, bias=True)
    (3): ReLU()
    (4): Linear(in_features=128, out_features=5, bias=True)
  )
)
WARNING: GIF is enabled but the environment does not support RGB array rendering.
INFO: Learning...
INFO: BootcampName.HIDER Bootcamp completed, starting BootcampName.SEEKER Bootcamp #0 for 500 days
INFO: BootcampName.SEEKER Bootcamp completed, starting BootcampName.SLOW_AGENT Bootcamp #0 for 1000 days
INFO: Number of parameters: 30085
INFO: QNetwork(
  (conv_feature): Sequential()
  (fc_feature): Sequential(
    (0): Linear(in_features=100, out_features=128, bias=True)
    (1): ReLU()
    (2): Linear(in_features=128, out_features=128, bias=True)
    (3): ReLU()
    (4): Linear(in_features=128, out_features=5, bias=True)
  )
)
WARNING: GIF is enabled but the environment does not support RGB array rendering.
INFO: Learning...
INFO: BootcampName.HIDER Bootcamp completed, starting BootcampName.SEEKER Bootcamp #0 for 500 days
INFO: BootcampName.SEEKER Bootcamp completed, starting BootcampName.SLOW_AGENT Bootcamp #0 for 1000 days
INFO: Number of parameters: 30085
INFO: QNetwork(
  (conv_feature): Sequential()
  (fc_feature): Sequential(
    (0): Linear(in_features=100, out_features=128, bias=True)
    (1): ReLU()
    (2): Linear(in_features=128, out_features=128, bias=True)
    (3): ReLU()
    (4): Linear(in_features=128, out_features=5, bias=True)
  )
)
WARNING: GIF is enabled but the environment does not support RGB array rendering.
INFO: Learning...
INFO: Number of parameters: 30085
INFO: QNetwork(
  (conv_feature): Sequential()
  (fc_feature): Sequential(
    (0): Linear(in_features=100, out_features=128, bias=True)
    (1): ReLU()
    (2): Linear(in_features=128, out_features=128, bias=True)
    (3): ReLU()
    (4): Linear(in_features=128, out_features=5, bias=True)
  )
)
WARNING: GIF is enabled but the environment does not support RGB array rendering.
INFO: Learning...
INFO: Number of parameters: 30085
INFO: QNetwork(
  (conv_feature): Sequential()
  (fc_feature): Sequential(
    (0): Linear(in_features=100, out_features=128, bias=True)
    (1): ReLU()
    (2): Linear(in_features=128, out_features=128, bias=True)
    (3): ReLU()
    (4): Linear(in_features=128, out_features=5, bias=True)
  )
)
WARNING: GIF is enabled but the environment does not support RGB array rendering.
INFO: Learning...
INFO: Number of parameters: 30085
INFO: QNetwork(
  (conv_feature): Sequential()
  (fc_feature): Sequential(
    (0): Linear(in_features=100, out_features=128, bias=True)
    (1): ReLU()
    (2): Linear(in_features=128, out_features=128, bias=True)
    (3): ReLU()
    (4): Linear(in_features=128, out_features=5, bias=True)
  )
)
WARNING: GIF is enabled but the environment does not support RGB array rendering.
INFO: Learning...
INFO: Number of parameters: 30085
INFO: QNetwork(
  (conv_feature): Sequential()
  (fc_feature): Sequential(
    (0): Linear(in_features=100, out_features=128, bias=True)
    (1): ReLU()
    (2): Linear(in_features=128, out_features=128, bias=True)
    (3): ReLU()
    (4): Linear(in_features=128, out_features=5, bias=True)
  )
)
WARNING: GIF is enabled but the environment does not support RGB array rendering.
INFO: Learning...
INFO: BootcampName.HIDER Bootcamp completed, starting BootcampName.SEEKER Bootcamp #0 for 500 days
INFO: Number of parameters: 30085
INFO: QNetwork(
  (conv_feature): Sequential()
  (fc_feature): Sequential(
    (0): Linear(in_features=100, out_features=128, bias=True)
    (1): ReLU()
    (2): Linear(in_features=128, out_features=128, bias=True)
    (3): ReLU()
    (4): Linear(in_features=128, out_features=5, bias=True)
  )
)
INFO: Learning...
INFO: BootcampName.HIDER Bootcamp completed, starting BootcampName.SEEKER Bootcamp #0 for 500 days
INFO: BootcampName.SEEKER Bootcamp completed, starting BootcampName.SLOW_AGENT Bootcamp #0 for 1000 days
INFO: Continuing with Bootcamp #0 BootcampName.SLOW_AGENT with slow factor: 9 for agent 1
INFO: Continuing with Bootcamp #0 BootcampName.SLOW_AGENT with slow factor: 9 for agent 0
INFO: Continuing with Bootcamp #0 BootcampName.SLOW_AGENT with slow factor: 8 for agent 1
INFO: Continuing with Bootcamp #0 BootcampName.SLOW_AGENT with slow factor: 8 for agent 0
INFO: Continuing with Bootcamp #0 BootcampName.SLOW_AGENT with slow factor: 7 for agent 1
INFO: Number of parameters: 30085
INFO: QNetwork(
  (conv_feature): Sequential()
  (fc_feature): Sequential(
    (0): Linear(in_features=100, out_features=128, bias=True)
    (1): ReLU()
    (2): Linear(in_features=128, out_features=128, bias=True)
    (3): ReLU()
    (4): Linear(in_features=128, out_features=5, bias=True)
  )
)
INFO: Learning...
INFO: BootcampName.HIDER Bootcamp completed, starting BootcampName.SEEKER Bootcamp #0 for 500 days
INFO: BootcampName.SEEKER Bootcamp completed, starting BootcampName.SLOW_AGENT Bootcamp #0 for 1000 days
INFO: Continuing with Bootcamp #0 BootcampName.SLOW_AGENT with slow factor: 9 for agent 1
INFO: Continuing with Bootcamp #0 BootcampName.SLOW_AGENT with slow factor: 9 for agent 0
INFO: Continuing with Bootcamp #0 BootcampName.SLOW_AGENT with slow factor: 8 for agent 1
INFO: Continuing with Bootcamp #0 BootcampName.SLOW_AGENT with slow factor: 8 for agent 0
INFO: Continuing with Bootcamp #0 BootcampName.SLOW_AGENT with slow factor: 7 for agent 1
INFO: Continuing with Bootcamp #0 BootcampName.SLOW_AGENT with slow factor: 7 for agent 0
INFO: Number of parameters: 30085
INFO: QNetwork(
  (conv_feature): Sequential()
  (fc_feature): Sequential(
    (0): Linear(in_features=100, out_features=128, bias=True)
    (1): ReLU()
    (2): Linear(in_features=128, out_features=128, bias=True)
    (3): ReLU()
    (4): Linear(in_features=128, out_features=5, bias=True)
  )
)
INFO: Learning...
INFO: BootcampName.HIDER Bootcamp completed, starting BootcampName.SEEKER Bootcamp #0 for 500 days
INFO: BootcampName.SEEKER Bootcamp completed, starting BootcampName.SLOW_AGENT Bootcamp #0 for 1000 days
INFO: Continuing with Bootcamp #0 BootcampName.SLOW_AGENT with slow factor: 9 for agent 1
INFO: Continuing with Bootcamp #0 BootcampName.SLOW_AGENT with slow factor: 9 for agent 0
INFO: Continuing with Bootcamp #0 BootcampName.SLOW_AGENT with slow factor: 8 for agent 1
INFO: Continuing with Bootcamp #0 BootcampName.SLOW_AGENT with slow factor: 8 for agent 0
INFO: Continuing with Bootcamp #0 BootcampName.SLOW_AGENT with slow factor: 7 for agent 1
INFO: Continuing with Bootcamp #0 BootcampName.SLOW_AGENT with slow factor: 7 for agent 0
INFO: Continuing with Bootcamp #0 BootcampName.SLOW_AGENT with slow factor: 6 for agent 1
INFO: Continuing with Bootcamp #0 BootcampName.SLOW_AGENT with slow factor: 6 for agent 0
INFO: Continuing with Bootcamp #0 BootcampName.SLOW_AGENT with slow factor: 5 for agent 1
INFO: Continuing with Bootcamp #0 BootcampName.SLOW_AGENT with slow factor: 5 for agent 0
INFO: Continuing with Bootcamp #0 BootcampName.SLOW_AGENT with slow factor: 4 for agent 1
INFO: Continuing with Bootcamp #0 BootcampName.SLOW_AGENT with slow factor: 4 for agent 0
INFO: Continuing with Bootcamp #0 BootcampName.SLOW_AGENT with slow factor: 3 for agent 1
INFO: Continuing with Bootcamp #0 BootcampName.SLOW_AGENT with slow factor: 3 for agent 0
INFO: Continuing with Bootcamp #0 BootcampName.SLOW_AGENT with slow factor: 2 for agent 1
INFO: Continuing with Bootcamp #0 BootcampName.SLOW_AGENT with slow factor: 2 for agent 0
INFO: BootcampName.SLOW_AGENT Bootcamp completed, starting BootcampName.COMBINED Bootcamp #0 for 1000 days
INFO: BootcampName.COMBINED Bootcamp completed, starting BootcampName.FINISHED Bootcamp #0 for 0 days
INFO: Number of parameters: 30085
INFO: QNetwork(
  (conv_feature): Sequential()
  (fc_feature): Sequential(
    (0): Linear(in_features=100, out_features=128, bias=True)
    (1): ReLU()
    (2): Linear(in_features=128, out_features=128, bias=True)
    (3): ReLU()
    (4): Linear(in_features=128, out_features=5, bias=True)
  )
)
INFO: Learning...
INFO: Number of parameters: 30085
INFO: QNetwork(
  (conv_feature): Sequential()
  (fc_feature): Sequential(
    (0): Linear(in_features=100, out_features=128, bias=True)
    (1): ReLU()
    (2): Linear(in_features=128, out_features=128, bias=True)
    (3): ReLU()
    (4): Linear(in_features=128, out_features=5, bias=True)
  )
)
INFO: Learning...
INFO: Number of parameters: 30085
INFO: QNetwork(
  (conv_feature): Sequential()
  (fc_feature): Sequential(
    (0): Linear(in_features=100, out_features=128, bias=True)
    (1): ReLU()
    (2): Linear(in_features=128, out_features=128, bias=True)
    (3): ReLU()
    (4): Linear(in_features=128, out_features=5, bias=True)
  )
)
WARNING: GIF is enabled but the environment does not support RGB array rendering.
INFO: Learning...
INFO: Number of parameters: 30085
INFO: QNetwork(
  (conv_feature): Sequential()
  (fc_feature): Sequential(
    (0): Linear(in_features=100, out_features=128, bias=True)
    (1): ReLU()
    (2): Linear(in_features=128, out_features=128, bias=True)
    (3): ReLU()
    (4): Linear(in_features=128, out_features=5, bias=True)
  )
)
WARNING: GIF is enabled but the environment does not support RGB array rendering.
INFO: Learning...
INFO: Number of parameters: 30085
INFO: QNetwork(
  (conv_feature): Sequential()
  (fc_feature): Sequential(
    (0): Linear(in_features=100, out_features=128, bias=True)
    (1): ReLU()
    (2): Linear(in_features=128, out_features=128, bias=True)
    (3): ReLU()
    (4): Linear(in_features=128, out_features=5, bias=True)
  )
)
WARNING: GIF is enabled but the environment does not support RGB array rendering.
INFO: Learning...
INFO: Number of parameters: 30085
INFO: QNetwork(
  (conv_feature): Sequential()
  (fc_feature): Sequential(
    (0): Linear(in_features=100, out_features=128, bias=True)
    (1): ReLU()
    (2): Linear(in_features=128, out_features=128, bias=True)
    (3): ReLU()
    (4): Linear(in_features=128, out_features=5, bias=True)
  )
)
WARNING: GIF is enabled but the environment does not support RGB array rendering.
INFO: Learning...
ERROR: display Surface quit
ERROR: Traceback (most recent call last):
  File "/home/eirik/Projects/XAI/rl/src/dqn/wrapper/multi_agent_dqn.py", line 107, in learn
    self._collect_rollouts()
  File "/home/eirik/Projects/XAI/rl/src/dqn/wrapper/multi_agent_dqn.py", line 202, in _collect_rollouts
    ) = self.env.get_wrapper_attr("step_multiple")(actions)
        ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/eirik/Projects/XAI/environments/gymnasium/wrappers/multi_agent_env.py", line 44, in step_multiple
    ) = self.get_wrapper_attr("concatenate_states")(full_states)
        ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/eirik/Projects/XAI/environments/gymnasium/envs/tag/tag.py", line 263, in concatenate_states
    self.render(self.render_mode)
  File "/home/eirik/Projects/XAI/environments/gymnasium/envs/tag/tag.py", line 241, in render
    return self.tag_renderer.render(self.state.full, render_mode)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/eirik/Projects/XAI/environments/gymnasium/envs/tag/tag_renderer.py", line 78, in render
    self.screen.blit(surf, (0, 0))
pygame.error: display Surface quit

INFO: Number of parameters: 30085
INFO: QNetwork(
  (conv_feature): Sequential()
  (fc_feature): Sequential(
    (0): Linear(in_features=100, out_features=128, bias=True)
    (1): ReLU()
    (2): Linear(in_features=128, out_features=128, bias=True)
    (3): ReLU()
    (4): Linear(in_features=128, out_features=5, bias=True)
  )
)
INFO: Learning...
INFO: BootcampName.HIDER Bootcamp completed, starting BootcampName.SEEKER Bootcamp #0 for 500 days
INFO: BootcampName.SEEKER Bootcamp completed, starting BootcampName.SLOW_AGENT Bootcamp #0 for 1000 days
INFO: Continuing with Bootcamp #0 BootcampName.SLOW_AGENT with slow factor: 9 for agent 1
INFO: Continuing with Bootcamp #0 BootcampName.SLOW_AGENT with slow factor: 9 for agent 0
INFO: Continuing with Bootcamp #0 BootcampName.SLOW_AGENT with slow factor: 8 for agent 1
INFO: Continuing with Bootcamp #0 BootcampName.SLOW_AGENT with slow factor: 8 for agent 0
INFO: Continuing with Bootcamp #0 BootcampName.SLOW_AGENT with slow factor: 7 for agent 1
INFO: Continuing with Bootcamp #0 BootcampName.SLOW_AGENT with slow factor: 7 for agent 0
INFO: Continuing with Bootcamp #0 BootcampName.SLOW_AGENT with slow factor: 6 for agent 1
INFO: Continuing with Bootcamp #0 BootcampName.SLOW_AGENT with slow factor: 6 for agent 0
INFO: Continuing with Bootcamp #0 BootcampName.SLOW_AGENT with slow factor: 5 for agent 1
INFO: Continuing with Bootcamp #0 BootcampName.SLOW_AGENT with slow factor: 5 for agent 0
INFO: Continuing with Bootcamp #0 BootcampName.SLOW_AGENT with slow factor: 4 for agent 1
INFO: Continuing with Bootcamp #0 BootcampName.SLOW_AGENT with slow factor: 4 for agent 0
INFO: Continuing with Bootcamp #0 BootcampName.SLOW_AGENT with slow factor: 3 for agent 1
INFO: Continuing with Bootcamp #0 BootcampName.SLOW_AGENT with slow factor: 3 for agent 0
INFO: Continuing with Bootcamp #0 BootcampName.SLOW_AGENT with slow factor: 2 for agent 1
INFO: Continuing with Bootcamp #0 BootcampName.SLOW_AGENT with slow factor: 2 for agent 0
INFO: BootcampName.SLOW_AGENT Bootcamp completed, starting BootcampName.COMBINED Bootcamp #0 for 1000 days
INFO: BootcampName.COMBINED Bootcamp completed, starting BootcampName.FINISHED Bootcamp #0 for 0 days
INFO: Number of parameters: 30085
INFO: QNetwork(
  (conv_feature): Sequential()
  (fc_feature): Sequential(
    (0): Linear(in_features=100, out_features=128, bias=True)
    (1): ReLU()
    (2): Linear(in_features=128, out_features=128, bias=True)
    (3): ReLU()
    (4): Linear(in_features=128, out_features=5, bias=True)
  )
)
INFO: Learning...
INFO: BootcampName.HIDER Bootcamp completed, starting BootcampName.SEEKER Bootcamp #0 for 500 days
INFO: BootcampName.SEEKER Bootcamp completed, starting BootcampName.SLOW_AGENT Bootcamp #0 for 1000 days
INFO: Continuing with Bootcamp #0 BootcampName.SLOW_AGENT with slow factor: 9 for agent 1
INFO: Continuing with Bootcamp #0 BootcampName.SLOW_AGENT with slow factor: 9 for agent 0
INFO: Continuing with Bootcamp #0 BootcampName.SLOW_AGENT with slow factor: 8 for agent 1
INFO: Continuing with Bootcamp #0 BootcampName.SLOW_AGENT with slow factor: 8 for agent 0
INFO: Continuing with Bootcamp #0 BootcampName.SLOW_AGENT with slow factor: 7 for agent 1
INFO: Continuing with Bootcamp #0 BootcampName.SLOW_AGENT with slow factor: 7 for agent 0
INFO: Continuing with Bootcamp #0 BootcampName.SLOW_AGENT with slow factor: 6 for agent 1
INFO: Continuing with Bootcamp #0 BootcampName.SLOW_AGENT with slow factor: 6 for agent 0
INFO: Continuing with Bootcamp #0 BootcampName.SLOW_AGENT with slow factor: 5 for agent 1
INFO: Continuing with Bootcamp #0 BootcampName.SLOW_AGENT with slow factor: 5 for agent 0
INFO: Continuing with Bootcamp #0 BootcampName.SLOW_AGENT with slow factor: 4 for agent 1
INFO: Continuing with Bootcamp #0 BootcampName.SLOW_AGENT with slow factor: 4 for agent 0
INFO: Continuing with Bootcamp #0 BootcampName.SLOW_AGENT with slow factor: 3 for agent 1
INFO: Continuing with Bootcamp #0 BootcampName.SLOW_AGENT with slow factor: 3 for agent 0
INFO: Continuing with Bootcamp #0 BootcampName.SLOW_AGENT with slow factor: 2 for agent 1
INFO: Continuing with Bootcamp #0 BootcampName.SLOW_AGENT with slow factor: 2 for agent 0
INFO: BootcampName.SLOW_AGENT Bootcamp completed, starting BootcampName.COMBINED Bootcamp #0 for 1000 days
INFO: BootcampName.COMBINED Bootcamp completed, starting BootcampName.FINISHED Bootcamp #0 for 0 days
INFO: Number of parameters: 30085
INFO: QNetwork(
  (conv_feature): Sequential()
  (fc_feature): Sequential(
    (0): Linear(in_features=100, out_features=128, bias=True)
    (1): ReLU()
    (2): Linear(in_features=128, out_features=128, bias=True)
    (3): ReLU()
    (4): Linear(in_features=128, out_features=5, bias=True)
  )
)
INFO: Learning...
INFO: BootcampName.HIDER Bootcamp completed, starting BootcampName.SEEKER Bootcamp #0 for 500 days
INFO: BootcampName.SEEKER Bootcamp completed, starting BootcampName.SLOW_AGENT Bootcamp #0 for 1000 days
INFO: Continuing with Bootcamp #0 BootcampName.SLOW_AGENT with slow factor: 9 for agent 1
INFO: Continuing with Bootcamp #0 BootcampName.SLOW_AGENT with slow factor: 9 for agent 0
INFO: Continuing with Bootcamp #0 BootcampName.SLOW_AGENT with slow factor: 8 for agent 1
INFO: Continuing with Bootcamp #0 BootcampName.SLOW_AGENT with slow factor: 8 for agent 0
INFO: Continuing with Bootcamp #0 BootcampName.SLOW_AGENT with slow factor: 7 for agent 1
INFO: Continuing with Bootcamp #0 BootcampName.SLOW_AGENT with slow factor: 7 for agent 0
INFO: Continuing with Bootcamp #0 BootcampName.SLOW_AGENT with slow factor: 6 for agent 1
INFO: Continuing with Bootcamp #0 BootcampName.SLOW_AGENT with slow factor: 6 for agent 0
INFO: Continuing with Bootcamp #0 BootcampName.SLOW_AGENT with slow factor: 5 for agent 1
INFO: Continuing with Bootcamp #0 BootcampName.SLOW_AGENT with slow factor: 5 for agent 0
INFO: Continuing with Bootcamp #0 BootcampName.SLOW_AGENT with slow factor: 4 for agent 1
INFO: Continuing with Bootcamp #0 BootcampName.SLOW_AGENT with slow factor: 4 for agent 0
INFO: Continuing with Bootcamp #0 BootcampName.SLOW_AGENT with slow factor: 3 for agent 1
INFO: Continuing with Bootcamp #0 BootcampName.SLOW_AGENT with slow factor: 3 for agent 0
INFO: Continuing with Bootcamp #0 BootcampName.SLOW_AGENT with slow factor: 2 for agent 1
INFO: Continuing with Bootcamp #0 BootcampName.SLOW_AGENT with slow factor: 2 for agent 0
INFO: BootcampName.SLOW_AGENT Bootcamp completed, starting BootcampName.COMBINED Bootcamp #0 for 1000 days
INFO: BootcampName.COMBINED Bootcamp completed, starting BootcampName.FINISHED Bootcamp #0 for 0 days
INFO: Number of parameters: 30085
INFO: QNetwork(
  (conv_feature): Sequential()
  (fc_feature): Sequential(
    (0): Linear(in_features=100, out_features=128, bias=True)
    (1): ReLU()
    (2): Linear(in_features=128, out_features=128, bias=True)
    (3): ReLU()
    (4): Linear(in_features=128, out_features=5, bias=True)
  )
)
INFO: Learning...
INFO: BootcampName.HIDER Bootcamp completed, starting BootcampName.SEEKER Bootcamp #0 for 500 days
INFO: BootcampName.SEEKER Bootcamp completed, starting BootcampName.SLOW_AGENT Bootcamp #0 for 1000 days
INFO: Continuing with Bootcamp #0 BootcampName.SLOW_AGENT with slow factor: 9 for agent 1
INFO: Continuing with Bootcamp #0 BootcampName.SLOW_AGENT with slow factor: 9 for agent 0
INFO: Continuing with Bootcamp #0 BootcampName.SLOW_AGENT with slow factor: 8 for agent 1
INFO: Continuing with Bootcamp #0 BootcampName.SLOW_AGENT with slow factor: 8 for agent 0
INFO: Continuing with Bootcamp #0 BootcampName.SLOW_AGENT with slow factor: 7 for agent 1
INFO: Continuing with Bootcamp #0 BootcampName.SLOW_AGENT with slow factor: 7 for agent 0
INFO: Continuing with Bootcamp #0 BootcampName.SLOW_AGENT with slow factor: 6 for agent 1
INFO: Continuing with Bootcamp #0 BootcampName.SLOW_AGENT with slow factor: 6 for agent 0
INFO: Continuing with Bootcamp #0 BootcampName.SLOW_AGENT with slow factor: 5 for agent 1
INFO: Continuing with Bootcamp #0 BootcampName.SLOW_AGENT with slow factor: 5 for agent 0
INFO: Continuing with Bootcamp #0 BootcampName.SLOW_AGENT with slow factor: 4 for agent 1
INFO: Continuing with Bootcamp #0 BootcampName.SLOW_AGENT with slow factor: 4 for agent 0
INFO: Continuing with Bootcamp #0 BootcampName.SLOW_AGENT with slow factor: 3 for agent 1
INFO: Continuing with Bootcamp #0 BootcampName.SLOW_AGENT with slow factor: 3 for agent 0
INFO: Continuing with Bootcamp #0 BootcampName.SLOW_AGENT with slow factor: 2 for agent 1
INFO: Continuing with Bootcamp #0 BootcampName.SLOW_AGENT with slow factor: 2 for agent 0
INFO: BootcampName.SLOW_AGENT Bootcamp completed, starting BootcampName.COMBINED Bootcamp #0 for 1000 days
INFO: BootcampName.COMBINED Bootcamp completed, starting BootcampName.FINISHED Bootcamp #0 for 0 days
INFO: Cleaning cache: /home/eirik/.cache/wandb/artifacts/obj 0.00390625 MB
INFO: cleaning local: /home/eirik/.local/share/wandb/artifacts/staging 0.00390625 MB
INFO: Number of parameters: 30085
INFO: QNetwork(
  (conv_feature): Sequential()
  (fc_feature): Sequential(
    (0): Linear(in_features=100, out_features=128, bias=True)
    (1): ReLU()
    (2): Linear(in_features=128, out_features=128, bias=True)
    (3): ReLU()
    (4): Linear(in_features=128, out_features=5, bias=True)
  )
)
INFO: Learning...
INFO: BootcampName.HIDER Bootcamp completed, starting BootcampName.SEEKER Bootcamp #0 for 500 days
INFO: BootcampName.SEEKER Bootcamp completed, starting BootcampName.SLOW_AGENT Bootcamp #0 for 1000 days
INFO: Continuing with Bootcamp #0 BootcampName.SLOW_AGENT with slow factor: 9 for agent 1
INFO: Continuing with Bootcamp #0 BootcampName.SLOW_AGENT with slow factor: 9 for agent 0
INFO: Continuing with Bootcamp #0 BootcampName.SLOW_AGENT with slow factor: 8 for agent 1
INFO: Continuing with Bootcamp #0 BootcampName.SLOW_AGENT with slow factor: 8 for agent 0
INFO: Continuing with Bootcamp #0 BootcampName.SLOW_AGENT with slow factor: 7 for agent 1
INFO: Continuing with Bootcamp #0 BootcampName.SLOW_AGENT with slow factor: 7 for agent 0
INFO: Continuing with Bootcamp #0 BootcampName.SLOW_AGENT with slow factor: 6 for agent 1
INFO: Continuing with Bootcamp #0 BootcampName.SLOW_AGENT with slow factor: 6 for agent 0
INFO: Continuing with Bootcamp #0 BootcampName.SLOW_AGENT with slow factor: 5 for agent 1
INFO: Continuing with Bootcamp #0 BootcampName.SLOW_AGENT with slow factor: 5 for agent 0
INFO: Continuing with Bootcamp #0 BootcampName.SLOW_AGENT with slow factor: 4 for agent 1
INFO: Continuing with Bootcamp #0 BootcampName.SLOW_AGENT with slow factor: 4 for agent 0
INFO: Continuing with Bootcamp #0 BootcampName.SLOW_AGENT with slow factor: 3 for agent 1
INFO: Continuing with Bootcamp #0 BootcampName.SLOW_AGENT with slow factor: 3 for agent 0
INFO: Continuing with Bootcamp #0 BootcampName.SLOW_AGENT with slow factor: 2 for agent 1
INFO: Continuing with Bootcamp #0 BootcampName.SLOW_AGENT with slow factor: 2 for agent 0
INFO: BootcampName.SLOW_AGENT Bootcamp completed, starting BootcampName.COMBINED Bootcamp #0 for 1000 days
INFO: BootcampName.COMBINED Bootcamp completed, starting BootcampName.FINISHED Bootcamp #0 for 0 days
INFO: Number of parameters: 30085
INFO: QNetwork(
  (conv_feature): Sequential()
  (fc_feature): Sequential(
    (0): Linear(in_features=100, out_features=128, bias=True)
    (1): ReLU()
    (2): Linear(in_features=128, out_features=128, bias=True)
    (3): ReLU()
    (4): Linear(in_features=128, out_features=5, bias=True)
  )
)
INFO: Learning...
INFO: BootcampName.HIDER Bootcamp completed, starting BootcampName.SEEKER Bootcamp #0 for 500 days
INFO: BootcampName.SEEKER Bootcamp completed, starting BootcampName.SLOW_AGENT Bootcamp #0 for 1000 days
INFO: Continuing with Bootcamp #0 BootcampName.SLOW_AGENT with slow factor: 9 for agent 1
INFO: Continuing with Bootcamp #0 BootcampName.SLOW_AGENT with slow factor: 9 for agent 0
INFO: Continuing with Bootcamp #0 BootcampName.SLOW_AGENT with slow factor: 8 for agent 1
INFO: Number of parameters: 30085
INFO: QNetwork(
  (conv_feature): Sequential()
  (fc_feature): Sequential(
    (0): Linear(in_features=100, out_features=128, bias=True)
    (1): ReLU()
    (2): Linear(in_features=128, out_features=128, bias=True)
    (3): ReLU()
    (4): Linear(in_features=128, out_features=5, bias=True)
  )
)
INFO: Learning...
INFO: BootcampName.HIDER Bootcamp completed, starting BootcampName.SEEKER Bootcamp #0 for 500 days
INFO: BootcampName.SEEKER Bootcamp completed, starting BootcampName.SLOW_AGENT Bootcamp #0 for 1000 days
INFO: Continuing with Bootcamp #0 BootcampName.SLOW_AGENT with slow factor: 9 for agent 1
INFO: Continuing with Bootcamp #0 BootcampName.SLOW_AGENT with slow factor: 9 for agent 0
INFO: Number of parameters: 30085
INFO: QNetwork(
  (conv_feature): Sequential()
  (fc_feature): Sequential(
    (0): Linear(in_features=100, out_features=128, bias=True)
    (1): ReLU()
    (2): Linear(in_features=128, out_features=128, bias=True)
    (3): ReLU()
    (4): Linear(in_features=128, out_features=5, bias=True)
  )
)
INFO: Learning...
INFO: BootcampName.HIDER Bootcamp completed, starting BootcampName.SEEKER Bootcamp #0 for 500 days
INFO: BootcampName.SEEKER Bootcamp completed, starting BootcampName.SLOW_AGENT Bootcamp #0 for 1000 days
INFO: Continuing with Bootcamp #0 BootcampName.SLOW_AGENT with slow factor: 9 for agent 1
INFO: Continuing with Bootcamp #0 BootcampName.SLOW_AGENT with slow factor: 9 for agent 0
INFO: Continuing with Bootcamp #0 BootcampName.SLOW_AGENT with slow factor: 8 for agent 1
INFO: Continuing with Bootcamp #0 BootcampName.SLOW_AGENT with slow factor: 8 for agent 0
INFO: Continuing with Bootcamp #0 BootcampName.SLOW_AGENT with slow factor: 7 for agent 1
INFO: Continuing with Bootcamp #0 BootcampName.SLOW_AGENT with slow factor: 7 for agent 0
INFO: Continuing with Bootcamp #0 BootcampName.SLOW_AGENT with slow factor: 6 for agent 1
INFO: Continuing with Bootcamp #0 BootcampName.SLOW_AGENT with slow factor: 6 for agent 0
INFO: Continuing with Bootcamp #0 BootcampName.SLOW_AGENT with slow factor: 5 for agent 1
INFO: Continuing with Bootcamp #0 BootcampName.SLOW_AGENT with slow factor: 5 for agent 0
INFO: Continuing with Bootcamp #0 BootcampName.SLOW_AGENT with slow factor: 4 for agent 1
INFO: Continuing with Bootcamp #0 BootcampName.SLOW_AGENT with slow factor: 4 for agent 0
INFO: Continuing with Bootcamp #0 BootcampName.SLOW_AGENT with slow factor: 3 for agent 1
INFO: Continuing with Bootcamp #0 BootcampName.SLOW_AGENT with slow factor: 3 for agent 0
INFO: Continuing with Bootcamp #0 BootcampName.SLOW_AGENT with slow factor: 2 for agent 1
INFO: Continuing with Bootcamp #0 BootcampName.SLOW_AGENT with slow factor: 2 for agent 0
INFO: BootcampName.SLOW_AGENT Bootcamp completed, starting BootcampName.COMBINED Bootcamp #0 for 1000 days
INFO: BootcampName.COMBINED Bootcamp completed, starting BootcampName.FINISHED Bootcamp #0 for 0 days
INFO: Number of parameters: 30085
INFO: QNetwork(
  (conv_feature): Sequential()
  (fc_feature): Sequential(
    (0): Linear(in_features=100, out_features=128, bias=True)
    (1): ReLU()
    (2): Linear(in_features=128, out_features=128, bias=True)
    (3): ReLU()
    (4): Linear(in_features=128, out_features=5, bias=True)
  )
)
INFO: Learning...
INFO: BootcampName.HIDER Bootcamp completed, starting BootcampName.SEEKER Bootcamp #0 for 500 days
INFO: BootcampName.SEEKER Bootcamp completed, starting BootcampName.SLOW_AGENT Bootcamp #0 for 1000 days
INFO: Continuing with Bootcamp #0 BootcampName.SLOW_AGENT with slow factor: 9 for agent 1
INFO: Continuing with Bootcamp #0 BootcampName.SLOW_AGENT with slow factor: 9 for agent 0
INFO: Continuing with Bootcamp #0 BootcampName.SLOW_AGENT with slow factor: 8 for agent 1
INFO: Continuing with Bootcamp #0 BootcampName.SLOW_AGENT with slow factor: 8 for agent 0
INFO: Continuing with Bootcamp #0 BootcampName.SLOW_AGENT with slow factor: 7 for agent 1
INFO: Continuing with Bootcamp #0 BootcampName.SLOW_AGENT with slow factor: 7 for agent 0
INFO: Continuing with Bootcamp #0 BootcampName.SLOW_AGENT with slow factor: 6 for agent 1
INFO: Number of parameters: 30085
INFO: QNetwork(
  (conv_feature): Sequential()
  (fc_feature): Sequential(
    (0): Linear(in_features=100, out_features=128, bias=True)
    (1): ReLU()
    (2): Linear(in_features=128, out_features=128, bias=True)
    (3): ReLU()
    (4): Linear(in_features=128, out_features=5, bias=True)
  )
)
INFO: Learning...
INFO: BootcampName.HIDER Bootcamp completed, starting BootcampName.SEEKER Bootcamp #0 for 500 days
INFO: BootcampName.SEEKER Bootcamp completed, starting BootcampName.SLOW_AGENT Bootcamp #0 for 1000 days
INFO: Continuing with Bootcamp #0 BootcampName.SLOW_AGENT with slow factor: 9 for agent 1
INFO: Continuing with Bootcamp #0 BootcampName.SLOW_AGENT with slow factor: 9 for agent 0
INFO: Continuing with Bootcamp #0 BootcampName.SLOW_AGENT with slow factor: 8 for agent 1
INFO: Continuing with Bootcamp #0 BootcampName.SLOW_AGENT with slow factor: 8 for agent 0
INFO: Continuing with Bootcamp #0 BootcampName.SLOW_AGENT with slow factor: 7 for agent 1
INFO: Continuing with Bootcamp #0 BootcampName.SLOW_AGENT with slow factor: 7 for agent 0
INFO: Continuing with Bootcamp #0 BootcampName.SLOW_AGENT with slow factor: 6 for agent 1
INFO: Continuing with Bootcamp #0 BootcampName.SLOW_AGENT with slow factor: 6 for agent 0
INFO: Continuing with Bootcamp #0 BootcampName.SLOW_AGENT with slow factor: 5 for agent 1
INFO: Continuing with Bootcamp #0 BootcampName.SLOW_AGENT with slow factor: 5 for agent 0
INFO: Continuing with Bootcamp #0 BootcampName.SLOW_AGENT with slow factor: 4 for agent 1
INFO: Continuing with Bootcamp #0 BootcampName.SLOW_AGENT with slow factor: 4 for agent 0
INFO: Continuing with Bootcamp #0 BootcampName.SLOW_AGENT with slow factor: 3 for agent 1
INFO: Continuing with Bootcamp #0 BootcampName.SLOW_AGENT with slow factor: 3 for agent 0
INFO: Continuing with Bootcamp #0 BootcampName.SLOW_AGENT with slow factor: 2 for agent 1
INFO: Continuing with Bootcamp #0 BootcampName.SLOW_AGENT with slow factor: 2 for agent 0
INFO: BootcampName.SLOW_AGENT Bootcamp completed, starting BootcampName.COMBINED Bootcamp #0 for 1000 days
INFO: BootcampName.COMBINED Bootcamp completed, starting BootcampName.FINISHED Bootcamp #0 for 0 days
INFO: Number of parameters: 30085
INFO: QNetwork(
  (conv_feature): Sequential()
  (fc_feature): Sequential(
    (0): Linear(in_features=100, out_features=128, bias=True)
    (1): ReLU()
    (2): Linear(in_features=128, out_features=128, bias=True)
    (3): ReLU()
    (4): Linear(in_features=128, out_features=5, bias=True)
  )
)
INFO: Learning...
INFO: Hyperparameters: lr=0.0001, gamma=0.9, eps_start=0.9, eps_end=0.05, eps_decay=50000, batch_size=32, tau=0.005,hidden_layers=[128, 128], conv_layers=[]
INFO: Hyperparameters: lr=0.0001, gamma=0.9, eps_start=0.9, eps_end=0.05, eps_decay=50000, batch_size=32, tau=0.005,hidden_layers=[128, 128], conv_layers=[]
INFO: BootcampName.HIDER Bootcamp completed, starting BootcampName.SEEKER Bootcamp #0 for 500 days
INFO: BootcampName.SEEKER Bootcamp completed, starting BootcampName.SLOW_AGENT Bootcamp #0 for 1000 days
INFO: Continuing with Bootcamp #0 BootcampName.SLOW_AGENT with slow factor: 9 for agent 1
INFO: Continuing with Bootcamp #0 BootcampName.SLOW_AGENT with slow factor: 9 for agent 0
INFO: Continuing with Bootcamp #0 BootcampName.SLOW_AGENT with slow factor: 8 for agent 1
INFO: Continuing with Bootcamp #0 BootcampName.SLOW_AGENT with slow factor: 8 for agent 0
INFO: Continuing with Bootcamp #0 BootcampName.SLOW_AGENT with slow factor: 7 for agent 1
INFO: Continuing with Bootcamp #0 BootcampName.SLOW_AGENT with slow factor: 7 for agent 0
INFO: Continuing with Bootcamp #0 BootcampName.SLOW_AGENT with slow factor: 6 for agent 1
INFO: Continuing with Bootcamp #0 BootcampName.SLOW_AGENT with slow factor: 6 for agent 0
INFO: Continuing with Bootcamp #0 BootcampName.SLOW_AGENT with slow factor: 5 for agent 1
INFO: Continuing with Bootcamp #0 BootcampName.SLOW_AGENT with slow factor: 5 for agent 0
INFO: Hyperparameters: lr=0.0001, gamma=0.9, eps_start=0.9, eps_end=0.05, eps_decay=50000, batch_size=32, tau=0.005,hidden_layers=[128, 128], conv_layers=[]
INFO: Hyperparameters: lr=0.0001, gamma=0.9, eps_start=0.9, eps_end=0.05, eps_decay=50000, batch_size=32, tau=0.005,hidden_layers=[128, 128], conv_layers=[]
INFO: BootcampName.HIDER Bootcamp completed, starting BootcampName.SEEKER Bootcamp #0 for 500 days
INFO: BootcampName.SEEKER Bootcamp completed, starting BootcampName.SLOW_AGENT Bootcamp #0 for 1000 days
INFO: Continuing with Bootcamp #0 BootcampName.SLOW_AGENT with slow factor: 9 for agent 1
INFO: Continuing with Bootcamp #0 BootcampName.SLOW_AGENT with slow factor: 9 for agent 0
INFO: Continuing with Bootcamp #0 BootcampName.SLOW_AGENT with slow factor: 8 for agent 1
INFO: Continuing with Bootcamp #0 BootcampName.SLOW_AGENT with slow factor: 8 for agent 0
INFO: Continuing with Bootcamp #0 BootcampName.SLOW_AGENT with slow factor: 7 for agent 1
INFO: Continuing with Bootcamp #0 BootcampName.SLOW_AGENT with slow factor: 7 for agent 0
INFO: Continuing with Bootcamp #0 BootcampName.SLOW_AGENT with slow factor: 6 for agent 1
INFO: Continuing with Bootcamp #0 BootcampName.SLOW_AGENT with slow factor: 6 for agent 0
INFO: Continuing with Bootcamp #0 BootcampName.SLOW_AGENT with slow factor: 5 for agent 1
INFO: Continuing with Bootcamp #0 BootcampName.SLOW_AGENT with slow factor: 5 for agent 0
INFO: Hyperparameters: lr=0.0001, gamma=0.9, eps_start=0.9, eps_end=0.05, eps_decay=50000, batch_size=32, tau=0.005,hidden_layers=[128, 128], conv_layers=[]
INFO: Hyperparameters: lr=0.0001, gamma=0.9, eps_start=0.9, eps_end=0.05, eps_decay=50000, batch_size=32, tau=0.005,hidden_layers=[128, 128], conv_layers=[]
INFO: BootcampName.HIDER Bootcamp completed, starting BootcampName.SEEKER Bootcamp #0 for 500 days
INFO: BootcampName.SEEKER Bootcamp completed, starting BootcampName.SLOW_AGENT Bootcamp #0 for 1000 days
INFO: Continuing with Bootcamp #0 BootcampName.SLOW_AGENT with slow factor: 9 for agent 1
INFO: Continuing with Bootcamp #0 BootcampName.SLOW_AGENT with slow factor: 9 for agent 0
INFO: Continuing with Bootcamp #0 BootcampName.SLOW_AGENT with slow factor: 8 for agent 1
INFO: Continuing with Bootcamp #0 BootcampName.SLOW_AGENT with slow factor: 8 for agent 0
INFO: Continuing with Bootcamp #0 BootcampName.SLOW_AGENT with slow factor: 7 for agent 1
INFO: Continuing with Bootcamp #0 BootcampName.SLOW_AGENT with slow factor: 7 for agent 0
INFO: Continuing with Bootcamp #0 BootcampName.SLOW_AGENT with slow factor: 6 for agent 1
INFO: Number of parameters: 30085
INFO: QNetwork(
  (conv_feature): Sequential()
  (fc_feature): Sequential(
    (0): Linear(in_features=100, out_features=128, bias=True)
    (1): ReLU()
    (2): Linear(in_features=128, out_features=128, bias=True)
    (3): ReLU()
    (4): Linear(in_features=128, out_features=5, bias=True)
  )
)
INFO: Learning...
INFO: Hyperparameters: lr=0.001, gamma=0.99, eps_start=1, eps_end=0.05, eps_decay=10000, batch_size=16, tau=0.01,hidden_layers=[128, 64], conv_layers=[64, 64]
INFO: Hyperparameters: lr=0.001, gamma=0.99, eps_start=1, eps_end=0.05, eps_decay=10000, batch_size=16, tau=0.01,hidden_layers=[128, 64], conv_layers=[64, 64]
INFO: BootcampName.HIDER Bootcamp completed, starting BootcampName.SEEKER Bootcamp #0 for 500 days
INFO: BootcampName.SEEKER Bootcamp completed, starting BootcampName.SLOW_AGENT Bootcamp #0 for 1000 days
INFO: Continuing with Bootcamp #0 BootcampName.SLOW_AGENT with slow factor: 9 for agent 1
INFO: Continuing with Bootcamp #0 BootcampName.SLOW_AGENT with slow factor: 9 for agent 0
INFO: Continuing with Bootcamp #0 BootcampName.SLOW_AGENT with slow factor: 8 for agent 1
INFO: Continuing with Bootcamp #0 BootcampName.SLOW_AGENT with slow factor: 8 for agent 0
INFO: Continuing with Bootcamp #0 BootcampName.SLOW_AGENT with slow factor: 7 for agent 1
INFO: Continuing with Bootcamp #0 BootcampName.SLOW_AGENT with slow factor: 7 for agent 0
INFO: Continuing with Bootcamp #0 BootcampName.SLOW_AGENT with slow factor: 6 for agent 1
INFO: Continuing with Bootcamp #0 BootcampName.SLOW_AGENT with slow factor: 6 for agent 0
INFO: Continuing with Bootcamp #0 BootcampName.SLOW_AGENT with slow factor: 5 for agent 1
INFO: Number of parameters: 266242
INFO: QNetwork(
  (conv_feature): Sequential()
  (fc_feature): Sequential(
    (0): Linear(in_features=4, out_features=512, bias=True)
    (1): ReLU()
    (2): Linear(in_features=512, out_features=512, bias=True)
    (3): ReLU()
    (4): Linear(in_features=512, out_features=2, bias=True)
  )
)
INFO: Learning...
INFO: Initializing Shap...
INFO: Explaining...
INFO: Number of parameters: 266242
INFO: QNetwork(
  (conv_feature): Sequential()
  (fc_feature): Sequential(
    (0): Linear(in_features=4, out_features=512, bias=True)
    (1): ReLU()
    (2): Linear(in_features=512, out_features=512, bias=True)
    (3): ReLU()
    (4): Linear(in_features=512, out_features=2, bias=True)
  )
)
WARNING: GIF is enabled but the environment does not support RGB array rendering.
INFO: Learning...
INFO: Number of parameters: 17410
INFO: QNetwork(
  (conv_feature): Sequential()
  (fc_feature): Sequential(
    (0): Linear(in_features=4, out_features=128, bias=True)
    (1): ReLU()
    (2): Linear(in_features=128, out_features=128, bias=True)
    (3): ReLU()
    (4): Linear(in_features=128, out_features=2, bias=True)
  )
)
INFO: Learning...
INFO: Cleaning cache: /home/eirik/.cache/wandb/artifacts/obj 0.00390625 MB
INFO: cleaning local: /home/eirik/.local/share/wandb/artifacts/staging 0.00390625 MB
INFO: Number of parameters: 17410
INFO: QNetwork(
  (conv_feature): Sequential()
  (fc_feature): Sequential(
    (0): Linear(in_features=4, out_features=128, bias=True)
    (1): ReLU()
    (2): Linear(in_features=128, out_features=128, bias=True)
    (3): ReLU()
    (4): Linear(in_features=128, out_features=2, bias=True)
  )
)
INFO: Learning...
INFO: Initializing Shap...
INFO: Explaining...
INFO: Number of parameters: 17410
INFO: QNetwork(
  (conv_feature): Sequential()
  (fc_feature): Sequential(
    (0): Linear(in_features=4, out_features=128, bias=True)
    (1): ReLU()
    (2): Linear(in_features=128, out_features=128, bias=True)
    (3): ReLU()
    (4): Linear(in_features=128, out_features=2, bias=True)
  )
)
INFO: Learning...
INFO: Number of parameters: 17410
INFO: QNetwork(
  (conv_feature): Sequential()
  (fc_feature): Sequential(
    (0): Linear(in_features=4, out_features=128, bias=True)
    (1): ReLU()
    (2): Linear(in_features=128, out_features=128, bias=True)
    (3): ReLU()
    (4): Linear(in_features=128, out_features=2, bias=True)
  )
)
INFO: Learning...
INFO: Number of parameters: 17410
INFO: QNetwork(
  (conv_feature): Sequential()
  (fc_feature): Sequential(
    (0): Linear(in_features=4, out_features=128, bias=True)
    (1): ReLU()
    (2): Linear(in_features=128, out_features=128, bias=True)
    (3): ReLU()
    (4): Linear(in_features=128, out_features=2, bias=True)
  )
)
INFO: Learning...
INFO: Number of parameters: 17410
INFO: QNetwork(
  (conv_feature): Sequential()
  (fc_feature): Sequential(
    (0): Linear(in_features=4, out_features=128, bias=True)
    (1): ReLU()
    (2): Linear(in_features=128, out_features=128, bias=True)
    (3): ReLU()
    (4): Linear(in_features=128, out_features=2, bias=True)
  )
)
INFO: Learning...
INFO: Number of parameters: 17410
INFO: QNetwork(
  (conv_feature): Sequential()
  (fc_feature): Sequential(
    (0): Linear(in_features=4, out_features=128, bias=True)
    (1): ReLU()
    (2): Linear(in_features=128, out_features=128, bias=True)
    (3): ReLU()
    (4): Linear(in_features=128, out_features=2, bias=True)
  )
)
INFO: Learning...
INFO: Number of parameters: 17410
INFO: QNetwork(
  (conv_feature): Sequential()
  (fc_feature): Sequential(
    (0): Linear(in_features=4, out_features=128, bias=True)
    (1): ReLU()
    (2): Linear(in_features=128, out_features=128, bias=True)
    (3): ReLU()
    (4): Linear(in_features=128, out_features=2, bias=True)
  )
)
INFO: Learning...
INFO: Number of parameters: 17410
INFO: QNetwork(
  (conv_feature): Sequential()
  (fc_feature): Sequential(
    (0): Linear(in_features=4, out_features=128, bias=True)
    (1): ReLU()
    (2): Linear(in_features=128, out_features=128, bias=True)
    (3): ReLU()
    (4): Linear(in_features=128, out_features=2, bias=True)
  )
)
INFO: Learning...
INFO: Number of parameters: 17410
INFO: QNetwork(
  (conv_feature): Sequential()
  (fc_feature): Sequential(
    (0): Linear(in_features=4, out_features=128, bias=True)
    (1): ReLU()
    (2): Linear(in_features=128, out_features=128, bias=True)
    (3): ReLU()
    (4): Linear(in_features=128, out_features=2, bias=True)
  )
)
INFO: Learning...
INFO: Number of parameters: 17410
INFO: QNetwork(
  (conv_feature): Sequential()
  (fc_feature): Sequential(
    (0): Linear(in_features=4, out_features=128, bias=True)
    (1): ReLU()
    (2): Linear(in_features=128, out_features=128, bias=True)
    (3): ReLU()
    (4): Linear(in_features=128, out_features=2, bias=True)
  )
)
INFO: Learning...
INFO: Number of parameters: 17410
INFO: QNetwork(
  (conv_feature): Sequential()
  (fc_feature): Sequential(
    (0): Linear(in_features=4, out_features=128, bias=True)
    (1): ReLU()
    (2): Linear(in_features=128, out_features=128, bias=True)
    (3): ReLU()
    (4): Linear(in_features=128, out_features=2, bias=True)
  )
)
INFO: Learning...
INFO: Number of parameters: 17410
INFO: QNetwork(
  (conv_feature): Sequential()
  (fc_feature): Sequential(
    (0): Linear(in_features=4, out_features=128, bias=True)
    (1): ReLU()
    (2): Linear(in_features=128, out_features=128, bias=True)
    (3): ReLU()
    (4): Linear(in_features=128, out_features=2, bias=True)
  )
)
INFO: Learning...
INFO: Number of parameters: 17410
INFO: QNetwork(
  (conv_feature): Sequential()
  (fc_feature): Sequential(
    (0): Linear(in_features=4, out_features=128, bias=True)
    (1): ReLU()
    (2): Linear(in_features=128, out_features=128, bias=True)
    (3): ReLU()
    (4): Linear(in_features=128, out_features=2, bias=True)
  )
)
INFO: Learning...
INFO: Number of parameters: 17410
INFO: QNetwork(
  (conv_feature): Sequential()
  (fc_feature): Sequential(
    (0): Linear(in_features=4, out_features=128, bias=True)
    (1): ReLU()
    (2): Linear(in_features=128, out_features=128, bias=True)
    (3): ReLU()
    (4): Linear(in_features=128, out_features=2, bias=True)
  )
)
INFO: Learning...
INFO: Number of parameters: 30085
INFO: QNetwork(
  (conv_feature): Sequential()
  (fc_feature): Sequential(
    (0): Linear(in_features=100, out_features=128, bias=True)
    (1): ReLU()
    (2): Linear(in_features=128, out_features=128, bias=True)
    (3): ReLU()
    (4): Linear(in_features=128, out_features=5, bias=True)
  )
)
WARNING: GIF is enabled but the environment does not support RGB array rendering.
INFO: Learning...
INFO: Number of parameters: 30085
INFO: QNetwork(
  (conv_feature): Sequential()
  (fc_feature): Sequential(
    (0): Linear(in_features=100, out_features=128, bias=True)
    (1): ReLU()
    (2): Linear(in_features=128, out_features=128, bias=True)
    (3): ReLU()
    (4): Linear(in_features=128, out_features=5, bias=True)
  )
)
WARNING: GIF is enabled but the environment does not support RGB array rendering.
INFO: Learning...
INFO: BootcampName.HIDER Bootcamp completed, starting BootcampName.SEEKER Bootcamp #0 for 0 days
INFO: BootcampName.SEEKER Bootcamp completed, starting BootcampName.SLOW_AGENT Bootcamp #0 for 0 days
INFO: Continuing with Bootcamp #0 BootcampName.SLOW_AGENT with slow factor: 9 for agent 1
INFO: Continuing with Bootcamp #0 BootcampName.SLOW_AGENT with slow factor: 9 for agent 0
INFO: Continuing with Bootcamp #0 BootcampName.SLOW_AGENT with slow factor: 8 for agent 1
INFO: Continuing with Bootcamp #0 BootcampName.SLOW_AGENT with slow factor: 8 for agent 0
INFO: Continuing with Bootcamp #0 BootcampName.SLOW_AGENT with slow factor: 7 for agent 1
INFO: Continuing with Bootcamp #0 BootcampName.SLOW_AGENT with slow factor: 7 for agent 0
INFO: Continuing with Bootcamp #0 BootcampName.SLOW_AGENT with slow factor: 6 for agent 1
INFO: Continuing with Bootcamp #0 BootcampName.SLOW_AGENT with slow factor: 6 for agent 0
INFO: Continuing with Bootcamp #0 BootcampName.SLOW_AGENT with slow factor: 5 for agent 1
INFO: Continuing with Bootcamp #0 BootcampName.SLOW_AGENT with slow factor: 5 for agent 0
INFO: Continuing with Bootcamp #0 BootcampName.SLOW_AGENT with slow factor: 4 for agent 1
INFO: Continuing with Bootcamp #0 BootcampName.SLOW_AGENT with slow factor: 4 for agent 0
INFO: Continuing with Bootcamp #0 BootcampName.SLOW_AGENT with slow factor: 3 for agent 1
INFO: Continuing with Bootcamp #0 BootcampName.SLOW_AGENT with slow factor: 3 for agent 0
INFO: Continuing with Bootcamp #0 BootcampName.SLOW_AGENT with slow factor: 2 for agent 1
INFO: Continuing with Bootcamp #0 BootcampName.SLOW_AGENT with slow factor: 2 for agent 0
INFO: BootcampName.SLOW_AGENT Bootcamp completed, starting BootcampName.COMBINED Bootcamp #0 for 0 days
INFO: BootcampName.COMBINED Bootcamp completed, starting BootcampName.FINISHED Bootcamp #0 for 0 days
INFO: Number of parameters: 30085
INFO: QNetwork(
  (conv_feature): Sequential()
  (fc_feature): Sequential(
    (0): Linear(in_features=100, out_features=128, bias=True)
    (1): ReLU()
    (2): Linear(in_features=128, out_features=128, bias=True)
    (3): ReLU()
    (4): Linear(in_features=128, out_features=5, bias=True)
  )
)
WARNING: GIF is enabled but the environment does not support RGB array rendering.
INFO: Learning...
INFO: BootcampName.HIDER Bootcamp completed, starting BootcampName.SEEKER Bootcamp #0 for 0 days
INFO: BootcampName.SEEKER Bootcamp completed, starting BootcampName.SLOW_AGENT Bootcamp #0 for 0 days
INFO: Continuing with Bootcamp #0 BootcampName.SLOW_AGENT with slow factor: 9 for agent 1
INFO: Continuing with Bootcamp #0 BootcampName.SLOW_AGENT with slow factor: 9 for agent 0
INFO: Continuing with Bootcamp #0 BootcampName.SLOW_AGENT with slow factor: 8 for agent 1
INFO: Continuing with Bootcamp #0 BootcampName.SLOW_AGENT with slow factor: 8 for agent 0
INFO: Continuing with Bootcamp #0 BootcampName.SLOW_AGENT with slow factor: 7 for agent 1
INFO: Continuing with Bootcamp #0 BootcampName.SLOW_AGENT with slow factor: 7 for agent 0
INFO: Continuing with Bootcamp #0 BootcampName.SLOW_AGENT with slow factor: 6 for agent 1
INFO: Continuing with Bootcamp #0 BootcampName.SLOW_AGENT with slow factor: 6 for agent 0
INFO: Continuing with Bootcamp #0 BootcampName.SLOW_AGENT with slow factor: 5 for agent 1
INFO: Continuing with Bootcamp #0 BootcampName.SLOW_AGENT with slow factor: 5 for agent 0
INFO: Continuing with Bootcamp #0 BootcampName.SLOW_AGENT with slow factor: 4 for agent 1
INFO: Continuing with Bootcamp #0 BootcampName.SLOW_AGENT with slow factor: 4 for agent 0
INFO: Continuing with Bootcamp #0 BootcampName.SLOW_AGENT with slow factor: 3 for agent 1
INFO: Continuing with Bootcamp #0 BootcampName.SLOW_AGENT with slow factor: 3 for agent 0
INFO: Continuing with Bootcamp #0 BootcampName.SLOW_AGENT with slow factor: 2 for agent 1
INFO: Continuing with Bootcamp #0 BootcampName.SLOW_AGENT with slow factor: 2 for agent 0
INFO: BootcampName.SLOW_AGENT Bootcamp completed, starting BootcampName.COMBINED Bootcamp #0 for 0 days
INFO: BootcampName.COMBINED Bootcamp completed, starting BootcampName.FINISHED Bootcamp #0 for 0 days
INFO: Number of parameters: 63845
INFO: QNetwork(
  (conv_feature): Sequential(
    (0): Conv2d(1, 32, kernel_size=(3, 3), stride=(1, 1))
    (1): ReLU()
    (2): BatchNorm2d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (3): Conv2d(32, 32, kernel_size=(3, 3), stride=(1, 1))
    (4): ReLU()
    (5): BatchNorm2d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
  )
  (fc_feature): Sequential(
    (0): Linear(in_features=288, out_features=128, bias=True)
    (1): ReLU()
    (2): Linear(in_features=128, out_features=128, bias=True)
    (3): ReLU()
    (4): Linear(in_features=128, out_features=5, bias=True)
  )
)
INFO: Learning...
INFO: BootcampName.HIDER Bootcamp completed, starting BootcampName.SEEKER Bootcamp #0 for 0 days
ERROR: boolean index did not match indexed array along dimension 0; dimension is 10 but corresponding boolean dimension is 7
ERROR: Traceback (most recent call last):
  File "/home/eirik/Projects/XAI/rl/src/dqn/wrapper/multi_agent_dqn.py", line 108, in learn
    self._collect_rollouts()
  File "/home/eirik/Projects/XAI/rl/src/dqn/wrapper/multi_agent_dqn.py", line 206, in _collect_rollouts
    ) = self.env.get_wrapper_attr("step_multiple")(actions)
        ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/eirik/Projects/XAI/environments/gymnasium/wrappers/multi_agent_env.py", line 44, in step_multiple
    ) = self.get_wrapper_attr("concatenate_states")(full_states)
        ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/eirik/Projects/XAI/environments/gymnasium/envs/tag/tag.py", line 261, in concatenate_states
    self.render(self.render_mode)
  File "/home/eirik/Projects/XAI/environments/gymnasium/envs/tag/tag.py", line 239, in render
    return self.tag_renderer.render(self.state.full, render_mode)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/eirik/Projects/XAI/environments/gymnasium/envs/tag/tag_renderer.py", line 64, in render
    self.apply_color_masks(color_matrix, state)
  File "/home/eirik/Projects/XAI/environments/gymnasium/envs/tag/tag_renderer.py", line 94, in apply_color_masks
    color_matrix[full_state == TileType.OBSTACLE.value] = Color.BLACK.value
    ~~~~~~~~~~~~^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
IndexError: boolean index did not match indexed array along dimension 0; dimension is 10 but corresponding boolean dimension is 7

INFO: Number of parameters: 63845
INFO: QNetwork(
  (conv_feature): Sequential(
    (0): Conv2d(1, 32, kernel_size=(3, 3), stride=(1, 1))
    (1): ReLU()
    (2): BatchNorm2d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (3): Conv2d(32, 32, kernel_size=(3, 3), stride=(1, 1))
    (4): ReLU()
    (5): BatchNorm2d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
  )
  (fc_feature): Sequential(
    (0): Linear(in_features=288, out_features=128, bias=True)
    (1): ReLU()
    (2): Linear(in_features=128, out_features=128, bias=True)
    (3): ReLU()
    (4): Linear(in_features=128, out_features=5, bias=True)
  )
)
INFO: Learning...
INFO: BootcampName.HIDER Bootcamp completed, starting BootcampName.SEEKER Bootcamp #0 for 0 days
ERROR: boolean index did not match indexed array along dimension 0; dimension is 10 but corresponding boolean dimension is 7
ERROR: Traceback (most recent call last):
  File "/home/eirik/Projects/XAI/rl/src/dqn/wrapper/multi_agent_dqn.py", line 108, in learn
    self._collect_rollouts()
  File "/home/eirik/Projects/XAI/rl/src/dqn/wrapper/multi_agent_dqn.py", line 206, in _collect_rollouts
    ) = self.env.get_wrapper_attr("step_multiple")(actions)
        ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/eirik/Projects/XAI/environments/gymnasium/wrappers/multi_agent_env.py", line 44, in step_multiple
    ) = self.get_wrapper_attr("concatenate_states")(full_states)
        ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/eirik/Projects/XAI/environments/gymnasium/envs/tag/tag.py", line 261, in concatenate_states
    self.render(self.render_mode)
  File "/home/eirik/Projects/XAI/environments/gymnasium/envs/tag/tag.py", line 239, in render
    return self.tag_renderer.render(self.state.full, render_mode)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/eirik/Projects/XAI/environments/gymnasium/envs/tag/tag_renderer.py", line 64, in render
    self.apply_color_masks(color_matrix, state)
  File "/home/eirik/Projects/XAI/environments/gymnasium/envs/tag/tag_renderer.py", line 94, in apply_color_masks
    color_matrix[full_state == TileType.OBSTACLE.value] = Color.BLACK.value
    ~~~~~~~~~~~~^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
IndexError: boolean index did not match indexed array along dimension 0; dimension is 10 but corresponding boolean dimension is 7

WARNING: Error: Could not find wandb directory: ./wandb
INFO: Number of parameters: 63845
INFO: QNetwork(
  (conv_feature): Sequential(
    (0): Conv2d(1, 32, kernel_size=(3, 3), stride=(1, 1))
    (1): ReLU()
    (2): BatchNorm2d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (3): Conv2d(32, 32, kernel_size=(3, 3), stride=(1, 1))
    (4): ReLU()
    (5): BatchNorm2d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
  )
  (fc_feature): Sequential(
    (0): Linear(in_features=288, out_features=128, bias=True)
    (1): ReLU()
    (2): Linear(in_features=128, out_features=128, bias=True)
    (3): ReLU()
    (4): Linear(in_features=128, out_features=5, bias=True)
  )
)
INFO: Learning...
INFO: BootcampName.HIDER Bootcamp completed, starting BootcampName.SEEKER Bootcamp #0 for 0 days
ERROR: boolean index did not match indexed array along dimension 0; dimension is 10 but corresponding boolean dimension is 7
ERROR: Traceback (most recent call last):
  File "/home/eirik/Projects/XAI/rl/src/dqn/wrapper/multi_agent_dqn.py", line 108, in learn
    self._collect_rollouts()
  File "/home/eirik/Projects/XAI/rl/src/dqn/wrapper/multi_agent_dqn.py", line 206, in _collect_rollouts
    ) = self.env.get_wrapper_attr("step_multiple")(actions)
        ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/eirik/Projects/XAI/environments/gymnasium/wrappers/multi_agent_env.py", line 44, in step_multiple
    ) = self.get_wrapper_attr("concatenate_states")(full_states)
        ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/eirik/Projects/XAI/environments/gymnasium/envs/tag/tag.py", line 261, in concatenate_states
    self.render(self.render_mode)
  File "/home/eirik/Projects/XAI/environments/gymnasium/envs/tag/tag.py", line 239, in render
    return self.tag_renderer.render(self.state.full, render_mode)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/eirik/Projects/XAI/environments/gymnasium/envs/tag/tag_renderer.py", line 64, in render
    self.apply_color_masks(color_matrix, state)
  File "/home/eirik/Projects/XAI/environments/gymnasium/envs/tag/tag_renderer.py", line 94, in apply_color_masks
    color_matrix[full_state == TileType.OBSTACLE.value] = Color.BLACK.value
    ~~~~~~~~~~~~^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
IndexError: boolean index did not match indexed array along dimension 0; dimension is 10 but corresponding boolean dimension is 7

WARNING: Error: Could not find wandb directory: ./wandb
INFO: Number of parameters: 63845
INFO: QNetwork(
  (conv_feature): Sequential(
    (0): Conv2d(1, 32, kernel_size=(3, 3), stride=(1, 1))
    (1): ReLU()
    (2): BatchNorm2d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (3): Conv2d(32, 32, kernel_size=(3, 3), stride=(1, 1))
    (4): ReLU()
    (5): BatchNorm2d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
  )
  (fc_feature): Sequential(
    (0): Linear(in_features=288, out_features=128, bias=True)
    (1): ReLU()
    (2): Linear(in_features=128, out_features=128, bias=True)
    (3): ReLU()
    (4): Linear(in_features=128, out_features=5, bias=True)
  )
)
INFO: Learning...
INFO: BootcampName.HIDER Bootcamp completed, starting BootcampName.SEEKER Bootcamp #0 for 0 days
INFO: BootcampName.SEEKER Bootcamp completed, starting BootcampName.SLOW_AGENT Bootcamp #0 for 0 days
INFO: Continuing with Bootcamp #0 BootcampName.SLOW_AGENT with slow factor: 9 for agent 1
INFO: Continuing with Bootcamp #0 BootcampName.SLOW_AGENT with slow factor: 9 for agent 0
INFO: Continuing with Bootcamp #0 BootcampName.SLOW_AGENT with slow factor: 8 for agent 1
INFO: Continuing with Bootcamp #0 BootcampName.SLOW_AGENT with slow factor: 8 for agent 0
INFO: Continuing with Bootcamp #0 BootcampName.SLOW_AGENT with slow factor: 7 for agent 1
INFO: Continuing with Bootcamp #0 BootcampName.SLOW_AGENT with slow factor: 7 for agent 0
INFO: Continuing with Bootcamp #0 BootcampName.SLOW_AGENT with slow factor: 6 for agent 1
INFO: Continuing with Bootcamp #0 BootcampName.SLOW_AGENT with slow factor: 6 for agent 0
INFO: Continuing with Bootcamp #0 BootcampName.SLOW_AGENT with slow factor: 5 for agent 1
INFO: Continuing with Bootcamp #0 BootcampName.SLOW_AGENT with slow factor: 5 for agent 0
INFO: Continuing with Bootcamp #0 BootcampName.SLOW_AGENT with slow factor: 4 for agent 1
INFO: Continuing with Bootcamp #0 BootcampName.SLOW_AGENT with slow factor: 4 for agent 0
INFO: Continuing with Bootcamp #0 BootcampName.SLOW_AGENT with slow factor: 3 for agent 1
INFO: Continuing with Bootcamp #0 BootcampName.SLOW_AGENT with slow factor: 3 for agent 0
INFO: Continuing with Bootcamp #0 BootcampName.SLOW_AGENT with slow factor: 2 for agent 1
INFO: Continuing with Bootcamp #0 BootcampName.SLOW_AGENT with slow factor: 2 for agent 0
INFO: BootcampName.SLOW_AGENT Bootcamp completed, starting BootcampName.COMBINED Bootcamp #0 for 0 days
INFO: BootcampName.COMBINED Bootcamp completed, starting BootcampName.FINISHED Bootcamp #0 for 0 days
INFO: Number of parameters: 63845
INFO: QNetwork(
  (conv_feature): Sequential(
    (0): Conv2d(1, 32, kernel_size=(3, 3), stride=(1, 1))
    (1): ReLU()
    (2): BatchNorm2d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (3): Conv2d(32, 32, kernel_size=(3, 3), stride=(1, 1))
    (4): ReLU()
    (5): BatchNorm2d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
  )
  (fc_feature): Sequential(
    (0): Linear(in_features=288, out_features=128, bias=True)
    (1): ReLU()
    (2): Linear(in_features=128, out_features=128, bias=True)
    (3): ReLU()
    (4): Linear(in_features=128, out_features=5, bias=True)
  )
)
INFO: Learning...
INFO: BootcampName.HIDER Bootcamp completed, starting BootcampName.SEEKER Bootcamp #0 for 0 days
INFO: BootcampName.SEEKER Bootcamp completed, starting BootcampName.SLOW_AGENT Bootcamp #0 for 0 days
INFO: Continuing with Bootcamp #0 BootcampName.SLOW_AGENT with slow factor: 9 for agent 1
INFO: Continuing with Bootcamp #0 BootcampName.SLOW_AGENT with slow factor: 9 for agent 0
INFO: Continuing with Bootcamp #0 BootcampName.SLOW_AGENT with slow factor: 8 for agent 1
INFO: Continuing with Bootcamp #0 BootcampName.SLOW_AGENT with slow factor: 8 for agent 0
INFO: Continuing with Bootcamp #0 BootcampName.SLOW_AGENT with slow factor: 7 for agent 1
INFO: Continuing with Bootcamp #0 BootcampName.SLOW_AGENT with slow factor: 7 for agent 0
INFO: Continuing with Bootcamp #0 BootcampName.SLOW_AGENT with slow factor: 6 for agent 1
INFO: Continuing with Bootcamp #0 BootcampName.SLOW_AGENT with slow factor: 6 for agent 0
INFO: Continuing with Bootcamp #0 BootcampName.SLOW_AGENT with slow factor: 5 for agent 1
INFO: Continuing with Bootcamp #0 BootcampName.SLOW_AGENT with slow factor: 5 for agent 0
INFO: Continuing with Bootcamp #0 BootcampName.SLOW_AGENT with slow factor: 4 for agent 1
INFO: Continuing with Bootcamp #0 BootcampName.SLOW_AGENT with slow factor: 4 for agent 0
INFO: Continuing with Bootcamp #0 BootcampName.SLOW_AGENT with slow factor: 3 for agent 1
INFO: Continuing with Bootcamp #0 BootcampName.SLOW_AGENT with slow factor: 3 for agent 0
INFO: Continuing with Bootcamp #0 BootcampName.SLOW_AGENT with slow factor: 2 for agent 1
INFO: Continuing with Bootcamp #0 BootcampName.SLOW_AGENT with slow factor: 2 for agent 0
INFO: BootcampName.SLOW_AGENT Bootcamp completed, starting BootcampName.COMBINED Bootcamp #0 for 0 days
INFO: BootcampName.COMBINED Bootcamp completed, starting BootcampName.FINISHED Bootcamp #0 for 0 days
INFO: Number of parameters: 63845
INFO: QNetwork(
  (conv_feature): Sequential(
    (0): Conv2d(1, 32, kernel_size=(3, 3), stride=(1, 1))
    (1): ReLU()
    (2): BatchNorm2d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (3): Conv2d(32, 32, kernel_size=(3, 3), stride=(1, 1))
    (4): ReLU()
    (5): BatchNorm2d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
  )
  (fc_feature): Sequential(
    (0): Linear(in_features=288, out_features=128, bias=True)
    (1): ReLU()
    (2): Linear(in_features=128, out_features=128, bias=True)
    (3): ReLU()
    (4): Linear(in_features=128, out_features=5, bias=True)
  )
)
WARNING: GIF is enabled but the environment does not support RGB array rendering.
INFO: Learning...
INFO: BootcampName.HIDER Bootcamp completed, starting BootcampName.SEEKER Bootcamp #0 for 0 days
INFO: BootcampName.SEEKER Bootcamp completed, starting BootcampName.SLOW_AGENT Bootcamp #0 for 0 days
INFO: Continuing with Bootcamp #0 BootcampName.SLOW_AGENT with slow factor: 9 for agent 1
INFO: Continuing with Bootcamp #0 BootcampName.SLOW_AGENT with slow factor: 9 for agent 0
INFO: Continuing with Bootcamp #0 BootcampName.SLOW_AGENT with slow factor: 8 for agent 1
INFO: Continuing with Bootcamp #0 BootcampName.SLOW_AGENT with slow factor: 8 for agent 0
INFO: Continuing with Bootcamp #0 BootcampName.SLOW_AGENT with slow factor: 7 for agent 1
INFO: Continuing with Bootcamp #0 BootcampName.SLOW_AGENT with slow factor: 7 for agent 0
INFO: Continuing with Bootcamp #0 BootcampName.SLOW_AGENT with slow factor: 6 for agent 1
INFO: Continuing with Bootcamp #0 BootcampName.SLOW_AGENT with slow factor: 6 for agent 0
INFO: Continuing with Bootcamp #0 BootcampName.SLOW_AGENT with slow factor: 5 for agent 1
INFO: Continuing with Bootcamp #0 BootcampName.SLOW_AGENT with slow factor: 5 for agent 0
INFO: Continuing with Bootcamp #0 BootcampName.SLOW_AGENT with slow factor: 4 for agent 1
INFO: Continuing with Bootcamp #0 BootcampName.SLOW_AGENT with slow factor: 4 for agent 0
INFO: Continuing with Bootcamp #0 BootcampName.SLOW_AGENT with slow factor: 3 for agent 1
INFO: Continuing with Bootcamp #0 BootcampName.SLOW_AGENT with slow factor: 3 for agent 0
INFO: Continuing with Bootcamp #0 BootcampName.SLOW_AGENT with slow factor: 2 for agent 1
INFO: Continuing with Bootcamp #0 BootcampName.SLOW_AGENT with slow factor: 2 for agent 0
INFO: BootcampName.SLOW_AGENT Bootcamp completed, starting BootcampName.COMBINED Bootcamp #0 for 0 days
INFO: BootcampName.COMBINED Bootcamp completed, starting BootcampName.FINISHED Bootcamp #0 for 0 days
INFO: Number of parameters: 63845
INFO: QNetwork(
  (conv_feature): Sequential(
    (0): Conv2d(1, 32, kernel_size=(3, 3), stride=(1, 1))
    (1): ReLU()
    (2): BatchNorm2d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (3): Conv2d(32, 32, kernel_size=(3, 3), stride=(1, 1))
    (4): ReLU()
    (5): BatchNorm2d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
  )
  (fc_feature): Sequential(
    (0): Linear(in_features=288, out_features=128, bias=True)
    (1): ReLU()
    (2): Linear(in_features=128, out_features=128, bias=True)
    (3): ReLU()
    (4): Linear(in_features=128, out_features=5, bias=True)
  )
)
WARNING: GIF is enabled but the environment does not support RGB array rendering.
INFO: Learning...
INFO: BootcampName.HIDER Bootcamp completed, starting BootcampName.SEEKER Bootcamp #0 for 0 days
INFO: BootcampName.SEEKER Bootcamp completed, starting BootcampName.SLOW_AGENT Bootcamp #0 for 0 days
INFO: Continuing with Bootcamp #0 BootcampName.SLOW_AGENT with slow factor: 9 for agent 1
INFO: Continuing with Bootcamp #0 BootcampName.SLOW_AGENT with slow factor: 9 for agent 0
INFO: Continuing with Bootcamp #0 BootcampName.SLOW_AGENT with slow factor: 8 for agent 1
INFO: Continuing with Bootcamp #0 BootcampName.SLOW_AGENT with slow factor: 8 for agent 0
INFO: Continuing with Bootcamp #0 BootcampName.SLOW_AGENT with slow factor: 7 for agent 1
INFO: Continuing with Bootcamp #0 BootcampName.SLOW_AGENT with slow factor: 7 for agent 0
INFO: Continuing with Bootcamp #0 BootcampName.SLOW_AGENT with slow factor: 6 for agent 1
INFO: Continuing with Bootcamp #0 BootcampName.SLOW_AGENT with slow factor: 6 for agent 0
INFO: Continuing with Bootcamp #0 BootcampName.SLOW_AGENT with slow factor: 5 for agent 1
INFO: Continuing with Bootcamp #0 BootcampName.SLOW_AGENT with slow factor: 5 for agent 0
INFO: Continuing with Bootcamp #0 BootcampName.SLOW_AGENT with slow factor: 4 for agent 1
INFO: Continuing with Bootcamp #0 BootcampName.SLOW_AGENT with slow factor: 4 for agent 0
INFO: Continuing with Bootcamp #0 BootcampName.SLOW_AGENT with slow factor: 3 for agent 1
INFO: Continuing with Bootcamp #0 BootcampName.SLOW_AGENT with slow factor: 3 for agent 0
INFO: Continuing with Bootcamp #0 BootcampName.SLOW_AGENT with slow factor: 2 for agent 1
INFO: Continuing with Bootcamp #0 BootcampName.SLOW_AGENT with slow factor: 2 for agent 0
INFO: BootcampName.SLOW_AGENT Bootcamp completed, starting BootcampName.COMBINED Bootcamp #0 for 0 days
INFO: BootcampName.COMBINED Bootcamp completed, starting BootcampName.FINISHED Bootcamp #0 for 0 days
INFO: Number of parameters: 63845
INFO: QNetwork(
  (conv_feature): Sequential(
    (0): Conv2d(1, 32, kernel_size=(3, 3), stride=(1, 1))
    (1): ReLU()
    (2): BatchNorm2d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (3): Conv2d(32, 32, kernel_size=(3, 3), stride=(1, 1))
    (4): ReLU()
    (5): BatchNorm2d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
  )
  (fc_feature): Sequential(
    (0): Linear(in_features=288, out_features=128, bias=True)
    (1): ReLU()
    (2): Linear(in_features=128, out_features=128, bias=True)
    (3): ReLU()
    (4): Linear(in_features=128, out_features=5, bias=True)
  )
)
WARNING: GIF is enabled but the environment does not support RGB array rendering.
INFO: Learning...
INFO: BootcampName.HIDER Bootcamp completed, starting BootcampName.SEEKER Bootcamp #0 for 0 days
INFO: BootcampName.SEEKER Bootcamp completed, starting BootcampName.SLOW_AGENT Bootcamp #0 for 0 days
INFO: Continuing with Bootcamp #0 BootcampName.SLOW_AGENT with slow factor: 9 for agent 1
INFO: Continuing with Bootcamp #0 BootcampName.SLOW_AGENT with slow factor: 9 for agent 0
INFO: Continuing with Bootcamp #0 BootcampName.SLOW_AGENT with slow factor: 8 for agent 1
INFO: Continuing with Bootcamp #0 BootcampName.SLOW_AGENT with slow factor: 8 for agent 0
INFO: Continuing with Bootcamp #0 BootcampName.SLOW_AGENT with slow factor: 7 for agent 1
INFO: Continuing with Bootcamp #0 BootcampName.SLOW_AGENT with slow factor: 7 for agent 0
INFO: Continuing with Bootcamp #0 BootcampName.SLOW_AGENT with slow factor: 6 for agent 1
INFO: Continuing with Bootcamp #0 BootcampName.SLOW_AGENT with slow factor: 6 for agent 0
INFO: Continuing with Bootcamp #0 BootcampName.SLOW_AGENT with slow factor: 5 for agent 1
INFO: Continuing with Bootcamp #0 BootcampName.SLOW_AGENT with slow factor: 5 for agent 0
INFO: Continuing with Bootcamp #0 BootcampName.SLOW_AGENT with slow factor: 4 for agent 1
INFO: Continuing with Bootcamp #0 BootcampName.SLOW_AGENT with slow factor: 4 for agent 0
INFO: Continuing with Bootcamp #0 BootcampName.SLOW_AGENT with slow factor: 3 for agent 1
INFO: Continuing with Bootcamp #0 BootcampName.SLOW_AGENT with slow factor: 3 for agent 0
INFO: Continuing with Bootcamp #0 BootcampName.SLOW_AGENT with slow factor: 2 for agent 1
INFO: Continuing with Bootcamp #0 BootcampName.SLOW_AGENT with slow factor: 2 for agent 0
INFO: BootcampName.SLOW_AGENT Bootcamp completed, starting BootcampName.COMBINED Bootcamp #0 for 0 days
INFO: BootcampName.COMBINED Bootcamp completed, starting BootcampName.FINISHED Bootcamp #0 for 0 days
INFO: Number of parameters: 63845
INFO: QNetwork(
  (conv_feature): Sequential(
    (0): Conv2d(1, 32, kernel_size=(3, 3), stride=(1, 1))
    (1): ReLU()
    (2): BatchNorm2d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (3): Conv2d(32, 32, kernel_size=(3, 3), stride=(1, 1))
    (4): ReLU()
    (5): BatchNorm2d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
  )
  (fc_feature): Sequential(
    (0): Linear(in_features=288, out_features=128, bias=True)
    (1): ReLU()
    (2): Linear(in_features=128, out_features=128, bias=True)
    (3): ReLU()
    (4): Linear(in_features=128, out_features=5, bias=True)
  )
)
WARNING: GIF is enabled but the environment does not support RGB array rendering.
INFO: Learning...
INFO: BootcampName.HIDER Bootcamp completed, starting BootcampName.SEEKER Bootcamp #0 for 0 days
INFO: BootcampName.SEEKER Bootcamp completed, starting BootcampName.SLOW_AGENT Bootcamp #0 for 0 days
INFO: Continuing with Bootcamp #0 BootcampName.SLOW_AGENT with slow factor: 9 for agent 1
INFO: Continuing with Bootcamp #0 BootcampName.SLOW_AGENT with slow factor: 9 for agent 0
INFO: Continuing with Bootcamp #0 BootcampName.SLOW_AGENT with slow factor: 8 for agent 1
INFO: Continuing with Bootcamp #0 BootcampName.SLOW_AGENT with slow factor: 8 for agent 0
INFO: Continuing with Bootcamp #0 BootcampName.SLOW_AGENT with slow factor: 7 for agent 1
INFO: Continuing with Bootcamp #0 BootcampName.SLOW_AGENT with slow factor: 7 for agent 0
INFO: Continuing with Bootcamp #0 BootcampName.SLOW_AGENT with slow factor: 6 for agent 1
INFO: Continuing with Bootcamp #0 BootcampName.SLOW_AGENT with slow factor: 6 for agent 0
INFO: Continuing with Bootcamp #0 BootcampName.SLOW_AGENT with slow factor: 5 for agent 1
INFO: Continuing with Bootcamp #0 BootcampName.SLOW_AGENT with slow factor: 5 for agent 0
INFO: Continuing with Bootcamp #0 BootcampName.SLOW_AGENT with slow factor: 4 for agent 1
INFO: Continuing with Bootcamp #0 BootcampName.SLOW_AGENT with slow factor: 4 for agent 0
INFO: Continuing with Bootcamp #0 BootcampName.SLOW_AGENT with slow factor: 3 for agent 1
INFO: Continuing with Bootcamp #0 BootcampName.SLOW_AGENT with slow factor: 3 for agent 0
INFO: Continuing with Bootcamp #0 BootcampName.SLOW_AGENT with slow factor: 2 for agent 1
INFO: Continuing with Bootcamp #0 BootcampName.SLOW_AGENT with slow factor: 2 for agent 0
INFO: BootcampName.SLOW_AGENT Bootcamp completed, starting BootcampName.COMBINED Bootcamp #0 for 0 days
INFO: BootcampName.COMBINED Bootcamp completed, starting BootcampName.FINISHED Bootcamp #0 for 0 days
INFO: Number of parameters: 47333
INFO: QNetwork(
  (conv_feature): Sequential(
    (0): Conv2d(1, 32, kernel_size=(3, 3), stride=(1, 1))
    (1): ReLU()
    (2): BatchNorm2d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (3): Conv2d(32, 32, kernel_size=(3, 3), stride=(1, 1))
    (4): ReLU()
    (5): BatchNorm2d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
  )
  (fc_feature): Sequential(
    (0): Linear(in_features=288, out_features=128, bias=True)
    (1): ReLU()
    (2): Linear(in_features=128, out_features=5, bias=True)
  )
)
INFO: Learning...
INFO: BootcampName.HIDER Bootcamp completed, starting BootcampName.SEEKER Bootcamp #0 for 0 days
INFO: BootcampName.SEEKER Bootcamp completed, starting BootcampName.SLOW_AGENT Bootcamp #0 for 0 days
INFO: Continuing with Bootcamp #0 BootcampName.SLOW_AGENT with slow factor: 9 for agent 1
INFO: Continuing with Bootcamp #0 BootcampName.SLOW_AGENT with slow factor: 9 for agent 0
INFO: Continuing with Bootcamp #0 BootcampName.SLOW_AGENT with slow factor: 8 for agent 1
INFO: Continuing with Bootcamp #0 BootcampName.SLOW_AGENT with slow factor: 8 for agent 0
INFO: Continuing with Bootcamp #0 BootcampName.SLOW_AGENT with slow factor: 7 for agent 1
INFO: Continuing with Bootcamp #0 BootcampName.SLOW_AGENT with slow factor: 7 for agent 0
INFO: Continuing with Bootcamp #0 BootcampName.SLOW_AGENT with slow factor: 6 for agent 1
INFO: Continuing with Bootcamp #0 BootcampName.SLOW_AGENT with slow factor: 6 for agent 0
INFO: Continuing with Bootcamp #0 BootcampName.SLOW_AGENT with slow factor: 5 for agent 1
INFO: Continuing with Bootcamp #0 BootcampName.SLOW_AGENT with slow factor: 5 for agent 0
INFO: Continuing with Bootcamp #0 BootcampName.SLOW_AGENT with slow factor: 4 for agent 1
INFO: Continuing with Bootcamp #0 BootcampName.SLOW_AGENT with slow factor: 4 for agent 0
INFO: Continuing with Bootcamp #0 BootcampName.SLOW_AGENT with slow factor: 3 for agent 1
INFO: Continuing with Bootcamp #0 BootcampName.SLOW_AGENT with slow factor: 3 for agent 0
INFO: Continuing with Bootcamp #0 BootcampName.SLOW_AGENT with slow factor: 2 for agent 1
INFO: Continuing with Bootcamp #0 BootcampName.SLOW_AGENT with slow factor: 2 for agent 0
INFO: BootcampName.SLOW_AGENT Bootcamp completed, starting BootcampName.COMBINED Bootcamp #0 for 0 days
INFO: BootcampName.COMBINED Bootcamp completed, starting BootcampName.FINISHED Bootcamp #0 for 0 days
INFO: Number of parameters: 47333
INFO: QNetwork(
  (conv_feature): Sequential(
    (0): Conv2d(1, 32, kernel_size=(3, 3), stride=(1, 1))
    (1): ReLU()
    (2): BatchNorm2d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (3): Conv2d(32, 32, kernel_size=(3, 3), stride=(1, 1))
    (4): ReLU()
    (5): BatchNorm2d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
  )
  (fc_feature): Sequential(
    (0): Linear(in_features=288, out_features=128, bias=True)
    (1): ReLU()
    (2): Linear(in_features=128, out_features=5, bias=True)
  )
)
INFO: Learning...
INFO: BootcampName.HIDER Bootcamp completed, starting BootcampName.SEEKER Bootcamp #0 for 0 days
INFO: BootcampName.SEEKER Bootcamp completed, starting BootcampName.SLOW_AGENT Bootcamp #0 for 0 days
INFO: Continuing with Bootcamp #0 BootcampName.SLOW_AGENT with slow factor: 9 for agent 1
INFO: Continuing with Bootcamp #0 BootcampName.SLOW_AGENT with slow factor: 9 for agent 0
INFO: Continuing with Bootcamp #0 BootcampName.SLOW_AGENT with slow factor: 8 for agent 1
INFO: Continuing with Bootcamp #0 BootcampName.SLOW_AGENT with slow factor: 8 for agent 0
INFO: Continuing with Bootcamp #0 BootcampName.SLOW_AGENT with slow factor: 7 for agent 1
INFO: Continuing with Bootcamp #0 BootcampName.SLOW_AGENT with slow factor: 7 for agent 0
INFO: Continuing with Bootcamp #0 BootcampName.SLOW_AGENT with slow factor: 6 for agent 1
INFO: Continuing with Bootcamp #0 BootcampName.SLOW_AGENT with slow factor: 6 for agent 0
INFO: Continuing with Bootcamp #0 BootcampName.SLOW_AGENT with slow factor: 5 for agent 1
INFO: Continuing with Bootcamp #0 BootcampName.SLOW_AGENT with slow factor: 5 for agent 0
INFO: Continuing with Bootcamp #0 BootcampName.SLOW_AGENT with slow factor: 4 for agent 1
INFO: Continuing with Bootcamp #0 BootcampName.SLOW_AGENT with slow factor: 4 for agent 0
INFO: Continuing with Bootcamp #0 BootcampName.SLOW_AGENT with slow factor: 3 for agent 1
INFO: Continuing with Bootcamp #0 BootcampName.SLOW_AGENT with slow factor: 3 for agent 0
INFO: Continuing with Bootcamp #0 BootcampName.SLOW_AGENT with slow factor: 2 for agent 1
INFO: Continuing with Bootcamp #0 BootcampName.SLOW_AGENT with slow factor: 2 for agent 0
INFO: BootcampName.SLOW_AGENT Bootcamp completed, starting BootcampName.COMBINED Bootcamp #0 for 0 days
INFO: BootcampName.COMBINED Bootcamp completed, starting BootcampName.FINISHED Bootcamp #0 for 0 days
INFO: Number of parameters: 47333
INFO: QNetwork(
  (conv_feature): Sequential(
    (0): Conv2d(1, 32, kernel_size=(3, 3), stride=(1, 1))
    (1): ReLU()
    (2): BatchNorm2d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (3): Conv2d(32, 32, kernel_size=(3, 3), stride=(1, 1))
    (4): ReLU()
    (5): BatchNorm2d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
  )
  (fc_feature): Sequential(
    (0): Linear(in_features=288, out_features=128, bias=True)
    (1): ReLU()
    (2): Linear(in_features=128, out_features=5, bias=True)
  )
)
WARNING: GIF is enabled but the environment does not support RGB array rendering.
INFO: Learning...
INFO: BootcampName.HIDER Bootcamp completed, starting BootcampName.SEEKER Bootcamp #0 for 0 days
INFO: BootcampName.SEEKER Bootcamp completed, starting BootcampName.SLOW_AGENT Bootcamp #0 for 0 days
INFO: Continuing with Bootcamp #0 BootcampName.SLOW_AGENT with slow factor: 9 for agent 1
INFO: Continuing with Bootcamp #0 BootcampName.SLOW_AGENT with slow factor: 9 for agent 0
INFO: Continuing with Bootcamp #0 BootcampName.SLOW_AGENT with slow factor: 8 for agent 1
INFO: Continuing with Bootcamp #0 BootcampName.SLOW_AGENT with slow factor: 8 for agent 0
INFO: Continuing with Bootcamp #0 BootcampName.SLOW_AGENT with slow factor: 7 for agent 1
INFO: Continuing with Bootcamp #0 BootcampName.SLOW_AGENT with slow factor: 7 for agent 0
INFO: Continuing with Bootcamp #0 BootcampName.SLOW_AGENT with slow factor: 6 for agent 1
INFO: Continuing with Bootcamp #0 BootcampName.SLOW_AGENT with slow factor: 6 for agent 0
INFO: Continuing with Bootcamp #0 BootcampName.SLOW_AGENT with slow factor: 5 for agent 1
INFO: Continuing with Bootcamp #0 BootcampName.SLOW_AGENT with slow factor: 5 for agent 0
INFO: Continuing with Bootcamp #0 BootcampName.SLOW_AGENT with slow factor: 4 for agent 1
INFO: Continuing with Bootcamp #0 BootcampName.SLOW_AGENT with slow factor: 4 for agent 0
INFO: Continuing with Bootcamp #0 BootcampName.SLOW_AGENT with slow factor: 3 for agent 1
INFO: Continuing with Bootcamp #0 BootcampName.SLOW_AGENT with slow factor: 3 for agent 0
INFO: Continuing with Bootcamp #0 BootcampName.SLOW_AGENT with slow factor: 2 for agent 1
INFO: Continuing with Bootcamp #0 BootcampName.SLOW_AGENT with slow factor: 2 for agent 0
INFO: BootcampName.SLOW_AGENT Bootcamp completed, starting BootcampName.COMBINED Bootcamp #0 for 0 days
INFO: BootcampName.COMBINED Bootcamp completed, starting BootcampName.FINISHED Bootcamp #0 for 0 days
INFO: Number of parameters: 47333
INFO: QNetwork(
  (conv_feature): Sequential(
    (0): Conv2d(1, 32, kernel_size=(3, 3), stride=(1, 1))
    (1): ReLU()
    (2): BatchNorm2d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (3): Conv2d(32, 32, kernel_size=(3, 3), stride=(1, 1))
    (4): ReLU()
    (5): BatchNorm2d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
  )
  (fc_feature): Sequential(
    (0): Linear(in_features=288, out_features=128, bias=True)
    (1): ReLU()
    (2): Linear(in_features=128, out_features=5, bias=True)
  )
)
WARNING: GIF is enabled but the environment does not support RGB array rendering.
INFO: Learning...
INFO: Number of parameters: 47333
INFO: QNetwork(
  (conv_feature): Sequential(
    (0): Conv2d(1, 32, kernel_size=(3, 3), stride=(1, 1))
    (1): ReLU()
    (2): BatchNorm2d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (3): Conv2d(32, 32, kernel_size=(3, 3), stride=(1, 1))
    (4): ReLU()
    (5): BatchNorm2d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
  )
  (fc_feature): Sequential(
    (0): Linear(in_features=288, out_features=128, bias=True)
    (1): ReLU()
    (2): Linear(in_features=128, out_features=5, bias=True)
  )
)
WARNING: GIF is enabled but the environment does not support RGB array rendering.
INFO: Learning...
INFO: Number of parameters: 47333
INFO: QNetwork(
  (conv_feature): Sequential(
    (0): Conv2d(1, 32, kernel_size=(3, 3), stride=(1, 1))
    (1): ReLU()
    (2): BatchNorm2d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (3): Conv2d(32, 32, kernel_size=(3, 3), stride=(1, 1))
    (4): ReLU()
    (5): BatchNorm2d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
  )
  (fc_feature): Sequential(
    (0): Linear(in_features=288, out_features=128, bias=True)
    (1): ReLU()
    (2): Linear(in_features=128, out_features=5, bias=True)
  )
)
WARNING: GIF is enabled but the environment does not support RGB array rendering.
INFO: Learning...
INFO: BootcampName.HIDER Bootcamp completed, starting BootcampName.SEEKER Bootcamp #0 for 0 days
INFO: BootcampName.SEEKER Bootcamp completed, starting BootcampName.SLOW_AGENT Bootcamp #0 for 0 days
INFO: Continuing with Bootcamp #0 BootcampName.SLOW_AGENT with slow factor: 9 for agent 1
INFO: Continuing with Bootcamp #0 BootcampName.SLOW_AGENT with slow factor: 9 for agent 0
INFO: Continuing with Bootcamp #0 BootcampName.SLOW_AGENT with slow factor: 8 for agent 1
INFO: Continuing with Bootcamp #0 BootcampName.SLOW_AGENT with slow factor: 8 for agent 0
INFO: Continuing with Bootcamp #0 BootcampName.SLOW_AGENT with slow factor: 7 for agent 1
INFO: Continuing with Bootcamp #0 BootcampName.SLOW_AGENT with slow factor: 7 for agent 0
INFO: Continuing with Bootcamp #0 BootcampName.SLOW_AGENT with slow factor: 6 for agent 1
INFO: Continuing with Bootcamp #0 BootcampName.SLOW_AGENT with slow factor: 6 for agent 0
INFO: Continuing with Bootcamp #0 BootcampName.SLOW_AGENT with slow factor: 5 for agent 1
INFO: Continuing with Bootcamp #0 BootcampName.SLOW_AGENT with slow factor: 5 for agent 0
INFO: Continuing with Bootcamp #0 BootcampName.SLOW_AGENT with slow factor: 4 for agent 1
INFO: Continuing with Bootcamp #0 BootcampName.SLOW_AGENT with slow factor: 4 for agent 0
INFO: Continuing with Bootcamp #0 BootcampName.SLOW_AGENT with slow factor: 3 for agent 1
INFO: Continuing with Bootcamp #0 BootcampName.SLOW_AGENT with slow factor: 3 for agent 0
INFO: Continuing with Bootcamp #0 BootcampName.SLOW_AGENT with slow factor: 2 for agent 1
INFO: Continuing with Bootcamp #0 BootcampName.SLOW_AGENT with slow factor: 2 for agent 0
INFO: BootcampName.SLOW_AGENT Bootcamp completed, starting BootcampName.COMBINED Bootcamp #0 for 0 days
INFO: BootcampName.COMBINED Bootcamp completed, starting BootcampName.FINISHED Bootcamp #0 for 0 days
INFO: Number of parameters: 47333
INFO: QNetwork(
  (conv_feature): Sequential(
    (0): Conv2d(1, 32, kernel_size=(3, 3), stride=(1, 1))
    (1): ReLU()
    (2): BatchNorm2d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (3): Conv2d(32, 32, kernel_size=(3, 3), stride=(1, 1))
    (4): ReLU()
    (5): BatchNorm2d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
  )
  (fc_feature): Sequential(
    (0): Linear(in_features=288, out_features=128, bias=True)
    (1): ReLU()
    (2): Linear(in_features=128, out_features=5, bias=True)
  )
)
WARNING: GIF is enabled but the environment does not support RGB array rendering.
INFO: Learning...
INFO: Number of parameters: 47333
INFO: QNetwork(
  (conv_feature): Sequential(
    (0): Conv2d(1, 32, kernel_size=(3, 3), stride=(1, 1))
    (1): ReLU()
    (2): BatchNorm2d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (3): Conv2d(32, 32, kernel_size=(3, 3), stride=(1, 1))
    (4): ReLU()
    (5): BatchNorm2d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
  )
  (fc_feature): Sequential(
    (0): Linear(in_features=288, out_features=128, bias=True)
    (1): ReLU()
    (2): Linear(in_features=128, out_features=5, bias=True)
  )
)
WARNING: GIF is enabled but the environment does not support RGB array rendering.
INFO: Learning...
INFO: Number of parameters: 47333
INFO: QNetwork(
  (conv_feature): Sequential(
    (0): Conv2d(1, 32, kernel_size=(3, 3), stride=(1, 1))
    (1): ReLU()
    (2): BatchNorm2d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (3): Conv2d(32, 32, kernel_size=(3, 3), stride=(1, 1))
    (4): ReLU()
    (5): BatchNorm2d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
  )
  (fc_feature): Sequential(
    (0): Linear(in_features=288, out_features=128, bias=True)
    (1): ReLU()
    (2): Linear(in_features=128, out_features=5, bias=True)
  )
)
WARNING: GIF is enabled but the environment does not support RGB array rendering.
INFO: Learning...
INFO: Number of parameters: 47333
INFO: QNetwork(
  (conv_feature): Sequential(
    (0): Conv2d(1, 32, kernel_size=(3, 3), stride=(1, 1))
    (1): ReLU()
    (2): BatchNorm2d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (3): Conv2d(32, 32, kernel_size=(3, 3), stride=(1, 1))
    (4): ReLU()
    (5): BatchNorm2d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
  )
  (fc_feature): Sequential(
    (0): Linear(in_features=288, out_features=128, bias=True)
    (1): ReLU()
    (2): Linear(in_features=128, out_features=5, bias=True)
  )
)
WARNING: GIF is enabled but the environment does not support RGB array rendering.
INFO: Learning...
INFO: BootcampName.HIDER Bootcamp completed, starting BootcampName.SEEKER Bootcamp #0 for 0 days
INFO: BootcampName.SEEKER Bootcamp completed, starting BootcampName.SLOW_AGENT Bootcamp #0 for 0 days
INFO: Continuing with Bootcamp #0 BootcampName.SLOW_AGENT with slow factor: 9 for agent 1
INFO: Continuing with Bootcamp #0 BootcampName.SLOW_AGENT with slow factor: 9 for agent 0
INFO: Continuing with Bootcamp #0 BootcampName.SLOW_AGENT with slow factor: 8 for agent 1
INFO: Number of parameters: 47333
INFO: QNetwork(
  (conv_feature): Sequential(
    (0): Conv2d(1, 32, kernel_size=(3, 3), stride=(1, 1))
    (1): ReLU()
    (2): BatchNorm2d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (3): Conv2d(32, 32, kernel_size=(3, 3), stride=(1, 1))
    (4): ReLU()
    (5): BatchNorm2d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
  )
  (fc_feature): Sequential(
    (0): Linear(in_features=288, out_features=128, bias=True)
    (1): ReLU()
    (2): Linear(in_features=128, out_features=5, bias=True)
  )
)
WARNING: GIF is enabled but the environment does not support RGB array rendering.
INFO: Learning...
INFO: BootcampName.HIDER Bootcamp completed, starting BootcampName.SEEKER Bootcamp #0 for 0 days
INFO: BootcampName.SEEKER Bootcamp completed, starting BootcampName.SLOW_AGENT Bootcamp #0 for 0 days
INFO: Continuing with Bootcamp #0 BootcampName.SLOW_AGENT with slow factor: 9 for agent 1
INFO: Continuing with Bootcamp #0 BootcampName.SLOW_AGENT with slow factor: 9 for agent 0
INFO: Continuing with Bootcamp #0 BootcampName.SLOW_AGENT with slow factor: 8 for agent 1
INFO: Continuing with Bootcamp #0 BootcampName.SLOW_AGENT with slow factor: 8 for agent 0
INFO: Continuing with Bootcamp #0 BootcampName.SLOW_AGENT with slow factor: 7 for agent 1
INFO: Continuing with Bootcamp #0 BootcampName.SLOW_AGENT with slow factor: 7 for agent 0
INFO: Continuing with Bootcamp #0 BootcampName.SLOW_AGENT with slow factor: 6 for agent 1
INFO: Continuing with Bootcamp #0 BootcampName.SLOW_AGENT with slow factor: 6 for agent 0
INFO: Continuing with Bootcamp #0 BootcampName.SLOW_AGENT with slow factor: 5 for agent 1
INFO: Continuing with Bootcamp #0 BootcampName.SLOW_AGENT with slow factor: 5 for agent 0
INFO: Continuing with Bootcamp #0 BootcampName.SLOW_AGENT with slow factor: 4 for agent 1
INFO: Continuing with Bootcamp #0 BootcampName.SLOW_AGENT with slow factor: 4 for agent 0
INFO: Continuing with Bootcamp #0 BootcampName.SLOW_AGENT with slow factor: 3 for agent 1
INFO: Continuing with Bootcamp #0 BootcampName.SLOW_AGENT with slow factor: 3 for agent 0
INFO: Continuing with Bootcamp #0 BootcampName.SLOW_AGENT with slow factor: 2 for agent 1
INFO: Continuing with Bootcamp #0 BootcampName.SLOW_AGENT with slow factor: 2 for agent 0
INFO: BootcampName.SLOW_AGENT Bootcamp completed, starting BootcampName.COMBINED Bootcamp #0 for 0 days
INFO: BootcampName.COMBINED Bootcamp completed, starting BootcampName.FINISHED Bootcamp #0 for 0 days
INFO: Number of parameters: 47333
INFO: QNetwork(
  (conv_feature): Sequential(
    (0): Conv2d(1, 32, kernel_size=(3, 3), stride=(1, 1))
    (1): ReLU()
    (2): BatchNorm2d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (3): Conv2d(32, 32, kernel_size=(3, 3), stride=(1, 1))
    (4): ReLU()
    (5): BatchNorm2d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
  )
  (fc_feature): Sequential(
    (0): Linear(in_features=288, out_features=128, bias=True)
    (1): ReLU()
    (2): Linear(in_features=128, out_features=5, bias=True)
  )
)
WARNING: GIF is enabled but the environment does not support RGB array rendering.
INFO: Learning...
INFO: BootcampName.HIDER Bootcamp completed, starting BootcampName.SEEKER Bootcamp #0 for 0 days
INFO: BootcampName.SEEKER Bootcamp completed, starting BootcampName.SLOW_AGENT Bootcamp #0 for 0 days
INFO: Continuing with Bootcamp #0 BootcampName.SLOW_AGENT with slow factor: 9 for agent 1
INFO: Continuing with Bootcamp #0 BootcampName.SLOW_AGENT with slow factor: 9 for agent 0
INFO: Continuing with Bootcamp #0 BootcampName.SLOW_AGENT with slow factor: 8 for agent 1
INFO: Continuing with Bootcamp #0 BootcampName.SLOW_AGENT with slow factor: 8 for agent 0
INFO: Continuing with Bootcamp #0 BootcampName.SLOW_AGENT with slow factor: 7 for agent 1
INFO: Continuing with Bootcamp #0 BootcampName.SLOW_AGENT with slow factor: 7 for agent 0
INFO: Continuing with Bootcamp #0 BootcampName.SLOW_AGENT with slow factor: 6 for agent 1
INFO: Continuing with Bootcamp #0 BootcampName.SLOW_AGENT with slow factor: 6 for agent 0
INFO: Continuing with Bootcamp #0 BootcampName.SLOW_AGENT with slow factor: 5 for agent 1
INFO: Continuing with Bootcamp #0 BootcampName.SLOW_AGENT with slow factor: 5 for agent 0
INFO: Continuing with Bootcamp #0 BootcampName.SLOW_AGENT with slow factor: 4 for agent 1
INFO: Continuing with Bootcamp #0 BootcampName.SLOW_AGENT with slow factor: 4 for agent 0
INFO: Continuing with Bootcamp #0 BootcampName.SLOW_AGENT with slow factor: 3 for agent 1
INFO: Continuing with Bootcamp #0 BootcampName.SLOW_AGENT with slow factor: 3 for agent 0
INFO: Continuing with Bootcamp #0 BootcampName.SLOW_AGENT with slow factor: 2 for agent 1
INFO: Continuing with Bootcamp #0 BootcampName.SLOW_AGENT with slow factor: 2 for agent 0
INFO: BootcampName.SLOW_AGENT Bootcamp completed, starting BootcampName.COMBINED Bootcamp #0 for 0 days
INFO: BootcampName.COMBINED Bootcamp completed, starting BootcampName.FINISHED Bootcamp #0 for 0 days
INFO: Number of parameters: 47333
INFO: QNetwork(
  (conv_feature): Sequential(
    (0): Conv2d(1, 32, kernel_size=(3, 3), stride=(1, 1))
    (1): ReLU()
    (2): BatchNorm2d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (3): Conv2d(32, 32, kernel_size=(3, 3), stride=(1, 1))
    (4): ReLU()
    (5): BatchNorm2d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
  )
  (fc_feature): Sequential(
    (0): Linear(in_features=288, out_features=128, bias=True)
    (1): ReLU()
    (2): Linear(in_features=128, out_features=5, bias=True)
  )
)
WARNING: GIF is enabled but the environment does not support RGB array rendering.
INFO: Learning...
INFO: BootcampName.HIDER Bootcamp completed, starting BootcampName.SEEKER Bootcamp #0 for 0 days
INFO: BootcampName.SEEKER Bootcamp completed, starting BootcampName.SLOW_AGENT Bootcamp #0 for 0 days
INFO: Continuing with Bootcamp #0 BootcampName.SLOW_AGENT with slow factor: 9 for agent 1
INFO: Continuing with Bootcamp #0 BootcampName.SLOW_AGENT with slow factor: 9 for agent 0
INFO: Continuing with Bootcamp #0 BootcampName.SLOW_AGENT with slow factor: 8 for agent 1
INFO: Continuing with Bootcamp #0 BootcampName.SLOW_AGENT with slow factor: 8 for agent 0
INFO: Continuing with Bootcamp #0 BootcampName.SLOW_AGENT with slow factor: 7 for agent 1
INFO: Continuing with Bootcamp #0 BootcampName.SLOW_AGENT with slow factor: 7 for agent 0
INFO: Continuing with Bootcamp #0 BootcampName.SLOW_AGENT with slow factor: 6 for agent 1
INFO: Continuing with Bootcamp #0 BootcampName.SLOW_AGENT with slow factor: 6 for agent 0
INFO: Continuing with Bootcamp #0 BootcampName.SLOW_AGENT with slow factor: 5 for agent 1
INFO: Continuing with Bootcamp #0 BootcampName.SLOW_AGENT with slow factor: 5 for agent 0
INFO: Continuing with Bootcamp #0 BootcampName.SLOW_AGENT with slow factor: 4 for agent 1
INFO: Continuing with Bootcamp #0 BootcampName.SLOW_AGENT with slow factor: 4 for agent 0
INFO: Continuing with Bootcamp #0 BootcampName.SLOW_AGENT with slow factor: 3 for agent 1
INFO: Continuing with Bootcamp #0 BootcampName.SLOW_AGENT with slow factor: 3 for agent 0
INFO: Continuing with Bootcamp #0 BootcampName.SLOW_AGENT with slow factor: 2 for agent 1
INFO: Continuing with Bootcamp #0 BootcampName.SLOW_AGENT with slow factor: 2 for agent 0
INFO: BootcampName.SLOW_AGENT Bootcamp completed, starting BootcampName.COMBINED Bootcamp #0 for 0 days
INFO: BootcampName.COMBINED Bootcamp completed, starting BootcampName.FINISHED Bootcamp #0 for 0 days
INFO: Number of parameters: 47333
INFO: QNetwork(
  (conv_feature): Sequential(
    (0): Conv2d(1, 32, kernel_size=(3, 3), stride=(1, 1))
    (1): ReLU()
    (2): BatchNorm2d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (3): Conv2d(32, 32, kernel_size=(3, 3), stride=(1, 1))
    (4): ReLU()
    (5): BatchNorm2d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
  )
  (fc_feature): Sequential(
    (0): Linear(in_features=288, out_features=128, bias=True)
    (1): ReLU()
    (2): Linear(in_features=128, out_features=5, bias=True)
  )
)
WARNING: GIF is enabled but the environment does not support RGB array rendering.
INFO: Learning...
INFO: BootcampName.HIDER Bootcamp completed, starting BootcampName.SEEKER Bootcamp #0 for 0 days
INFO: BootcampName.SEEKER Bootcamp completed, starting BootcampName.SLOW_AGENT Bootcamp #0 for 0 days
INFO: Continuing with Bootcamp #0 BootcampName.SLOW_AGENT with slow factor: 9 for agent 1
INFO: Continuing with Bootcamp #0 BootcampName.SLOW_AGENT with slow factor: 9 for agent 0
INFO: Continuing with Bootcamp #0 BootcampName.SLOW_AGENT with slow factor: 8 for agent 1
INFO: Continuing with Bootcamp #0 BootcampName.SLOW_AGENT with slow factor: 8 for agent 0
INFO: Continuing with Bootcamp #0 BootcampName.SLOW_AGENT with slow factor: 7 for agent 1
INFO: Continuing with Bootcamp #0 BootcampName.SLOW_AGENT with slow factor: 7 for agent 0
INFO: Continuing with Bootcamp #0 BootcampName.SLOW_AGENT with slow factor: 6 for agent 1
INFO: Continuing with Bootcamp #0 BootcampName.SLOW_AGENT with slow factor: 6 for agent 0
INFO: Continuing with Bootcamp #0 BootcampName.SLOW_AGENT with slow factor: 5 for agent 1
INFO: Continuing with Bootcamp #0 BootcampName.SLOW_AGENT with slow factor: 5 for agent 0
INFO: Continuing with Bootcamp #0 BootcampName.SLOW_AGENT with slow factor: 4 for agent 1
INFO: Continuing with Bootcamp #0 BootcampName.SLOW_AGENT with slow factor: 4 for agent 0
INFO: Continuing with Bootcamp #0 BootcampName.SLOW_AGENT with slow factor: 3 for agent 1
INFO: Continuing with Bootcamp #0 BootcampName.SLOW_AGENT with slow factor: 3 for agent 0
INFO: Continuing with Bootcamp #0 BootcampName.SLOW_AGENT with slow factor: 2 for agent 1
INFO: Continuing with Bootcamp #0 BootcampName.SLOW_AGENT with slow factor: 2 for agent 0
INFO: BootcampName.SLOW_AGENT Bootcamp completed, starting BootcampName.COMBINED Bootcamp #0 for 0 days
INFO: BootcampName.COMBINED Bootcamp completed, starting BootcampName.FINISHED Bootcamp #0 for 0 days
WARNING: No frames in gif to save.
WARNING: No frames in gif to save.
INFO: Number of parameters: 120069
INFO: QNetwork(
  (conv_feature): Sequential(
    (0): Conv2d(1, 32, kernel_size=(3, 3), stride=(1, 1))
    (1): ReLU()
    (2): BatchNorm2d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
  )
  (fc_feature): Sequential(
    (0): Linear(in_features=800, out_features=128, bias=True)
    (1): ReLU()
    (2): Linear(in_features=128, out_features=128, bias=True)
    (3): ReLU()
    (4): Linear(in_features=128, out_features=5, bias=True)
  )
)
INFO: Learning...
INFO: BootcampName.HIDER Bootcamp completed, starting BootcampName.SEEKER Bootcamp #0 for 0 days
INFO: BootcampName.SEEKER Bootcamp completed, starting BootcampName.SLOW_AGENT Bootcamp #0 for 0 days
INFO: Continuing with Bootcamp #0 BootcampName.SLOW_AGENT with slow factor: 9 for agent 1
INFO: Continuing with Bootcamp #0 BootcampName.SLOW_AGENT with slow factor: 9 for agent 0
INFO: Continuing with Bootcamp #0 BootcampName.SLOW_AGENT with slow factor: 8 for agent 1
INFO: Continuing with Bootcamp #0 BootcampName.SLOW_AGENT with slow factor: 8 for agent 0
INFO: Continuing with Bootcamp #0 BootcampName.SLOW_AGENT with slow factor: 7 for agent 1
INFO: Continuing with Bootcamp #0 BootcampName.SLOW_AGENT with slow factor: 7 for agent 0
INFO: Continuing with Bootcamp #0 BootcampName.SLOW_AGENT with slow factor: 6 for agent 1
INFO: Continuing with Bootcamp #0 BootcampName.SLOW_AGENT with slow factor: 6 for agent 0
INFO: Continuing with Bootcamp #0 BootcampName.SLOW_AGENT with slow factor: 5 for agent 1
INFO: Continuing with Bootcamp #0 BootcampName.SLOW_AGENT with slow factor: 5 for agent 0
INFO: Continuing with Bootcamp #0 BootcampName.SLOW_AGENT with slow factor: 4 for agent 1
INFO: Continuing with Bootcamp #0 BootcampName.SLOW_AGENT with slow factor: 4 for agent 0
INFO: Continuing with Bootcamp #0 BootcampName.SLOW_AGENT with slow factor: 3 for agent 1
INFO: Continuing with Bootcamp #0 BootcampName.SLOW_AGENT with slow factor: 3 for agent 0
INFO: Continuing with Bootcamp #0 BootcampName.SLOW_AGENT with slow factor: 2 for agent 1
INFO: Continuing with Bootcamp #0 BootcampName.SLOW_AGENT with slow factor: 2 for agent 0
INFO: BootcampName.SLOW_AGENT Bootcamp completed, starting BootcampName.COMBINED Bootcamp #0 for 0 days
INFO: BootcampName.COMBINED Bootcamp completed, starting BootcampName.FINISHED Bootcamp #0 for 0 days
INFO: Number of parameters: 120069
INFO: QNetwork(
  (conv_feature): Sequential(
    (0): Conv2d(1, 32, kernel_size=(3, 3), stride=(1, 1))
    (1): ReLU()
    (2): BatchNorm2d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
  )
  (fc_feature): Sequential(
    (0): Linear(in_features=800, out_features=128, bias=True)
    (1): ReLU()
    (2): Linear(in_features=128, out_features=128, bias=True)
    (3): ReLU()
    (4): Linear(in_features=128, out_features=5, bias=True)
  )
)
INFO: Learning...
INFO: BootcampName.HIDER Bootcamp completed, starting BootcampName.SEEKER Bootcamp #0 for 0 days
INFO: BootcampName.SEEKER Bootcamp completed, starting BootcampName.SLOW_AGENT Bootcamp #0 for 0 days
INFO: Continuing with Bootcamp #0 BootcampName.SLOW_AGENT with slow factor: 9 for agent 1
INFO: Continuing with Bootcamp #0 BootcampName.SLOW_AGENT with slow factor: 9 for agent 0
INFO: Continuing with Bootcamp #0 BootcampName.SLOW_AGENT with slow factor: 8 for agent 1
INFO: Continuing with Bootcamp #0 BootcampName.SLOW_AGENT with slow factor: 8 for agent 0
INFO: Continuing with Bootcamp #0 BootcampName.SLOW_AGENT with slow factor: 7 for agent 1
INFO: Continuing with Bootcamp #0 BootcampName.SLOW_AGENT with slow factor: 7 for agent 0
INFO: Continuing with Bootcamp #0 BootcampName.SLOW_AGENT with slow factor: 6 for agent 1
INFO: Continuing with Bootcamp #0 BootcampName.SLOW_AGENT with slow factor: 6 for agent 0
INFO: Continuing with Bootcamp #0 BootcampName.SLOW_AGENT with slow factor: 5 for agent 1
INFO: Continuing with Bootcamp #0 BootcampName.SLOW_AGENT with slow factor: 5 for agent 0
INFO: Continuing with Bootcamp #0 BootcampName.SLOW_AGENT with slow factor: 4 for agent 1
INFO: Continuing with Bootcamp #0 BootcampName.SLOW_AGENT with slow factor: 4 for agent 0
INFO: Continuing with Bootcamp #0 BootcampName.SLOW_AGENT with slow factor: 3 for agent 1
INFO: Continuing with Bootcamp #0 BootcampName.SLOW_AGENT with slow factor: 3 for agent 0
INFO: Continuing with Bootcamp #0 BootcampName.SLOW_AGENT with slow factor: 2 for agent 1
INFO: Continuing with Bootcamp #0 BootcampName.SLOW_AGENT with slow factor: 2 for agent 0
INFO: BootcampName.SLOW_AGENT Bootcamp completed, starting BootcampName.COMBINED Bootcamp #0 for 0 days
INFO: BootcampName.COMBINED Bootcamp completed, starting BootcampName.FINISHED Bootcamp #0 for 0 days
INFO: Number of parameters: 83205
INFO: QNetwork(
  (conv_feature): Sequential(
    (0): Conv2d(1, 32, kernel_size=(3, 3), stride=(1, 1))
    (1): ReLU()
    (2): BatchNorm2d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
  )
  (fc_feature): Sequential(
    (0): Linear(in_features=512, out_features=128, bias=True)
    (1): ReLU()
    (2): Linear(in_features=128, out_features=128, bias=True)
    (3): ReLU()
    (4): Linear(in_features=128, out_features=5, bias=True)
  )
)
INFO: Learning...
INFO: BootcampName.HIDER Bootcamp completed, starting BootcampName.SEEKER Bootcamp #0 for 0 days
INFO: BootcampName.SEEKER Bootcamp completed, starting BootcampName.SLOW_AGENT Bootcamp #0 for 0 days
INFO: Continuing with Bootcamp #0 BootcampName.SLOW_AGENT with slow factor: 9 for agent 1
INFO: Continuing with Bootcamp #0 BootcampName.SLOW_AGENT with slow factor: 9 for agent 0
INFO: Continuing with Bootcamp #0 BootcampName.SLOW_AGENT with slow factor: 8 for agent 1
INFO: Continuing with Bootcamp #0 BootcampName.SLOW_AGENT with slow factor: 8 for agent 0
INFO: Continuing with Bootcamp #0 BootcampName.SLOW_AGENT with slow factor: 7 for agent 1
INFO: Continuing with Bootcamp #0 BootcampName.SLOW_AGENT with slow factor: 7 for agent 0
INFO: Continuing with Bootcamp #0 BootcampName.SLOW_AGENT with slow factor: 6 for agent 1
INFO: Continuing with Bootcamp #0 BootcampName.SLOW_AGENT with slow factor: 6 for agent 0
INFO: Continuing with Bootcamp #0 BootcampName.SLOW_AGENT with slow factor: 5 for agent 1
INFO: Continuing with Bootcamp #0 BootcampName.SLOW_AGENT with slow factor: 5 for agent 0
INFO: Continuing with Bootcamp #0 BootcampName.SLOW_AGENT with slow factor: 4 for agent 1
INFO: Continuing with Bootcamp #0 BootcampName.SLOW_AGENT with slow factor: 4 for agent 0
INFO: Continuing with Bootcamp #0 BootcampName.SLOW_AGENT with slow factor: 3 for agent 1
INFO: Continuing with Bootcamp #0 BootcampName.SLOW_AGENT with slow factor: 3 for agent 0
INFO: Continuing with Bootcamp #0 BootcampName.SLOW_AGENT with slow factor: 2 for agent 1
INFO: Continuing with Bootcamp #0 BootcampName.SLOW_AGENT with slow factor: 2 for agent 0
INFO: BootcampName.SLOW_AGENT Bootcamp completed, starting BootcampName.COMBINED Bootcamp #0 for 0 days
INFO: BootcampName.COMBINED Bootcamp completed, starting BootcampName.FINISHED Bootcamp #0 for 0 days
INFO: Number of parameters: 83205
INFO: QNetwork(
  (conv_feature): Sequential(
    (0): Conv2d(1, 32, kernel_size=(3, 3), stride=(1, 1))
    (1): ReLU()
    (2): BatchNorm2d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
  )
  (fc_feature): Sequential(
    (0): Linear(in_features=512, out_features=128, bias=True)
    (1): ReLU()
    (2): Linear(in_features=128, out_features=128, bias=True)
    (3): ReLU()
    (4): Linear(in_features=128, out_features=5, bias=True)
  )
)
WARNING: GIF is enabled but the environment does not support RGB array rendering.
INFO: Learning...
INFO: BootcampName.HIDER Bootcamp completed, starting BootcampName.SEEKER Bootcamp #0 for 0 days
INFO: BootcampName.SEEKER Bootcamp completed, starting BootcampName.SLOW_AGENT Bootcamp #0 for 0 days
INFO: Continuing with Bootcamp #0 BootcampName.SLOW_AGENT with slow factor: 9 for agent 1
INFO: Continuing with Bootcamp #0 BootcampName.SLOW_AGENT with slow factor: 9 for agent 0
INFO: Continuing with Bootcamp #0 BootcampName.SLOW_AGENT with slow factor: 8 for agent 1
INFO: Continuing with Bootcamp #0 BootcampName.SLOW_AGENT with slow factor: 8 for agent 0
INFO: Continuing with Bootcamp #0 BootcampName.SLOW_AGENT with slow factor: 7 for agent 1
INFO: Continuing with Bootcamp #0 BootcampName.SLOW_AGENT with slow factor: 7 for agent 0
INFO: Continuing with Bootcamp #0 BootcampName.SLOW_AGENT with slow factor: 6 for agent 1
INFO: Continuing with Bootcamp #0 BootcampName.SLOW_AGENT with slow factor: 6 for agent 0
INFO: Continuing with Bootcamp #0 BootcampName.SLOW_AGENT with slow factor: 5 for agent 1
INFO: Continuing with Bootcamp #0 BootcampName.SLOW_AGENT with slow factor: 5 for agent 0
INFO: Continuing with Bootcamp #0 BootcampName.SLOW_AGENT with slow factor: 4 for agent 1
INFO: Continuing with Bootcamp #0 BootcampName.SLOW_AGENT with slow factor: 4 for agent 0
INFO: Continuing with Bootcamp #0 BootcampName.SLOW_AGENT with slow factor: 3 for agent 1
INFO: Continuing with Bootcamp #0 BootcampName.SLOW_AGENT with slow factor: 3 for agent 0
INFO: Continuing with Bootcamp #0 BootcampName.SLOW_AGENT with slow factor: 2 for agent 1
INFO: Continuing with Bootcamp #0 BootcampName.SLOW_AGENT with slow factor: 2 for agent 0
INFO: BootcampName.SLOW_AGENT Bootcamp completed, starting BootcampName.COMBINED Bootcamp #0 for 0 days
INFO: BootcampName.COMBINED Bootcamp completed, starting BootcampName.FINISHED Bootcamp #0 for 0 days
INFO: Number of parameters: 54533
INFO: QNetwork(
  (conv_feature): Sequential(
    (0): Conv2d(1, 32, kernel_size=(3, 3), stride=(1, 1))
    (1): ReLU()
    (2): BatchNorm2d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
  )
  (fc_feature): Sequential(
    (0): Linear(in_features=288, out_features=128, bias=True)
    (1): ReLU()
    (2): Linear(in_features=128, out_features=128, bias=True)
    (3): ReLU()
    (4): Linear(in_features=128, out_features=5, bias=True)
  )
)
WARNING: GIF is enabled but the environment does not support RGB array rendering.
INFO: Learning...
INFO: BootcampName.HIDER Bootcamp completed, starting BootcampName.SEEKER Bootcamp #0 for 0 days
INFO: BootcampName.SEEKER Bootcamp completed, starting BootcampName.SLOW_AGENT Bootcamp #0 for 0 days
INFO: Continuing with Bootcamp #0 BootcampName.SLOW_AGENT with slow factor: 9 for agent 1
INFO: Continuing with Bootcamp #0 BootcampName.SLOW_AGENT with slow factor: 9 for agent 0
INFO: Continuing with Bootcamp #0 BootcampName.SLOW_AGENT with slow factor: 8 for agent 1
INFO: Continuing with Bootcamp #0 BootcampName.SLOW_AGENT with slow factor: 8 for agent 0
INFO: Continuing with Bootcamp #0 BootcampName.SLOW_AGENT with slow factor: 7 for agent 1
INFO: Continuing with Bootcamp #0 BootcampName.SLOW_AGENT with slow factor: 7 for agent 0
INFO: Continuing with Bootcamp #0 BootcampName.SLOW_AGENT with slow factor: 6 for agent 1
INFO: Continuing with Bootcamp #0 BootcampName.SLOW_AGENT with slow factor: 6 for agent 0
INFO: Continuing with Bootcamp #0 BootcampName.SLOW_AGENT with slow factor: 5 for agent 1
INFO: Continuing with Bootcamp #0 BootcampName.SLOW_AGENT with slow factor: 5 for agent 0
INFO: Continuing with Bootcamp #0 BootcampName.SLOW_AGENT with slow factor: 4 for agent 1
INFO: Continuing with Bootcamp #0 BootcampName.SLOW_AGENT with slow factor: 4 for agent 0
INFO: Continuing with Bootcamp #0 BootcampName.SLOW_AGENT with slow factor: 3 for agent 1
INFO: Continuing with Bootcamp #0 BootcampName.SLOW_AGENT with slow factor: 3 for agent 0
INFO: Continuing with Bootcamp #0 BootcampName.SLOW_AGENT with slow factor: 2 for agent 1
INFO: Continuing with Bootcamp #0 BootcampName.SLOW_AGENT with slow factor: 2 for agent 0
INFO: BootcampName.SLOW_AGENT Bootcamp completed, starting BootcampName.COMBINED Bootcamp #0 for 0 days
INFO: BootcampName.COMBINED Bootcamp completed, starting BootcampName.FINISHED Bootcamp #0 for 0 days
WARNING: No frames in gif to save.
WARNING: No frames in gif to save.
WARNING: No frames in gif to save.
WARNING: No frames in gif to save.
WARNING: No frames in gif to save.
WARNING: No frames in gif to save.
INFO: Number of parameters: 54533
INFO: QNetwork(
  (conv_feature): Sequential(
    (0): Conv2d(1, 32, kernel_size=(3, 3), stride=(1, 1))
    (1): ReLU()
    (2): BatchNorm2d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
  )
  (fc_feature): Sequential(
    (0): Linear(in_features=288, out_features=128, bias=True)
    (1): ReLU()
    (2): Linear(in_features=128, out_features=128, bias=True)
    (3): ReLU()
    (4): Linear(in_features=128, out_features=5, bias=True)
  )
)
WARNING: GIF is enabled but the environment does not support RGB array rendering.
INFO: Learning...
INFO: BootcampName.HIDER Bootcamp completed, starting BootcampName.SEEKER Bootcamp #0 for 0 days
INFO: BootcampName.SEEKER Bootcamp completed, starting BootcampName.SLOW_AGENT Bootcamp #0 for 0 days
INFO: Continuing with Bootcamp #0 BootcampName.SLOW_AGENT with slow factor: 9 for agent 1
INFO: Continuing with Bootcamp #0 BootcampName.SLOW_AGENT with slow factor: 9 for agent 0
INFO: Continuing with Bootcamp #0 BootcampName.SLOW_AGENT with slow factor: 8 for agent 1
INFO: Continuing with Bootcamp #0 BootcampName.SLOW_AGENT with slow factor: 8 for agent 0
INFO: Continuing with Bootcamp #0 BootcampName.SLOW_AGENT with slow factor: 7 for agent 1
INFO: Continuing with Bootcamp #0 BootcampName.SLOW_AGENT with slow factor: 7 for agent 0
INFO: Continuing with Bootcamp #0 BootcampName.SLOW_AGENT with slow factor: 6 for agent 1
INFO: Continuing with Bootcamp #0 BootcampName.SLOW_AGENT with slow factor: 6 for agent 0
INFO: Continuing with Bootcamp #0 BootcampName.SLOW_AGENT with slow factor: 5 for agent 1
INFO: Continuing with Bootcamp #0 BootcampName.SLOW_AGENT with slow factor: 5 for agent 0
INFO: Continuing with Bootcamp #0 BootcampName.SLOW_AGENT with slow factor: 4 for agent 1
INFO: Continuing with Bootcamp #0 BootcampName.SLOW_AGENT with slow factor: 4 for agent 0
INFO: Continuing with Bootcamp #0 BootcampName.SLOW_AGENT with slow factor: 3 for agent 1
INFO: Continuing with Bootcamp #0 BootcampName.SLOW_AGENT with slow factor: 3 for agent 0
INFO: Continuing with Bootcamp #0 BootcampName.SLOW_AGENT with slow factor: 2 for agent 1
INFO: Continuing with Bootcamp #0 BootcampName.SLOW_AGENT with slow factor: 2 for agent 0
INFO: BootcampName.SLOW_AGENT Bootcamp completed, starting BootcampName.COMBINED Bootcamp #0 for 0 days
INFO: BootcampName.COMBINED Bootcamp completed, starting BootcampName.FINISHED Bootcamp #0 for 0 days
WARNING: No frames in gif to save.
WARNING: No frames in gif to save.
WARNING: No frames in gif to save.
WARNING: No frames in gif to save.
WARNING: No frames in gif to save.
WARNING: No frames in gif to save.
INFO: Number of parameters: 54533
INFO: QNetwork(
  (conv_feature): Sequential(
    (0): Conv2d(1, 32, kernel_size=(3, 3), stride=(1, 1))
    (1): ReLU()
    (2): BatchNorm2d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
  )
  (fc_feature): Sequential(
    (0): Linear(in_features=288, out_features=128, bias=True)
    (1): ReLU()
    (2): Linear(in_features=128, out_features=128, bias=True)
    (3): ReLU()
    (4): Linear(in_features=128, out_features=5, bias=True)
  )
)
WARNING: GIF is enabled but the environment does not support RGB array rendering.
INFO: Learning...
INFO: BootcampName.HIDER Bootcamp completed, starting BootcampName.SEEKER Bootcamp #0 for 0 days
INFO: BootcampName.SEEKER Bootcamp completed, starting BootcampName.SLOW_AGENT Bootcamp #0 for 0 days
INFO: Continuing with Bootcamp #0 BootcampName.SLOW_AGENT with slow factor: 9 for agent 1
INFO: Continuing with Bootcamp #0 BootcampName.SLOW_AGENT with slow factor: 9 for agent 0
INFO: Continuing with Bootcamp #0 BootcampName.SLOW_AGENT with slow factor: 8 for agent 1
INFO: Continuing with Bootcamp #0 BootcampName.SLOW_AGENT with slow factor: 8 for agent 0
INFO: Continuing with Bootcamp #0 BootcampName.SLOW_AGENT with slow factor: 7 for agent 1
INFO: Continuing with Bootcamp #0 BootcampName.SLOW_AGENT with slow factor: 7 for agent 0
INFO: Continuing with Bootcamp #0 BootcampName.SLOW_AGENT with slow factor: 6 for agent 1
INFO: Continuing with Bootcamp #0 BootcampName.SLOW_AGENT with slow factor: 6 for agent 0
INFO: Continuing with Bootcamp #0 BootcampName.SLOW_AGENT with slow factor: 5 for agent 1
INFO: Continuing with Bootcamp #0 BootcampName.SLOW_AGENT with slow factor: 5 for agent 0
INFO: Continuing with Bootcamp #0 BootcampName.SLOW_AGENT with slow factor: 4 for agent 1
INFO: Continuing with Bootcamp #0 BootcampName.SLOW_AGENT with slow factor: 4 for agent 0
INFO: Continuing with Bootcamp #0 BootcampName.SLOW_AGENT with slow factor: 3 for agent 1
INFO: Continuing with Bootcamp #0 BootcampName.SLOW_AGENT with slow factor: 3 for agent 0
INFO: Continuing with Bootcamp #0 BootcampName.SLOW_AGENT with slow factor: 2 for agent 1
INFO: Continuing with Bootcamp #0 BootcampName.SLOW_AGENT with slow factor: 2 for agent 0
INFO: BootcampName.SLOW_AGENT Bootcamp completed, starting BootcampName.COMBINED Bootcamp #0 for 0 days
INFO: BootcampName.COMBINED Bootcamp completed, starting BootcampName.FINISHED Bootcamp #0 for 0 days
INFO: Number of parameters: 54533
INFO: QNetwork(
  (conv_feature): Sequential(
    (0): Conv2d(1, 32, kernel_size=(3, 3), stride=(1, 1))
    (1): ReLU()
    (2): BatchNorm2d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
  )
  (fc_feature): Sequential(
    (0): Linear(in_features=288, out_features=128, bias=True)
    (1): ReLU()
    (2): Linear(in_features=128, out_features=128, bias=True)
    (3): ReLU()
    (4): Linear(in_features=128, out_features=5, bias=True)
  )
)
WARNING: GIF is enabled but the environment does not support RGB array rendering.
INFO: Learning...
INFO: BootcampName.HIDER Bootcamp completed, starting BootcampName.SEEKER Bootcamp #0 for 0 days
INFO: BootcampName.SEEKER Bootcamp completed, starting BootcampName.SLOW_AGENT Bootcamp #0 for 0 days
INFO: Continuing with Bootcamp #0 BootcampName.SLOW_AGENT with slow factor: 9 for agent 1
INFO: Continuing with Bootcamp #0 BootcampName.SLOW_AGENT with slow factor: 9 for agent 0
INFO: Continuing with Bootcamp #0 BootcampName.SLOW_AGENT with slow factor: 8 for agent 1
INFO: Continuing with Bootcamp #0 BootcampName.SLOW_AGENT with slow factor: 8 for agent 0
INFO: Continuing with Bootcamp #0 BootcampName.SLOW_AGENT with slow factor: 7 for agent 1
INFO: Continuing with Bootcamp #0 BootcampName.SLOW_AGENT with slow factor: 7 for agent 0
INFO: Continuing with Bootcamp #0 BootcampName.SLOW_AGENT with slow factor: 6 for agent 1
INFO: Continuing with Bootcamp #0 BootcampName.SLOW_AGENT with slow factor: 6 for agent 0
INFO: Continuing with Bootcamp #0 BootcampName.SLOW_AGENT with slow factor: 5 for agent 1
INFO: Continuing with Bootcamp #0 BootcampName.SLOW_AGENT with slow factor: 5 for agent 0
INFO: Continuing with Bootcamp #0 BootcampName.SLOW_AGENT with slow factor: 4 for agent 1
INFO: Continuing with Bootcamp #0 BootcampName.SLOW_AGENT with slow factor: 4 for agent 0
INFO: Continuing with Bootcamp #0 BootcampName.SLOW_AGENT with slow factor: 3 for agent 1
INFO: Continuing with Bootcamp #0 BootcampName.SLOW_AGENT with slow factor: 3 for agent 0
INFO: Continuing with Bootcamp #0 BootcampName.SLOW_AGENT with slow factor: 2 for agent 1
INFO: Continuing with Bootcamp #0 BootcampName.SLOW_AGENT with slow factor: 2 for agent 0
INFO: BootcampName.SLOW_AGENT Bootcamp completed, starting BootcampName.COMBINED Bootcamp #0 for 0 days
INFO: BootcampName.COMBINED Bootcamp completed, starting BootcampName.FINISHED Bootcamp #0 for 0 days
INFO: Number of parameters: 54533
INFO: QNetwork(
  (conv_feature): Sequential(
    (0): Conv2d(1, 32, kernel_size=(3, 3), stride=(1, 1))
    (1): ReLU()
    (2): BatchNorm2d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
  )
  (fc_feature): Sequential(
    (0): Linear(in_features=288, out_features=128, bias=True)
    (1): ReLU()
    (2): Linear(in_features=128, out_features=128, bias=True)
    (3): ReLU()
    (4): Linear(in_features=128, out_features=5, bias=True)
  )
)
WARNING: GIF is enabled but the environment does not support RGB array rendering.
INFO: Learning...
INFO: BootcampName.HIDER Bootcamp completed, starting BootcampName.SEEKER Bootcamp #0 for 0 days
INFO: BootcampName.SEEKER Bootcamp completed, starting BootcampName.SLOW_AGENT Bootcamp #0 for 0 days
INFO: Continuing with Bootcamp #0 BootcampName.SLOW_AGENT with slow factor: 9 for agent 1
INFO: Continuing with Bootcamp #0 BootcampName.SLOW_AGENT with slow factor: 9 for agent 0
INFO: Continuing with Bootcamp #0 BootcampName.SLOW_AGENT with slow factor: 8 for agent 1
INFO: Continuing with Bootcamp #0 BootcampName.SLOW_AGENT with slow factor: 8 for agent 0
INFO: Continuing with Bootcamp #0 BootcampName.SLOW_AGENT with slow factor: 7 for agent 1
INFO: Continuing with Bootcamp #0 BootcampName.SLOW_AGENT with slow factor: 7 for agent 0
INFO: Continuing with Bootcamp #0 BootcampName.SLOW_AGENT with slow factor: 6 for agent 1
INFO: Continuing with Bootcamp #0 BootcampName.SLOW_AGENT with slow factor: 6 for agent 0
INFO: Continuing with Bootcamp #0 BootcampName.SLOW_AGENT with slow factor: 5 for agent 1
INFO: Continuing with Bootcamp #0 BootcampName.SLOW_AGENT with slow factor: 5 for agent 0
INFO: Continuing with Bootcamp #0 BootcampName.SLOW_AGENT with slow factor: 4 for agent 1
INFO: Continuing with Bootcamp #0 BootcampName.SLOW_AGENT with slow factor: 4 for agent 0
INFO: Continuing with Bootcamp #0 BootcampName.SLOW_AGENT with slow factor: 3 for agent 1
INFO: Continuing with Bootcamp #0 BootcampName.SLOW_AGENT with slow factor: 3 for agent 0
INFO: Continuing with Bootcamp #0 BootcampName.SLOW_AGENT with slow factor: 2 for agent 1
INFO: Continuing with Bootcamp #0 BootcampName.SLOW_AGENT with slow factor: 2 for agent 0
INFO: BootcampName.SLOW_AGENT Bootcamp completed, starting BootcampName.COMBINED Bootcamp #0 for 0 days
INFO: BootcampName.COMBINED Bootcamp completed, starting BootcampName.FINISHED Bootcamp #0 for 0 days
INFO: Number of parameters: 54533
INFO: QNetwork(
  (conv_feature): Sequential(
    (0): Conv2d(1, 32, kernel_size=(3, 3), stride=(1, 1))
    (1): ReLU()
    (2): BatchNorm2d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
  )
  (fc_feature): Sequential(
    (0): Linear(in_features=288, out_features=128, bias=True)
    (1): ReLU()
    (2): Linear(in_features=128, out_features=128, bias=True)
    (3): ReLU()
    (4): Linear(in_features=128, out_features=5, bias=True)
  )
)
WARNING: GIF is enabled but the environment does not support RGB array rendering.
INFO: Learning...
INFO: BootcampName.HIDER Bootcamp completed, starting BootcampName.SEEKER Bootcamp #0 for 0 days
INFO: BootcampName.SEEKER Bootcamp completed, starting BootcampName.SLOW_AGENT Bootcamp #0 for 0 days
INFO: Continuing with Bootcamp #0 BootcampName.SLOW_AGENT with slow factor: 9 for agent 1
INFO: Continuing with Bootcamp #0 BootcampName.SLOW_AGENT with slow factor: 9 for agent 0
INFO: Continuing with Bootcamp #0 BootcampName.SLOW_AGENT with slow factor: 8 for agent 1
INFO: Continuing with Bootcamp #0 BootcampName.SLOW_AGENT with slow factor: 8 for agent 0
INFO: Continuing with Bootcamp #0 BootcampName.SLOW_AGENT with slow factor: 7 for agent 1
INFO: Continuing with Bootcamp #0 BootcampName.SLOW_AGENT with slow factor: 7 for agent 0
INFO: Continuing with Bootcamp #0 BootcampName.SLOW_AGENT with slow factor: 6 for agent 1
INFO: Continuing with Bootcamp #0 BootcampName.SLOW_AGENT with slow factor: 6 for agent 0
INFO: Continuing with Bootcamp #0 BootcampName.SLOW_AGENT with slow factor: 5 for agent 1
INFO: Continuing with Bootcamp #0 BootcampName.SLOW_AGENT with slow factor: 5 for agent 0
INFO: Continuing with Bootcamp #0 BootcampName.SLOW_AGENT with slow factor: 4 for agent 1
INFO: Continuing with Bootcamp #0 BootcampName.SLOW_AGENT with slow factor: 4 for agent 0
INFO: Continuing with Bootcamp #0 BootcampName.SLOW_AGENT with slow factor: 3 for agent 1
INFO: Continuing with Bootcamp #0 BootcampName.SLOW_AGENT with slow factor: 3 for agent 0
INFO: Continuing with Bootcamp #0 BootcampName.SLOW_AGENT with slow factor: 2 for agent 1
INFO: Continuing with Bootcamp #0 BootcampName.SLOW_AGENT with slow factor: 2 for agent 0
INFO: BootcampName.SLOW_AGENT Bootcamp completed, starting BootcampName.COMBINED Bootcamp #0 for 0 days
INFO: BootcampName.COMBINED Bootcamp completed, starting BootcampName.FINISHED Bootcamp #0 for 0 days
INFO: Number of parameters: 54533
INFO: QNetwork(
  (conv_feature): Sequential(
    (0): Conv2d(1, 32, kernel_size=(3, 3), stride=(1, 1))
    (1): ReLU()
    (2): BatchNorm2d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
  )
  (fc_feature): Sequential(
    (0): Linear(in_features=288, out_features=128, bias=True)
    (1): ReLU()
    (2): Linear(in_features=128, out_features=128, bias=True)
    (3): ReLU()
    (4): Linear(in_features=128, out_features=5, bias=True)
  )
)
WARNING: GIF is enabled but the environment does not support RGB array rendering.
INFO: Learning...
INFO: BootcampName.HIDER Bootcamp completed, starting BootcampName.SEEKER Bootcamp #0 for 0 days
INFO: BootcampName.SEEKER Bootcamp completed, starting BootcampName.SLOW_AGENT Bootcamp #0 for 0 days
INFO: Continuing with Bootcamp #0 BootcampName.SLOW_AGENT with slow factor: 9 for agent 1
INFO: Continuing with Bootcamp #0 BootcampName.SLOW_AGENT with slow factor: 9 for agent 0
INFO: Continuing with Bootcamp #0 BootcampName.SLOW_AGENT with slow factor: 8 for agent 1
INFO: Continuing with Bootcamp #0 BootcampName.SLOW_AGENT with slow factor: 8 for agent 0
INFO: Continuing with Bootcamp #0 BootcampName.SLOW_AGENT with slow factor: 7 for agent 1
INFO: Continuing with Bootcamp #0 BootcampName.SLOW_AGENT with slow factor: 7 for agent 0
INFO: Continuing with Bootcamp #0 BootcampName.SLOW_AGENT with slow factor: 6 for agent 1
INFO: Continuing with Bootcamp #0 BootcampName.SLOW_AGENT with slow factor: 6 for agent 0
INFO: Continuing with Bootcamp #0 BootcampName.SLOW_AGENT with slow factor: 5 for agent 1
INFO: Continuing with Bootcamp #0 BootcampName.SLOW_AGENT with slow factor: 5 for agent 0
INFO: Continuing with Bootcamp #0 BootcampName.SLOW_AGENT with slow factor: 4 for agent 1
INFO: Continuing with Bootcamp #0 BootcampName.SLOW_AGENT with slow factor: 4 for agent 0
INFO: Continuing with Bootcamp #0 BootcampName.SLOW_AGENT with slow factor: 3 for agent 1
INFO: Continuing with Bootcamp #0 BootcampName.SLOW_AGENT with slow factor: 3 for agent 0
INFO: Continuing with Bootcamp #0 BootcampName.SLOW_AGENT with slow factor: 2 for agent 1
INFO: Continuing with Bootcamp #0 BootcampName.SLOW_AGENT with slow factor: 2 for agent 0
INFO: BootcampName.SLOW_AGENT Bootcamp completed, starting BootcampName.COMBINED Bootcamp #0 for 0 days
INFO: BootcampName.COMBINED Bootcamp completed, starting BootcampName.FINISHED Bootcamp #0 for 0 days
INFO: Number of parameters: 54533
INFO: QNetwork(
  (conv_feature): Sequential(
    (0): Conv2d(1, 32, kernel_size=(3, 3), stride=(1, 1))
    (1): ReLU()
    (2): BatchNorm2d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
  )
  (fc_feature): Sequential(
    (0): Linear(in_features=288, out_features=128, bias=True)
    (1): ReLU()
    (2): Linear(in_features=128, out_features=128, bias=True)
    (3): ReLU()
    (4): Linear(in_features=128, out_features=5, bias=True)
  )
)
WARNING: GIF is enabled but the environment does not support RGB array rendering.
INFO: Learning...
INFO: BootcampName.HIDER Bootcamp completed, starting BootcampName.SEEKER Bootcamp #0 for 0 days
INFO: BootcampName.SEEKER Bootcamp completed, starting BootcampName.SLOW_AGENT Bootcamp #0 for 0 days
INFO: Continuing with Bootcamp #0 BootcampName.SLOW_AGENT with slow factor: 9 for agent 1
INFO: Continuing with Bootcamp #0 BootcampName.SLOW_AGENT with slow factor: 9 for agent 0
INFO: Continuing with Bootcamp #0 BootcampName.SLOW_AGENT with slow factor: 8 for agent 1
INFO: Continuing with Bootcamp #0 BootcampName.SLOW_AGENT with slow factor: 8 for agent 0
INFO: Continuing with Bootcamp #0 BootcampName.SLOW_AGENT with slow factor: 7 for agent 1
INFO: Continuing with Bootcamp #0 BootcampName.SLOW_AGENT with slow factor: 7 for agent 0
INFO: Continuing with Bootcamp #0 BootcampName.SLOW_AGENT with slow factor: 6 for agent 1
INFO: Continuing with Bootcamp #0 BootcampName.SLOW_AGENT with slow factor: 6 for agent 0
INFO: Continuing with Bootcamp #0 BootcampName.SLOW_AGENT with slow factor: 5 for agent 1
INFO: Continuing with Bootcamp #0 BootcampName.SLOW_AGENT with slow factor: 5 for agent 0
INFO: Continuing with Bootcamp #0 BootcampName.SLOW_AGENT with slow factor: 4 for agent 1
INFO: Continuing with Bootcamp #0 BootcampName.SLOW_AGENT with slow factor: 4 for agent 0
INFO: Continuing with Bootcamp #0 BootcampName.SLOW_AGENT with slow factor: 3 for agent 1
INFO: Continuing with Bootcamp #0 BootcampName.SLOW_AGENT with slow factor: 3 for agent 0
INFO: Continuing with Bootcamp #0 BootcampName.SLOW_AGENT with slow factor: 2 for agent 1
INFO: Continuing with Bootcamp #0 BootcampName.SLOW_AGENT with slow factor: 2 for agent 0
INFO: BootcampName.SLOW_AGENT Bootcamp completed, starting BootcampName.COMBINED Bootcamp #0 for 0 days
INFO: BootcampName.COMBINED Bootcamp completed, starting BootcampName.FINISHED Bootcamp #0 for 0 days
INFO: Number of parameters: 54533
INFO: QNetwork(
  (conv_feature): Sequential(
    (0): Conv2d(1, 32, kernel_size=(3, 3), stride=(1, 1))
    (1): ReLU()
    (2): BatchNorm2d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
  )
  (fc_feature): Sequential(
    (0): Linear(in_features=288, out_features=128, bias=True)
    (1): ReLU()
    (2): Linear(in_features=128, out_features=128, bias=True)
    (3): ReLU()
    (4): Linear(in_features=128, out_features=5, bias=True)
  )
)
WARNING: GIF is enabled but the environment does not support RGB array rendering.
INFO: Learning...
INFO: BootcampName.HIDER Bootcamp completed, starting BootcampName.SEEKER Bootcamp #0 for 0 days
INFO: BootcampName.SEEKER Bootcamp completed, starting BootcampName.SLOW_AGENT Bootcamp #0 for 0 days
INFO: Continuing with Bootcamp #0 BootcampName.SLOW_AGENT with slow factor: 9 for agent 1
INFO: Continuing with Bootcamp #0 BootcampName.SLOW_AGENT with slow factor: 9 for agent 0
INFO: Continuing with Bootcamp #0 BootcampName.SLOW_AGENT with slow factor: 8 for agent 1
INFO: Continuing with Bootcamp #0 BootcampName.SLOW_AGENT with slow factor: 8 for agent 0
INFO: Continuing with Bootcamp #0 BootcampName.SLOW_AGENT with slow factor: 7 for agent 1
INFO: Continuing with Bootcamp #0 BootcampName.SLOW_AGENT with slow factor: 7 for agent 0
INFO: Continuing with Bootcamp #0 BootcampName.SLOW_AGENT with slow factor: 6 for agent 1
INFO: Continuing with Bootcamp #0 BootcampName.SLOW_AGENT with slow factor: 6 for agent 0
INFO: Continuing with Bootcamp #0 BootcampName.SLOW_AGENT with slow factor: 5 for agent 1
INFO: Continuing with Bootcamp #0 BootcampName.SLOW_AGENT with slow factor: 5 for agent 0
INFO: Continuing with Bootcamp #0 BootcampName.SLOW_AGENT with slow factor: 4 for agent 1
INFO: Continuing with Bootcamp #0 BootcampName.SLOW_AGENT with slow factor: 4 for agent 0
INFO: Continuing with Bootcamp #0 BootcampName.SLOW_AGENT with slow factor: 3 for agent 1
INFO: Continuing with Bootcamp #0 BootcampName.SLOW_AGENT with slow factor: 3 for agent 0
INFO: Continuing with Bootcamp #0 BootcampName.SLOW_AGENT with slow factor: 2 for agent 1
INFO: Continuing with Bootcamp #0 BootcampName.SLOW_AGENT with slow factor: 2 for agent 0
INFO: BootcampName.SLOW_AGENT Bootcamp completed, starting BootcampName.COMBINED Bootcamp #0 for 0 days
INFO: BootcampName.COMBINED Bootcamp completed, starting BootcampName.FINISHED Bootcamp #0 for 0 days
WARNING: No frames in gif to save.
WARNING: No frames in gif to save.
WARNING: No frames in gif to save.
WARNING: No frames in gif to save.
WARNING: No frames in gif to save.
WARNING: No frames in gif to save.
WARNING: No frames in gif to save.
WARNING: No frames in gif to save.
WARNING: No frames in gif to save.
WARNING: No frames in gif to save.
WARNING: No frames in gif to save.
WARNING: No frames in gif to save.
WARNING: No frames in gif to save.
WARNING: No frames in gif to save.
WARNING: No frames in gif to save.
WARNING: No frames in gif to save.
INFO: Number of parameters: 54533
INFO: QNetwork(
  (conv_feature): Sequential(
    (0): Conv2d(1, 32, kernel_size=(3, 3), stride=(1, 1))
    (1): ReLU()
    (2): BatchNorm2d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
  )
  (fc_feature): Sequential(
    (0): Linear(in_features=288, out_features=128, bias=True)
    (1): ReLU()
    (2): Linear(in_features=128, out_features=128, bias=True)
    (3): ReLU()
    (4): Linear(in_features=128, out_features=5, bias=True)
  )
)
WARNING: GIF is enabled but the environment does not support RGB array rendering.
INFO: Learning...
INFO: BootcampName.HIDER Bootcamp completed, starting BootcampName.SEEKER Bootcamp #0 for 0 days
INFO: BootcampName.SEEKER Bootcamp completed, starting BootcampName.SLOW_AGENT Bootcamp #0 for 0 days
INFO: Continuing with Bootcamp #0 BootcampName.SLOW_AGENT with slow factor: 9 for agent 1
INFO: Continuing with Bootcamp #0 BootcampName.SLOW_AGENT with slow factor: 9 for agent 0
INFO: Continuing with Bootcamp #0 BootcampName.SLOW_AGENT with slow factor: 8 for agent 1
INFO: Continuing with Bootcamp #0 BootcampName.SLOW_AGENT with slow factor: 8 for agent 0
INFO: Continuing with Bootcamp #0 BootcampName.SLOW_AGENT with slow factor: 7 for agent 1
INFO: Continuing with Bootcamp #0 BootcampName.SLOW_AGENT with slow factor: 7 for agent 0
INFO: Continuing with Bootcamp #0 BootcampName.SLOW_AGENT with slow factor: 6 for agent 1
INFO: Continuing with Bootcamp #0 BootcampName.SLOW_AGENT with slow factor: 6 for agent 0
INFO: Continuing with Bootcamp #0 BootcampName.SLOW_AGENT with slow factor: 5 for agent 1
INFO: Continuing with Bootcamp #0 BootcampName.SLOW_AGENT with slow factor: 5 for agent 0
INFO: Continuing with Bootcamp #0 BootcampName.SLOW_AGENT with slow factor: 4 for agent 1
INFO: Continuing with Bootcamp #0 BootcampName.SLOW_AGENT with slow factor: 4 for agent 0
INFO: Continuing with Bootcamp #0 BootcampName.SLOW_AGENT with slow factor: 3 for agent 1
INFO: Continuing with Bootcamp #0 BootcampName.SLOW_AGENT with slow factor: 3 for agent 0
INFO: Continuing with Bootcamp #0 BootcampName.SLOW_AGENT with slow factor: 2 for agent 1
INFO: Continuing with Bootcamp #0 BootcampName.SLOW_AGENT with slow factor: 2 for agent 0
INFO: BootcampName.SLOW_AGENT Bootcamp completed, starting BootcampName.COMBINED Bootcamp #0 for 0 days
INFO: BootcampName.COMBINED Bootcamp completed, starting BootcampName.FINISHED Bootcamp #0 for 0 days
WARNING: No frames in gif to save.
WARNING: No frames in gif to save.
WARNING: No frames in gif to save.
WARNING: No frames in gif to save.
WARNING: No frames in gif to save.
WARNING: No frames in gif to save.
INFO: Number of parameters: 54533
INFO: QNetwork(
  (conv_feature): Sequential(
    (0): Conv2d(1, 32, kernel_size=(3, 3), stride=(1, 1))
    (1): ReLU()
    (2): BatchNorm2d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
  )
  (fc_feature): Sequential(
    (0): Linear(in_features=288, out_features=128, bias=True)
    (1): ReLU()
    (2): Linear(in_features=128, out_features=128, bias=True)
    (3): ReLU()
    (4): Linear(in_features=128, out_features=5, bias=True)
  )
)
WARNING: GIF is enabled but the environment does not support RGB array rendering.
INFO: Learning...
INFO: BootcampName.HIDER Bootcamp completed, starting BootcampName.SEEKER Bootcamp #0 for 0 days
INFO: BootcampName.SEEKER Bootcamp completed, starting BootcampName.SLOW_AGENT Bootcamp #0 for 0 days
INFO: Continuing with Bootcamp #0 BootcampName.SLOW_AGENT with slow factor: 9 for agent 1
INFO: Continuing with Bootcamp #0 BootcampName.SLOW_AGENT with slow factor: 9 for agent 0
INFO: Continuing with Bootcamp #0 BootcampName.SLOW_AGENT with slow factor: 8 for agent 1
INFO: Continuing with Bootcamp #0 BootcampName.SLOW_AGENT with slow factor: 8 for agent 0
INFO: Continuing with Bootcamp #0 BootcampName.SLOW_AGENT with slow factor: 7 for agent 1
INFO: Continuing with Bootcamp #0 BootcampName.SLOW_AGENT with slow factor: 7 for agent 0
INFO: Continuing with Bootcamp #0 BootcampName.SLOW_AGENT with slow factor: 6 for agent 1
INFO: Continuing with Bootcamp #0 BootcampName.SLOW_AGENT with slow factor: 6 for agent 0
INFO: Continuing with Bootcamp #0 BootcampName.SLOW_AGENT with slow factor: 5 for agent 1
INFO: Continuing with Bootcamp #0 BootcampName.SLOW_AGENT with slow factor: 5 for agent 0
INFO: Continuing with Bootcamp #0 BootcampName.SLOW_AGENT with slow factor: 4 for agent 1
INFO: Continuing with Bootcamp #0 BootcampName.SLOW_AGENT with slow factor: 4 for agent 0
INFO: Continuing with Bootcamp #0 BootcampName.SLOW_AGENT with slow factor: 3 for agent 1
INFO: Continuing with Bootcamp #0 BootcampName.SLOW_AGENT with slow factor: 3 for agent 0
INFO: Continuing with Bootcamp #0 BootcampName.SLOW_AGENT with slow factor: 2 for agent 1
INFO: Continuing with Bootcamp #0 BootcampName.SLOW_AGENT with slow factor: 2 for agent 0
INFO: BootcampName.SLOW_AGENT Bootcamp completed, starting BootcampName.COMBINED Bootcamp #0 for 0 days
INFO: BootcampName.COMBINED Bootcamp completed, starting BootcampName.FINISHED Bootcamp #0 for 0 days
WARNING: No frames in gif to save.
WARNING: No frames in gif to save.
WARNING: No frames in gif to save.
WARNING: No frames in gif to save.
WARNING: No frames in gif to save.
WARNING: No frames in gif to save.
INFO: Number of parameters: 54533
INFO: QNetwork(
  (conv_feature): Sequential(
    (0): Conv2d(1, 32, kernel_size=(3, 3), stride=(1, 1))
    (1): ReLU()
    (2): BatchNorm2d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
  )
  (fc_feature): Sequential(
    (0): Linear(in_features=288, out_features=128, bias=True)
    (1): ReLU()
    (2): Linear(in_features=128, out_features=128, bias=True)
    (3): ReLU()
    (4): Linear(in_features=128, out_features=5, bias=True)
  )
)
INFO: Learning...
INFO: BootcampName.HIDER Bootcamp completed, starting BootcampName.SEEKER Bootcamp #0 for 0 days
INFO: BootcampName.SEEKER Bootcamp completed, starting BootcampName.SLOW_AGENT Bootcamp #0 for 0 days
INFO: Continuing with Bootcamp #0 BootcampName.SLOW_AGENT with slow factor: 9 for agent 1
INFO: Continuing with Bootcamp #0 BootcampName.SLOW_AGENT with slow factor: 9 for agent 0
INFO: Continuing with Bootcamp #0 BootcampName.SLOW_AGENT with slow factor: 8 for agent 1
INFO: Continuing with Bootcamp #0 BootcampName.SLOW_AGENT with slow factor: 8 for agent 0
INFO: Continuing with Bootcamp #0 BootcampName.SLOW_AGENT with slow factor: 7 for agent 1
INFO: Continuing with Bootcamp #0 BootcampName.SLOW_AGENT with slow factor: 7 for agent 0
INFO: Continuing with Bootcamp #0 BootcampName.SLOW_AGENT with slow factor: 6 for agent 1
INFO: Continuing with Bootcamp #0 BootcampName.SLOW_AGENT with slow factor: 6 for agent 0
INFO: Continuing with Bootcamp #0 BootcampName.SLOW_AGENT with slow factor: 5 for agent 1
INFO: Continuing with Bootcamp #0 BootcampName.SLOW_AGENT with slow factor: 5 for agent 0
INFO: Continuing with Bootcamp #0 BootcampName.SLOW_AGENT with slow factor: 4 for agent 1
INFO: Continuing with Bootcamp #0 BootcampName.SLOW_AGENT with slow factor: 4 for agent 0
INFO: Continuing with Bootcamp #0 BootcampName.SLOW_AGENT with slow factor: 3 for agent 1
INFO: Continuing with Bootcamp #0 BootcampName.SLOW_AGENT with slow factor: 3 for agent 0
INFO: Continuing with Bootcamp #0 BootcampName.SLOW_AGENT with slow factor: 2 for agent 1
INFO: Continuing with Bootcamp #0 BootcampName.SLOW_AGENT with slow factor: 2 for agent 0
INFO: BootcampName.SLOW_AGENT Bootcamp completed, starting BootcampName.COMBINED Bootcamp #0 for 0 days
INFO: BootcampName.COMBINED Bootcamp completed, starting BootcampName.FINISHED Bootcamp #0 for 0 days
INFO: Number of parameters: 54533
INFO: QNetwork(
  (conv_feature): Sequential(
    (0): Conv2d(1, 32, kernel_size=(3, 3), stride=(1, 1))
    (1): ReLU()
    (2): BatchNorm2d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
  )
  (fc_feature): Sequential(
    (0): Linear(in_features=288, out_features=128, bias=True)
    (1): ReLU()
    (2): Linear(in_features=128, out_features=128, bias=True)
    (3): ReLU()
    (4): Linear(in_features=128, out_features=5, bias=True)
  )
)
INFO: Learning...
INFO: BootcampName.HIDER Bootcamp completed, starting BootcampName.SEEKER Bootcamp #0 for 0 days
INFO: BootcampName.SEEKER Bootcamp completed, starting BootcampName.SLOW_AGENT Bootcamp #0 for 0 days
INFO: Continuing with Bootcamp #0 BootcampName.SLOW_AGENT with slow factor: 9 for agent 1
INFO: Continuing with Bootcamp #0 BootcampName.SLOW_AGENT with slow factor: 9 for agent 0
INFO: Continuing with Bootcamp #0 BootcampName.SLOW_AGENT with slow factor: 8 for agent 1
INFO: Continuing with Bootcamp #0 BootcampName.SLOW_AGENT with slow factor: 8 for agent 0
INFO: Continuing with Bootcamp #0 BootcampName.SLOW_AGENT with slow factor: 7 for agent 1
INFO: Continuing with Bootcamp #0 BootcampName.SLOW_AGENT with slow factor: 7 for agent 0
INFO: Continuing with Bootcamp #0 BootcampName.SLOW_AGENT with slow factor: 6 for agent 1
INFO: Continuing with Bootcamp #0 BootcampName.SLOW_AGENT with slow factor: 6 for agent 0
INFO: Continuing with Bootcamp #0 BootcampName.SLOW_AGENT with slow factor: 5 for agent 1
INFO: Continuing with Bootcamp #0 BootcampName.SLOW_AGENT with slow factor: 5 for agent 0
INFO: Continuing with Bootcamp #0 BootcampName.SLOW_AGENT with slow factor: 4 for agent 1
INFO: Continuing with Bootcamp #0 BootcampName.SLOW_AGENT with slow factor: 4 for agent 0
INFO: Continuing with Bootcamp #0 BootcampName.SLOW_AGENT with slow factor: 3 for agent 1
INFO: Continuing with Bootcamp #0 BootcampName.SLOW_AGENT with slow factor: 3 for agent 0
INFO: Continuing with Bootcamp #0 BootcampName.SLOW_AGENT with slow factor: 2 for agent 1
INFO: Continuing with Bootcamp #0 BootcampName.SLOW_AGENT with slow factor: 2 for agent 0
INFO: BootcampName.SLOW_AGENT Bootcamp completed, starting BootcampName.COMBINED Bootcamp #0 for 0 days
INFO: BootcampName.COMBINED Bootcamp completed, starting BootcampName.FINISHED Bootcamp #0 for 0 days
INFO: Number of parameters: 54533
INFO: QNetwork(
  (conv_feature): Sequential(
    (0): Conv2d(1, 32, kernel_size=(3, 3), stride=(1, 1))
    (1): ReLU()
    (2): BatchNorm2d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
  )
  (fc_feature): Sequential(
    (0): Linear(in_features=288, out_features=128, bias=True)
    (1): ReLU()
    (2): Linear(in_features=128, out_features=128, bias=True)
    (3): ReLU()
    (4): Linear(in_features=128, out_features=5, bias=True)
  )
)
INFO: Learning...
INFO: BootcampName.HIDER Bootcamp completed, starting BootcampName.SEEKER Bootcamp #0 for 0 days
INFO: BootcampName.SEEKER Bootcamp completed, starting BootcampName.SLOW_AGENT Bootcamp #0 for 0 days
INFO: Continuing with Bootcamp #0 BootcampName.SLOW_AGENT with slow factor: 9 for agent 1
INFO: Continuing with Bootcamp #0 BootcampName.SLOW_AGENT with slow factor: 9 for agent 0
INFO: Continuing with Bootcamp #0 BootcampName.SLOW_AGENT with slow factor: 8 for agent 1
INFO: Continuing with Bootcamp #0 BootcampName.SLOW_AGENT with slow factor: 8 for agent 0
INFO: Continuing with Bootcamp #0 BootcampName.SLOW_AGENT with slow factor: 7 for agent 1
INFO: Continuing with Bootcamp #0 BootcampName.SLOW_AGENT with slow factor: 7 for agent 0
INFO: Continuing with Bootcamp #0 BootcampName.SLOW_AGENT with slow factor: 6 for agent 1
INFO: Continuing with Bootcamp #0 BootcampName.SLOW_AGENT with slow factor: 6 for agent 0
INFO: Continuing with Bootcamp #0 BootcampName.SLOW_AGENT with slow factor: 5 for agent 1
INFO: Continuing with Bootcamp #0 BootcampName.SLOW_AGENT with slow factor: 5 for agent 0
INFO: Continuing with Bootcamp #0 BootcampName.SLOW_AGENT with slow factor: 4 for agent 1
INFO: Continuing with Bootcamp #0 BootcampName.SLOW_AGENT with slow factor: 4 for agent 0
INFO: Continuing with Bootcamp #0 BootcampName.SLOW_AGENT with slow factor: 3 for agent 1
INFO: Continuing with Bootcamp #0 BootcampName.SLOW_AGENT with slow factor: 3 for agent 0
INFO: Continuing with Bootcamp #0 BootcampName.SLOW_AGENT with slow factor: 2 for agent 1
INFO: Continuing with Bootcamp #0 BootcampName.SLOW_AGENT with slow factor: 2 for agent 0
INFO: BootcampName.SLOW_AGENT Bootcamp completed, starting BootcampName.COMBINED Bootcamp #0 for 0 days
INFO: BootcampName.COMBINED Bootcamp completed, starting BootcampName.FINISHED Bootcamp #0 for 0 days
INFO: Number of parameters: 54533
INFO: QNetwork(
  (conv_feature): Sequential(
    (0): Conv2d(1, 32, kernel_size=(3, 3), stride=(1, 1))
    (1): ReLU()
    (2): BatchNorm2d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
  )
  (fc_feature): Sequential(
    (0): Linear(in_features=288, out_features=128, bias=True)
    (1): ReLU()
    (2): Linear(in_features=128, out_features=128, bias=True)
    (3): ReLU()
    (4): Linear(in_features=128, out_features=5, bias=True)
  )
)
WARNING: GIF is enabled but the environment does not support RGB array rendering.
INFO: Learning...
INFO: BootcampName.HIDER Bootcamp completed, starting BootcampName.SEEKER Bootcamp #0 for 0 days
INFO: BootcampName.SEEKER Bootcamp completed, starting BootcampName.SLOW_AGENT Bootcamp #0 for 0 days
INFO: Continuing with Bootcamp #0 BootcampName.SLOW_AGENT with slow factor: 9 for agent 1
INFO: Continuing with Bootcamp #0 BootcampName.SLOW_AGENT with slow factor: 9 for agent 0
INFO: Continuing with Bootcamp #0 BootcampName.SLOW_AGENT with slow factor: 8 for agent 1
INFO: Continuing with Bootcamp #0 BootcampName.SLOW_AGENT with slow factor: 8 for agent 0
INFO: Continuing with Bootcamp #0 BootcampName.SLOW_AGENT with slow factor: 7 for agent 1
INFO: Continuing with Bootcamp #0 BootcampName.SLOW_AGENT with slow factor: 7 for agent 0
INFO: Continuing with Bootcamp #0 BootcampName.SLOW_AGENT with slow factor: 6 for agent 1
INFO: Continuing with Bootcamp #0 BootcampName.SLOW_AGENT with slow factor: 6 for agent 0
INFO: Continuing with Bootcamp #0 BootcampName.SLOW_AGENT with slow factor: 5 for agent 1
INFO: Continuing with Bootcamp #0 BootcampName.SLOW_AGENT with slow factor: 5 for agent 0
INFO: Continuing with Bootcamp #0 BootcampName.SLOW_AGENT with slow factor: 4 for agent 1
INFO: Continuing with Bootcamp #0 BootcampName.SLOW_AGENT with slow factor: 4 for agent 0
INFO: Continuing with Bootcamp #0 BootcampName.SLOW_AGENT with slow factor: 3 for agent 1
INFO: Continuing with Bootcamp #0 BootcampName.SLOW_AGENT with slow factor: 3 for agent 0
INFO: Continuing with Bootcamp #0 BootcampName.SLOW_AGENT with slow factor: 2 for agent 1
INFO: Continuing with Bootcamp #0 BootcampName.SLOW_AGENT with slow factor: 2 for agent 0
INFO: BootcampName.SLOW_AGENT Bootcamp completed, starting BootcampName.COMBINED Bootcamp #0 for 0 days
INFO: BootcampName.COMBINED Bootcamp completed, starting BootcampName.FINISHED Bootcamp #0 for 0 days
INFO: Number of parameters: 54533
INFO: QNetwork(
  (conv_feature): Sequential(
    (0): Conv2d(1, 32, kernel_size=(3, 3), stride=(1, 1))
    (1): ReLU()
    (2): BatchNorm2d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
  )
  (fc_feature): Sequential(
    (0): Linear(in_features=288, out_features=128, bias=True)
    (1): ReLU()
    (2): Linear(in_features=128, out_features=128, bias=True)
    (3): ReLU()
    (4): Linear(in_features=128, out_features=5, bias=True)
  )
)
WARNING: GIF is enabled but the environment does not support RGB array rendering.
INFO: Learning...
INFO: BootcampName.HIDER Bootcamp completed, starting BootcampName.SEEKER Bootcamp #0 for 0 days
INFO: BootcampName.SEEKER Bootcamp completed, starting BootcampName.SLOW_AGENT Bootcamp #0 for 0 days
INFO: Continuing with Bootcamp #0 BootcampName.SLOW_AGENT with slow factor: 9 for agent 1
INFO: Continuing with Bootcamp #0 BootcampName.SLOW_AGENT with slow factor: 9 for agent 0
INFO: Continuing with Bootcamp #0 BootcampName.SLOW_AGENT with slow factor: 8 for agent 1
INFO: Continuing with Bootcamp #0 BootcampName.SLOW_AGENT with slow factor: 8 for agent 0
INFO: Continuing with Bootcamp #0 BootcampName.SLOW_AGENT with slow factor: 7 for agent 1
INFO: Continuing with Bootcamp #0 BootcampName.SLOW_AGENT with slow factor: 7 for agent 0
INFO: Continuing with Bootcamp #0 BootcampName.SLOW_AGENT with slow factor: 6 for agent 1
INFO: Continuing with Bootcamp #0 BootcampName.SLOW_AGENT with slow factor: 6 for agent 0
INFO: Continuing with Bootcamp #0 BootcampName.SLOW_AGENT with slow factor: 5 for agent 1
INFO: Continuing with Bootcamp #0 BootcampName.SLOW_AGENT with slow factor: 5 for agent 0
INFO: Continuing with Bootcamp #0 BootcampName.SLOW_AGENT with slow factor: 4 for agent 1
INFO: Continuing with Bootcamp #0 BootcampName.SLOW_AGENT with slow factor: 4 for agent 0
INFO: Continuing with Bootcamp #0 BootcampName.SLOW_AGENT with slow factor: 3 for agent 1
INFO: Continuing with Bootcamp #0 BootcampName.SLOW_AGENT with slow factor: 3 for agent 0
INFO: Continuing with Bootcamp #0 BootcampName.SLOW_AGENT with slow factor: 2 for agent 1
INFO: Continuing with Bootcamp #0 BootcampName.SLOW_AGENT with slow factor: 2 for agent 0
INFO: BootcampName.SLOW_AGENT Bootcamp completed, starting BootcampName.COMBINED Bootcamp #0 for 0 days
INFO: BootcampName.COMBINED Bootcamp completed, starting BootcampName.FINISHED Bootcamp #0 for 0 days
INFO: Number of parameters: 54533
INFO: QNetwork(
  (conv_feature): Sequential(
    (0): Conv2d(1, 32, kernel_size=(3, 3), stride=(1, 1))
    (1): ReLU()
    (2): BatchNorm2d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
  )
  (fc_feature): Sequential(
    (0): Linear(in_features=288, out_features=128, bias=True)
    (1): ReLU()
    (2): Linear(in_features=128, out_features=128, bias=True)
    (3): ReLU()
    (4): Linear(in_features=128, out_features=5, bias=True)
  )
)
WARNING: GIF is enabled but the environment does not support RGB array rendering.
INFO: Learning...
INFO: BootcampName.HIDER Bootcamp completed, starting BootcampName.SEEKER Bootcamp #0 for 0 days
INFO: BootcampName.SEEKER Bootcamp completed, starting BootcampName.SLOW_AGENT Bootcamp #0 for 0 days
INFO: Continuing with Bootcamp #0 BootcampName.SLOW_AGENT with slow factor: 9 for agent 1
INFO: Continuing with Bootcamp #0 BootcampName.SLOW_AGENT with slow factor: 9 for agent 0
INFO: Continuing with Bootcamp #0 BootcampName.SLOW_AGENT with slow factor: 8 for agent 1
INFO: Continuing with Bootcamp #0 BootcampName.SLOW_AGENT with slow factor: 8 for agent 0
INFO: Continuing with Bootcamp #0 BootcampName.SLOW_AGENT with slow factor: 7 for agent 1
INFO: Continuing with Bootcamp #0 BootcampName.SLOW_AGENT with slow factor: 7 for agent 0
INFO: Continuing with Bootcamp #0 BootcampName.SLOW_AGENT with slow factor: 6 for agent 1
INFO: Continuing with Bootcamp #0 BootcampName.SLOW_AGENT with slow factor: 6 for agent 0
INFO: Continuing with Bootcamp #0 BootcampName.SLOW_AGENT with slow factor: 5 for agent 1
INFO: Continuing with Bootcamp #0 BootcampName.SLOW_AGENT with slow factor: 5 for agent 0
INFO: Continuing with Bootcamp #0 BootcampName.SLOW_AGENT with slow factor: 4 for agent 1
INFO: Continuing with Bootcamp #0 BootcampName.SLOW_AGENT with slow factor: 4 for agent 0
INFO: Continuing with Bootcamp #0 BootcampName.SLOW_AGENT with slow factor: 3 for agent 1
INFO: Continuing with Bootcamp #0 BootcampName.SLOW_AGENT with slow factor: 3 for agent 0
INFO: Continuing with Bootcamp #0 BootcampName.SLOW_AGENT with slow factor: 2 for agent 1
INFO: Continuing with Bootcamp #0 BootcampName.SLOW_AGENT with slow factor: 2 for agent 0
INFO: BootcampName.SLOW_AGENT Bootcamp completed, starting BootcampName.COMBINED Bootcamp #0 for 0 days
INFO: BootcampName.COMBINED Bootcamp completed, starting BootcampName.FINISHED Bootcamp #0 for 0 days
<<<<<<< HEAD
<<<<<<< HEAD
>>>>>>> 5944ba2 (model: tag)
=======
=======
>>>>>>> main
INFO: Number of parameters: 83076
INFO: QNetwork(
  (conv_feature): Sequential(
    (0): Conv2d(1, 32, kernel_size=(3, 3), stride=(1, 1))
    (1): ReLU()
    (2): BatchNorm2d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
  )
  (fc_feature): Sequential(
    (0): Linear(in_features=512, out_features=128, bias=True)
    (1): ReLU()
    (2): Linear(in_features=128, out_features=128, bias=True)
    (3): ReLU()
    (4): Linear(in_features=128, out_features=4, bias=True)
  )
)
WARNING: GIF is enabled but the environment does not support RGB array rendering.
INFO: Learning...
INFO: BootcampName.HIDER Bootcamp completed, starting BootcampName.SEEKER Bootcamp #0 for 0 days
INFO: BootcampName.SEEKER Bootcamp completed, starting BootcampName.SLOW_AGENT Bootcamp #0 for 0 days
INFO: Continuing with Bootcamp #0 BootcampName.SLOW_AGENT with slow factor: 9 for agent 1
INFO: Continuing with Bootcamp #0 BootcampName.SLOW_AGENT with slow factor: 9 for agent 0
INFO: Continuing with Bootcamp #0 BootcampName.SLOW_AGENT with slow factor: 8 for agent 1
INFO: Continuing with Bootcamp #0 BootcampName.SLOW_AGENT with slow factor: 8 for agent 0
INFO: Continuing with Bootcamp #0 BootcampName.SLOW_AGENT with slow factor: 7 for agent 1
INFO: Continuing with Bootcamp #0 BootcampName.SLOW_AGENT with slow factor: 7 for agent 0
INFO: Continuing with Bootcamp #0 BootcampName.SLOW_AGENT with slow factor: 6 for agent 1
INFO: Continuing with Bootcamp #0 BootcampName.SLOW_AGENT with slow factor: 6 for agent 0
INFO: Continuing with Bootcamp #0 BootcampName.SLOW_AGENT with slow factor: 5 for agent 1
INFO: Continuing with Bootcamp #0 BootcampName.SLOW_AGENT with slow factor: 5 for agent 0
INFO: Continuing with Bootcamp #0 BootcampName.SLOW_AGENT with slow factor: 4 for agent 1
INFO: Continuing with Bootcamp #0 BootcampName.SLOW_AGENT with slow factor: 4 for agent 0
INFO: Continuing with Bootcamp #0 BootcampName.SLOW_AGENT with slow factor: 3 for agent 1
INFO: Continuing with Bootcamp #0 BootcampName.SLOW_AGENT with slow factor: 3 for agent 0
INFO: Continuing with Bootcamp #0 BootcampName.SLOW_AGENT with slow factor: 2 for agent 1
INFO: Continuing with Bootcamp #0 BootcampName.SLOW_AGENT with slow factor: 2 for agent 0
INFO: BootcampName.SLOW_AGENT Bootcamp completed, starting BootcampName.COMBINED Bootcamp #0 for 0 days
INFO: BootcampName.COMBINED Bootcamp completed, starting BootcampName.FINISHED Bootcamp #0 for 0 days
WARNING: No frames in gif to save.
WARNING: No frames in gif to save.
INFO: Number of parameters: 83076
INFO: QNetwork(
  (conv_feature): Sequential(
    (0): Conv2d(1, 32, kernel_size=(3, 3), stride=(1, 1))
    (1): ReLU()
    (2): BatchNorm2d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
  )
  (fc_feature): Sequential(
    (0): Linear(in_features=512, out_features=128, bias=True)
    (1): ReLU()
    (2): Linear(in_features=128, out_features=128, bias=True)
    (3): ReLU()
    (4): Linear(in_features=128, out_features=4, bias=True)
  )
)
WARNING: GIF is enabled but the environment does not support RGB array rendering.
INFO: Learning...
INFO: BootcampName.HIDER Bootcamp completed, starting BootcampName.SEEKER Bootcamp #0 for 0 days
INFO: BootcampName.SEEKER Bootcamp completed, starting BootcampName.SLOW_AGENT Bootcamp #0 for 0 days
INFO: Continuing with Bootcamp #0 BootcampName.SLOW_AGENT with slow factor: 9 for agent 1
INFO: Continuing with Bootcamp #0 BootcampName.SLOW_AGENT with slow factor: 9 for agent 0
INFO: Continuing with Bootcamp #0 BootcampName.SLOW_AGENT with slow factor: 8 for agent 1
INFO: Continuing with Bootcamp #0 BootcampName.SLOW_AGENT with slow factor: 8 for agent 0
INFO: Continuing with Bootcamp #0 BootcampName.SLOW_AGENT with slow factor: 7 for agent 1
INFO: Continuing with Bootcamp #0 BootcampName.SLOW_AGENT with slow factor: 7 for agent 0
INFO: Continuing with Bootcamp #0 BootcampName.SLOW_AGENT with slow factor: 6 for agent 1
INFO: Continuing with Bootcamp #0 BootcampName.SLOW_AGENT with slow factor: 6 for agent 0
INFO: Continuing with Bootcamp #0 BootcampName.SLOW_AGENT with slow factor: 5 for agent 1
INFO: Continuing with Bootcamp #0 BootcampName.SLOW_AGENT with slow factor: 5 for agent 0
INFO: Continuing with Bootcamp #0 BootcampName.SLOW_AGENT with slow factor: 4 for agent 1
INFO: Continuing with Bootcamp #0 BootcampName.SLOW_AGENT with slow factor: 4 for agent 0
INFO: Continuing with Bootcamp #0 BootcampName.SLOW_AGENT with slow factor: 3 for agent 1
INFO: Continuing with Bootcamp #0 BootcampName.SLOW_AGENT with slow factor: 3 for agent 0
INFO: Continuing with Bootcamp #0 BootcampName.SLOW_AGENT with slow factor: 2 for agent 1
INFO: Continuing with Bootcamp #0 BootcampName.SLOW_AGENT with slow factor: 2 for agent 0
INFO: BootcampName.SLOW_AGENT Bootcamp completed, starting BootcampName.COMBINED Bootcamp #0 for 0 days
INFO: BootcampName.COMBINED Bootcamp completed, starting BootcampName.FINISHED Bootcamp #0 for 0 days
INFO: Number of parameters: 83076
INFO: QNetwork(
  (conv_feature): Sequential(
    (0): Conv2d(1, 32, kernel_size=(3, 3), stride=(1, 1))
    (1): ReLU()
    (2): BatchNorm2d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
  )
  (fc_feature): Sequential(
    (0): Linear(in_features=512, out_features=128, bias=True)
    (1): ReLU()
    (2): Linear(in_features=128, out_features=128, bias=True)
    (3): ReLU()
    (4): Linear(in_features=128, out_features=4, bias=True)
  )
)
WARNING: GIF is enabled but the environment does not support RGB array rendering.
INFO: Learning...
INFO: BootcampName.HIDER Bootcamp completed, starting BootcampName.SEEKER Bootcamp #0 for 0 days
INFO: BootcampName.SEEKER Bootcamp completed, starting BootcampName.SLOW_AGENT Bootcamp #0 for 0 days
INFO: Continuing with Bootcamp #0 BootcampName.SLOW_AGENT with slow factor: 9 for agent 1
INFO: Continuing with Bootcamp #0 BootcampName.SLOW_AGENT with slow factor: 9 for agent 0
INFO: Continuing with Bootcamp #0 BootcampName.SLOW_AGENT with slow factor: 8 for agent 1
INFO: Continuing with Bootcamp #0 BootcampName.SLOW_AGENT with slow factor: 8 for agent 0
INFO: Continuing with Bootcamp #0 BootcampName.SLOW_AGENT with slow factor: 7 for agent 1
INFO: Continuing with Bootcamp #0 BootcampName.SLOW_AGENT with slow factor: 7 for agent 0
INFO: Continuing with Bootcamp #0 BootcampName.SLOW_AGENT with slow factor: 6 for agent 1
INFO: Continuing with Bootcamp #0 BootcampName.SLOW_AGENT with slow factor: 6 for agent 0
INFO: Continuing with Bootcamp #0 BootcampName.SLOW_AGENT with slow factor: 5 for agent 1
INFO: Continuing with Bootcamp #0 BootcampName.SLOW_AGENT with slow factor: 5 for agent 0
INFO: Continuing with Bootcamp #0 BootcampName.SLOW_AGENT with slow factor: 4 for agent 1
INFO: Continuing with Bootcamp #0 BootcampName.SLOW_AGENT with slow factor: 4 for agent 0
INFO: Continuing with Bootcamp #0 BootcampName.SLOW_AGENT with slow factor: 3 for agent 1
INFO: Continuing with Bootcamp #0 BootcampName.SLOW_AGENT with slow factor: 3 for agent 0
INFO: Continuing with Bootcamp #0 BootcampName.SLOW_AGENT with slow factor: 2 for agent 1
INFO: Continuing with Bootcamp #0 BootcampName.SLOW_AGENT with slow factor: 2 for agent 0
INFO: BootcampName.SLOW_AGENT Bootcamp completed, starting BootcampName.COMBINED Bootcamp #0 for 0 days
INFO: BootcampName.COMBINED Bootcamp completed, starting BootcampName.FINISHED Bootcamp #0 for 0 days
INFO: Number of parameters: 83076
INFO: QNetwork(
  (conv_feature): Sequential(
    (0): Conv2d(1, 32, kernel_size=(3, 3), stride=(1, 1))
    (1): ReLU()
    (2): BatchNorm2d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
  )
  (fc_feature): Sequential(
    (0): Linear(in_features=512, out_features=128, bias=True)
    (1): ReLU()
    (2): Linear(in_features=128, out_features=128, bias=True)
    (3): ReLU()
    (4): Linear(in_features=128, out_features=4, bias=True)
  )
)
WARNING: GIF is enabled but the environment does not support RGB array rendering.
INFO: Learning...
INFO: BootcampName.HIDER Bootcamp completed, starting BootcampName.SEEKER Bootcamp #0 for 0 days
INFO: BootcampName.SEEKER Bootcamp completed, starting BootcampName.SLOW_AGENT Bootcamp #0 for 0 days
INFO: Continuing with Bootcamp #0 BootcampName.SLOW_AGENT with slow factor: 9 for agent 1
INFO: Continuing with Bootcamp #0 BootcampName.SLOW_AGENT with slow factor: 9 for agent 0
INFO: Continuing with Bootcamp #0 BootcampName.SLOW_AGENT with slow factor: 8 for agent 1
INFO: Continuing with Bootcamp #0 BootcampName.SLOW_AGENT with slow factor: 8 for agent 0
INFO: Continuing with Bootcamp #0 BootcampName.SLOW_AGENT with slow factor: 7 for agent 1
INFO: Continuing with Bootcamp #0 BootcampName.SLOW_AGENT with slow factor: 7 for agent 0
INFO: Continuing with Bootcamp #0 BootcampName.SLOW_AGENT with slow factor: 6 for agent 1
INFO: Continuing with Bootcamp #0 BootcampName.SLOW_AGENT with slow factor: 6 for agent 0
INFO: Continuing with Bootcamp #0 BootcampName.SLOW_AGENT with slow factor: 5 for agent 1
INFO: Continuing with Bootcamp #0 BootcampName.SLOW_AGENT with slow factor: 5 for agent 0
INFO: Continuing with Bootcamp #0 BootcampName.SLOW_AGENT with slow factor: 4 for agent 1
INFO: Continuing with Bootcamp #0 BootcampName.SLOW_AGENT with slow factor: 4 for agent 0
INFO: Continuing with Bootcamp #0 BootcampName.SLOW_AGENT with slow factor: 3 for agent 1
INFO: Continuing with Bootcamp #0 BootcampName.SLOW_AGENT with slow factor: 3 for agent 0
INFO: Continuing with Bootcamp #0 BootcampName.SLOW_AGENT with slow factor: 2 for agent 1
INFO: Continuing with Bootcamp #0 BootcampName.SLOW_AGENT with slow factor: 2 for agent 0
INFO: BootcampName.SLOW_AGENT Bootcamp completed, starting BootcampName.COMBINED Bootcamp #0 for 0 days
INFO: BootcampName.COMBINED Bootcamp completed, starting BootcampName.FINISHED Bootcamp #0 for 0 days
INFO: Number of parameters: 83076
INFO: QNetwork(
  (conv_feature): Sequential(
    (0): Conv2d(1, 32, kernel_size=(3, 3), stride=(1, 1))
    (1): ReLU()
    (2): BatchNorm2d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
  )
  (fc_feature): Sequential(
    (0): Linear(in_features=512, out_features=128, bias=True)
    (1): ReLU()
    (2): Linear(in_features=128, out_features=128, bias=True)
    (3): ReLU()
    (4): Linear(in_features=128, out_features=4, bias=True)
  )
)
WARNING: GIF is enabled but the environment does not support RGB array rendering.
INFO: Learning...
INFO: BootcampName.HIDER Bootcamp completed, starting BootcampName.SEEKER Bootcamp #0 for 0 days
INFO: BootcampName.SEEKER Bootcamp completed, starting BootcampName.SLOW_AGENT Bootcamp #0 for 0 days
INFO: Continuing with Bootcamp #0 BootcampName.SLOW_AGENT with slow factor: 9 for agent 1
INFO: Continuing with Bootcamp #0 BootcampName.SLOW_AGENT with slow factor: 9 for agent 0
INFO: Continuing with Bootcamp #0 BootcampName.SLOW_AGENT with slow factor: 8 for agent 1
INFO: Continuing with Bootcamp #0 BootcampName.SLOW_AGENT with slow factor: 8 for agent 0
INFO: Continuing with Bootcamp #0 BootcampName.SLOW_AGENT with slow factor: 7 for agent 1
INFO: Continuing with Bootcamp #0 BootcampName.SLOW_AGENT with slow factor: 7 for agent 0
INFO: Continuing with Bootcamp #0 BootcampName.SLOW_AGENT with slow factor: 6 for agent 1
INFO: Continuing with Bootcamp #0 BootcampName.SLOW_AGENT with slow factor: 6 for agent 0
INFO: Continuing with Bootcamp #0 BootcampName.SLOW_AGENT with slow factor: 5 for agent 1
INFO: Continuing with Bootcamp #0 BootcampName.SLOW_AGENT with slow factor: 5 for agent 0
INFO: Continuing with Bootcamp #0 BootcampName.SLOW_AGENT with slow factor: 4 for agent 1
INFO: Continuing with Bootcamp #0 BootcampName.SLOW_AGENT with slow factor: 4 for agent 0
INFO: Continuing with Bootcamp #0 BootcampName.SLOW_AGENT with slow factor: 3 for agent 1
INFO: Continuing with Bootcamp #0 BootcampName.SLOW_AGENT with slow factor: 3 for agent 0
INFO: Continuing with Bootcamp #0 BootcampName.SLOW_AGENT with slow factor: 2 for agent 1
INFO: Continuing with Bootcamp #0 BootcampName.SLOW_AGENT with slow factor: 2 for agent 0
INFO: BootcampName.SLOW_AGENT Bootcamp completed, starting BootcampName.COMBINED Bootcamp #0 for 0 days
INFO: BootcampName.COMBINED Bootcamp completed, starting BootcampName.FINISHED Bootcamp #0 for 0 days
INFO: Number of parameters: 83076
INFO: QNetwork(
  (conv_feature): Sequential(
    (0): Conv2d(1, 32, kernel_size=(3, 3), stride=(1, 1))
    (1): ReLU()
    (2): BatchNorm2d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
  )
  (fc_feature): Sequential(
    (0): Linear(in_features=512, out_features=128, bias=True)
    (1): ReLU()
    (2): Linear(in_features=128, out_features=128, bias=True)
    (3): ReLU()
    (4): Linear(in_features=128, out_features=4, bias=True)
  )
)
WARNING: GIF is enabled but the environment does not support RGB array rendering.
INFO: Learning...
INFO: BootcampName.HIDER Bootcamp completed, starting BootcampName.SEEKER Bootcamp #0 for 0 days
INFO: BootcampName.SEEKER Bootcamp completed, starting BootcampName.SLOW_AGENT Bootcamp #0 for 0 days
INFO: Continuing with Bootcamp #0 BootcampName.SLOW_AGENT with slow factor: 9 for agent 1
INFO: Continuing with Bootcamp #0 BootcampName.SLOW_AGENT with slow factor: 9 for agent 0
INFO: Continuing with Bootcamp #0 BootcampName.SLOW_AGENT with slow factor: 8 for agent 1
INFO: Continuing with Bootcamp #0 BootcampName.SLOW_AGENT with slow factor: 8 for agent 0
INFO: Continuing with Bootcamp #0 BootcampName.SLOW_AGENT with slow factor: 7 for agent 1
INFO: Continuing with Bootcamp #0 BootcampName.SLOW_AGENT with slow factor: 7 for agent 0
INFO: Continuing with Bootcamp #0 BootcampName.SLOW_AGENT with slow factor: 6 for agent 1
INFO: Continuing with Bootcamp #0 BootcampName.SLOW_AGENT with slow factor: 6 for agent 0
INFO: Continuing with Bootcamp #0 BootcampName.SLOW_AGENT with slow factor: 5 for agent 1
INFO: Continuing with Bootcamp #0 BootcampName.SLOW_AGENT with slow factor: 5 for agent 0
INFO: Continuing with Bootcamp #0 BootcampName.SLOW_AGENT with slow factor: 4 for agent 1
INFO: Continuing with Bootcamp #0 BootcampName.SLOW_AGENT with slow factor: 4 for agent 0
INFO: Continuing with Bootcamp #0 BootcampName.SLOW_AGENT with slow factor: 3 for agent 1
INFO: Continuing with Bootcamp #0 BootcampName.SLOW_AGENT with slow factor: 3 for agent 0
INFO: Continuing with Bootcamp #0 BootcampName.SLOW_AGENT with slow factor: 2 for agent 1
INFO: Continuing with Bootcamp #0 BootcampName.SLOW_AGENT with slow factor: 2 for agent 0
INFO: BootcampName.SLOW_AGENT Bootcamp completed, starting BootcampName.COMBINED Bootcamp #0 for 0 days
INFO: BootcampName.COMBINED Bootcamp completed, starting BootcampName.FINISHED Bootcamp #0 for 0 days
INFO: Number of parameters: 83076
INFO: QNetwork(
  (conv_feature): Sequential(
    (0): Conv2d(1, 32, kernel_size=(3, 3), stride=(1, 1))
    (1): ReLU()
    (2): BatchNorm2d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
  )
  (fc_feature): Sequential(
    (0): Linear(in_features=512, out_features=128, bias=True)
    (1): ReLU()
    (2): Linear(in_features=128, out_features=128, bias=True)
    (3): ReLU()
    (4): Linear(in_features=128, out_features=4, bias=True)
  )
)
WARNING: GIF is enabled but the environment does not support RGB array rendering.
INFO: Learning...
INFO: BootcampName.HIDER Bootcamp completed, starting BootcampName.SEEKER Bootcamp #0 for 0 days
INFO: BootcampName.SEEKER Bootcamp completed, starting BootcampName.SLOW_AGENT Bootcamp #0 for 0 days
INFO: Continuing with Bootcamp #0 BootcampName.SLOW_AGENT with slow factor: 9 for agent 1
INFO: Continuing with Bootcamp #0 BootcampName.SLOW_AGENT with slow factor: 9 for agent 0
INFO: Continuing with Bootcamp #0 BootcampName.SLOW_AGENT with slow factor: 8 for agent 1
INFO: Continuing with Bootcamp #0 BootcampName.SLOW_AGENT with slow factor: 8 for agent 0
INFO: Continuing with Bootcamp #0 BootcampName.SLOW_AGENT with slow factor: 7 for agent 1
INFO: Continuing with Bootcamp #0 BootcampName.SLOW_AGENT with slow factor: 7 for agent 0
INFO: Continuing with Bootcamp #0 BootcampName.SLOW_AGENT with slow factor: 6 for agent 1
INFO: Continuing with Bootcamp #0 BootcampName.SLOW_AGENT with slow factor: 6 for agent 0
INFO: Continuing with Bootcamp #0 BootcampName.SLOW_AGENT with slow factor: 5 for agent 1
INFO: Continuing with Bootcamp #0 BootcampName.SLOW_AGENT with slow factor: 5 for agent 0
INFO: Continuing with Bootcamp #0 BootcampName.SLOW_AGENT with slow factor: 4 for agent 1
INFO: Continuing with Bootcamp #0 BootcampName.SLOW_AGENT with slow factor: 4 for agent 0
INFO: Continuing with Bootcamp #0 BootcampName.SLOW_AGENT with slow factor: 3 for agent 1
INFO: Continuing with Bootcamp #0 BootcampName.SLOW_AGENT with slow factor: 3 for agent 0
INFO: Continuing with Bootcamp #0 BootcampName.SLOW_AGENT with slow factor: 2 for agent 1
INFO: Continuing with Bootcamp #0 BootcampName.SLOW_AGENT with slow factor: 2 for agent 0
INFO: BootcampName.SLOW_AGENT Bootcamp completed, starting BootcampName.COMBINED Bootcamp #0 for 0 days
INFO: BootcampName.COMBINED Bootcamp completed, starting BootcampName.FINISHED Bootcamp #0 for 0 days
WARNING: No frames in gif to save.
WARNING: No frames in gif to save.
WARNING: No frames in gif to save.
WARNING: No frames in gif to save.
WARNING: No frames in gif to save.
WARNING: No frames in gif to save.
WARNING: No frames in gif to save.
WARNING: No frames in gif to save.
WARNING: No frames in gif to save.
WARNING: No frames in gif to save.
WARNING: No frames in gif to save.
WARNING: No frames in gif to save.
WARNING: No frames in gif to save.
WARNING: No frames in gif to save.
WARNING: No frames in gif to save.
WARNING: No frames in gif to save.
WARNING: No frames in gif to save.
WARNING: No frames in gif to save.
WARNING: No frames in gif to save.
WARNING: No frames in gif to save.
WARNING: No frames in gif to save.
WARNING: No frames in gif to save.
INFO: Cleaning cache: /home/eirik/.cache/wandb/artifacts/obj 0.00390625 MB
INFO: cleaning local: /home/eirik/.local/share/wandb/artifacts/staging 0.00390625 MB
WARNING: No frames in gif to save.
WARNING: No frames in gif to save.
WARNING: No frames in gif to save.
WARNING: No frames in gif to save.
WARNING: No frames in gif to save.
WARNING: No frames in gif to save.
WARNING: No frames in gif to save.
WARNING: No frames in gif to save.
WARNING: No frames in gif to save.
WARNING: No frames in gif to save.
WARNING: No frames in gif to save.
WARNING: No frames in gif to save.
WARNING: No frames in gif to save.
WARNING: No frames in gif to save.
WARNING: No frames in gif to save.
WARNING: No frames in gif to save.
WARNING: No frames in gif to save.
WARNING: No frames in gif to save.
WARNING: No frames in gif to save.
WARNING: No frames in gif to save.
INFO: Cleaning cache: /home/eirik/.cache/wandb/artifacts/obj 0.00390625 MB
INFO: cleaning local: /home/eirik/.local/share/wandb/artifacts/staging 0.00390625 MB
WARNING: No frames in gif to save.
WARNING: No frames in gif to save.
WARNING: No frames in gif to save.
WARNING: No frames in gif to save.
WARNING: No frames in gif to save.
WARNING: No frames in gif to save.
WARNING: No frames in gif to save.
WARNING: No frames in gif to save.
WARNING: No frames in gif to save.
WARNING: No frames in gif to save.
WARNING: No frames in gif to save.
WARNING: No frames in gif to save.
WARNING: No frames in gif to save.
WARNING: No frames in gif to save.
WARNING: No frames in gif to save.
WARNING: No frames in gif to save.
WARNING: No frames in gif to save.
WARNING: No frames in gif to save.
INFO: Number of parameters: 26724
INFO: QNetwork(
  (conv_feature): Sequential(
    (0): Conv2d(1, 32, kernel_size=(3, 3), stride=(1, 1))
    (1): ReLU()
    (2): BatchNorm2d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (3): Conv2d(32, 32, kernel_size=(3, 3), stride=(1, 1))
    (4): ReLU()
    (5): BatchNorm2d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
  )
  (fc_feature): Sequential(
    (0): Linear(in_features=128, out_features=128, bias=True)
    (1): ReLU()
    (2): Linear(in_features=128, out_features=4, bias=True)
  )
)
WARNING: GIF is enabled but the environment does not support RGB array rendering.
INFO: Learning...
INFO: BootcampName.HIDER Bootcamp completed, starting BootcampName.SEEKER Bootcamp #0 for 0 days
INFO: BootcampName.SEEKER Bootcamp completed, starting BootcampName.SLOW_AGENT Bootcamp #0 for 0 days
INFO: Continuing with Bootcamp #0 BootcampName.SLOW_AGENT with slow factor: 9 for agent 1
INFO: Continuing with Bootcamp #0 BootcampName.SLOW_AGENT with slow factor: 9 for agent 0
INFO: Continuing with Bootcamp #0 BootcampName.SLOW_AGENT with slow factor: 8 for agent 1
INFO: Continuing with Bootcamp #0 BootcampName.SLOW_AGENT with slow factor: 8 for agent 0
INFO: Continuing with Bootcamp #0 BootcampName.SLOW_AGENT with slow factor: 7 for agent 1
INFO: Continuing with Bootcamp #0 BootcampName.SLOW_AGENT with slow factor: 7 for agent 0
INFO: Continuing with Bootcamp #0 BootcampName.SLOW_AGENT with slow factor: 6 for agent 1
INFO: Continuing with Bootcamp #0 BootcampName.SLOW_AGENT with slow factor: 6 for agent 0
INFO: Continuing with Bootcamp #0 BootcampName.SLOW_AGENT with slow factor: 5 for agent 1
INFO: Continuing with Bootcamp #0 BootcampName.SLOW_AGENT with slow factor: 5 for agent 0
INFO: Continuing with Bootcamp #0 BootcampName.SLOW_AGENT with slow factor: 4 for agent 1
INFO: Continuing with Bootcamp #0 BootcampName.SLOW_AGENT with slow factor: 4 for agent 0
INFO: Continuing with Bootcamp #0 BootcampName.SLOW_AGENT with slow factor: 3 for agent 1
INFO: Continuing with Bootcamp #0 BootcampName.SLOW_AGENT with slow factor: 3 for agent 0
INFO: Continuing with Bootcamp #0 BootcampName.SLOW_AGENT with slow factor: 2 for agent 1
INFO: Continuing with Bootcamp #0 BootcampName.SLOW_AGENT with slow factor: 2 for agent 0
INFO: BootcampName.SLOW_AGENT Bootcamp completed, starting BootcampName.COMBINED Bootcamp #0 for 0 days
INFO: BootcampName.COMBINED Bootcamp completed, starting BootcampName.FINISHED Bootcamp #0 for 0 days
WARNING: No frames in gif to save.
WARNING: No frames in gif to save.
WARNING: No frames in gif to save.
WARNING: No frames in gif to save.
WARNING: No frames in gif to save.
WARNING: No frames in gif to save.
WARNING: No frames in gif to save.
WARNING: No frames in gif to save.
WARNING: No frames in gif to save.
WARNING: No frames in gif to save.
WARNING: No frames in gif to save.
WARNING: No frames in gif to save.
WARNING: No frames in gif to save.
WARNING: No frames in gif to save.
WARNING: No frames in gif to save.
WARNING: No frames in gif to save.
WARNING: No frames in gif to save.
WARNING: No frames in gif to save.
INFO: Number of parameters: 26724
INFO: QNetwork(
  (conv_feature): Sequential(
    (0): Conv2d(1, 32, kernel_size=(3, 3), stride=(1, 1))
    (1): ReLU()
    (2): BatchNorm2d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (3): Conv2d(32, 32, kernel_size=(3, 3), stride=(1, 1))
    (4): ReLU()
    (5): BatchNorm2d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
  )
  (fc_feature): Sequential(
    (0): Linear(in_features=128, out_features=128, bias=True)
    (1): ReLU()
    (2): Linear(in_features=128, out_features=4, bias=True)
  )
)
WARNING: GIF is enabled but the environment does not support RGB array rendering.
INFO: Learning...
INFO: BootcampName.HIDER Bootcamp completed, starting BootcampName.SEEKER Bootcamp #0 for 0 days
INFO: BootcampName.SEEKER Bootcamp completed, starting BootcampName.SLOW_AGENT Bootcamp #0 for 0 days
INFO: Continuing with Bootcamp #0 BootcampName.SLOW_AGENT with slow factor: 9 for agent 1
INFO: Continuing with Bootcamp #0 BootcampName.SLOW_AGENT with slow factor: 9 for agent 0
INFO: Continuing with Bootcamp #0 BootcampName.SLOW_AGENT with slow factor: 8 for agent 1
INFO: Continuing with Bootcamp #0 BootcampName.SLOW_AGENT with slow factor: 8 for agent 0
INFO: Continuing with Bootcamp #0 BootcampName.SLOW_AGENT with slow factor: 7 for agent 1
INFO: Continuing with Bootcamp #0 BootcampName.SLOW_AGENT with slow factor: 7 for agent 0
INFO: Continuing with Bootcamp #0 BootcampName.SLOW_AGENT with slow factor: 6 for agent 1
INFO: Continuing with Bootcamp #0 BootcampName.SLOW_AGENT with slow factor: 6 for agent 0
INFO: Continuing with Bootcamp #0 BootcampName.SLOW_AGENT with slow factor: 5 for agent 1
INFO: Continuing with Bootcamp #0 BootcampName.SLOW_AGENT with slow factor: 5 for agent 0
INFO: Continuing with Bootcamp #0 BootcampName.SLOW_AGENT with slow factor: 4 for agent 1
INFO: Continuing with Bootcamp #0 BootcampName.SLOW_AGENT with slow factor: 4 for agent 0
INFO: Continuing with Bootcamp #0 BootcampName.SLOW_AGENT with slow factor: 3 for agent 1
INFO: Continuing with Bootcamp #0 BootcampName.SLOW_AGENT with slow factor: 3 for agent 0
INFO: Continuing with Bootcamp #0 BootcampName.SLOW_AGENT with slow factor: 2 for agent 1
INFO: Continuing with Bootcamp #0 BootcampName.SLOW_AGENT with slow factor: 2 for agent 0
INFO: BootcampName.SLOW_AGENT Bootcamp completed, starting BootcampName.COMBINED Bootcamp #0 for 0 days
INFO: BootcampName.COMBINED Bootcamp completed, starting BootcampName.FINISHED Bootcamp #0 for 0 days
INFO: Number of parameters: 26724
INFO: QNetwork(
  (conv_feature): Sequential(
    (0): Conv2d(1, 32, kernel_size=(3, 3), stride=(1, 1))
    (1): ReLU()
    (2): BatchNorm2d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (3): Conv2d(32, 32, kernel_size=(3, 3), stride=(1, 1))
    (4): ReLU()
    (5): BatchNorm2d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
  )
  (fc_feature): Sequential(
    (0): Linear(in_features=128, out_features=128, bias=True)
    (1): ReLU()
    (2): Linear(in_features=128, out_features=4, bias=True)
  )
)
WARNING: GIF is enabled but the environment does not support RGB array rendering.
INFO: Learning...
INFO: BootcampName.HIDER Bootcamp completed, starting BootcampName.SEEKER Bootcamp #0 for 0 days
INFO: BootcampName.SEEKER Bootcamp completed, starting BootcampName.SLOW_AGENT Bootcamp #0 for 0 days
INFO: Continuing with Bootcamp #0 BootcampName.SLOW_AGENT with slow factor: 9 for agent 1
INFO: Continuing with Bootcamp #0 BootcampName.SLOW_AGENT with slow factor: 9 for agent 0
INFO: Continuing with Bootcamp #0 BootcampName.SLOW_AGENT with slow factor: 8 for agent 1
INFO: Continuing with Bootcamp #0 BootcampName.SLOW_AGENT with slow factor: 8 for agent 0
INFO: Continuing with Bootcamp #0 BootcampName.SLOW_AGENT with slow factor: 7 for agent 1
INFO: Continuing with Bootcamp #0 BootcampName.SLOW_AGENT with slow factor: 7 for agent 0
INFO: Continuing with Bootcamp #0 BootcampName.SLOW_AGENT with slow factor: 6 for agent 1
INFO: Continuing with Bootcamp #0 BootcampName.SLOW_AGENT with slow factor: 6 for agent 0
INFO: Continuing with Bootcamp #0 BootcampName.SLOW_AGENT with slow factor: 5 for agent 1
INFO: Continuing with Bootcamp #0 BootcampName.SLOW_AGENT with slow factor: 5 for agent 0
INFO: Continuing with Bootcamp #0 BootcampName.SLOW_AGENT with slow factor: 4 for agent 1
INFO: Continuing with Bootcamp #0 BootcampName.SLOW_AGENT with slow factor: 4 for agent 0
INFO: Continuing with Bootcamp #0 BootcampName.SLOW_AGENT with slow factor: 3 for agent 1
INFO: Continuing with Bootcamp #0 BootcampName.SLOW_AGENT with slow factor: 3 for agent 0
INFO: Continuing with Bootcamp #0 BootcampName.SLOW_AGENT with slow factor: 2 for agent 1
INFO: Continuing with Bootcamp #0 BootcampName.SLOW_AGENT with slow factor: 2 for agent 0
INFO: BootcampName.SLOW_AGENT Bootcamp completed, starting BootcampName.COMBINED Bootcamp #0 for 0 days
INFO: BootcampName.COMBINED Bootcamp completed, starting BootcampName.FINISHED Bootcamp #0 for 0 days
WARNING: No frames in gif to save.
WARNING: No frames in gif to save.
WARNING: No frames in gif to save.
WARNING: No frames in gif to save.
WARNING: No frames in gif to save.
WARNING: No frames in gif to save.
WARNING: No frames in gif to save.
WARNING: No frames in gif to save.
WARNING: No frames in gif to save.
WARNING: No frames in gif to save.
INFO: Number of parameters: 26724
INFO: QNetwork(
  (conv_feature): Sequential(
    (0): Conv2d(1, 32, kernel_size=(3, 3), stride=(1, 1))
    (1): ReLU()
    (2): BatchNorm2d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (3): Conv2d(32, 32, kernel_size=(3, 3), stride=(1, 1))
    (4): ReLU()
    (5): BatchNorm2d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
  )
  (fc_feature): Sequential(
    (0): Linear(in_features=128, out_features=128, bias=True)
    (1): ReLU()
    (2): Linear(in_features=128, out_features=4, bias=True)
  )
)
WARNING: GIF is enabled but the environment does not support RGB array rendering.
INFO: Learning...
INFO: BootcampName.HIDER Bootcamp completed, starting BootcampName.SEEKER Bootcamp #0 for 0 days
INFO: BootcampName.SEEKER Bootcamp completed, starting BootcampName.SLOW_AGENT Bootcamp #0 for 0 days
INFO: Continuing with Bootcamp #0 BootcampName.SLOW_AGENT with slow factor: 9 for agent 1
INFO: Continuing with Bootcamp #0 BootcampName.SLOW_AGENT with slow factor: 9 for agent 0
INFO: Continuing with Bootcamp #0 BootcampName.SLOW_AGENT with slow factor: 8 for agent 1
INFO: Continuing with Bootcamp #0 BootcampName.SLOW_AGENT with slow factor: 8 for agent 0
INFO: Continuing with Bootcamp #0 BootcampName.SLOW_AGENT with slow factor: 7 for agent 1
INFO: Continuing with Bootcamp #0 BootcampName.SLOW_AGENT with slow factor: 7 for agent 0
INFO: Continuing with Bootcamp #0 BootcampName.SLOW_AGENT with slow factor: 6 for agent 1
INFO: Continuing with Bootcamp #0 BootcampName.SLOW_AGENT with slow factor: 6 for agent 0
INFO: Continuing with Bootcamp #0 BootcampName.SLOW_AGENT with slow factor: 5 for agent 1
INFO: Continuing with Bootcamp #0 BootcampName.SLOW_AGENT with slow factor: 5 for agent 0
INFO: Continuing with Bootcamp #0 BootcampName.SLOW_AGENT with slow factor: 4 for agent 1
INFO: Continuing with Bootcamp #0 BootcampName.SLOW_AGENT with slow factor: 4 for agent 0
INFO: Continuing with Bootcamp #0 BootcampName.SLOW_AGENT with slow factor: 3 for agent 1
INFO: Continuing with Bootcamp #0 BootcampName.SLOW_AGENT with slow factor: 3 for agent 0
INFO: Continuing with Bootcamp #0 BootcampName.SLOW_AGENT with slow factor: 2 for agent 1
INFO: Continuing with Bootcamp #0 BootcampName.SLOW_AGENT with slow factor: 2 for agent 0
INFO: BootcampName.SLOW_AGENT Bootcamp completed, starting BootcampName.COMBINED Bootcamp #0 for 0 days
INFO: BootcampName.COMBINED Bootcamp completed, starting BootcampName.FINISHED Bootcamp #0 for 0 days
WARNING: No frames in gif to save.
WARNING: No frames in gif to save.
WARNING: No frames in gif to save.
WARNING: No frames in gif to save.
WARNING: No frames in gif to save.
WARNING: No frames in gif to save.
WARNING: No frames in gif to save.
WARNING: No frames in gif to save.
WARNING: No frames in gif to save.
WARNING: No frames in gif to save.
WARNING: No frames in gif to save.
WARNING: No frames in gif to save.
WARNING: No frames in gif to save.
WARNING: No frames in gif to save.
WARNING: No frames in gif to save.
WARNING: No frames in gif to save.
ERROR: torch.cat(): expected a non-empty list of Tensors
ERROR: Traceback (most recent call last):
  File "/home/eirik/Projects/XAI/rl/src/dqn/wrapper/multi_agent_dqn.py", line 108, in learn
    self._collect_rollouts()
  File "/home/eirik/Projects/XAI/rl/src/dqn/wrapper/multi_agent_dqn.py", line 253, in _collect_rollouts
    self.agents[i].train(
  File "/home/eirik/Projects/XAI/rl/src/dqn/dqn.py", line 290, in train
    self._optimize_model()
  File "/home/eirik/Projects/XAI/rl/src/dqn/dqn.py", line 345, in _optimize_model
    non_final_next_states = torch.cat(
                            ^^^^^^^^^^
RuntimeError: torch.cat(): expected a non-empty list of Tensors

WARNING: Error: Could not find wandb directory: ./wandb
INFO: Number of parameters: 77796
INFO: QNetwork(
  (conv_feature): Sequential(
    (0): Conv2d(1, 32, kernel_size=(3, 3), stride=(1, 1))
    (1): ReLU()
    (2): BatchNorm2d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (3): Conv2d(32, 32, kernel_size=(3, 3), stride=(1, 1))
    (4): ReLU()
    (5): BatchNorm2d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
  )
  (fc_feature): Sequential(
    (0): Linear(in_features=128, out_features=512, bias=True)
    (1): ReLU()
    (2): Linear(in_features=512, out_features=4, bias=True)
  )
)
WARNING: GIF is enabled but the environment does not support RGB array rendering.
INFO: Learning...
INFO: BootcampName.HIDER Bootcamp completed, starting BootcampName.SEEKER Bootcamp #0 for 0 days
INFO: BootcampName.SEEKER Bootcamp completed, starting BootcampName.SLOW_AGENT Bootcamp #0 for 0 days
INFO: Continuing with Bootcamp #0 BootcampName.SLOW_AGENT with slow factor: 9 for agent 1
INFO: Continuing with Bootcamp #0 BootcampName.SLOW_AGENT with slow factor: 9 for agent 0
INFO: Continuing with Bootcamp #0 BootcampName.SLOW_AGENT with slow factor: 8 for agent 1
INFO: Continuing with Bootcamp #0 BootcampName.SLOW_AGENT with slow factor: 8 for agent 0
INFO: Continuing with Bootcamp #0 BootcampName.SLOW_AGENT with slow factor: 7 for agent 1
INFO: Continuing with Bootcamp #0 BootcampName.SLOW_AGENT with slow factor: 7 for agent 0
INFO: Continuing with Bootcamp #0 BootcampName.SLOW_AGENT with slow factor: 6 for agent 1
INFO: Continuing with Bootcamp #0 BootcampName.SLOW_AGENT with slow factor: 6 for agent 0
INFO: Continuing with Bootcamp #0 BootcampName.SLOW_AGENT with slow factor: 5 for agent 1
INFO: Continuing with Bootcamp #0 BootcampName.SLOW_AGENT with slow factor: 5 for agent 0
INFO: Continuing with Bootcamp #0 BootcampName.SLOW_AGENT with slow factor: 4 for agent 1
INFO: Continuing with Bootcamp #0 BootcampName.SLOW_AGENT with slow factor: 4 for agent 0
INFO: Continuing with Bootcamp #0 BootcampName.SLOW_AGENT with slow factor: 3 for agent 1
INFO: Continuing with Bootcamp #0 BootcampName.SLOW_AGENT with slow factor: 3 for agent 0
INFO: Continuing with Bootcamp #0 BootcampName.SLOW_AGENT with slow factor: 2 for agent 1
INFO: Continuing with Bootcamp #0 BootcampName.SLOW_AGENT with slow factor: 2 for agent 0
INFO: BootcampName.SLOW_AGENT Bootcamp completed, starting BootcampName.COMBINED Bootcamp #0 for 0 days
INFO: BootcampName.COMBINED Bootcamp completed, starting BootcampName.FINISHED Bootcamp #0 for 0 days
WARNING: No frames in gif to save.
WARNING: No frames in gif to save.
INFO: Number of parameters: 77796
INFO: QNetwork(
  (conv_feature): Sequential(
    (0): Conv2d(1, 32, kernel_size=(3, 3), stride=(1, 1))
    (1): ReLU()
    (2): BatchNorm2d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (3): Conv2d(32, 32, kernel_size=(3, 3), stride=(1, 1))
    (4): ReLU()
    (5): BatchNorm2d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
  )
  (fc_feature): Sequential(
    (0): Linear(in_features=128, out_features=512, bias=True)
    (1): ReLU()
    (2): Linear(in_features=512, out_features=4, bias=True)
  )
)
INFO: Learning...
INFO: BootcampName.HIDER Bootcamp completed, starting BootcampName.SEEKER Bootcamp #0 for 0 days
INFO: BootcampName.SEEKER Bootcamp completed, starting BootcampName.SLOW_AGENT Bootcamp #0 for 0 days
INFO: Continuing with Bootcamp #0 BootcampName.SLOW_AGENT with slow factor: 9 for agent 1
INFO: Continuing with Bootcamp #0 BootcampName.SLOW_AGENT with slow factor: 9 for agent 0
INFO: Continuing with Bootcamp #0 BootcampName.SLOW_AGENT with slow factor: 8 for agent 1
INFO: Continuing with Bootcamp #0 BootcampName.SLOW_AGENT with slow factor: 8 for agent 0
INFO: Continuing with Bootcamp #0 BootcampName.SLOW_AGENT with slow factor: 7 for agent 1
INFO: Continuing with Bootcamp #0 BootcampName.SLOW_AGENT with slow factor: 7 for agent 0
INFO: Continuing with Bootcamp #0 BootcampName.SLOW_AGENT with slow factor: 6 for agent 1
INFO: Continuing with Bootcamp #0 BootcampName.SLOW_AGENT with slow factor: 6 for agent 0
INFO: Continuing with Bootcamp #0 BootcampName.SLOW_AGENT with slow factor: 5 for agent 1
INFO: Continuing with Bootcamp #0 BootcampName.SLOW_AGENT with slow factor: 5 for agent 0
INFO: Continuing with Bootcamp #0 BootcampName.SLOW_AGENT with slow factor: 4 for agent 1
INFO: Continuing with Bootcamp #0 BootcampName.SLOW_AGENT with slow factor: 4 for agent 0
INFO: Continuing with Bootcamp #0 BootcampName.SLOW_AGENT with slow factor: 3 for agent 1
INFO: Continuing with Bootcamp #0 BootcampName.SLOW_AGENT with slow factor: 3 for agent 0
INFO: Continuing with Bootcamp #0 BootcampName.SLOW_AGENT with slow factor: 2 for agent 1
INFO: Continuing with Bootcamp #0 BootcampName.SLOW_AGENT with slow factor: 2 for agent 0
INFO: BootcampName.SLOW_AGENT Bootcamp completed, starting BootcampName.COMBINED Bootcamp #0 for 0 days
INFO: BootcampName.COMBINED Bootcamp completed, starting BootcampName.FINISHED Bootcamp #0 for 0 days
ERROR: torch.cat(): expected a non-empty list of Tensors
ERROR: Traceback (most recent call last):
  File "/home/eirik/Projects/XAI/rl/src/dqn/wrapper/multi_agent_dqn.py", line 108, in learn
    self._collect_rollouts()
  File "/home/eirik/Projects/XAI/rl/src/dqn/wrapper/multi_agent_dqn.py", line 253, in _collect_rollouts
    self.agents[i].train(
  File "/home/eirik/Projects/XAI/rl/src/dqn/dqn.py", line 290, in train
    self._optimize_model()
  File "/home/eirik/Projects/XAI/rl/src/dqn/dqn.py", line 345, in _optimize_model
    non_final_next_states = torch.cat(
                            ^^^^^^^^^^
RuntimeError: torch.cat(): expected a non-empty list of Tensors

WARNING: Error: Could not find wandb directory: ./wandb
INFO: Number of parameters: 77796
INFO: QNetwork(
  (conv_feature): Sequential(
    (0): Conv2d(1, 32, kernel_size=(3, 3), stride=(1, 1))
    (1): ReLU()
    (2): BatchNorm2d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (3): Conv2d(32, 32, kernel_size=(3, 3), stride=(1, 1))
    (4): ReLU()
    (5): BatchNorm2d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
  )
  (fc_feature): Sequential(
    (0): Linear(in_features=128, out_features=512, bias=True)
    (1): ReLU()
    (2): Linear(in_features=512, out_features=4, bias=True)
  )
)
INFO: Learning...
INFO: BootcampName.HIDER Bootcamp completed, starting BootcampName.SEEKER Bootcamp #0 for 0 days
INFO: BootcampName.SEEKER Bootcamp completed, starting BootcampName.SLOW_AGENT Bootcamp #0 for 0 days
INFO: Continuing with Bootcamp #0 BootcampName.SLOW_AGENT with slow factor: 9 for agent 1
INFO: Continuing with Bootcamp #0 BootcampName.SLOW_AGENT with slow factor: 9 for agent 0
INFO: Continuing with Bootcamp #0 BootcampName.SLOW_AGENT with slow factor: 8 for agent 1
INFO: Continuing with Bootcamp #0 BootcampName.SLOW_AGENT with slow factor: 8 for agent 0
INFO: Continuing with Bootcamp #0 BootcampName.SLOW_AGENT with slow factor: 7 for agent 1
INFO: Continuing with Bootcamp #0 BootcampName.SLOW_AGENT with slow factor: 7 for agent 0
INFO: Continuing with Bootcamp #0 BootcampName.SLOW_AGENT with slow factor: 6 for agent 1
INFO: Continuing with Bootcamp #0 BootcampName.SLOW_AGENT with slow factor: 6 for agent 0
INFO: Continuing with Bootcamp #0 BootcampName.SLOW_AGENT with slow factor: 5 for agent 1
INFO: Continuing with Bootcamp #0 BootcampName.SLOW_AGENT with slow factor: 5 for agent 0
INFO: Continuing with Bootcamp #0 BootcampName.SLOW_AGENT with slow factor: 4 for agent 1
INFO: Continuing with Bootcamp #0 BootcampName.SLOW_AGENT with slow factor: 4 for agent 0
INFO: Continuing with Bootcamp #0 BootcampName.SLOW_AGENT with slow factor: 3 for agent 1
INFO: Continuing with Bootcamp #0 BootcampName.SLOW_AGENT with slow factor: 3 for agent 0
INFO: Continuing with Bootcamp #0 BootcampName.SLOW_AGENT with slow factor: 2 for agent 1
INFO: Continuing with Bootcamp #0 BootcampName.SLOW_AGENT with slow factor: 2 for agent 0
INFO: BootcampName.SLOW_AGENT Bootcamp completed, starting BootcampName.COMBINED Bootcamp #0 for 0 days
INFO: BootcampName.COMBINED Bootcamp completed, starting BootcampName.FINISHED Bootcamp #0 for 0 days
INFO: Number of parameters: 77796
INFO: QNetwork(
  (conv_feature): Sequential(
    (0): Conv2d(1, 32, kernel_size=(3, 3), stride=(1, 1))
    (1): ReLU()
    (2): BatchNorm2d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (3): Conv2d(32, 32, kernel_size=(3, 3), stride=(1, 1))
    (4): ReLU()
    (5): BatchNorm2d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
  )
  (fc_feature): Sequential(
    (0): Linear(in_features=128, out_features=512, bias=True)
    (1): ReLU()
    (2): Linear(in_features=512, out_features=4, bias=True)
  )
)
INFO: Learning...
INFO: BootcampName.HIDER Bootcamp completed, starting BootcampName.SEEKER Bootcamp #0 for 0 days
INFO: BootcampName.SEEKER Bootcamp completed, starting BootcampName.SLOW_AGENT Bootcamp #0 for 0 days
INFO: Continuing with Bootcamp #0 BootcampName.SLOW_AGENT with slow factor: 9 for agent 1
INFO: Continuing with Bootcamp #0 BootcampName.SLOW_AGENT with slow factor: 9 for agent 0
INFO: Continuing with Bootcamp #0 BootcampName.SLOW_AGENT with slow factor: 8 for agent 1
INFO: Continuing with Bootcamp #0 BootcampName.SLOW_AGENT with slow factor: 8 for agent 0
INFO: Continuing with Bootcamp #0 BootcampName.SLOW_AGENT with slow factor: 7 for agent 1
INFO: Continuing with Bootcamp #0 BootcampName.SLOW_AGENT with slow factor: 7 for agent 0
INFO: Continuing with Bootcamp #0 BootcampName.SLOW_AGENT with slow factor: 6 for agent 1
INFO: Continuing with Bootcamp #0 BootcampName.SLOW_AGENT with slow factor: 6 for agent 0
INFO: Continuing with Bootcamp #0 BootcampName.SLOW_AGENT with slow factor: 5 for agent 1
INFO: Continuing with Bootcamp #0 BootcampName.SLOW_AGENT with slow factor: 5 for agent 0
INFO: Continuing with Bootcamp #0 BootcampName.SLOW_AGENT with slow factor: 4 for agent 1
INFO: Continuing with Bootcamp #0 BootcampName.SLOW_AGENT with slow factor: 4 for agent 0
INFO: Continuing with Bootcamp #0 BootcampName.SLOW_AGENT with slow factor: 3 for agent 1
INFO: Continuing with Bootcamp #0 BootcampName.SLOW_AGENT with slow factor: 3 for agent 0
INFO: Continuing with Bootcamp #0 BootcampName.SLOW_AGENT with slow factor: 2 for agent 1
INFO: Continuing with Bootcamp #0 BootcampName.SLOW_AGENT with slow factor: 2 for agent 0
INFO: BootcampName.SLOW_AGENT Bootcamp completed, starting BootcampName.COMBINED Bootcamp #0 for 0 days
INFO: BootcampName.COMBINED Bootcamp completed, starting BootcampName.FINISHED Bootcamp #0 for 0 days
INFO: Number of parameters: 77796
INFO: QNetwork(
  (conv_feature): Sequential(
    (0): Conv2d(1, 32, kernel_size=(3, 3), stride=(1, 1))
    (1): ReLU()
    (2): BatchNorm2d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (3): Conv2d(32, 32, kernel_size=(3, 3), stride=(1, 1))
    (4): ReLU()
    (5): BatchNorm2d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
  )
  (fc_feature): Sequential(
    (0): Linear(in_features=128, out_features=512, bias=True)
    (1): ReLU()
    (2): Linear(in_features=512, out_features=4, bias=True)
  )
)
INFO: Learning...
INFO: BootcampName.HIDER Bootcamp completed, starting BootcampName.SEEKER Bootcamp #0 for 0 days
INFO: BootcampName.SEEKER Bootcamp completed, starting BootcampName.SLOW_AGENT Bootcamp #0 for 0 days
INFO: Continuing with Bootcamp #0 BootcampName.SLOW_AGENT with slow factor: 9 for agent 1
INFO: Continuing with Bootcamp #0 BootcampName.SLOW_AGENT with slow factor: 9 for agent 0
INFO: Continuing with Bootcamp #0 BootcampName.SLOW_AGENT with slow factor: 8 for agent 1
INFO: Continuing with Bootcamp #0 BootcampName.SLOW_AGENT with slow factor: 8 for agent 0
INFO: Continuing with Bootcamp #0 BootcampName.SLOW_AGENT with slow factor: 7 for agent 1
INFO: Continuing with Bootcamp #0 BootcampName.SLOW_AGENT with slow factor: 7 for agent 0
INFO: Continuing with Bootcamp #0 BootcampName.SLOW_AGENT with slow factor: 6 for agent 1
INFO: Continuing with Bootcamp #0 BootcampName.SLOW_AGENT with slow factor: 6 for agent 0
INFO: Continuing with Bootcamp #0 BootcampName.SLOW_AGENT with slow factor: 5 for agent 1
INFO: Continuing with Bootcamp #0 BootcampName.SLOW_AGENT with slow factor: 5 for agent 0
INFO: Continuing with Bootcamp #0 BootcampName.SLOW_AGENT with slow factor: 4 for agent 1
INFO: Continuing with Bootcamp #0 BootcampName.SLOW_AGENT with slow factor: 4 for agent 0
INFO: Continuing with Bootcamp #0 BootcampName.SLOW_AGENT with slow factor: 3 for agent 1
INFO: Continuing with Bootcamp #0 BootcampName.SLOW_AGENT with slow factor: 3 for agent 0
INFO: Continuing with Bootcamp #0 BootcampName.SLOW_AGENT with slow factor: 2 for agent 1
INFO: Continuing with Bootcamp #0 BootcampName.SLOW_AGENT with slow factor: 2 for agent 0
INFO: BootcampName.SLOW_AGENT Bootcamp completed, starting BootcampName.COMBINED Bootcamp #0 for 0 days
INFO: BootcampName.COMBINED Bootcamp completed, starting BootcampName.FINISHED Bootcamp #0 for 0 days
<<<<<<< HEAD
<<<<<<< HEAD
>>>>>>> d11a0db (model)
=======
=======
>>>>>>> main
INFO: Number of parameters: 77796
INFO: QNetwork(
  (conv_feature): Sequential(
    (0): Conv2d(1, 32, kernel_size=(3, 3), stride=(1, 1))
    (1): ReLU()
    (2): BatchNorm2d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (3): Conv2d(32, 32, kernel_size=(3, 3), stride=(1, 1))
    (4): ReLU()
    (5): BatchNorm2d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
  )
  (fc_feature): Sequential(
    (0): Linear(in_features=128, out_features=512, bias=True)
    (1): ReLU()
    (2): Linear(in_features=512, out_features=4, bias=True)
  )
)
INFO: Learning...
INFO: BootcampName.HIDER Bootcamp completed, starting BootcampName.SEEKER Bootcamp #0 for 0 days
INFO: BootcampName.SEEKER Bootcamp completed, starting BootcampName.SLOW_AGENT Bootcamp #0 for 0 days
INFO: Continuing with Bootcamp #0 BootcampName.SLOW_AGENT with slow factor: 9 for agent 1
INFO: Continuing with Bootcamp #0 BootcampName.SLOW_AGENT with slow factor: 9 for agent 0
INFO: Continuing with Bootcamp #0 BootcampName.SLOW_AGENT with slow factor: 8 for agent 1
INFO: Continuing with Bootcamp #0 BootcampName.SLOW_AGENT with slow factor: 8 for agent 0
INFO: Continuing with Bootcamp #0 BootcampName.SLOW_AGENT with slow factor: 7 for agent 1
INFO: Continuing with Bootcamp #0 BootcampName.SLOW_AGENT with slow factor: 7 for agent 0
INFO: Continuing with Bootcamp #0 BootcampName.SLOW_AGENT with slow factor: 6 for agent 1
INFO: Continuing with Bootcamp #0 BootcampName.SLOW_AGENT with slow factor: 6 for agent 0
INFO: Continuing with Bootcamp #0 BootcampName.SLOW_AGENT with slow factor: 5 for agent 1
INFO: Continuing with Bootcamp #0 BootcampName.SLOW_AGENT with slow factor: 5 for agent 0
INFO: Continuing with Bootcamp #0 BootcampName.SLOW_AGENT with slow factor: 4 for agent 1
INFO: Continuing with Bootcamp #0 BootcampName.SLOW_AGENT with slow factor: 4 for agent 0
INFO: Continuing with Bootcamp #0 BootcampName.SLOW_AGENT with slow factor: 3 for agent 1
INFO: Continuing with Bootcamp #0 BootcampName.SLOW_AGENT with slow factor: 3 for agent 0
INFO: Continuing with Bootcamp #0 BootcampName.SLOW_AGENT with slow factor: 2 for agent 1
INFO: Continuing with Bootcamp #0 BootcampName.SLOW_AGENT with slow factor: 2 for agent 0
INFO: BootcampName.SLOW_AGENT Bootcamp completed, starting BootcampName.COMBINED Bootcamp #0 for 0 days
INFO: BootcampName.COMBINED Bootcamp completed, starting BootcampName.FINISHED Bootcamp #0 for 0 days
ERROR: torch.cat(): expected a non-empty list of Tensors
ERROR: Traceback (most recent call last):
  File "/home/eirik/Projects/XAI/rl/src/dqn/wrapper/multi_agent_dqn.py", line 108, in learn
    self._collect_rollouts()
  File "/home/eirik/Projects/XAI/rl/src/dqn/wrapper/multi_agent_dqn.py", line 253, in _collect_rollouts
    self.agents[i].train(
  File "/home/eirik/Projects/XAI/rl/src/dqn/dqn.py", line 290, in train
    self._optimize_model()
  File "/home/eirik/Projects/XAI/rl/src/dqn/dqn.py", line 345, in _optimize_model
    non_final_next_states = torch.cat(
                            ^^^^^^^^^^
RuntimeError: torch.cat(): expected a non-empty list of Tensors

WARNING: Error: Could not find wandb directory: ./wandb
INFO: Number of parameters: 77796
INFO: QNetwork(
  (conv_feature): Sequential(
    (0): Conv2d(1, 32, kernel_size=(3, 3), stride=(1, 1))
    (1): ReLU()
    (2): BatchNorm2d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (3): Conv2d(32, 32, kernel_size=(3, 3), stride=(1, 1))
    (4): ReLU()
    (5): BatchNorm2d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
  )
  (fc_feature): Sequential(
    (0): Linear(in_features=128, out_features=512, bias=True)
    (1): ReLU()
    (2): Linear(in_features=512, out_features=4, bias=True)
  )
)
INFO: Learning...
ERROR: 5 is not a valid BootcampName
ERROR: Traceback (most recent call last):
  File "/home/eirik/Projects/XAI/rl/src/dqn/wrapper/multi_agent_dqn.py", line 108, in learn
    self._collect_rollouts()
  File "/home/eirik/Projects/XAI/rl/src/dqn/wrapper/multi_agent_dqn.py", line 206, in _collect_rollouts
    ) = self.env.get_wrapper_attr("step_multiple")(actions)
        ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/eirik/Projects/XAI/environments/gymnasium/wrappers/multi_agent_env.py", line 29, in step_multiple
    observation, reward, terminated, trunc, info = self.env.step(action)
                                                   ^^^^^^^^^^^^^^^^^^^^^
  File "/home/eirik/.cache/pypoetry/virtualenvs/xai-is73Zs3s-py3.11/lib/python3.11/site-packages/gymnasium/wrappers/common.py", line 393, in step
    return super().step(action)
           ^^^^^^^^^^^^^^^^^^^^
  File "/home/eirik/.cache/pypoetry/virtualenvs/xai-is73Zs3s-py3.11/lib/python3.11/site-packages/gymnasium/core.py", line 322, in step
    return self.env.step(action)
           ^^^^^^^^^^^^^^^^^^^^^
  File "/home/eirik/.cache/pypoetry/virtualenvs/xai-is73Zs3s-py3.11/lib/python3.11/site-packages/gymnasium/wrappers/common.py", line 285, in step
    return self.env.step(action)
           ^^^^^^^^^^^^^^^^^^^^^
  File "/home/eirik/Projects/XAI/environments/gymnasium/envs/tag/tag.py", line 92, in step
    self.bootcamp.step()
  File "/home/eirik/Projects/XAI/environments/gymnasium/envs/tag/utils/bootcamp.py", line 63, in step
    self._next()
  File "/home/eirik/Projects/XAI/environments/gymnasium/envs/tag/utils/bootcamp.py", line 107, in _next
    self._next()
  File "/home/eirik/Projects/XAI/environments/gymnasium/envs/tag/utils/bootcamp.py", line 107, in _next
    self._next()
  File "/home/eirik/Projects/XAI/environments/gymnasium/envs/tag/utils/bootcamp.py", line 107, in _next
    self._next()
  [Previous line repeated 1 more time]
  File "/home/eirik/Projects/XAI/environments/gymnasium/envs/tag/utils/bootcamp.py", line 106, in _next
    self._name = BootcampName(self._name.value + 1)
                 ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/usr/lib/python3.11/enum.py", line 717, in __call__
    return cls.__new__(cls, value)
           ^^^^^^^^^^^^^^^^^^^^^^^
  File "/usr/lib/python3.11/enum.py", line 1133, in __new__
    raise ve_exc
ValueError: 5 is not a valid BootcampName

WARNING: Error: Could not find wandb directory: ./wandb
INFO: Number of parameters: 77796
INFO: QNetwork(
  (conv_feature): Sequential(
    (0): Conv2d(1, 32, kernel_size=(3, 3), stride=(1, 1))
    (1): ReLU()
    (2): BatchNorm2d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (3): Conv2d(32, 32, kernel_size=(3, 3), stride=(1, 1))
    (4): ReLU()
    (5): BatchNorm2d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
  )
  (fc_feature): Sequential(
    (0): Linear(in_features=128, out_features=512, bias=True)
    (1): ReLU()
    (2): Linear(in_features=512, out_features=4, bias=True)
  )
)
INFO: Learning...
INFO: Number of parameters: 77796
INFO: QNetwork(
  (conv_feature): Sequential(
    (0): Conv2d(1, 32, kernel_size=(3, 3), stride=(1, 1))
    (1): ReLU()
    (2): BatchNorm2d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (3): Conv2d(32, 32, kernel_size=(3, 3), stride=(1, 1))
    (4): ReLU()
    (5): BatchNorm2d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
  )
  (fc_feature): Sequential(
    (0): Linear(in_features=128, out_features=512, bias=True)
    (1): ReLU()
    (2): Linear(in_features=512, out_features=4, bias=True)
  )
)
INFO: Learning...
ERROR: torch.cat(): expected a non-empty list of Tensors
ERROR: Traceback (most recent call last):
  File "/home/eirik/Projects/XAI/rl/src/dqn/wrapper/multi_agent_dqn.py", line 108, in learn
    self._collect_rollouts()
  File "/home/eirik/Projects/XAI/rl/src/dqn/wrapper/multi_agent_dqn.py", line 253, in _collect_rollouts
    self.agents[i].train(
  File "/home/eirik/Projects/XAI/rl/src/dqn/dqn.py", line 290, in train
    self._optimize_model()
  File "/home/eirik/Projects/XAI/rl/src/dqn/dqn.py", line 345, in _optimize_model
    non_final_next_states = torch.cat(
                            ^^^^^^^^^^
RuntimeError: torch.cat(): expected a non-empty list of Tensors

WARNING: Error: Could not find wandb directory: ./wandb
<<<<<<< HEAD
<<<<<<< HEAD
>>>>>>> 88755ce (model)
=======
=======
>>>>>>> main
INFO: Number of parameters: 77796
INFO: QNetwork(
  (conv_feature): Sequential(
    (0): Conv2d(1, 32, kernel_size=(3, 3), stride=(1, 1))
    (1): ReLU()
    (2): BatchNorm2d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (3): Conv2d(32, 32, kernel_size=(3, 3), stride=(1, 1))
    (4): ReLU()
    (5): BatchNorm2d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
  )
  (fc_feature): Sequential(
    (0): Linear(in_features=128, out_features=512, bias=True)
    (1): ReLU()
    (2): Linear(in_features=512, out_features=4, bias=True)
  )
)
INFO: Learning...
ERROR: torch.cat(): expected a non-empty list of Tensors
ERROR: Traceback (most recent call last):
  File "/home/eirik/Projects/XAI/rl/src/dqn/wrapper/multi_agent_dqn.py", line 108, in learn
    self._collect_rollouts()
  File "/home/eirik/Projects/XAI/rl/src/dqn/wrapper/multi_agent_dqn.py", line 253, in _collect_rollouts
    self.agents[i].train(
  File "/home/eirik/Projects/XAI/rl/src/dqn/dqn.py", line 292, in train
    self._optimize_model()
  File "/home/eirik/Projects/XAI/rl/src/dqn/dqn.py", line 347, in _optimize_model
RuntimeError: torch.cat(): expected a non-empty list of Tensors

WARNING: Error: Could not find wandb directory: ./wandb
INFO: Number of parameters: 77796
INFO: QNetwork(
  (conv_feature): Sequential(
    (0): Conv2d(1, 32, kernel_size=(3, 3), stride=(1, 1))
    (1): ReLU()
    (2): BatchNorm2d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (3): Conv2d(32, 32, kernel_size=(3, 3), stride=(1, 1))
    (4): ReLU()
    (5): BatchNorm2d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
  )
  (fc_feature): Sequential(
    (0): Linear(in_features=128, out_features=512, bias=True)
    (1): ReLU()
    (2): Linear(in_features=512, out_features=4, bias=True)
  )
)
INFO: Learning...
INFO: Number of parameters: 77796
INFO: QNetwork(
  (conv_feature): Sequential(
    (0): Conv2d(1, 32, kernel_size=(3, 3), stride=(1, 1))
    (1): ReLU()
    (2): BatchNorm2d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (3): Conv2d(32, 32, kernel_size=(3, 3), stride=(1, 1))
    (4): ReLU()
    (5): BatchNorm2d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
  )
  (fc_feature): Sequential(
    (0): Linear(in_features=128, out_features=512, bias=True)
    (1): ReLU()
    (2): Linear(in_features=512, out_features=4, bias=True)
  )
)
INFO: Learning...
ERROR: torch.cat(): expected a non-empty list of Tensors
ERROR: Traceback (most recent call last):
  File "/home/eirik/Projects/XAI/rl/src/dqn/wrapper/multi_agent_dqn.py", line 108, in learn
    self._collect_rollouts()
  File "/home/eirik/Projects/XAI/rl/src/dqn/wrapper/multi_agent_dqn.py", line 253, in _collect_rollouts
    self.agents[i].train(
  File "/home/eirik/Projects/XAI/rl/src/dqn/dqn.py", line 292, in train
  File "/home/eirik/Projects/XAI/rl/src/dqn/dqn.py", line 351, in _optimize_model
    f"No next states in batch for agent {self.agent_id}."
                        ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
RuntimeError: torch.cat(): expected a non-empty list of Tensors

WARNING: Error: Could not find wandb directory: ./wandb
INFO: Number of parameters: 77796
INFO: QNetwork(
  (conv_feature): Sequential(
    (0): Conv2d(1, 32, kernel_size=(3, 3), stride=(1, 1))
    (1): ReLU()
    (2): BatchNorm2d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (3): Conv2d(32, 32, kernel_size=(3, 3), stride=(1, 1))
    (4): ReLU()
    (5): BatchNorm2d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
  )
  (fc_feature): Sequential(
    (0): Linear(in_features=128, out_features=512, bias=True)
    (1): ReLU()
    (2): Linear(in_features=512, out_features=4, bias=True)
  )
)
INFO: Learning...
INFO: Number of parameters: 77796
INFO: QNetwork(
  (conv_feature): Sequential(
    (0): Conv2d(1, 32, kernel_size=(3, 3), stride=(1, 1))
    (1): ReLU()
    (2): BatchNorm2d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (3): Conv2d(32, 32, kernel_size=(3, 3), stride=(1, 1))
    (4): ReLU()
    (5): BatchNorm2d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
  )
  (fc_feature): Sequential(
    (0): Linear(in_features=128, out_features=512, bias=True)
    (1): ReLU()
    (2): Linear(in_features=512, out_features=4, bias=True)
  )
)
INFO: Learning...
INFO: Number of parameters: 77796
INFO: QNetwork(
  (conv_feature): Sequential(
    (0): Conv2d(1, 32, kernel_size=(3, 3), stride=(1, 1))
    (1): ReLU()
    (2): BatchNorm2d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (3): Conv2d(32, 32, kernel_size=(3, 3), stride=(1, 1))
    (4): ReLU()
    (5): BatchNorm2d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
  )
  (fc_feature): Sequential(
    (0): Linear(in_features=128, out_features=512, bias=True)
    (1): ReLU()
    (2): Linear(in_features=512, out_features=4, bias=True)
  )
)
INFO: Learning...
INFO: Number of parameters: 77796
INFO: QNetwork(
  (conv_feature): Sequential(
    (0): Conv2d(1, 32, kernel_size=(3, 3), stride=(1, 1))
    (1): ReLU()
    (2): BatchNorm2d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (3): Conv2d(32, 32, kernel_size=(3, 3), stride=(1, 1))
    (4): ReLU()
    (5): BatchNorm2d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
  )
  (fc_feature): Sequential(
    (0): Linear(in_features=128, out_features=512, bias=True)
    (1): ReLU()
    (2): Linear(in_features=512, out_features=4, bias=True)
  )
)
INFO: Learning...
INFO: Number of parameters: 77796
INFO: QNetwork(
  (conv_feature): Sequential(
    (0): Conv2d(1, 32, kernel_size=(3, 3), stride=(1, 1))
    (1): ReLU()
    (2): BatchNorm2d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (3): Conv2d(32, 32, kernel_size=(3, 3), stride=(1, 1))
    (4): ReLU()
    (5): BatchNorm2d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
  )
  (fc_feature): Sequential(
    (0): Linear(in_features=128, out_features=512, bias=True)
    (1): ReLU()
    (2): Linear(in_features=512, out_features=4, bias=True)
  )
)
INFO: Learning...
INFO: Number of parameters: 77796
INFO: QNetwork(
  (conv_feature): Sequential(
    (0): Conv2d(1, 32, kernel_size=(3, 3), stride=(1, 1))
    (1): ReLU()
    (2): BatchNorm2d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (3): Conv2d(32, 32, kernel_size=(3, 3), stride=(1, 1))
    (4): ReLU()
    (5): BatchNorm2d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
  )
  (fc_feature): Sequential(
    (0): Linear(in_features=128, out_features=512, bias=True)
    (1): ReLU()
    (2): Linear(in_features=512, out_features=4, bias=True)
  )
)
INFO: Learning...
INFO: Number of parameters: 77796
INFO: QNetwork(
  (conv_feature): Sequential(
    (0): Conv2d(1, 32, kernel_size=(3, 3), stride=(1, 1))
    (1): ReLU()
    (2): BatchNorm2d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (3): Conv2d(32, 32, kernel_size=(3, 3), stride=(1, 1))
    (4): ReLU()
    (5): BatchNorm2d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
  )
  (fc_feature): Sequential(
    (0): Linear(in_features=128, out_features=512, bias=True)
    (1): ReLU()
    (2): Linear(in_features=512, out_features=4, bias=True)
  )
)
INFO: Learning...
INFO: Number of parameters: 77796
INFO: QNetwork(
  (conv_feature): Sequential(
    (0): Conv2d(1, 32, kernel_size=(3, 3), stride=(1, 1))
    (1): ReLU()
    (2): BatchNorm2d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (3): Conv2d(32, 32, kernel_size=(3, 3), stride=(1, 1))
    (4): ReLU()
    (5): BatchNorm2d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
  )
  (fc_feature): Sequential(
    (0): Linear(in_features=128, out_features=512, bias=True)
    (1): ReLU()
    (2): Linear(in_features=512, out_features=4, bias=True)
  )
)
INFO: Learning...
INFO: Number of parameters: 77796
INFO: QNetwork(
  (conv_feature): Sequential(
    (0): Conv2d(1, 32, kernel_size=(3, 3), stride=(1, 1))
    (1): ReLU()
    (2): BatchNorm2d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (3): Conv2d(32, 32, kernel_size=(3, 3), stride=(1, 1))
    (4): ReLU()
    (5): BatchNorm2d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
  )
  (fc_feature): Sequential(
    (0): Linear(in_features=128, out_features=512, bias=True)
    (1): ReLU()
    (2): Linear(in_features=512, out_features=4, bias=True)
  )
)
INFO: Learning...
INFO: Number of parameters: 77796
INFO: QNetwork(
  (conv_feature): Sequential(
    (0): Conv2d(1, 32, kernel_size=(3, 3), stride=(1, 1))
    (1): ReLU()
    (2): BatchNorm2d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (3): Conv2d(32, 32, kernel_size=(3, 3), stride=(1, 1))
    (4): ReLU()
    (5): BatchNorm2d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
  )
  (fc_feature): Sequential(
    (0): Linear(in_features=128, out_features=512, bias=True)
    (1): ReLU()
    (2): Linear(in_features=512, out_features=4, bias=True)
  )
)
INFO: Learning...
INFO: Number of parameters: 77796
INFO: QNetwork(
  (conv_feature): Sequential(
    (0): Conv2d(1, 32, kernel_size=(3, 3), stride=(1, 1))
    (1): ReLU()
    (2): BatchNorm2d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (3): Conv2d(32, 32, kernel_size=(3, 3), stride=(1, 1))
    (4): ReLU()
    (5): BatchNorm2d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
  )
  (fc_feature): Sequential(
    (0): Linear(in_features=128, out_features=512, bias=True)
    (1): ReLU()
    (2): Linear(in_features=512, out_features=4, bias=True)
  )
)
INFO: Learning...
INFO: Number of parameters: 77796
INFO: QNetwork(
  (conv_feature): Sequential(
    (0): Conv2d(1, 32, kernel_size=(3, 3), stride=(1, 1))
    (1): ReLU()
    (2): BatchNorm2d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (3): Conv2d(32, 32, kernel_size=(3, 3), stride=(1, 1))
    (4): ReLU()
    (5): BatchNorm2d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
  )
  (fc_feature): Sequential(
    (0): Linear(in_features=128, out_features=512, bias=True)
    (1): ReLU()
    (2): Linear(in_features=512, out_features=4, bias=True)
  )
)
INFO: Learning...
ERROR: cannot access local variable 'non_final_next_states' where it is not associated with a value
ERROR: Traceback (most recent call last):
  File "/home/eirik/Projects/XAI/rl/src/dqn/wrapper/multi_agent_dqn.py", line 108, in learn
    self._collect_rollouts()
  File "/home/eirik/Projects/XAI/rl/src/dqn/wrapper/multi_agent_dqn.py", line 253, in _collect_rollouts
    self.agents[i].train(
  File "/home/eirik/Projects/XAI/rl/src/dqn/dqn.py", line 292, in train
    self._optimize_model()
  File "/home/eirik/Projects/XAI/rl/src/dqn/dqn.py", line 373, in _optimize_model
    self.policy_net(non_final_next_states).max(1)[1].unsqueeze(1)
                    ^^^^^^^^^^^^^^^^^^^^^
UnboundLocalError: cannot access local variable 'non_final_next_states' where it is not associated with a value

WARNING: Error: Could not find wandb directory: ./wandb
INFO: Number of parameters: 4580
INFO: QNetwork(
  (conv_feature): Sequential()
  (fc_feature): Sequential(
    (0): Linear(in_features=36, out_features=64, bias=True)
    (1): ReLU()
    (2): Linear(in_features=64, out_features=32, bias=True)
    (3): ReLU()
    (4): Linear(in_features=32, out_features=4, bias=True)
  )
)
INFO: Learning...
ERROR: Next state cannot be None.
ERROR: Traceback (most recent call last):
  File "/home/eirik/Projects/XAI/rl/src/dqn/wrapper/multi_agent_dqn.py", line 108, in learn
    self._collect_rollouts()
  File "/home/eirik/Projects/XAI/rl/src/dqn/wrapper/multi_agent_dqn.py", line 253, in _collect_rollouts
    self.agents[i].train(
  File "/home/eirik/Projects/XAI/rl/src/dqn/dqn.py", line 290, in train
    raise ValueError("Next state cannot be None.")
ValueError: Next state cannot be None.

WARNING: Error: Could not find wandb directory: ./wandb
INFO: Number of parameters: 4580
INFO: QNetwork(
  (conv_feature): Sequential()
  (fc_feature): Sequential(
    (0): Linear(in_features=36, out_features=64, bias=True)
    (1): ReLU()
    (2): Linear(in_features=64, out_features=32, bias=True)
    (3): ReLU()
    (4): Linear(in_features=32, out_features=4, bias=True)
  )
)
INFO: Number of parameters: 4580
INFO: QNetwork(
  (conv_feature): Sequential()
  (fc_feature): Sequential(
    (0): Linear(in_features=36, out_features=64, bias=True)
    (1): ReLU()
    (2): Linear(in_features=64, out_features=32, bias=True)
    (3): ReLU()
    (4): Linear(in_features=32, out_features=4, bias=True)
  )
)
INFO: Learning...
ERROR: Next state cannot be None.
ERROR: Traceback (most recent call last):
  File "/home/eirik/Projects/XAI/rl/src/dqn/wrapper/multi_agent_dqn.py", line 108, in learn
    self._collect_rollouts()
  File "/home/eirik/Projects/XAI/rl/src/dqn/wrapper/multi_agent_dqn.py", line 253, in _collect_rollouts
    self.agents[i].train(
  File "/home/eirik/Projects/XAI/rl/src/dqn/dqn.py", line 291, in train
    raise ValueError("Next state cannot be None.")
ValueError: Next state cannot be None.

WARNING: Error: Could not find wandb directory: ./wandb
INFO: Number of parameters: 4580
INFO: QNetwork(
  (conv_feature): Sequential()
  (fc_feature): Sequential(
    (0): Linear(in_features=36, out_features=64, bias=True)
    (1): ReLU()
    (2): Linear(in_features=64, out_features=32, bias=True)
    (3): ReLU()
    (4): Linear(in_features=32, out_features=4, bias=True)
  )
)
INFO: Learning...
INFO: Number of parameters: 4580
INFO: QNetwork(
  (conv_feature): Sequential()
  (fc_feature): Sequential(
    (0): Linear(in_features=36, out_features=64, bias=True)
    (1): ReLU()
    (2): Linear(in_features=64, out_features=32, bias=True)
    (3): ReLU()
    (4): Linear(in_features=32, out_features=4, bias=True)
  )
)
INFO: Learning...
INFO: Number of parameters: 8740
INFO: QNetwork(
  (conv_feature): Sequential()
  (fc_feature): Sequential(
    (0): Linear(in_features=36, out_features=64, bias=True)
    (1): ReLU()
    (2): Linear(in_features=64, out_features=64, bias=True)
    (3): ReLU()
    (4): Linear(in_features=64, out_features=32, bias=True)
    (5): ReLU()
    (6): Linear(in_features=32, out_features=4, bias=True)
  )
)
WARNING: GIF is enabled but the environment does not support RGB array rendering.
INFO: Learning...
WARNING: No frames in gif to save.
WARNING: No frames in gif to save.
WARNING: No frames in gif to save.
WARNING: No frames in gif to save.
WARNING: No frames in gif to save.
WARNING: No frames in gif to save.
<<<<<<< HEAD
<<<<<<< HEAD
>>>>>>> b953503 (feat: advanced env)
=======
=======
>>>>>>> main
INFO: Number of parameters: 332964
INFO: QNetwork(
  (conv_feature): Sequential(
    (0): Conv2d(1, 32, kernel_size=(3, 3), stride=(1, 1))
    (1): ReLU()
    (2): BatchNorm2d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
  )
  (fc_feature): Sequential(
    (0): Linear(in_features=512, out_features=512, bias=True)
    (1): ReLU()
    (2): Linear(in_features=512, out_features=128, bias=True)
    (3): ReLU()
    (4): Linear(in_features=128, out_features=32, bias=True)
    (5): ReLU()
    (6): Linear(in_features=32, out_features=4, bias=True)
  )
)
WARNING: GIF is enabled but the environment does not support RGB array rendering.
INFO: Learning...
INFO: Number of parameters: 480420
INFO: QNetwork(
  (conv_feature): Sequential(
    (0): Conv2d(1, 32, kernel_size=(3, 3), stride=(1, 1))
    (1): ReLU()
    (2): BatchNorm2d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
  )
  (fc_feature): Sequential(
    (0): Linear(in_features=800, out_features=512, bias=True)
    (1): ReLU()
    (2): Linear(in_features=512, out_features=128, bias=True)
    (3): ReLU()
    (4): Linear(in_features=128, out_features=32, bias=True)
    (5): ReLU()
    (6): Linear(in_features=32, out_features=4, bias=True)
  )
)
WARNING: GIF is enabled but the environment does not support RGB array rendering.
INFO: Learning...
INFO: Number of parameters: 480420
INFO: QNetwork(
  (conv_feature): Sequential(
    (0): Conv2d(1, 32, kernel_size=(3, 3), stride=(1, 1))
    (1): ReLU()
    (2): BatchNorm2d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
  )
  (fc_feature): Sequential(
    (0): Linear(in_features=800, out_features=512, bias=True)
    (1): ReLU()
    (2): Linear(in_features=512, out_features=128, bias=True)
    (3): ReLU()
    (4): Linear(in_features=128, out_features=32, bias=True)
    (5): ReLU()
    (6): Linear(in_features=32, out_features=4, bias=True)
  )
)
WARNING: GIF is enabled but the environment does not support RGB array rendering.
INFO: Learning...
INFO: Number of parameters: 480420
INFO: QNetwork(
  (conv_feature): Sequential(
    (0): Conv2d(1, 32, kernel_size=(3, 3), stride=(1, 1))
    (1): ReLU()
    (2): BatchNorm2d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
  )
  (fc_feature): Sequential(
    (0): Linear(in_features=800, out_features=512, bias=True)
    (1): ReLU()
    (2): Linear(in_features=512, out_features=128, bias=True)
    (3): ReLU()
    (4): Linear(in_features=128, out_features=32, bias=True)
    (5): ReLU()
    (6): Linear(in_features=32, out_features=4, bias=True)
  )
)
WARNING: GIF is enabled but the environment does not support RGB array rendering.
INFO: Learning...
<<<<<<< HEAD
>>>>>>> d248804 (feat: all in)
=======
>>>>>>> 3ffcdcd (feat: created cav scores)
=======
INFO: Number of parameters: 480420
INFO: QNetwork(
  (conv_feature): Sequential(
    (0): Conv2d(1, 32, kernel_size=(3, 3), stride=(1, 1))
    (1): ReLU()
    (2): BatchNorm2d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
  )
  (fc_feature): Sequential(
    (0): Linear(in_features=800, out_features=512, bias=True)
    (1): ReLU()
    (2): Linear(in_features=512, out_features=128, bias=True)
    (3): ReLU()
    (4): Linear(in_features=128, out_features=32, bias=True)
    (5): ReLU()
    (6): Linear(in_features=32, out_features=4, bias=True)
  )
)
WARNING: GIF is enabled but the environment does not support RGB array rendering.
INFO: Learning...
WARNING: No frames in gif to save.
WARNING: No frames in gif to save.
WARNING: No frames in gif to save.
WARNING: No frames in gif to save.
INFO: Number of parameters: 480453
INFO: QNetwork(
  (conv_feature): Sequential(
    (0): Conv2d(1, 32, kernel_size=(3, 3), stride=(1, 1))
    (1): ReLU()
    (2): BatchNorm2d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
  )
  (fc_feature): Sequential(
    (0): Linear(in_features=800, out_features=512, bias=True)
    (1): ReLU()
    (2): Linear(in_features=512, out_features=128, bias=True)
    (3): ReLU()
    (4): Linear(in_features=128, out_features=32, bias=True)
    (5): ReLU()
    (6): Linear(in_features=32, out_features=5, bias=True)
  )
)
WARNING: GIF is enabled but the environment does not support RGB array rendering.
INFO: Learning...
WARNING: No frames in gif to save.
WARNING: No frames in gif to save.
WARNING: No frames in gif to save.
WARNING: No frames in gif to save.
INFO: Number of parameters: 480453
INFO: QNetwork(
  (conv_feature): Sequential(
    (0): Conv2d(1, 32, kernel_size=(3, 3), stride=(1, 1))
    (1): ReLU()
    (2): BatchNorm2d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
  )
  (fc_feature): Sequential(
    (0): Linear(in_features=800, out_features=512, bias=True)
    (1): ReLU()
    (2): Linear(in_features=512, out_features=128, bias=True)
    (3): ReLU()
    (4): Linear(in_features=128, out_features=32, bias=True)
    (5): ReLU()
    (6): Linear(in_features=32, out_features=5, bias=True)
  )
)
WARNING: GIF is enabled but the environment does not support RGB array rendering.
INFO: Learning...
INFO: Number of parameters: 480453
INFO: QNetwork(
  (conv_feature): Sequential(
    (0): Conv2d(1, 32, kernel_size=(3, 3), stride=(1, 1))
    (1): ReLU()
    (2): BatchNorm2d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
  )
  (fc_feature): Sequential(
    (0): Linear(in_features=800, out_features=512, bias=True)
    (1): ReLU()
    (2): Linear(in_features=512, out_features=128, bias=True)
    (3): ReLU()
    (4): Linear(in_features=128, out_features=32, bias=True)
    (5): ReLU()
    (6): Linear(in_features=32, out_features=5, bias=True)
  )
)
WARNING: GIF is enabled but the environment does not support RGB array rendering.
INFO: Learning...
INFO: Number of parameters: 480453
INFO: QNetwork(
  (conv_feature): Sequential(
    (0): Conv2d(1, 32, kernel_size=(3, 3), stride=(1, 1))
    (1): ReLU()
    (2): BatchNorm2d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
  )
  (fc_feature): Sequential(
    (0): Linear(in_features=800, out_features=512, bias=True)
    (1): ReLU()
    (2): Linear(in_features=512, out_features=128, bias=True)
    (3): ReLU()
    (4): Linear(in_features=128, out_features=32, bias=True)
    (5): ReLU()
    (6): Linear(in_features=32, out_features=5, bias=True)
  )
)
WARNING: GIF is enabled but the environment does not support RGB array rendering.
INFO: Learning...
INFO: Number of parameters: 480453
INFO: QNetwork(
  (conv_feature): Sequential(
    (0): Conv2d(1, 32, kernel_size=(3, 3), stride=(1, 1))
    (1): ReLU()
    (2): BatchNorm2d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
  )
  (fc_feature): Sequential(
    (0): Linear(in_features=800, out_features=512, bias=True)
    (1): ReLU()
    (2): Linear(in_features=512, out_features=128, bias=True)
    (3): ReLU()
    (4): Linear(in_features=128, out_features=32, bias=True)
    (5): ReLU()
    (6): Linear(in_features=32, out_features=5, bias=True)
  )
)
WARNING: GIF is enabled but the environment does not support RGB array rendering.
INFO: Learning...
INFO: Number of parameters: 480453
INFO: QNetwork(
  (conv_feature): Sequential(
    (0): Conv2d(1, 32, kernel_size=(3, 3), stride=(1, 1))
    (1): ReLU()
    (2): BatchNorm2d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
  )
  (fc_feature): Sequential(
    (0): Linear(in_features=800, out_features=512, bias=True)
    (1): ReLU()
    (2): Linear(in_features=512, out_features=128, bias=True)
    (3): ReLU()
    (4): Linear(in_features=128, out_features=32, bias=True)
    (5): ReLU()
    (6): Linear(in_features=32, out_features=5, bias=True)
  )
)
WARNING: GIF is enabled but the environment does not support RGB array rendering.
INFO: Learning...
INFO: Number of parameters: 480453
INFO: QNetwork(
  (conv_feature): Sequential(
    (0): Conv2d(1, 32, kernel_size=(3, 3), stride=(1, 1))
    (1): ReLU()
    (2): BatchNorm2d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
  )
  (fc_feature): Sequential(
    (0): Linear(in_features=800, out_features=512, bias=True)
    (1): ReLU()
    (2): Linear(in_features=512, out_features=128, bias=True)
    (3): ReLU()
    (4): Linear(in_features=128, out_features=32, bias=True)
    (5): ReLU()
    (6): Linear(in_features=32, out_features=5, bias=True)
  )
)
WARNING: GIF is enabled but the environment does not support RGB array rendering.
INFO: Learning...
>>>>>>> main
INFO: Number of parameters: 159716
INFO: QNetwork(
  (conv_feature): Sequential(
    (0): Conv2d(1, 32, kernel_size=(3, 3), stride=(1, 1))
    (1): ReLU()
    (2): BatchNorm2d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (3): Conv2d(32, 32, kernel_size=(3, 3), stride=(1, 1))
    (4): ReLU()
    (5): BatchNorm2d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
  )
  (fc_feature): Sequential(
    (0): Linear(in_features=288, out_features=512, bias=True)
    (1): ReLU()
    (2): Linear(in_features=512, out_features=4, bias=True)
  )
)
INFO: model downloaded at: /home/eirik/Projects/XAI/artifacts/model_1550:v42
INFO: Metadata: {'steps_done': 139293}
INFO: Number of parameters: 159716
INFO: QNetwork(
  (conv_feature): Sequential(
    (0): Conv2d(1, 32, kernel_size=(3, 3), stride=(1, 1))
    (1): ReLU()
    (2): BatchNorm2d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (3): Conv2d(32, 32, kernel_size=(3, 3), stride=(1, 1))
    (4): ReLU()
    (5): BatchNorm2d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
  )
  (fc_feature): Sequential(
    (0): Linear(in_features=288, out_features=512, bias=True)
    (1): ReLU()
    (2): Linear(in_features=512, out_features=4, bias=True)
  )
)
WARNING: GIF is enabled but the environment does not support RGB array rendering.
INFO: Learning...
INFO: Number of parameters: 23557
INFO: QNetwork(
  (conv_feature): Sequential()
  (fc_feature): Sequential(
    (0): Linear(in_features=49, out_features=128, bias=True)
    (1): ReLU()
    (2): Linear(in_features=128, out_features=128, bias=True)
    (3): ReLU()
    (4): Linear(in_features=128, out_features=5, bias=True)
  )
)
WARNING: GIF is enabled but the environment does not support RGB array rendering.
INFO: Learning...
INFO: Number of parameters: 30085
INFO: QNetwork(
  (conv_feature): Sequential()
  (fc_feature): Sequential(
    (0): Linear(in_features=100, out_features=128, bias=True)
    (1): ReLU()
    (2): Linear(in_features=128, out_features=128, bias=True)
    (3): ReLU()
    (4): Linear(in_features=128, out_features=5, bias=True)
  )
)
WARNING: GIF is enabled but the environment does not support RGB array rendering.
INFO: Learning...
INFO: Number of parameters: 183845
INFO: QNetwork(
  (conv_feature): Sequential(
    (0): Conv2d(1, 64, kernel_size=(3, 3), stride=(1, 1))
    (1): ReLU()
    (2): Conv2d(64, 32, kernel_size=(3, 3), stride=(1, 1))
    (3): ReLU()
  )
  (fc_feature): Sequential(
    (0): Linear(in_features=1152, out_features=128, bias=True)
    (1): ReLU()
    (2): Linear(in_features=128, out_features=128, bias=True)
    (3): ReLU()
    (4): Linear(in_features=128, out_features=5, bias=True)
  )
)
WARNING: GIF is enabled but the environment does not support RGB array rendering.
INFO: Learning...
INFO: Number of parameters: 183845
INFO: QNetwork(
  (conv_feature): Sequential(
    (0): Conv2d(1, 64, kernel_size=(3, 3), stride=(1, 1))
    (1): ReLU()
    (2): Conv2d(64, 32, kernel_size=(3, 3), stride=(1, 1))
    (3): ReLU()
  )
  (fc_feature): Sequential(
    (0): Linear(in_features=1152, out_features=128, bias=True)
    (1): ReLU()
    (2): Linear(in_features=128, out_features=128, bias=True)
    (3): ReLU()
    (4): Linear(in_features=128, out_features=5, bias=True)
  )
)
WARNING: GIF is enabled but the environment does not support RGB array rendering.
INFO: Learning...
INFO: Number of parameters: 183845
INFO: QNetwork(
  (conv_feature): Sequential(
    (0): Conv2d(1, 64, kernel_size=(3, 3), stride=(1, 1))
    (1): ReLU()
    (2): Conv2d(64, 32, kernel_size=(3, 3), stride=(1, 1))
    (3): ReLU()
  )
  (fc_feature): Sequential(
    (0): Linear(in_features=1152, out_features=128, bias=True)
    (1): ReLU()
    (2): Linear(in_features=128, out_features=128, bias=True)
    (3): ReLU()
    (4): Linear(in_features=128, out_features=5, bias=True)
  )
)
WARNING: GIF is enabled but the environment does not support RGB array rendering.
INFO: Learning...
INFO: Number of parameters: 250022
INFO: QNetwork(
  (conv_feature): Sequential(
    (0): Conv2d(1, 64, kernel_size=(3, 3), stride=(1, 1))
    (1): ReLU()
    (2): Conv2d(64, 32, kernel_size=(3, 3), stride=(1, 1))
    (3): ReLU()
  )
  (fc_feature): Sequential(
    (0): Linear(in_features=1152, out_features=128, bias=True)
    (1): ReLU()
    (2): Linear(in_features=128, out_features=128, bias=True)
    (3): ReLU()
  )
  (value_stream): Sequential(
    (0): Linear(in_features=128, out_features=128, bias=True)
    (1): ReLU()
    (2): Linear(in_features=128, out_features=128, bias=True)
    (3): ReLU()
    (4): Linear(in_features=128, out_features=1, bias=True)
  )
  (advantage_stream): Sequential(
    (0): Linear(in_features=128, out_features=128, bias=True)
    (1): ReLU()
    (2): Linear(in_features=128, out_features=128, bias=True)
    (3): ReLU()
    (4): Linear(in_features=128, out_features=5, bias=True)
  )
)
WARNING: GIF is enabled but the environment does not support RGB array rendering.
INFO: Learning...
INFO: Number of parameters: 250022
INFO: QNetwork(
  (conv_feature): Sequential(
    (0): Conv2d(1, 64, kernel_size=(3, 3), stride=(1, 1))
    (1): ReLU()
    (2): Conv2d(64, 32, kernel_size=(3, 3), stride=(1, 1))
    (3): ReLU()
  )
  (fc_feature): Sequential(
    (0): Linear(in_features=1152, out_features=128, bias=True)
    (1): ReLU()
    (2): Linear(in_features=128, out_features=128, bias=True)
    (3): ReLU()
  )
  (value_stream): Sequential(
    (0): Linear(in_features=128, out_features=128, bias=True)
    (1): ReLU()
    (2): Linear(in_features=128, out_features=128, bias=True)
    (3): ReLU()
    (4): Linear(in_features=128, out_features=1, bias=True)
  )
  (advantage_stream): Sequential(
    (0): Linear(in_features=128, out_features=128, bias=True)
    (1): ReLU()
    (2): Linear(in_features=128, out_features=128, bias=True)
    (3): ReLU()
    (4): Linear(in_features=128, out_features=5, bias=True)
  )
)
WARNING: GIF is enabled but the environment does not support RGB array rendering.
INFO: Learning...
INFO: Number of parameters: 250022
INFO: QNetwork(
  (conv_feature): Sequential(
    (0): Conv2d(1, 64, kernel_size=(3, 3), stride=(1, 1))
    (1): ReLU()
    (2): Conv2d(64, 32, kernel_size=(3, 3), stride=(1, 1))
    (3): ReLU()
  )
  (fc_feature): Sequential(
    (0): Linear(in_features=1152, out_features=128, bias=True)
    (1): ReLU()
    (2): Linear(in_features=128, out_features=128, bias=True)
    (3): ReLU()
  )
  (value_stream): Sequential(
    (0): Linear(in_features=128, out_features=128, bias=True)
    (1): ReLU()
    (2): Linear(in_features=128, out_features=128, bias=True)
    (3): ReLU()
    (4): Linear(in_features=128, out_features=1, bias=True)
  )
  (advantage_stream): Sequential(
    (0): Linear(in_features=128, out_features=128, bias=True)
    (1): ReLU()
    (2): Linear(in_features=128, out_features=128, bias=True)
    (3): ReLU()
    (4): Linear(in_features=128, out_features=5, bias=True)
  )
)
WARNING: GIF is enabled but the environment does not support RGB array rendering.
INFO: Learning...
INFO: Number of parameters: 250022
INFO: QNetwork(
  (conv_feature): Sequential(
    (0): Conv2d(1, 64, kernel_size=(3, 3), stride=(1, 1))
    (1): ReLU()
    (2): Conv2d(64, 32, kernel_size=(3, 3), stride=(1, 1))
    (3): ReLU()
  )
  (fc_feature): Sequential(
    (0): Linear(in_features=1152, out_features=128, bias=True)
    (1): ReLU()
    (2): Linear(in_features=128, out_features=128, bias=True)
    (3): ReLU()
  )
  (value_stream): Sequential(
    (0): Linear(in_features=128, out_features=128, bias=True)
    (1): ReLU()
    (2): Linear(in_features=128, out_features=128, bias=True)
    (3): ReLU()
    (4): Linear(in_features=128, out_features=1, bias=True)
  )
  (advantage_stream): Sequential(
    (0): Linear(in_features=128, out_features=128, bias=True)
    (1): ReLU()
    (2): Linear(in_features=128, out_features=128, bias=True)
    (3): ReLU()
    (4): Linear(in_features=128, out_features=5, bias=True)
  )
)
WARNING: GIF is enabled but the environment does not support RGB array rendering.
INFO: Learning...
INFO: Number of parameters: 250022
INFO: QNetwork(
  (conv_feature): Sequential(
    (0): Conv2d(1, 64, kernel_size=(3, 3), stride=(1, 1))
    (1): ReLU()
    (2): Conv2d(64, 32, kernel_size=(3, 3), stride=(1, 1))
    (3): ReLU()
  )
  (fc_feature): Sequential(
    (0): Linear(in_features=1152, out_features=128, bias=True)
    (1): ReLU()
    (2): Linear(in_features=128, out_features=128, bias=True)
    (3): ReLU()
  )
  (value_stream): Sequential(
    (0): Linear(in_features=128, out_features=128, bias=True)
    (1): ReLU()
    (2): Linear(in_features=128, out_features=128, bias=True)
    (3): ReLU()
    (4): Linear(in_features=128, out_features=1, bias=True)
  )
  (advantage_stream): Sequential(
    (0): Linear(in_features=128, out_features=128, bias=True)
    (1): ReLU()
    (2): Linear(in_features=128, out_features=128, bias=True)
    (3): ReLU()
    (4): Linear(in_features=128, out_features=5, bias=True)
  )
)
INFO: Number of parameters: 250022
INFO: QNetwork(
  (conv_feature): Sequential(
    (0): Conv2d(1, 64, kernel_size=(3, 3), stride=(1, 1))
    (1): ReLU()
    (2): Conv2d(64, 32, kernel_size=(3, 3), stride=(1, 1))
    (3): ReLU()
  )
  (fc_feature): Sequential(
    (0): Linear(in_features=1152, out_features=128, bias=True)
    (1): ReLU()
    (2): Linear(in_features=128, out_features=128, bias=True)
    (3): ReLU()
  )
  (value_stream): Sequential(
    (0): Linear(in_features=128, out_features=128, bias=True)
    (1): ReLU()
    (2): Linear(in_features=128, out_features=128, bias=True)
    (3): ReLU()
    (4): Linear(in_features=128, out_features=1, bias=True)
  )
  (advantage_stream): Sequential(
    (0): Linear(in_features=128, out_features=128, bias=True)
    (1): ReLU()
    (2): Linear(in_features=128, out_features=128, bias=True)
    (3): ReLU()
    (4): Linear(in_features=128, out_features=5, bias=True)
  )
)
WARNING: GIF is enabled but the environment does not support RGB array rendering.
INFO: Learning...
ERROR: You must call wandb.init() before wandb.log()
ERROR: Traceback (most recent call last):
  File "/home/eirik/Projects/XAI/rl/src/dqn/wrapper/multi_agent_dqn.py", line 139, in learn
    self.wandb_manager.log(log)
  File "/home/eirik/Projects/XAI/managers/src/wandb_manager.py", line 104, in log
    wandb.log(data)
  File "/home/eirik/.cache/pypoetry/virtualenvs/xai-is73Zs3s-py3.11/lib/python3.11/site-packages/wandb/sdk/lib/preinit.py", line 36, in preinit_wrapper
    raise wandb.Error(f"You must call wandb.init() before {name}()")
wandb.errors.errors.Error: You must call wandb.init() before wandb.log()

WARNING: Error: Could not find wandb directory: ./wandb
WARNING: Error: Could not find wandb directory: ./wandb
INFO: Number of parameters: 250022
INFO: QNetwork(
  (conv_feature): Sequential(
    (0): Conv2d(1, 64, kernel_size=(3, 3), stride=(1, 1))
    (1): ReLU()
    (2): Conv2d(64, 32, kernel_size=(3, 3), stride=(1, 1))
    (3): ReLU()
  )
  (fc_feature): Sequential(
    (0): Linear(in_features=1152, out_features=128, bias=True)
    (1): ReLU()
    (2): Linear(in_features=128, out_features=128, bias=True)
    (3): ReLU()
  )
  (value_stream): Sequential(
    (0): Linear(in_features=128, out_features=128, bias=True)
    (1): ReLU()
    (2): Linear(in_features=128, out_features=128, bias=True)
    (3): ReLU()
    (4): Linear(in_features=128, out_features=1, bias=True)
  )
  (advantage_stream): Sequential(
    (0): Linear(in_features=128, out_features=128, bias=True)
    (1): ReLU()
    (2): Linear(in_features=128, out_features=128, bias=True)
    (3): ReLU()
    (4): Linear(in_features=128, out_features=5, bias=True)
  )
)
WARNING: GIF is enabled but the environment does not support RGB array rendering.
INFO: Learning...
INFO: Number of parameters: 30085
INFO: QNetwork(
  (conv_feature): Sequential()
  (fc_feature): Sequential(
    (0): Linear(in_features=100, out_features=128, bias=True)
    (1): ReLU()
    (2): Linear(in_features=128, out_features=128, bias=True)
    (3): ReLU()
    (4): Linear(in_features=128, out_features=5, bias=True)
  )
)
WARNING: GIF is enabled but the environment does not support RGB array rendering.
INFO: Learning...
INFO: Number of parameters: 174309
INFO: QNetwork(
  (conv_feature): Sequential(
    (0): Conv2d(1, 32, kernel_size=(3, 3), stride=(1, 1))
    (1): ReLU()
    (2): Conv2d(32, 32, kernel_size=(3, 3), stride=(1, 1))
    (3): ReLU()
  )
  (fc_feature): Sequential(
    (0): Linear(in_features=1152, out_features=128, bias=True)
    (1): ReLU()
    (2): Linear(in_features=128, out_features=128, bias=True)
    (3): ReLU()
    (4): Linear(in_features=128, out_features=5, bias=True)
  )
)
WARNING: GIF is enabled but the environment does not support RGB array rendering.
INFO: Learning...
INFO: Number of parameters: 174309
INFO: QNetwork(
  (conv_feature): Sequential(
    (0): Conv2d(1, 32, kernel_size=(3, 3), stride=(1, 1))
    (1): ReLU()
    (2): Conv2d(32, 32, kernel_size=(3, 3), stride=(1, 1))
    (3): ReLU()
  )
  (fc_feature): Sequential(
    (0): Linear(in_features=1152, out_features=128, bias=True)
    (1): ReLU()
    (2): Linear(in_features=128, out_features=128, bias=True)
    (3): ReLU()
    (4): Linear(in_features=128, out_features=5, bias=True)
  )
)
WARNING: GIF is enabled but the environment does not support RGB array rendering.
INFO: Learning...
ERROR: 'TagRenderer' object has no attribute 'post_init_screen'
ERROR: Traceback (most recent call last):
  File "/home/eirik/Projects/XAI/rl/src/dqn/wrapper/multi_agent_dqn.py", line 108, in learn
    self._collect_rollouts()
  File "/home/eirik/Projects/XAI/rl/src/dqn/wrapper/multi_agent_dqn.py", line 206, in _collect_rollouts
    ) = self.env.get_wrapper_attr("step_multiple")(actions)
        ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/eirik/Projects/XAI/environments/gymnasium/wrappers/multi_agent_env.py", line 44, in step_multiple
    ) = self.get_wrapper_attr("concatenate_states")(full_states)
        ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/eirik/Projects/XAI/environments/gymnasium/envs/tag/tag.py", line 271, in concatenate_states
    self.render()
  File "/home/eirik/Projects/XAI/environments/gymnasium/envs/tag/tag.py", line 247, in render
    return self.tag_renderer.render(self.state.full, render_mode)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/eirik/Projects/XAI/environments/gymnasium/envs/tag/tag_renderer.py", line 86, in render
    self._init_screen()
  File "/home/eirik/Projects/XAI/environments/gymnasium/envs/tag/tag_renderer.py", line 40, in _init_screen
    if self.post_init_screen:
       ^^^^^^^^^^^^^^^^^^^^^
AttributeError: 'TagRenderer' object has no attribute 'post_init_screen'

INFO: Number of parameters: 174309
INFO: QNetwork(
  (conv_feature): Sequential(
    (0): Conv2d(1, 32, kernel_size=(3, 3), stride=(1, 1))
    (1): ReLU()
    (2): Conv2d(32, 32, kernel_size=(3, 3), stride=(1, 1))
    (3): ReLU()
  )
  (fc_feature): Sequential(
    (0): Linear(in_features=1152, out_features=128, bias=True)
    (1): ReLU()
    (2): Linear(in_features=128, out_features=128, bias=True)
    (3): ReLU()
    (4): Linear(in_features=128, out_features=5, bias=True)
  )
)
WARNING: GIF is enabled but the environment does not support RGB array rendering.
INFO: Learning...
INFO: Number of parameters: 174309
INFO: QNetwork(
  (conv_feature): Sequential(
    (0): Conv2d(1, 32, kernel_size=(3, 3), stride=(1, 1))
    (1): ReLU()
    (2): Conv2d(32, 32, kernel_size=(3, 3), stride=(1, 1))
    (3): ReLU()
  )
  (fc_feature): Sequential(
    (0): Linear(in_features=1152, out_features=128, bias=True)
    (1): ReLU()
    (2): Linear(in_features=128, out_features=128, bias=True)
    (3): ReLU()
    (4): Linear(in_features=128, out_features=5, bias=True)
  )
)
WARNING: GIF is enabled but the environment does not support RGB array rendering.
INFO: Learning...
INFO: Number of parameters: 174309
INFO: QNetwork(
  (conv_feature): Sequential(
    (0): Conv2d(1, 32, kernel_size=(3, 3), stride=(1, 1))
    (1): ReLU()
    (2): Conv2d(32, 32, kernel_size=(3, 3), stride=(1, 1))
    (3): ReLU()
  )
  (fc_feature): Sequential(
    (0): Linear(in_features=1152, out_features=128, bias=True)
    (1): ReLU()
    (2): Linear(in_features=128, out_features=128, bias=True)
    (3): ReLU()
    (4): Linear(in_features=128, out_features=5, bias=True)
  )
)
WARNING: GIF is enabled but the environment does not support RGB array rendering.
INFO: Learning...
INFO: Number of parameters: 174309
INFO: QNetwork(
  (conv_feature): Sequential(
    (0): Conv2d(1, 32, kernel_size=(3, 3), stride=(1, 1))
    (1): ReLU()
    (2): Conv2d(32, 32, kernel_size=(3, 3), stride=(1, 1))
    (3): ReLU()
  )
  (fc_feature): Sequential(
    (0): Linear(in_features=1152, out_features=128, bias=True)
    (1): ReLU()
    (2): Linear(in_features=128, out_features=128, bias=True)
    (3): ReLU()
    (4): Linear(in_features=128, out_features=5, bias=True)
  )
)
WARNING: GIF is enabled but the environment does not support RGB array rendering.
INFO: Learning...
INFO: Number of parameters: 174309
INFO: QNetwork(
  (conv_feature): Sequential(
    (0): Conv2d(1, 32, kernel_size=(3, 3), stride=(1, 1))
    (1): ReLU()
    (2): Conv2d(32, 32, kernel_size=(3, 3), stride=(1, 1))
    (3): ReLU()
  )
  (fc_feature): Sequential(
    (0): Linear(in_features=1152, out_features=128, bias=True)
    (1): ReLU()
    (2): Linear(in_features=128, out_features=128, bias=True)
    (3): ReLU()
    (4): Linear(in_features=128, out_features=5, bias=True)
  )
)
WARNING: GIF is enabled but the environment does not support RGB array rendering.
INFO: Learning...
INFO: Number of parameters: 174309
INFO: QNetwork(
  (conv_feature): Sequential(
    (0): Conv2d(1, 32, kernel_size=(3, 3), stride=(1, 1))
    (1): ReLU()
    (2): Conv2d(32, 32, kernel_size=(3, 3), stride=(1, 1))
    (3): ReLU()
  )
  (fc_feature): Sequential(
    (0): Linear(in_features=1152, out_features=128, bias=True)
    (1): ReLU()
    (2): Linear(in_features=128, out_features=128, bias=True)
    (3): ReLU()
    (4): Linear(in_features=128, out_features=5, bias=True)
  )
)
WARNING: GIF is enabled but the environment does not support RGB array rendering.
INFO: Learning...
INFO: Number of parameters: 174309
INFO: QNetwork(
  (conv_feature): Sequential(
    (0): Conv2d(1, 32, kernel_size=(3, 3), stride=(1, 1))
    (1): ReLU()
    (2): Conv2d(32, 32, kernel_size=(3, 3), stride=(1, 1))
    (3): ReLU()
  )
  (fc_feature): Sequential(
    (0): Linear(in_features=1152, out_features=128, bias=True)
    (1): ReLU()
    (2): Linear(in_features=128, out_features=128, bias=True)
    (3): ReLU()
    (4): Linear(in_features=128, out_features=5, bias=True)
  )
)
WARNING: GIF is enabled but the environment does not support RGB array rendering.
INFO: Learning...
INFO: Number of parameters: 174309
INFO: QNetwork(
  (conv_feature): Sequential(
    (0): Conv2d(1, 32, kernel_size=(3, 3), stride=(1, 1))
    (1): ReLU()
    (2): Conv2d(32, 32, kernel_size=(3, 3), stride=(1, 1))
    (3): ReLU()
  )
  (fc_feature): Sequential(
    (0): Linear(in_features=1152, out_features=128, bias=True)
    (1): ReLU()
    (2): Linear(in_features=128, out_features=128, bias=True)
    (3): ReLU()
    (4): Linear(in_features=128, out_features=5, bias=True)
  )
)
WARNING: GIF is enabled but the environment does not support RGB array rendering.
INFO: Learning...
INFO: Number of parameters: 174309
INFO: QNetwork(
  (conv_feature): Sequential(
    (0): Conv2d(1, 32, kernel_size=(3, 3), stride=(1, 1))
    (1): ReLU()
    (2): Conv2d(32, 32, kernel_size=(3, 3), stride=(1, 1))
    (3): ReLU()
  )
  (fc_feature): Sequential(
    (0): Linear(in_features=1152, out_features=128, bias=True)
    (1): ReLU()
    (2): Linear(in_features=128, out_features=128, bias=True)
    (3): ReLU()
    (4): Linear(in_features=128, out_features=5, bias=True)
  )
)
WARNING: GIF is enabled but the environment does not support RGB array rendering.
INFO: Learning...
INFO: Number of parameters: 174309
INFO: QNetwork(
  (conv_feature): Sequential(
    (0): Conv2d(1, 32, kernel_size=(3, 3), stride=(1, 1))
    (1): ReLU()
    (2): Conv2d(32, 32, kernel_size=(3, 3), stride=(1, 1))
    (3): ReLU()
  )
  (fc_feature): Sequential(
    (0): Linear(in_features=1152, out_features=128, bias=True)
    (1): ReLU()
    (2): Linear(in_features=128, out_features=128, bias=True)
    (3): ReLU()
    (4): Linear(in_features=128, out_features=5, bias=True)
  )
)
WARNING: GIF is enabled but the environment does not support RGB array rendering.
INFO: Learning...
INFO: Number of parameters: 174309
INFO: QNetwork(
  (conv_feature): Sequential(
    (0): Conv2d(1, 32, kernel_size=(3, 3), stride=(1, 1))
    (1): ReLU()
    (2): Conv2d(32, 32, kernel_size=(3, 3), stride=(1, 1))
    (3): ReLU()
  )
  (fc_feature): Sequential(
    (0): Linear(in_features=1152, out_features=128, bias=True)
    (1): ReLU()
    (2): Linear(in_features=128, out_features=128, bias=True)
    (3): ReLU()
    (4): Linear(in_features=128, out_features=5, bias=True)
  )
)
WARNING: GIF is enabled but the environment does not support RGB array rendering.
INFO: Learning...
INFO: Number of parameters: 174309
INFO: QNetwork(
  (conv_feature): Sequential(
    (0): Conv2d(1, 32, kernel_size=(3, 3), stride=(1, 1))
    (1): ReLU()
    (2): Conv2d(32, 32, kernel_size=(3, 3), stride=(1, 1))
    (3): ReLU()
  )
  (fc_feature): Sequential(
    (0): Linear(in_features=1152, out_features=128, bias=True)
    (1): ReLU()
    (2): Linear(in_features=128, out_features=128, bias=True)
    (3): ReLU()
    (4): Linear(in_features=128, out_features=5, bias=True)
  )
)
WARNING: GIF is enabled but the environment does not support RGB array rendering.
INFO: Learning...
INFO: Number of parameters: 174309
INFO: QNetwork(
  (conv_feature): Sequential(
    (0): Conv2d(1, 32, kernel_size=(3, 3), stride=(1, 1))
    (1): ReLU()
    (2): Conv2d(32, 32, kernel_size=(3, 3), stride=(1, 1))
    (3): ReLU()
  )
  (fc_feature): Sequential(
    (0): Linear(in_features=1152, out_features=128, bias=True)
    (1): ReLU()
    (2): Linear(in_features=128, out_features=128, bias=True)
    (3): ReLU()
    (4): Linear(in_features=128, out_features=5, bias=True)
  )
)
WARNING: GIF is enabled but the environment does not support RGB array rendering.
INFO: Learning...
INFO: Number of parameters: 174309
INFO: QNetwork(
  (conv_feature): Sequential(
    (0): Conv2d(1, 32, kernel_size=(3, 3), stride=(1, 1))
    (1): ReLU()
    (2): Conv2d(32, 32, kernel_size=(3, 3), stride=(1, 1))
    (3): ReLU()
  )
  (fc_feature): Sequential(
    (0): Linear(in_features=1152, out_features=128, bias=True)
    (1): ReLU()
    (2): Linear(in_features=128, out_features=128, bias=True)
    (3): ReLU()
    (4): Linear(in_features=128, out_features=5, bias=True)
  )
)
WARNING: GIF is enabled but the environment does not support RGB array rendering.
INFO: Learning...
INFO: Number of parameters: 174309
INFO: QNetwork(
  (conv_feature): Sequential(
    (0): Conv2d(1, 32, kernel_size=(3, 3), stride=(1, 1))
    (1): ReLU()
    (2): Conv2d(32, 32, kernel_size=(3, 3), stride=(1, 1))
    (3): ReLU()
  )
  (fc_feature): Sequential(
    (0): Linear(in_features=1152, out_features=128, bias=True)
    (1): ReLU()
    (2): Linear(in_features=128, out_features=128, bias=True)
    (3): ReLU()
    (4): Linear(in_features=128, out_features=5, bias=True)
  )
)
WARNING: GIF is enabled but the environment does not support RGB array rendering.
INFO: Learning...
INFO: Number of parameters: 174309
INFO: QNetwork(
  (conv_feature): Sequential(
    (0): Conv2d(1, 32, kernel_size=(3, 3), stride=(1, 1))
    (1): ReLU()
    (2): Conv2d(32, 32, kernel_size=(3, 3), stride=(1, 1))
    (3): ReLU()
  )
  (fc_feature): Sequential(
    (0): Linear(in_features=1152, out_features=128, bias=True)
    (1): ReLU()
    (2): Linear(in_features=128, out_features=128, bias=True)
    (3): ReLU()
    (4): Linear(in_features=128, out_features=5, bias=True)
  )
)
INFO: Learning...
INFO: Number of parameters: 174309
INFO: QNetwork(
  (conv_feature): Sequential(
    (0): Conv2d(1, 32, kernel_size=(3, 3), stride=(1, 1))
    (1): ReLU()
    (2): Conv2d(32, 32, kernel_size=(3, 3), stride=(1, 1))
    (3): ReLU()
  )
  (fc_feature): Sequential(
    (0): Linear(in_features=1152, out_features=128, bias=True)
    (1): ReLU()
    (2): Linear(in_features=128, out_features=128, bias=True)
    (3): ReLU()
    (4): Linear(in_features=128, out_features=5, bias=True)
  )
)
INFO: Learning...
INFO: Number of parameters: 174309
INFO: QNetwork(
  (conv_feature): Sequential(
    (0): Conv2d(1, 32, kernel_size=(3, 3), stride=(1, 1))
    (1): ReLU()
    (2): Conv2d(32, 32, kernel_size=(3, 3), stride=(1, 1))
    (3): ReLU()
  )
  (fc_feature): Sequential(
    (0): Linear(in_features=1152, out_features=128, bias=True)
    (1): ReLU()
    (2): Linear(in_features=128, out_features=128, bias=True)
    (3): ReLU()
    (4): Linear(in_features=128, out_features=5, bias=True)
  )
)
WARNING: GIF is enabled but the environment does not support RGB array rendering.
INFO: Learning...
INFO: Number of parameters: 174309
INFO: QNetwork(
  (conv_feature): Sequential(
    (0): Conv2d(1, 32, kernel_size=(3, 3), stride=(1, 1))
    (1): ReLU()
    (2): Conv2d(32, 32, kernel_size=(3, 3), stride=(1, 1))
    (3): ReLU()
  )
  (fc_feature): Sequential(
    (0): Linear(in_features=1152, out_features=128, bias=True)
    (1): ReLU()
    (2): Linear(in_features=128, out_features=128, bias=True)
    (3): ReLU()
    (4): Linear(in_features=128, out_features=5, bias=True)
  )
)
WARNING: GIF is enabled but the environment does not support RGB array rendering.
INFO: Learning...
INFO: Number of parameters: 174309
INFO: QNetwork(
  (conv_feature): Sequential(
    (0): Conv2d(1, 32, kernel_size=(3, 3), stride=(1, 1))
    (1): ReLU()
    (2): Conv2d(32, 32, kernel_size=(3, 3), stride=(1, 1))
    (3): ReLU()
  )
  (fc_feature): Sequential(
    (0): Linear(in_features=1152, out_features=128, bias=True)
    (1): ReLU()
    (2): Linear(in_features=128, out_features=128, bias=True)
    (3): ReLU()
    (4): Linear(in_features=128, out_features=5, bias=True)
  )
)
WARNING: GIF is enabled but the environment does not support RGB array rendering.
INFO: Learning...
INFO: Number of parameters: 174309
INFO: QNetwork(
  (conv_feature): Sequential(
    (0): Conv2d(1, 32, kernel_size=(3, 3), stride=(1, 1))
    (1): ReLU()
    (2): Conv2d(32, 32, kernel_size=(3, 3), stride=(1, 1))
    (3): ReLU()
  )
  (fc_feature): Sequential(
    (0): Linear(in_features=1152, out_features=128, bias=True)
    (1): ReLU()
    (2): Linear(in_features=128, out_features=128, bias=True)
    (3): ReLU()
    (4): Linear(in_features=128, out_features=5, bias=True)
  )
)
WARNING: GIF is enabled but the environment does not support RGB array rendering.
INFO: Learning...
INFO: Number of parameters: 174309
INFO: QNetwork(
  (conv_feature): Sequential(
    (0): Conv2d(1, 32, kernel_size=(3, 3), stride=(1, 1))
    (1): ReLU()
    (2): Conv2d(32, 32, kernel_size=(3, 3), stride=(1, 1))
    (3): ReLU()
  )
  (fc_feature): Sequential(
    (0): Linear(in_features=1152, out_features=128, bias=True)
    (1): ReLU()
    (2): Linear(in_features=128, out_features=128, bias=True)
    (3): ReLU()
    (4): Linear(in_features=128, out_features=5, bias=True)
  )
)
INFO: Number of parameters: 174309
INFO: QNetwork(
  (conv_feature): Sequential(
    (0): Conv2d(1, 32, kernel_size=(3, 3), stride=(1, 1))
    (1): ReLU()
    (2): Conv2d(32, 32, kernel_size=(3, 3), stride=(1, 1))
    (3): ReLU()
  )
  (fc_feature): Sequential(
    (0): Linear(in_features=1152, out_features=128, bias=True)
    (1): ReLU()
    (2): Linear(in_features=128, out_features=128, bias=True)
    (3): ReLU()
    (4): Linear(in_features=128, out_features=5, bias=True)
  )
)
INFO: Learning...
INFO: Number of parameters: 174309
INFO: QNetwork(
  (conv_feature): Sequential(
    (0): Conv2d(1, 32, kernel_size=(3, 3), stride=(1, 1))
    (1): ReLU()
    (2): Conv2d(32, 32, kernel_size=(3, 3), stride=(1, 1))
    (3): ReLU()
  )
  (fc_feature): Sequential(
    (0): Linear(in_features=1152, out_features=128, bias=True)
    (1): ReLU()
    (2): Linear(in_features=128, out_features=128, bias=True)
    (3): ReLU()
    (4): Linear(in_features=128, out_features=5, bias=True)
  )
)
INFO: Learning...
INFO: Number of parameters: 174309
INFO: QNetwork(
  (conv_feature): Sequential(
    (0): Conv2d(1, 32, kernel_size=(3, 3), stride=(1, 1))
    (1): ReLU()
    (2): Conv2d(32, 32, kernel_size=(3, 3), stride=(1, 1))
    (3): ReLU()
  )
  (fc_feature): Sequential(
    (0): Linear(in_features=1152, out_features=128, bias=True)
    (1): ReLU()
    (2): Linear(in_features=128, out_features=128, bias=True)
    (3): ReLU()
    (4): Linear(in_features=128, out_features=5, bias=True)
  )
)
INFO: Learning...
INFO: Number of parameters: 174309
INFO: QNetwork(
  (conv_feature): Sequential(
    (0): Conv2d(1, 32, kernel_size=(3, 3), stride=(1, 1))
    (1): ReLU()
    (2): Conv2d(32, 32, kernel_size=(3, 3), stride=(1, 1))
    (3): ReLU()
  )
  (fc_feature): Sequential(
    (0): Linear(in_features=1152, out_features=128, bias=True)
    (1): ReLU()
    (2): Linear(in_features=128, out_features=128, bias=True)
    (3): ReLU()
    (4): Linear(in_features=128, out_features=5, bias=True)
  )
)
WARNING: GIF is enabled but the environment does not support RGB array rendering.
INFO: Learning...
INFO: Number of parameters: 174309
INFO: QNetwork(
  (conv_feature): Sequential(
    (0): Conv2d(1, 32, kernel_size=(3, 3), stride=(1, 1))
    (1): ReLU()
    (2): Conv2d(32, 32, kernel_size=(3, 3), stride=(1, 1))
    (3): ReLU()
  )
  (fc_feature): Sequential(
    (0): Linear(in_features=1152, out_features=128, bias=True)
    (1): ReLU()
    (2): Linear(in_features=128, out_features=128, bias=True)
    (3): ReLU()
    (4): Linear(in_features=128, out_features=5, bias=True)
  )
)
WARNING: GIF is enabled but the environment does not support RGB array rendering.
INFO: Learning...
INFO: Number of parameters: 174309
INFO: QNetwork(
  (conv_feature): Sequential(
    (0): Conv2d(1, 32, kernel_size=(3, 3), stride=(1, 1))
    (1): ReLU()
    (2): Conv2d(32, 32, kernel_size=(3, 3), stride=(1, 1))
    (3): ReLU()
  )
  (fc_feature): Sequential(
    (0): Linear(in_features=1152, out_features=128, bias=True)
    (1): ReLU()
    (2): Linear(in_features=128, out_features=128, bias=True)
    (3): ReLU()
    (4): Linear(in_features=128, out_features=5, bias=True)
  )
)
WARNING: GIF is enabled but the environment does not support RGB array rendering.
INFO: Learning...
WARNING: No frames in gif to save.
WARNING: No frames in gif to save.
INFO: Number of parameters: 174309
INFO: QNetwork(
  (conv_feature): Sequential(
    (0): Conv2d(1, 32, kernel_size=(3, 3), stride=(1, 1))
    (1): ReLU()
    (2): Conv2d(32, 32, kernel_size=(3, 3), stride=(1, 1))
    (3): ReLU()
  )
  (fc_feature): Sequential(
    (0): Linear(in_features=1152, out_features=128, bias=True)
    (1): ReLU()
    (2): Linear(in_features=128, out_features=128, bias=True)
    (3): ReLU()
    (4): Linear(in_features=128, out_features=5, bias=True)
  )
)
WARNING: GIF is enabled but the environment does not support RGB array rendering.
INFO: Learning...
INFO: Number of parameters: 174309
INFO: QNetwork(
  (conv_feature): Sequential(
    (0): Conv2d(1, 32, kernel_size=(3, 3), stride=(1, 1))
    (1): ReLU()
    (2): Conv2d(32, 32, kernel_size=(3, 3), stride=(1, 1))
    (3): ReLU()
  )
  (fc_feature): Sequential(
    (0): Linear(in_features=1152, out_features=128, bias=True)
    (1): ReLU()
    (2): Linear(in_features=128, out_features=128, bias=True)
    (3): ReLU()
    (4): Linear(in_features=128, out_features=5, bias=True)
  )
)
WARNING: GIF is enabled but the environment does not support RGB array rendering.
INFO: Learning...
INFO: Number of parameters: 174309
INFO: QNetwork(
  (conv_feature): Sequential(
    (0): Conv2d(1, 32, kernel_size=(3, 3), stride=(1, 1))
    (1): ReLU()
    (2): Conv2d(32, 32, kernel_size=(3, 3), stride=(1, 1))
    (3): ReLU()
  )
  (fc_feature): Sequential(
    (0): Linear(in_features=1152, out_features=128, bias=True)
    (1): ReLU()
    (2): Linear(in_features=128, out_features=128, bias=True)
    (3): ReLU()
    (4): Linear(in_features=128, out_features=5, bias=True)
  )
)
WARNING: GIF is enabled but the environment does not support RGB array rendering.
INFO: Learning...
WARNING: No frames in gif to save.
WARNING: No frames in gif to save.
INFO: Number of parameters: 174309
INFO: QNetwork(
  (conv_feature): Sequential(
    (0): Conv2d(1, 32, kernel_size=(3, 3), stride=(1, 1))
    (1): ReLU()
    (2): Conv2d(32, 32, kernel_size=(3, 3), stride=(1, 1))
    (3): ReLU()
  )
  (fc_feature): Sequential(
    (0): Linear(in_features=1152, out_features=128, bias=True)
    (1): ReLU()
    (2): Linear(in_features=128, out_features=128, bias=True)
    (3): ReLU()
    (4): Linear(in_features=128, out_features=5, bias=True)
  )
)
WARNING: GIF is enabled but the environment does not support RGB array rendering.
INFO: Learning...
ERROR: 'TagRenderer' object has no attribute '_seeker_sprite'
ERROR: Traceback (most recent call last):
  File "/home/eirik/Projects/XAI/rl/src/dqn/wrapper/multi_agent_dqn.py", line 108, in learn
    self._collect_rollouts()
  File "/home/eirik/Projects/XAI/rl/src/dqn/wrapper/multi_agent_dqn.py", line 206, in _collect_rollouts
    ) = self.env.get_wrapper_attr("step_multiple")(actions)
        ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/eirik/Projects/XAI/environments/gymnasium/wrappers/multi_agent_env.py", line 44, in step_multiple
    ) = self.get_wrapper_attr("concatenate_states")(full_states)
        ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/eirik/Projects/XAI/environments/gymnasium/envs/tag/tag.py", line 284, in concatenate_states
    self.render()
  File "/home/eirik/Projects/XAI/environments/gymnasium/envs/tag/tag.py", line 258, in render
    return self.tag_renderer.render(self.state.full, render_mode)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/eirik/Projects/XAI/environments/gymnasium/envs/tag/tag_renderer.py", line 91, in render
    self.apply_color_masks(color_matrix, state)
  File "/home/eirik/Projects/XAI/environments/gymnasium/envs/tag/tag_renderer.py", line 128, in apply_color_masks
    if self._seeker_sprite is not None or self._hider_sprite is not None:
       ^^^^^^^^^^^^^^^^^^^
AttributeError: 'TagRenderer' object has no attribute '_seeker_sprite'

WARNING: Error: Could not find wandb directory: ./wandb
INFO: Number of parameters: 174309
INFO: QNetwork(
  (conv_feature): Sequential(
    (0): Conv2d(1, 32, kernel_size=(3, 3), stride=(1, 1))
    (1): ReLU()
    (2): Conv2d(32, 32, kernel_size=(3, 3), stride=(1, 1))
    (3): ReLU()
  )
  (fc_feature): Sequential(
    (0): Linear(in_features=1152, out_features=128, bias=True)
    (1): ReLU()
    (2): Linear(in_features=128, out_features=128, bias=True)
    (3): ReLU()
    (4): Linear(in_features=128, out_features=5, bias=True)
  )
)
WARNING: GIF is enabled but the environment does not support RGB array rendering.
INFO: Learning...
ERROR: 'TagRenderer' object has no attribute '_seeker_sprite'
ERROR: Traceback (most recent call last):
  File "/home/eirik/Projects/XAI/rl/src/dqn/wrapper/multi_agent_dqn.py", line 108, in learn
    self._collect_rollouts()
  File "/home/eirik/Projects/XAI/rl/src/dqn/wrapper/multi_agent_dqn.py", line 206, in _collect_rollouts
    ) = self.env.get_wrapper_attr("step_multiple")(actions)
        ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/eirik/Projects/XAI/environments/gymnasium/wrappers/multi_agent_env.py", line 44, in step_multiple
    ) = self.get_wrapper_attr("concatenate_states")(full_states)
        ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/eirik/Projects/XAI/environments/gymnasium/envs/tag/tag.py", line 284, in concatenate_states
    self.render()
  File "/home/eirik/Projects/XAI/environments/gymnasium/envs/tag/tag.py", line 258, in render
    return self.tag_renderer.render(self.state.full, render_mode)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/eirik/Projects/XAI/environments/gymnasium/envs/tag/tag_renderer.py", line 91, in render
    self.apply_color_masks(color_matrix, state)
  File "/home/eirik/Projects/XAI/environments/gymnasium/envs/tag/tag_renderer.py", line 129, in apply_color_masks
    if self._seeker_sprite is not None or self._hider_sprite is not None:
       ^^^^^^^^^^^^^^^^^^^
AttributeError: 'TagRenderer' object has no attribute '_seeker_sprite'

WARNING: Error: Could not find wandb directory: ./wandb
INFO: Number of parameters: 174309
INFO: QNetwork(
  (conv_feature): Sequential(
    (0): Conv2d(1, 32, kernel_size=(3, 3), stride=(1, 1))
    (1): ReLU()
    (2): Conv2d(32, 32, kernel_size=(3, 3), stride=(1, 1))
    (3): ReLU()
  )
  (fc_feature): Sequential(
    (0): Linear(in_features=1152, out_features=128, bias=True)
    (1): ReLU()
    (2): Linear(in_features=128, out_features=128, bias=True)
    (3): ReLU()
    (4): Linear(in_features=128, out_features=5, bias=True)
  )
)
WARNING: GIF is enabled but the environment does not support RGB array rendering.
INFO: Learning...
ERROR: int() argument must be a string, a bytes-like object or a real number, not 'pygame.surface.Surface'
ERROR: Traceback (most recent call last):
  File "/home/eirik/Projects/XAI/rl/src/dqn/wrapper/multi_agent_dqn.py", line 108, in learn
    self._collect_rollouts()
  File "/home/eirik/Projects/XAI/rl/src/dqn/wrapper/multi_agent_dqn.py", line 206, in _collect_rollouts
    ) = self.env.get_wrapper_attr("step_multiple")(actions)
        ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/eirik/Projects/XAI/environments/gymnasium/wrappers/multi_agent_env.py", line 44, in step_multiple
    ) = self.get_wrapper_attr("concatenate_states")(full_states)
        ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/eirik/Projects/XAI/environments/gymnasium/envs/tag/tag.py", line 284, in concatenate_states
    self.render()
  File "/home/eirik/Projects/XAI/environments/gymnasium/envs/tag/tag.py", line 258, in render
    return self.tag_renderer.render(self.state.full, render_mode)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/eirik/Projects/XAI/environments/gymnasium/envs/tag/tag_renderer.py", line 86, in render
    self.apply_color_masks(color_matrix, state)
  File "/home/eirik/Projects/XAI/environments/gymnasium/envs/tag/tag_renderer.py", line 123, in apply_color_masks
    color_matrix[full_state == TileType.SEEKER.value] = self._seeker_sprite
    ~~~~~~~~~~~~^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
TypeError: int() argument must be a string, a bytes-like object or a real number, not 'pygame.surface.Surface'

WARNING: Error: Could not find wandb directory: ./wandb
INFO: Number of parameters: 174309
INFO: QNetwork(
  (conv_feature): Sequential(
    (0): Conv2d(1, 32, kernel_size=(3, 3), stride=(1, 1))
    (1): ReLU()
    (2): Conv2d(32, 32, kernel_size=(3, 3), stride=(1, 1))
    (3): ReLU()
  )
  (fc_feature): Sequential(
    (0): Linear(in_features=1152, out_features=128, bias=True)
    (1): ReLU()
    (2): Linear(in_features=128, out_features=128, bias=True)
    (3): ReLU()
    (4): Linear(in_features=128, out_features=5, bias=True)
  )
)
WARNING: GIF is enabled but the environment does not support RGB array rendering.
INFO: Learning...
INFO: Number of parameters: 174309
INFO: QNetwork(
  (conv_feature): Sequential(
    (0): Conv2d(1, 32, kernel_size=(3, 3), stride=(1, 1))
    (1): ReLU()
    (2): Conv2d(32, 32, kernel_size=(3, 3), stride=(1, 1))
    (3): ReLU()
  )
  (fc_feature): Sequential(
    (0): Linear(in_features=1152, out_features=128, bias=True)
    (1): ReLU()
    (2): Linear(in_features=128, out_features=128, bias=True)
    (3): ReLU()
    (4): Linear(in_features=128, out_features=5, bias=True)
  )
)
WARNING: GIF is enabled but the environment does not support RGB array rendering.
INFO: Learning...
INFO: Number of parameters: 174309
INFO: QNetwork(
  (conv_feature): Sequential(
    (0): Conv2d(1, 32, kernel_size=(3, 3), stride=(1, 1))
    (1): ReLU()
    (2): Conv2d(32, 32, kernel_size=(3, 3), stride=(1, 1))
    (3): ReLU()
  )
  (fc_feature): Sequential(
    (0): Linear(in_features=1152, out_features=128, bias=True)
    (1): ReLU()
    (2): Linear(in_features=128, out_features=128, bias=True)
    (3): ReLU()
    (4): Linear(in_features=128, out_features=5, bias=True)
  )
)
WARNING: GIF is enabled but the environment does not support RGB array rendering.
INFO: Learning...
INFO: Number of parameters: 174309
INFO: QNetwork(
  (conv_feature): Sequential(
    (0): Conv2d(1, 32, kernel_size=(3, 3), stride=(1, 1))
    (1): ReLU()
    (2): Conv2d(32, 32, kernel_size=(3, 3), stride=(1, 1))
    (3): ReLU()
  )
  (fc_feature): Sequential(
    (0): Linear(in_features=1152, out_features=128, bias=True)
    (1): ReLU()
    (2): Linear(in_features=128, out_features=128, bias=True)
    (3): ReLU()
    (4): Linear(in_features=128, out_features=5, bias=True)
  )
)
WARNING: GIF is enabled but the environment does not support RGB array rendering.
INFO: Learning...
INFO: Number of parameters: 174309
INFO: QNetwork(
  (conv_feature): Sequential(
    (0): Conv2d(1, 32, kernel_size=(3, 3), stride=(1, 1))
    (1): ReLU()
    (2): Conv2d(32, 32, kernel_size=(3, 3), stride=(1, 1))
    (3): ReLU()
  )
  (fc_feature): Sequential(
    (0): Linear(in_features=1152, out_features=128, bias=True)
    (1): ReLU()
    (2): Linear(in_features=128, out_features=128, bias=True)
    (3): ReLU()
    (4): Linear(in_features=128, out_features=5, bias=True)
  )
)
WARNING: GIF is enabled but the environment does not support RGB array rendering.
INFO: Learning...
INFO: Number of parameters: 174309
INFO: QNetwork(
  (conv_feature): Sequential(
    (0): Conv2d(1, 32, kernel_size=(3, 3), stride=(1, 1))
    (1): ReLU()
    (2): Conv2d(32, 32, kernel_size=(3, 3), stride=(1, 1))
    (3): ReLU()
  )
  (fc_feature): Sequential(
    (0): Linear(in_features=1152, out_features=128, bias=True)
    (1): ReLU()
    (2): Linear(in_features=128, out_features=128, bias=True)
    (3): ReLU()
    (4): Linear(in_features=128, out_features=5, bias=True)
  )
)
WARNING: GIF is enabled but the environment does not support RGB array rendering.
INFO: Learning...
INFO: Number of parameters: 174309
INFO: QNetwork(
  (conv_feature): Sequential(
    (0): Conv2d(1, 32, kernel_size=(3, 3), stride=(1, 1))
    (1): ReLU()
    (2): Conv2d(32, 32, kernel_size=(3, 3), stride=(1, 1))
    (3): ReLU()
  )
  (fc_feature): Sequential(
    (0): Linear(in_features=1152, out_features=128, bias=True)
    (1): ReLU()
    (2): Linear(in_features=128, out_features=128, bias=True)
    (3): ReLU()
    (4): Linear(in_features=128, out_features=5, bias=True)
  )
)
WARNING: GIF is enabled but the environment does not support RGB array rendering.
INFO: Learning...
ERROR: No video mode has been set
ERROR: Traceback (most recent call last):
  File "/home/eirik/Projects/XAI/rl/src/dqn/wrapper/multi_agent_dqn.py", line 108, in learn
    self._collect_rollouts()
  File "/home/eirik/Projects/XAI/rl/src/dqn/wrapper/multi_agent_dqn.py", line 206, in _collect_rollouts
    ) = self.env.get_wrapper_attr("step_multiple")(actions)
        ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/eirik/Projects/XAI/environments/gymnasium/wrappers/multi_agent_env.py", line 44, in step_multiple
    ) = self.get_wrapper_attr("concatenate_states")(full_states)
        ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/eirik/Projects/XAI/environments/gymnasium/envs/tag/tag.py", line 284, in concatenate_states
    self.render()
  File "/home/eirik/Projects/XAI/environments/gymnasium/envs/tag/tag.py", line 258, in render
    return self.tag_renderer.render(self.state.full, render_mode)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/eirik/Projects/XAI/environments/gymnasium/envs/tag/tag_renderer.py", line 105, in render
    surf = self._apply_sprites(surf, state)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/eirik/Projects/XAI/environments/gymnasium/envs/tag/tag_renderer.py", line 126, in _apply_sprites
    self._seeker_sprite.convert_alpha(),
    ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
pygame.error: No video mode has been set

WARNING: Error: Could not find wandb directory: ./wandb
INFO: Number of parameters: 174309
INFO: QNetwork(
  (conv_feature): Sequential(
    (0): Conv2d(1, 32, kernel_size=(3, 3), stride=(1, 1))
    (1): ReLU()
    (2): Conv2d(32, 32, kernel_size=(3, 3), stride=(1, 1))
    (3): ReLU()
  )
  (fc_feature): Sequential(
    (0): Linear(in_features=1152, out_features=128, bias=True)
    (1): ReLU()
    (2): Linear(in_features=128, out_features=128, bias=True)
    (3): ReLU()
    (4): Linear(in_features=128, out_features=5, bias=True)
  )
)
WARNING: GIF is enabled but the environment does not support RGB array rendering.
INFO: Learning...
ERROR: No video mode has been set
ERROR: Traceback (most recent call last):
  File "/home/eirik/Projects/XAI/rl/src/dqn/wrapper/multi_agent_dqn.py", line 108, in learn
    self._collect_rollouts()
  File "/home/eirik/Projects/XAI/rl/src/dqn/wrapper/multi_agent_dqn.py", line 206, in _collect_rollouts
    ) = self.env.get_wrapper_attr("step_multiple")(actions)
        ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/eirik/Projects/XAI/environments/gymnasium/wrappers/multi_agent_env.py", line 44, in step_multiple
    ) = self.get_wrapper_attr("concatenate_states")(full_states)
        ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/eirik/Projects/XAI/environments/gymnasium/envs/tag/tag.py", line 284, in concatenate_states
    self.render()
  File "/home/eirik/Projects/XAI/environments/gymnasium/envs/tag/tag.py", line 258, in render
    return self.tag_renderer.render(self.state.full, render_mode)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/eirik/Projects/XAI/environments/gymnasium/envs/tag/tag_renderer.py", line 105, in render
    surf = self._apply_sprites(surf, state)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/eirik/Projects/XAI/environments/gymnasium/envs/tag/tag_renderer.py", line 130, in _apply_sprites
    self._seeker_sprite.convert_alpha(),
    ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
pygame.error: No video mode has been set

WARNING: Error: Could not find wandb directory: ./wandb
INFO: Number of parameters: 174309
INFO: QNetwork(
  (conv_feature): Sequential(
    (0): Conv2d(1, 32, kernel_size=(3, 3), stride=(1, 1))
    (1): ReLU()
    (2): Conv2d(32, 32, kernel_size=(3, 3), stride=(1, 1))
    (3): ReLU()
  )
  (fc_feature): Sequential(
    (0): Linear(in_features=1152, out_features=128, bias=True)
    (1): ReLU()
    (2): Linear(in_features=128, out_features=128, bias=True)
    (3): ReLU()
    (4): Linear(in_features=128, out_features=5, bias=True)
  )
)
WARNING: GIF is enabled but the environment does not support RGB array rendering.
INFO: Learning...
ERROR: No video mode has been set
ERROR: Traceback (most recent call last):
  File "/home/eirik/Projects/XAI/rl/src/dqn/wrapper/multi_agent_dqn.py", line 108, in learn
    self._collect_rollouts()
  File "/home/eirik/Projects/XAI/rl/src/dqn/wrapper/multi_agent_dqn.py", line 206, in _collect_rollouts
    ) = self.env.get_wrapper_attr("step_multiple")(actions)
        ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/eirik/Projects/XAI/environments/gymnasium/wrappers/multi_agent_env.py", line 44, in step_multiple
    ) = self.get_wrapper_attr("concatenate_states")(full_states)
        ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/eirik/Projects/XAI/environments/gymnasium/envs/tag/tag.py", line 284, in concatenate_states
    self.render()
  File "/home/eirik/Projects/XAI/environments/gymnasium/envs/tag/tag.py", line 258, in render
    return self.tag_renderer.render(self.state.full, render_mode)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/eirik/Projects/XAI/environments/gymnasium/envs/tag/tag_renderer.py", line 105, in render
    surf = self._apply_sprites(surf, state)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/eirik/Projects/XAI/environments/gymnasium/envs/tag/tag_renderer.py", line 127, in _apply_sprites
    self._seeker_sprite.convert_alpha(),
    ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
pygame.error: No video mode has been set

WARNING: Error: Could not find wandb directory: ./wandb
INFO: Number of parameters: 174309
INFO: QNetwork(
  (conv_feature): Sequential(
    (0): Conv2d(1, 32, kernel_size=(3, 3), stride=(1, 1))
    (1): ReLU()
    (2): Conv2d(32, 32, kernel_size=(3, 3), stride=(1, 1))
    (3): ReLU()
  )
  (fc_feature): Sequential(
    (0): Linear(in_features=1152, out_features=128, bias=True)
    (1): ReLU()
    (2): Linear(in_features=128, out_features=128, bias=True)
    (3): ReLU()
    (4): Linear(in_features=128, out_features=5, bias=True)
  )
)
WARNING: GIF is enabled but the environment does not support RGB array rendering.
INFO: Learning...
INFO: Number of parameters: 174309
INFO: QNetwork(
  (conv_feature): Sequential(
    (0): Conv2d(1, 32, kernel_size=(3, 3), stride=(1, 1))
    (1): ReLU()
    (2): Conv2d(32, 32, kernel_size=(3, 3), stride=(1, 1))
    (3): ReLU()
  )
  (fc_feature): Sequential(
    (0): Linear(in_features=1152, out_features=128, bias=True)
    (1): ReLU()
    (2): Linear(in_features=128, out_features=128, bias=True)
    (3): ReLU()
    (4): Linear(in_features=128, out_features=5, bias=True)
  )
)
WARNING: GIF is enabled but the environment does not support RGB array rendering.
INFO: Learning...
ERROR: No video mode has been set
ERROR: Traceback (most recent call last):
  File "/home/eirik/Projects/XAI/rl/src/dqn/wrapper/multi_agent_dqn.py", line 108, in learn
    self._collect_rollouts()
  File "/home/eirik/Projects/XAI/rl/src/dqn/wrapper/multi_agent_dqn.py", line 206, in _collect_rollouts
    ) = self.env.get_wrapper_attr("step_multiple")(actions)
        ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/eirik/Projects/XAI/environments/gymnasium/wrappers/multi_agent_env.py", line 44, in step_multiple
    ) = self.get_wrapper_attr("concatenate_states")(full_states)
        ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/eirik/Projects/XAI/environments/gymnasium/envs/tag/tag.py", line 284, in concatenate_states
    self.render()
  File "/home/eirik/Projects/XAI/environments/gymnasium/envs/tag/tag.py", line 258, in render
    return self.tag_renderer.render(self.state.full, render_mode)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/eirik/Projects/XAI/environments/gymnasium/envs/tag/tag_renderer.py", line 105, in render
    surf = self._apply_sprites(surf, state)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/eirik/Projects/XAI/environments/gymnasium/envs/tag/tag_renderer.py", line 126, in _apply_sprites
    self._seeker_sprite.convert_alpha(),
    ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
pygame.error: No video mode has been set

WARNING: Error: Could not find wandb directory: ./wandb
INFO: Number of parameters: 174309
INFO: QNetwork(
  (conv_feature): Sequential(
    (0): Conv2d(1, 32, kernel_size=(3, 3), stride=(1, 1))
    (1): ReLU()
    (2): Conv2d(32, 32, kernel_size=(3, 3), stride=(1, 1))
    (3): ReLU()
  )
  (fc_feature): Sequential(
    (0): Linear(in_features=1152, out_features=128, bias=True)
    (1): ReLU()
    (2): Linear(in_features=128, out_features=128, bias=True)
    (3): ReLU()
    (4): Linear(in_features=128, out_features=5, bias=True)
  )
)
WARNING: GIF is enabled but the environment does not support RGB array rendering.
INFO: Learning...
INFO: Number of parameters: 174309
INFO: QNetwork(
  (conv_feature): Sequential(
    (0): Conv2d(1, 32, kernel_size=(3, 3), stride=(1, 1))
    (1): ReLU()
    (2): Conv2d(32, 32, kernel_size=(3, 3), stride=(1, 1))
    (3): ReLU()
  )
  (fc_feature): Sequential(
    (0): Linear(in_features=1152, out_features=128, bias=True)
    (1): ReLU()
    (2): Linear(in_features=128, out_features=128, bias=True)
    (3): ReLU()
    (4): Linear(in_features=128, out_features=5, bias=True)
  )
)
WARNING: GIF is enabled but the environment does not support RGB array rendering.
INFO: Learning...
INFO: Number of parameters: 174309
INFO: QNetwork(
  (conv_feature): Sequential(
    (0): Conv2d(1, 32, kernel_size=(3, 3), stride=(1, 1))
    (1): ReLU()
    (2): Conv2d(32, 32, kernel_size=(3, 3), stride=(1, 1))
    (3): ReLU()
  )
  (fc_feature): Sequential(
    (0): Linear(in_features=1152, out_features=128, bias=True)
    (1): ReLU()
    (2): Linear(in_features=128, out_features=128, bias=True)
    (3): ReLU()
    (4): Linear(in_features=128, out_features=5, bias=True)
  )
)
WARNING: GIF is enabled but the environment does not support RGB array rendering.
INFO: Learning...
INFO: Number of parameters: 174309
INFO: QNetwork(
  (conv_feature): Sequential(
    (0): Conv2d(1, 32, kernel_size=(3, 3), stride=(1, 1))
    (1): ReLU()
    (2): Conv2d(32, 32, kernel_size=(3, 3), stride=(1, 1))
    (3): ReLU()
  )
  (fc_feature): Sequential(
    (0): Linear(in_features=1152, out_features=128, bias=True)
    (1): ReLU()
    (2): Linear(in_features=128, out_features=128, bias=True)
    (3): ReLU()
    (4): Linear(in_features=128, out_features=5, bias=True)
  )
)
WARNING: GIF is enabled but the environment does not support RGB array rendering.
INFO: Learning...
INFO: Number of parameters: 174309
INFO: QNetwork(
  (conv_feature): Sequential(
    (0): Conv2d(1, 32, kernel_size=(3, 3), stride=(1, 1))
    (1): ReLU()
    (2): Conv2d(32, 32, kernel_size=(3, 3), stride=(1, 1))
    (3): ReLU()
  )
  (fc_feature): Sequential(
    (0): Linear(in_features=1152, out_features=128, bias=True)
    (1): ReLU()
    (2): Linear(in_features=128, out_features=128, bias=True)
    (3): ReLU()
    (4): Linear(in_features=128, out_features=5, bias=True)
  )
)
WARNING: GIF is enabled but the environment does not support RGB array rendering.
INFO: Learning...
ERROR: 'TagRenderer' object has no attribute '_seeker_action'
ERROR: Traceback (most recent call last):
  File "/home/eirik/Projects/XAI/rl/src/dqn/wrapper/multi_agent_dqn.py", line 108, in learn
    self._collect_rollouts()
  File "/home/eirik/Projects/XAI/rl/src/dqn/wrapper/multi_agent_dqn.py", line 206, in _collect_rollouts
    ) = self.env.get_wrapper_attr("step_multiple")(actions)
        ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/eirik/Projects/XAI/environments/gymnasium/wrappers/multi_agent_env.py", line 44, in step_multiple
    ) = self.get_wrapper_attr("concatenate_states")(full_states)
        ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/eirik/Projects/XAI/environments/gymnasium/envs/tag/tag.py", line 293, in concatenate_states
    self.render()
  File "/home/eirik/Projects/XAI/environments/gymnasium/envs/tag/tag.py", line 267, in render
    return self.tag_renderer.render(self.state.full, render_mode)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/eirik/Projects/XAI/environments/gymnasium/envs/tag/tag_renderer.py", line 106, in render
    surf = self._apply_sprites(surf, state)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/eirik/Projects/XAI/environments/gymnasium/envs/tag/tag_renderer.py", line 126, in _apply_sprites
    sprite = self._transform_sprite(self._seeker_sprite, self._seeker_action)
                                                         ^^^^^^^^^^^^^^^^^^^
AttributeError: 'TagRenderer' object has no attribute '_seeker_action'

WARNING: Error: Could not find wandb directory: ./wandb
INFO: Number of parameters: 174309
INFO: QNetwork(
  (conv_feature): Sequential(
    (0): Conv2d(1, 32, kernel_size=(3, 3), stride=(1, 1))
    (1): ReLU()
    (2): Conv2d(32, 32, kernel_size=(3, 3), stride=(1, 1))
    (3): ReLU()
  )
  (fc_feature): Sequential(
    (0): Linear(in_features=1152, out_features=128, bias=True)
    (1): ReLU()
    (2): Linear(in_features=128, out_features=128, bias=True)
    (3): ReLU()
    (4): Linear(in_features=128, out_features=5, bias=True)
  )
)
WARNING: GIF is enabled but the environment does not support RGB array rendering.
INFO: Learning...
INFO: Number of parameters: 174309
INFO: QNetwork(
  (conv_feature): Sequential(
    (0): Conv2d(1, 32, kernel_size=(3, 3), stride=(1, 1))
    (1): ReLU()
    (2): Conv2d(32, 32, kernel_size=(3, 3), stride=(1, 1))
    (3): ReLU()
  )
  (fc_feature): Sequential(
    (0): Linear(in_features=1152, out_features=128, bias=True)
    (1): ReLU()
    (2): Linear(in_features=128, out_features=128, bias=True)
    (3): ReLU()
    (4): Linear(in_features=128, out_features=5, bias=True)
  )
)
WARNING: GIF is enabled but the environment does not support RGB array rendering.
INFO: Learning...
INFO: Number of parameters: 174309
INFO: QNetwork(
  (conv_feature): Sequential(
    (0): Conv2d(1, 32, kernel_size=(3, 3), stride=(1, 1))
    (1): ReLU()
    (2): Conv2d(32, 32, kernel_size=(3, 3), stride=(1, 1))
    (3): ReLU()
  )
  (fc_feature): Sequential(
    (0): Linear(in_features=1152, out_features=128, bias=True)
    (1): ReLU()
    (2): Linear(in_features=128, out_features=128, bias=True)
    (3): ReLU()
    (4): Linear(in_features=128, out_features=5, bias=True)
  )
)
WARNING: GIF is enabled but the environment does not support RGB array rendering.
INFO: Learning...
INFO: Number of parameters: 174309
INFO: QNetwork(
  (conv_feature): Sequential(
    (0): Conv2d(1, 32, kernel_size=(3, 3), stride=(1, 1))
    (1): ReLU()
    (2): Conv2d(32, 32, kernel_size=(3, 3), stride=(1, 1))
    (3): ReLU()
  )
  (fc_feature): Sequential(
    (0): Linear(in_features=1152, out_features=128, bias=True)
    (1): ReLU()
    (2): Linear(in_features=128, out_features=128, bias=True)
    (3): ReLU()
    (4): Linear(in_features=128, out_features=5, bias=True)
  )
)
WARNING: GIF is enabled but the environment does not support RGB array rendering.
INFO: Learning...
